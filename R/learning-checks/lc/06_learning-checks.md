**`r paste0("(LC", chap, ".", (lc <- lc + 1), ")")`** What is the goal of including an interaction term in a multiple regression model? - A. To create more variables for analysis. - B. To account for the effect of one explanatory variable on the response while considering the influence of another explanatory variable. - C. To make the model more complex without any real benefit. - D. To automatically improve the fit of the regression line.

**Solution**:


**`r paste0("(LC", chap, ".", (lc <- lc + 1), ")")`** How does the inclusion of both main effects and interaction terms in a regression model affect the interpretation of individual coefficients? - A. They represent simple marginal effects. - B. They become meaningless. - C. They are conditional effects, depending on the level of the interacting variables. - D. They are interpreted in the same way as in models without interactions.

**Solution**:


**`r paste0("(LC", chap, ".", (lc <- lc + 1), ")")`** Which statement about the use of dummy variables in regression models is correct? - A. Dummy variables are used to represent numerical variables. - B. Dummy variables are used to represent categorical variables at least two levels. - C. Dummy variables always decrease the R-squared value. - D. Dummy variables are unnecessary in regression models.

**Solution**:


**`r paste0("(LC", chap, ".", (lc <- lc + 1), ")")`** How should a model with one categorical regressor and one numerical regressor, but no interactions, be interpreted? - A. The slope of the model for each category is different. - B. The slope of the model for each category is the same. - C. There is no relationship between the categorical regressor and the response. - D. There is no relationship between the numerical regressor and the response.

**Solution**:


**`r paste0("(LC", chap, ".", (lc <- lc + 1), ")")`** Compute the observed response values, fitted values, and residuals for the model without interactions.

**Solution**:


**`r paste0("(LC", chap, ".", (lc <- lc + 1), ")")`** What is the main benefit of visualizing the fitted values and residuals of a multiple regression model? - A. To find errors in the dataset. - B. To check the assumptions of the regression model, such as linearity and homoscedasticity. - C. To always improve the model's accuracy. - D. To increase the complexity of the model.

**Solution**:


**`r paste0("(LC", chap, ".", (lc <- lc + 1), ")")`** Conduct a new exploratory data analysis with the same outcome variable $y$ `debt` but with `credit_rating` and `age` as the new explanatory variables $x_1$ and $x_2$. What can you say about the relationship between a credit card holder's debt and their credit rating and age?

**Solution**:


**`r paste0("(LC", chap, ".", (lc <- lc + 1), ")")`** Fit a new simple linear regression using `lm(debt ~ credit_rating + age, data = credit_ch6)` where `credit_rating` and `age` are the new numerical explanatory variables $x_1$ and $x_2$. Get information about the "best-fitting" regression plane from the regression table by finding the coefficient of the model. How do the regression results match up with the results from your previous exploratory data analysis?

**Solution**:


**`r paste0("(LC", chap, ".", (lc <- lc + 1), ")")`** Which of the following statements best describes the interpretation of a regression coefficient in a multiple regression model? - A. It is the additional effect of a regressor on the response when other regressors have already been taken into account. - B. It is the average response variable value when all explanatory variables are zero. - C. It is always positive if the correlation is strong. - D. It cannot be interpreted if there are more than two explanatory variables.

**Solution**:


**`r paste0("(LC", chap, ".", (lc <- lc + 1), ")")`** What is a characteristic of the "best-fitting" plane in a multiple regression model with two numerical explanatory variables? - A. It represents the line of best fit for each explanatory variable separately. - B. It minimizes the product of residuals. - C. It minimizes the sum of squared residuals for all combinations of regressors. - D. It shows the exact predictions for every data point.

**Solution**:


**`r paste0("(LC", chap, ".", (lc <- lc + 1), ")")`** What does the intercept represent in a multiple regression model with two explanatory variables? - A. The effect of one explanatory variable, keeping the other constant. - B. The change in the response variable per unit change in the explanatory variable. - C. The correlation between the two explanatory variables. - D. The expected value of the response variable when all regressors are zero.

**Solution**:


**`r paste0("(LC", chap, ".", (lc <- lc + 1), ")")`** What does the term "partial slope" refer to in a multiple regression model? - A. The additional effect of a regressor on the response variable, when all the other regressors have been taken into account. - B. The total slope of all variables combined. - C. The slope when all variables are zero. - D. The average of all slopes in the model.

**Solution**:


