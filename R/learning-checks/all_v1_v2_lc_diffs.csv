chapter_num,status_simple,v2_lc,v2_idx,v2_text,v1_lc,v1_idx,v1_text,dist
01,edited,1,1,"Repeat the earlier installation steps, but for the `dplyr`, `nycflights23`, and `knitr` packages. This will install the earlier mentioned `dplyr` package for data wrangling, the `nycflights23` package containing data on all domestic flights leaving a New York City airport in 2023, and the `knitr` package for generating easy-to-read tables in R. We'll use these packages in the next section.",1,1,"Repeat the earlier installation steps, but for the `dplyr`, `nycflights13`, and `knitr` packages. This will install the earlier mentioned `dplyr` package for data wrangling, the `nycflights13` package containing data on all domestic flights leaving a NYC airport in 2013, and the `knitr` package for generating easy-to-read tables in R. We'll use these packages in the next section.",0.018829612277718843
01,unchanged,2,6,"""Load"" the `dplyr`, `nycflights23`, and `knitr` packages as well by repeating the earlier steps.",2,6,"""Load"" the `dplyr`, `nycflights13`, and `knitr` packages as well by repeating the earlier steps.",0
01,unchanged,3,11,What does any *ONE* row in this `flights` dataset refer to? - A. Data on an airline - B. Data on a flight - C. Data on an airport - D. Data on multiple flights,3,11,What does any *ONE* row in this `flights` dataset refer to? - A. Data on an airline - B. Data on a flight - C. Data on an airport - D. Data on multiple flights,0
01,unchanged,4,16,What are some other examples in this dataset of *categorical* variables? What makes them different than *quantitative* variables?,4,16,What are some other examples in this dataset of *categorical* variables? What makes them different than *quantitative* variables?,0
01,unchanged,5,21,"What properties of each airport do the variables `lat`, `lon`, `alt`, `tz`, `dst`, and `tzone` describe in the `airports` data frame? Take your best guess.",5,21,"What properties of each airport do the variables `lat`, `lon`, `alt`, `tz`, `dst`, and `tzone` describe in the `airports` data frame? Take your best guess.",0
01,edited,6,26,Provide the names of variables in a data frame with at least three variables where one of them is an identification variable and the other two are not.,6,26,"Provide the names of variables in a data frame with at least three variables where one of them is an identification variable and the other two are not. Further, create your own tidy data frame that matches these conditions.",0.10515986937005162
01,unchanged,7,31,"Look at the help file for the `airports` data frame. Revise your earlier guesses about what the variables `lat`, `lon`, `alt`, `tz`, `dst`, and `tzone` each describe.",7,31,"Look at the help file for the `airports` data frame. Revise your earlier guesses about what the variables `lat`, `lon`, `alt`, `tz`, `dst`, and `tzone` each describe.",0
02,unchanged,1,1,"Take a look at both the `flights` data frame from the `nycflights23` package and the `envoy_flights` data frame from the `moderndive` package by running `View(flights)` and `View(envoy_flights)`. In what respect do these data frames differ? For example, think about the number of rows in each dataset.",1,1,"Take a look at both the `flights` data frame from the `nycflights13` package and the `alaska_flights` data frame from the `moderndive` package by running `View(flights)` and `View(alaska_flights)`. In what respect do these data frames differ? For example, think about the number of rows in each dataset.",0
02,edited,2,6,What are practical reasons why `dep_delay` and `arr_delay` have a positive relationship?,2,6,What are some practical reasons why `dep_delay` and `arr_delay` have a positive relationship?,0.037466578120378125
02,unchanged,3,11,"What variables in the `weather` data frame would you expect to have a negative correlation (i.e., a negative relationship) with `dep_delay`? Why? Remember that we are focusing on numerical variables here. Hint: Explore the `weather` dataset by using the `View()` function.",3,11,"What variables in the `weather` data frame would you expect to have a negative correlation (i.e., a negative relationship) with `dep_delay`? Why? Remember that we are focusing on numerical variables here. Hint: Explore the `weather` dataset by using the `View()` function.",0
02,edited,4,16,"Why do you believe there is a cluster of points near (0, 0)? What does (0, 0) correspond to in terms of the Envoy Air flights?",4,16,"Why do you believe there is a cluster of points near (0, 0)? What does (0, 0) correspond to in terms of the Alaska Air flights?",0.04154756925488068
02,unchanged,5,21,What are some other features of the plot that stand out to you?,5,21,What are some other features of the plot that stand out to you?,0
02,unchanged,6,26,Create a new scatterplot using different variables in the `envoy_flights` data frame by modifying the example given.,6,26,Create a new scatterplot using different variables in the `alaska_flights` data frame by modifying the example given.,0
02,unchanged,7,31,Why is setting the `alpha` argument value useful with scatterplots? What further information does it give you that a regular scatterplot cannot?,7,31,Why is setting the `alpha` argument value useful with scatterplots? What further information does it give you that a regular scatterplot cannot?,0
02,unchanged,8,36,"After viewing Figure \@ref(fig:alpha), give an approximate range of arrival delays and departure delays that occur most frequently. How has that region changed compared to when you observed the same plot without `alpha = 0.2` set in Figure \@ref(fig:noalpha)?",8,36,"After viewing Figure \@ref(fig:alpha), give an approximate range of arrival delays and departure delays that occur most frequently. How has that region changed compared to when you observed the same plot without `alpha = 0.2` set in Figure \@ref(fig:noalpha)?",0
02,unchanged,9,41,Take a look at both the `weather` data frame from the `nycflights23` package and the `early_january_2023_weather` data frame from the `moderndive` package by running `View(weather)` and `View(early_january_2023_weather)`. In what respect do these data frames differ?,9,41,Take a look at both the `weather` data frame from the `nycflights13` package and the `early_january_weather` data frame from the `moderndive` package by running `View(weather)` and `View(early_january_weather)`. In what respect do these data frames differ?,0
02,unchanged,10,46,"`View()` the `flights` data frame again. Why does the `time_hour` variable uniquely identify the hour of the measurement, whereas the `hour` variable does not?",10,46,"`View()` the `flights` data frame again. Why does the `time_hour` variable uniquely identify the hour of the measurement, whereas the `hour` variable does not?",0
02,unchanged,11,51,Why should linegraphs be avoided when there is not a clear ordering of the horizontal axis?,11,51,Why should linegraphs be avoided when there is not a clear ordering of the horizontal axis?,0
02,unchanged,12,56,Why are linegraphs frequently used when time is the explanatory variable on the x-axis?,12,56,Why are linegraphs frequently used when time is the explanatory variable on the x-axis?,0
02,edited,13,61,Plot a time series of a variable other than `wind_speed` for Newark Airport in the first 15 days of January 2023. Try to select a variable that doesn't have a lot of missing (`NA`) values.,13,61,Plot a time series of a variable other than `temp` for Newark Airport in the first 15 days of January 2013.,0.1768624645947171
02,edited,14,66,What does changing the number of bins from 30 to 20 tell us about the distribution of wind speeds?,14,66,What does changing the number of bins from 30 to 40 tell us about the distribution of temperatures?,0.11320364965213614
02,edited,15,71,Would you classify the distribution of wind speeds as symmetric or skewed in one direction or another?,15,71,Would you classify the distribution of temperatures as symmetric or skewed in one direction or another?,0.13367745247589136
02,unchanged,16,76,"What would you guess is the ""center"" value in this distribution? Why did you make that choice?",16,76,"What would you guess is the ""center"" value in this distribution? Why did you make that choice?",0
02,unchanged,17,81,Is this data spread out greatly from the center or is it close? Why?,17,81,Is this data spread out greatly from the center or is it close? Why?,0
02,unchanged,18,86,What other things do you notice about this faceted plot? How does a faceted plot help us see relationships between two variables?,18,86,What other things do you notice about this faceted plot? How does a faceted plot help us see relationships between two variables?,0
02,edited,19,91,"What do the numbers 1-12 correspond to in the plot? What about 10, 20, and 30?",19,91,"What do the numbers 1-12 correspond to in the plot? What about 25, 50, 75, 100?",0.003541087607597637
02,unchanged,20,96,For which types of datasets would faceted plots not work well in comparing relationships between variables? Give an example describing the nature of these variables and other important characteristics.,20,96,For which types of datasets would faceted plots not work well in comparing relationships between variables? Give an example describing the nature of these variables and other important characteristics.,0
02,unchanged,21,101,Does the `wind_speed` variable in the `weather` dataset have a lot of variability? Why do you say that?,21,101,Does the `temp` variable in the `weather` dataset have a lot of variability? Why do you say that?,0
02,edited,22,106,What do the dots at the top of the plot for January correspond to? Explain what might have occurred in January to produce these points.,22,106,What does the dot at the bottom of the plot for May correspond to? Explain what might have occurred in May to produce this point.,0.2858088732578362
02,edited,23,111,Which months seem to have the highest variability in wind speed? What reasons can you give for this?,23,111,Which months have the highest variability in temperature? What reasons can you give for this?,0.2130534803658658
02,unchanged,24,116,We looked at the distribution of the numerical variable `wind_speed` split by the numerical variable `month` that we converted using the `factor()` function in order to make a side-by-side boxplot. Why would a boxplot of `wind_speed` split by the numerical variable `pressure` similarly converted to a categorical variable using the `factor()` not be informative?,24,116,We looked at the distribution of the numerical variable `temp` split by the numerical variable `month` that we converted using the `factor()` function in order to make a side-by-side boxplot. Why would a boxplot of `temp` split by the numerical variable `pressure` similarly converted to a categorical variable using the `factor()` not be informative?,0
02,unchanged,25,121,Boxplots provide a simple way to identify outliers. Why may outliers be easier to identify when looking at a boxplot instead of a faceted histogram?,25,121,Boxplots provide a simple way to identify outliers. Why may outliers be easier to identify when looking at a boxplot instead of a faceted histogram?,0
02,unchanged,26,126,Why are histograms inappropriate for categorical variables?,26,126,Why are histograms inappropriate for categorical variables?,0
02,unchanged,27,131,What is the difference between histograms and barplots?,27,131,What is the difference between histograms and barplots?,0
02,edited,28,136,How many Alaska Air flights departed NYC in 2023?,28,136,How many Envoy Air flights departed NYC in 2013?,0.14601350754656006
02,edited,29,141,"What was the 7th highest airline for departed flights from NYC in 2023? How could we better present the table to get this answer quickly? ### Must avoid pie charts! One of the most common plots used to visualize the distribution of categorical data is the \index{pie charts} pie chart. While they may seem harmless enough, pie charts actually present a problem in that humans are unable to judge angles well. As Naomi Robbins describes in her book, *Creating More Effective Graphs* [@robbins2013], we overestimate angles greater than 90 degrees and we underestimate angles less than 90 degrees. In other words, it is difficult for us to determine the relative size of one piece of the pie compared to another. Let's examine the same data used in our previous barplot of the number of flights departing NYC by airline in Figure \@ref(fig:flightsbar), but this time we will use a pie chart in Figure \@ref(fig:carrierpie). Try to answer the following questions: * How much smaller is the portion of the pie for Hawaiian Airlines Inc. (`HA`) compared to United Airlines (`UA`)? * What is the third largest carrier in terms of departing flights? * How many carriers have fewer flights than Delta Air Lines Inc. (`DL`)? if (is_html_output()) { ggplot(flights, mapping = aes(x = factor(1), fill = carrier)) + geom_bar(width = 1) + coord_polar(theta = ""y"") + theme( axis.title.x = element_blank(), axis.title.y = element_blank(), axis.ticks = element_blank(), axis.text.y = element_blank(), axis.text.x = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank() ) + guides(fill = guide_legend(keywidth = 0.8, keyheight = 0.8)) } else { ggplot(flights, mapping = aes(x = factor(1), fill = carrier)) + geom_bar(width = 1) + coord_polar(theta = ""y"") + theme_light() + theme( axis.title.x = element_blank(), axis.title.y = element_blank(), axis.ticks = element_blank(), axis.text.y = element_blank(), axis.text.x = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank() ) + guides(fill = guide_legend(keywidth = 0.8, keyheight = 0.8)) + scale_fill_grey() } While it is quite difficult to answer these questions when looking at the pie chart in Figure \@ref(fig:carrierpie), we can much more easily answer these questions using the barchart in Figure \@ref(fig:flightsbar). This is true since barplots present the information in a way such that comparisons between categories can be made with single horizontal lines, whereas pie charts present the information in a way such that comparisons must be made by \index{pie charts!problems with} comparing angles.",29,141,"What was the 7th highest airline for departed flights from NYC in 2013? How could we better present the table to get this answer quickly? ### Must avoid pie charts! One of the most common plots used to visualize the distribution of categorical data is the \index{pie charts} pie chart. While they may seem harmless enough, pie charts actually present a problem in that humans are unable to judge angles well. As Naomi Robbins describes in her book, *Creating More Effective Graphs* [@robbins2013], we overestimate angles greater than 90 degrees and we underestimate angles less than 90 degrees. In other words, it is difficult for us to determine the relative size of one piece of the pie compared to another. Let's examine the same data used in our previous barplot of the number of flights departing NYC by airline in Figure \@ref(fig:flightsbar), but this time we will use a pie chart in Figure \@ref(fig:carrierpie). Try to answer the following questions: * How much larger is the portion of the pie for ExpressJet Airlines (`EV`) compared to US Airways (`US`)? * What is the third largest carrier in terms of departing flights? * How many carriers have fewer flights than United Airlines (`UA`)? if (is_html_output()) { ggplot(flights, mapping = aes(x = factor(1), fill = carrier)) + geom_bar(width = 1) + coord_polar(theta = ""y"") + theme( axis.title.x = element_blank(), axis.title.y = element_blank(), axis.ticks = element_blank(), axis.text.y = element_blank(), axis.text.x = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank() ) + guides(fill = guide_legend(keywidth = 0.8, keyheight = 0.8)) } else { ggplot(flights, mapping = aes(x = factor(1), fill = carrier)) + geom_bar(width = 1) + coord_polar(theta = ""y"") + theme_light() + theme( axis.title.x = element_blank(), axis.title.y = element_blank(), axis.ticks = element_blank(), axis.text.y = element_blank(), axis.text.x = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank() ) + guides(fill = guide_legend(keywidth = 0.8, keyheight = 0.8)) + scale_fill_grey() } While it is quite difficult to answer these questions when looking at the pie chart in Figure \@ref(fig:carrierpie), we can much more easily answer these questions using the barchart in Figure \@ref(fig:flightsbar). This is true since barplots present the information in a way such that comparisons between categories can be made with single horizontal lines, whereas pie charts present the information in a way such that comparisons must be made by \index{pie charts!problems with} comparing angles.",0.0025768361436292464
02,unchanged,30,146,Why should pie charts be avoided and replaced by barplots?,30,146,Why should pie charts be avoided and replaced by barplots?,0
02,unchanged,31,151,Why do you think people continue to use pie charts?,31,151,Why do you think people continue to use pie charts?,0
02,unchanged,32,156,What kinds of questions are not easily answered by looking at Figure \@ref(fig:flights-stacked-bar)?,32,156,What kinds of questions are not easily answered by looking at Figure \@ref(fig:flights-stacked-bar)?,0
02,edited,33,161,"What can you say, if anything, about the relationship between airline and airport in NYC in 2023 in regard to the number of departing flights?",33,161,"What can you say, if anything, about the relationship between airline and airport in NYC in 2013 in regards to the number of departing flights?",0.020400003297986635
02,unchanged,34,166,Why might the side-by-side barplot be preferable to a stacked barplot in this case?,34,166,Why might the side-by-side barplot be preferable to a stacked barplot in this case?,0
02,unchanged,35,171,"What are the disadvantages of using a dodged barplot, in general?",35,171,"What are the disadvantages of using a dodged barplot, in general?",0
02,unchanged,36,176,Why is the faceted barplot preferred to the side-by-side and stacked barplots in this case?,36,176,Why is the faceted barplot preferred to the side-by-side and stacked barplots in this case?,0
02,unchanged,37,181,What information about the different carriers at different airports is more easily seen in the faceted barplot?,37,181,What information about the different carriers at different airports is more easily seen in the faceted barplot?,0
03,unchanged,1,1,"What's another way of using the ""not"" operator `!` to filter only the rows that are not going to Burlington, VT nor Seattle, WA in the `flights` data frame? Test this out using the previous code.",1,1,"What's another way of using the ""not"" operator `!` to filter only the rows that are not going to Burlington, VT nor Seattle, WA in the `flights` data frame? Test this out using the previous code.",0
03,unchanged,2,6,"Say a doctor is studying the effect of smoking on lung cancer for a large number of patients who have records measured at five-year intervals. She notices that a large number of patients have missing data points because the patient has died, so she chooses to ignore these patients in her analysis. What is wrong with this doctor's approach?",2,6,"Say a doctor is studying the effect of smoking on lung cancer for a large number of patients who have records measured at five-year intervals. She notices that a large number of patients have missing data points because the patient has died, so she chooses to ignore these patients in her analysis. What is wrong with this doctor's approach?",0
03,unchanged,3,11,"Modify the earlier `summarize()` function code that creates the `summary_windspeed` data frame to also use the `n()` summary function: `summarize(... , count = n())`. What does the returned value correspond to?",3,11,"Modify the earlier `summarize()` function code that creates the `summary_temp` data frame to also use the `n()` summary function: `summarize(... , count = n())`. What does the returned value correspond to?",0
03,edited,4,16,"Why doesn't the following code work? Run the code line-by-line instead of all at once, and then look at the data. In other words, select and then run `summary_windspeed <- weather |> summarize(mean = mean(wind_speed, na.rm = TRUE))` first. summary_windspeed <- weather |> summarize(mean = mean(wind_speed, na.rm = TRUE)) |> summarize(std_dev = sd(wind_speed, na.rm = TRUE))",4,16,"Why doesn't the following code work? Run the code line-by-line instead of all at once, and then look at the data. In other words, run `summary_temp <- weather %>% summarize(mean = mean(temp, na.rm = TRUE))` first. summary_temp <- weather %>% summarize(mean = mean(temp, na.rm = TRUE)) %>% summarize(std_dev = sd(temp, na.rm = TRUE))",0.19277745600152563
03,edited,5,21,Recall from Chapter \@ref(viz) when we looked at wind speeds by months in NYC. What does the standard deviation column in the `summary_monthly_temp` data frame tell us about temperatures in NYC throughout the year?,5,21,Recall from Chapter \@ref(viz) when we looked at temperatures by months in NYC. What does the standard deviation column in the `summary_monthly_temp` data frame tell us about temperatures in NYC throughout the year?,0.05896765564112061
03,edited,6,26,What code would be required to get the mean and standard deviation wind speed for each day in 2023 for NYC?,6,26,What code would be required to get the mean and standard deviation temperature for each day in 2013 for NYC?,0.14618423065098163
03,unchanged,7,31,"Recreate `by_monthly_origin`, but instead of grouping via `group_by(origin, month)`, group variables in a different order `group_by(month, origin)`. What differs in the resulting dataset?",7,31,"Recreate `by_monthly_origin`, but instead of grouping via `group_by(origin, month)`, group variables in a different order `group_by(month, origin)`. What differs in the resulting dataset?",0
03,unchanged,8,36,How could we identify how many flights left each of the three airports for each `carrier`?,8,36,How could we identify how many flights left each of the three airports for each `carrier`?,0
03,unchanged,9,41,How does the `filter()` operation differ from a `group_by()` followed by a `summarize()`?,9,41,How does the `filter()` operation differ from a `group_by()` followed by a `summarize()`?,0
03,unchanged,10,46,What do positive values of the `gain` variable in `flights` correspond to? What about negative values? And what about a zero value?,10,46,What do positive values of the `gain` variable in `flights` correspond to? What about negative values? And what about a zero value?,0
03,unchanged,11,51,Could we create the `dep_delay` and `arr_delay` columns by simply subtracting `dep_time` from `sched_dep_time` and similarly for arrivals? Try the code out and explain any differences between the result and what actually appears in `flights`.,11,51,Could we create the `dep_delay` and `arr_delay` columns by simply subtracting `dep_time` from `sched_dep_time` and similarly for arrivals? Try the code out and explain any differences between the result and what actually appears in `flights`.,0
03,unchanged,12,56,What can we say about the distribution of `gain`? Describe it in a few sentences using the plot and the `gain_summary` data frame values.,12,56,What can we say about the distribution of `gain`? Describe it in a few sentences using the plot and the `gain_summary` data frame values.,0
03,unchanged,13,61,"Looking at Figure \@ref(fig:reldiagram), when joining `flights` and `weather` (or, in other words, matching the hourly weather values with each flight), why do we need to join by all of `year`, `month`, `day`, `hour`, and `origin`, and not just `hour`?",13,61,"Looking at Figure \@ref(fig:reldiagram), when joining `flights` and `weather` (or, in other words, matching the hourly weather values with each flight), why do we need to join by all of `year`, `month`, `day`, `hour`, and `origin`, and not just `hour`?",0
03,unchanged,14,66,What surprises you about the top 10 destinations from NYC in 2023?,14,66,What surprises you about the top 10 destinations from NYC in 2013?,0
03,unchanged,15,71,What are some advantages of data in normal forms? What are some disadvantages?,15,71,What are some advantages of data in normal forms? What are some disadvantages?,0
03,unchanged,16,76,"What are some ways to select all three of the `dest`, `air_time`, and `distance` variables from `flights`? Give the code showing how to do this in at least three different ways.",16,76,"What are some ways to select all three of the `dest`, `air_time`, and `distance` variables from `flights`? Give the code showing how to do this in at least three different ways.",0
03,unchanged,17,81,"How could one use `starts_with()`, `ends_with()`, and `contains()` to select columns from the `flights` data frame? Provide three different examples in total: one for `starts_with()`, one for `ends_with()`, and one for `contains()`.",17,81,"How could one use `starts_with()`, `ends_with()`, and `contains()` to select columns from the `flights` data frame? Provide three different examples in total: one for `starts_with()`, one for `ends_with()`, and one for `contains()`.",0
03,unchanged,18,86,Why might we want to use the `select()` function on a data frame?,18,86,Why might we want to use the `select` function on a data frame?,0
03,unchanged,19,91,Create a new data frame that shows the top 5 airports with the largest arrival delays from NYC in 2023.,19,91,Create a new data frame that shows the top 5 airports with the largest arrival delays from NYC in 2013.,0
03,edited,20,96,"Let's now put your newly acquired data-wrangling skills to the test! An airline industry measure of a passenger airline's capacity is the [available seat miles](https://en.wikipedia.org/wiki/Available_seat_miles), which is equal to the number of seats available multiplied by the number of miles or kilometers flown summed over all flights. For example, let's consider the scenario in Figure \@ref(fig:available-seat-miles). Since the airplane has 4 seats and it travels 200 miles, the available seat miles are $4 \times 200 = 800$. include_graphics(""images/flowcharts/flowchart/flowchart.012.png"") Extending this idea, let's say an airline had 2 flights using a plane with 10 seats that flew 500 miles and 3 flights using a plane with 20 seats that flew 1000 miles, the available seat miles would be $2 \times 10 \times 500 + 3 \times 20 \times 1000 = 70,000$ seat miles. Using the datasets included in the `nycflights23` package, compute the available seat miles for each airline sorted in descending order. After completing all the necessary data-wrangling steps, the resulting data frame should have `r nrow(nycflights23::airlines)` rows (one for each airline) and 2 columns (airline name and available seat miles). Here are some hints: 1. **Crucial**: Unless you are very confident in what you are doing, it is worthwhile not starting to code right away. Rather, first sketch out on paper all the necessary data wrangling steps not using exact code, but rather high-level *pseudocode* that is informal yet detailed enough to articulate what you are doing. This way you won't confuse *what* you are trying to do (the algorithm) with *how* you are going to do it (writing `dplyr` code). 1. Take a close look at all the datasets using the `View()` function: `flights`, `weather`, `planes`, `airports`, and `airlines` to identify which variables are necessary to compute available seat miles. 1. Figure \@ref(fig:reldiagram) showing how the various datasets can be joined will also be useful. 1. Consider the data-wrangling verbs in Table \@ref(tab:wrangle-summary-table) as your toolbox!",20,96,"Let's now put your newly acquired data wrangling skills to the test! An airline industry measure of a passenger airline's capacity is the [available seat miles](https://en.wikipedia.org/wiki/Available_seat_miles), which is equal to the number of seats available multiplied by the number of miles or kilometers flown summed over all flights. For example, let's consider the scenario in Figure \@ref(fig:available-seat-miles). Since the airplane has 4 seats and it travels 200 miles, the available seat miles are $4 \times 200 = 800$. include_graphics(""images/flowcharts/flowchart/flowchart.012.png"") Extending this idea, let's say an airline had 2 flights using a plane with 10 seats that flew 500 miles and 3 flights using a plane with 20 seats that flew 1000 miles, the available seat miles would be $2 \times 10 \times 500 + 3 \times 20 \times 1000 = 70,000$ seat miles. Using the datasets included in the `nycflights13` package, compute the available seat miles for each airline sorted in descending order. After completing all the necessary data wrangling steps, the resulting data frame should have 16 rows (one for each airline) and 2 columns (airline name and available seat miles). Here are some hints: 1. **Crucial**: Unless you are very confident in what you are doing, it is worthwhile not starting to code right away. Rather, first sketch out on paper all the necessary data wrangling steps not using exact code, but rather high-level *pseudocode* that is informal yet detailed enough to articulate what you are doing. This way you won't confuse *what* you are trying to do (the algorithm) with *how* you are going to do it (writing `dplyr` code). 1. Take a close look at all the datasets using the `View()` function: `flights`, `weather`, `planes`, `airports`, and `airlines` to identify which variables are necessary to compute available seat miles. 1. Figure \@ref(fig:reldiagram) showing how the various datasets can be joined will also be useful. 1. Consider the data wrangling verbs in Table \@ref(tab:wrangle-summary-table) as your toolbox!",2.763689575612238e-4
04,unchanged,1,1,"What are common characteristics of ""tidy"" data frames?",1,1,"What are common characteristics of ""tidy"" data frames?",0
04,unchanged,2,6,"What makes ""tidy"" data frames useful for organizing data?",2,6,"What makes ""tidy"" data frames useful for organizing data?",0
04,edited,3,11,"Take a look at the `airline_safety` data frame included in the `fivethirtyeight` data package. Run the following: airline_safety After reading the help file by running `?airline_safety`, we see that `airline_safety` is a data frame containing information on different airline companies' safety records. This data was originally reported on the data journalism website, FiveThirtyEight.com, in Nate Silver's article, [""Should Travelers Avoid Flying Airlines That Have Had Crashes in the Past?""](https://fivethirtyeight.com/features/should-travelers-avoid-flying-airlines-that-have-had-crashes-in-the-past/). Let's only consider the variables `airline` and those relating to fatalities for simplicity: airline_safety_smaller <- airline_safety |> select(airline, starts_with(""fatalities"")) airline_safety_smaller This data frame is not in ""tidy"" format. How would you convert this data frame to be in ""tidy"" format, in particular so that it has a variable `fatalities_years` indicating the incident year and a variable `count` of the fatality counts?",3,11,"Take a look at the `airline_safety` data frame included in the `fivethirtyeight` data package. Run the following: airline_safety After reading the help file by running `?airline_safety`, we see that `airline_safety` is a data frame containing information on different airline companies' safety records. This data was originally reported on the data journalism website, FiveThirtyEight.com, in Nate Silver's article, [""Should Travelers Avoid Flying Airlines That Have Had Crashes in the Past?""](https://fivethirtyeight.com/features/should-travelers-avoid-flying-airlines-that-have-had-crashes-in-the-past/). Let's only consider the variables `airline` and those relating to fatalities for simplicity: airline_safety_smaller <- airline_safety %>% select(airline, starts_with(""fatalities"")) airline_safety_smaller This data frame is not in ""tidy"" format. How would you convert this data frame to be in ""tidy"" format, in particular so that it has a variable `fatalities_years` indicating the incident year and a variable `count` of the fatality counts?",0.0010462221144718065
04,unchanged,4,16,"Convert the `dem_score` data frame into a ""tidy"" data frame and assign the name of `dem_score_tidy` to the resulting long-formatted data frame.",4,16,"Convert the `dem_score` data frame into a ""tidy"" data frame and assign the name of `dem_score_tidy` to the resulting long-formatted data frame.",0
04,unchanged,5,21,"Read in the life expectancy data stored at <https://moderndive.com/data/le_mess.csv> and convert it to a ""tidy"" data frame.",5,21,"Read in the life expectancy data stored at <https://moderndive.com/data/le_mess.csv> and convert it to a ""tidy"" data frame.",0
05,edited,1,1,"Conduct a new exploratory data analysis with the same outcome variable $y$ being `fert_rate` but with `obes_rate` as the new explanatory variable $x$. Remember, this involves three things: (a) Looking at the raw data values. (a) Computing summary statistics. (a) Creating data visualizations. What can you say about the relationship between obesity rate and fertility rate based on this exploration?",1,1,"Conduct a new exploratory data analysis with the same outcome variable $y$ being `score` but with `age` as the new explanatory variable $x$. Remember, this involves three things: (a) Looking at the raw data values. (a) Computing summary statistics. (a) Creating data visualizations. What can you say about the relationship between age and teaching scores based on this exploration?",0.06152284326055191
05,new,2,6,What is the main purpose of performing an exploratory data analysis (EDA) before fitting a regression model? - A. To predict future values. - B. To understand the relationship between variables and detect potential issues. - C. To create more variables. - D. To generate random samples.,NA,NA,NA,0.9
05,new,3,11,Which of the following is correct about the correlation coefficient? - A. It ranges from -2 to 2. - B. It only measures the strength of non-linear relationships. - C. It ranges from -1 to 1 and measures the strength of linear relationships. - D. It is always zero.,NA,NA,NA,0.9
05,edited,4,16,"Fit a simple linear regression using `lm(fert_rate ~ obes_rate, data = UN_data_ch5)` where `obes_rate` is the new explanatory variable $x$. Learn about the ""best-fitting"" line from the regression coefficients by applying the `coef()` function. How do the regression results match up with your earlier exploratory data analysis?",2,6,"Fit a new simple linear regression using `lm(score ~ age, data = evals_ch5)` where `age` is the new explanatory variable $x$. Get information about the ""best-fitting"" line from the regression table by applying the `get_regression_table()` function. How do the regression results match up with the results from your earlier exploratory data analysis?",0.08155061388617274
05,new,5,21,What does the intercept term $b_0$ represent in simple linear regression? - A. The change in the outcome for a one-unit change in the explanatory variable. - B. The predicted value of the outcome when the explanatory variable is zero. - C. The standard error of the regression. - D. The correlation between the outcome and explanatory variables.,NA,NA,NA,0.9
05,new,6,26,"What best describes the ""slope"" of a simple linear regression line? - A. The increase in the explanatory variable for a one-unit increase in the outcome. - B. The average of the explanatory variable. - C. The change in the outcome for a one-unit increase in the explanatory variable. - D. The minimum value of the outcome variable.",NA,NA,NA,0.9
05,new,7,31,What does a negative slope in a simple linear regression indicate? - A. The outcome variable decreases as the explanatory variable increases. - B. The explanatory variable remains constant as the outcome variable increases. - C. The correlation coefficient is zero. - D. The outcome variable increases as the explanatory variable increases.,NA,NA,NA,0.9
05,new,8,36,"What is a ""wrapper function"" in the context of statistical modeling in R? - A. A function that directly fits a regression model without using any other functions. - B. A function that combines other functions to simplify complex operations and provide a user-friendly interface. - C. A function that removes missing values from a dataset before analysis. - D. A function that only handles categorical data in regression models.",NA,NA,NA,0.9
05,edited,9,41,Generate a data frame of the residuals of the *Learning check* model where you used `obes_rate` as the explanatory $x$ variable.,3,11,Generate a data frame of the residuals of the model where you used `age` as the explanatory $x$ variable.,0.12341427618745857
05,new,10,46,Which of the following statements is true about the regression line in a simple linear regression model? - A. The regression line represents the average of the outcome variable. - B. The regression line minimizes the sum of squared differences between the observed and predicted values. - C. The regression line always has a slope of zero. - D. The regression line is only useful when there is no correlation between variables.,NA,NA,NA,0.9
05,edited,11,51,Conduct a new exploratory data analysis with the same explanatory variable $x$ being `continent` but with `gdp_per_capita` as the new outcome variable $y$. What can you say about the differences in GDP per capita between continents based on this exploration?,4,16,Conduct a new exploratory data analysis with the same explanatory variable $x$ being `continent` but with `gdpPercap` as the new outcome variable $y$. What can you say about the differences in GDP per capita between continents based on this exploration?,0.029473684210526315
05,new,12,56,"When using a categorical explanatory variable in regression, what does the baseline group represent? - A. The group with the highest mean - B. The group chosen for comparison with all other groups - C. The group with the most data points - D. The group with the lowest standard deviation",NA,NA,NA,0.9
05,edited,13,61,"Fit a linear regression using `lm(gdp_per_capita ~ continent, data = gapminder2022)` where `gdp_per_capita` is the new outcome variable. Get information about the ""best-fitting"" line from the regression coefficients. How do the regression results match up with the results from your previous exploratory data analysis?",5,21,"Fit a new linear regression using `lm(gdpPercap ~ continent, data = gapminder2007)` where `gdpPercap` is the new outcome variable $y$. Get information about the ""best-fitting"" line from the regression table by applying the `get_regression_table()` function. How do the regression results match up with the results from your previous exploratory data analysis?",0.10255472909567012
05,new,14,66,"How many ""offsets"" or differences from the baseline will a regression model output for a categorical variable with 4 levels? - A. 1 - B. 2 - C. 3 - D. 4",NA,NA,NA,0.9
05,new,15,71,Which interpretation is correct for a positive coefficient in a regression model with a categorical explanatory variable? - A. It indicates the baseline group. - B. It represents the mean value of the baseline group. - C. The corresponding group has a higher response mean than the baseline's. - D. The corresponding group has a lower response mean than the baseline's.,NA,NA,NA,0.9
05,new,16,76,Which of the following statements about residuals in regression is true? - A. Residuals are the differences between the fitted and observed response values. - B. Residuals are always positive. - C. Residuals are not important for model evaluation. - D. Residuals are the predicted values in the model.,NA,NA,NA,0.9
05,edited,17,81,"Using either the sorting functionality of RStudio's spreadsheet viewer or using the data wrangling tools you learned in Chapter \@ref(wrangling), identify the five countries with the five smallest (most negative) residuals? What do these negative residuals say about their life expectancy relative to their continents' life expectancy?",6,26,"Using either the sorting functionality of RStudio's spreadsheet viewer or using the data wrangling tools you learned in Chapter \@ref(wrangling), identify the five countries with the five smallest (most negative) residuals? What do these negative residuals say about their life expectancy relative to their continents' life expectancy?",0.04631578947368421
05,edited,18,86,"Repeat this process, but identify the five countries with the five largest (most positive) residuals. What do these positive residuals say about their life expectancy relative to their continents' life expectancy?",7,31,"Repeat this process, but identify the five countries with the five largest (most positive) residuals. What do these positive residuals say about their life expectancy relative to their continents' life expectancy?",0.04631578947368421
05,edited,19,91,"Note in Figure \@ref(fig:three-lines) there are 3 points marked with dots and: * The ""best"" fitting solid regression line `r if_else(is_latex_output(), """", ""in blue"")` * An arbitrarily chosen dotted `r if_else(is_latex_output(), """", ""red"")` line * Another arbitrarily chosen dashed `r if_else(is_latex_output(), """", ""green"")` line example <- tibble( x = c(0, 0.5, 1), y = c(2, 1, 3) ) ggplot(example, aes(x = x, y = y)) + geom_smooth(method = ""lm"", se = FALSE, fullrange = TRUE) + geom_hline(yintercept = 2.5, col = ""red"", linetype = ""dotted"", size = 1) + geom_abline( intercept = 2, slope = -1, col = ""forestgreen"", linetype = ""dashed"", linewidth = 1 ) + geom_point(size = 4) Compute the sum of squared residuals by hand for each line. Show that the regression line `r if_else(is_latex_output(), """", ""in blue"")` has the smallest value of these three lines.",8,36,"Note in Figure \@ref(fig:three-lines) there are 3 points marked with dots and: * The ""best"" fitting solid regression line `r if_else(is_latex_output(), """", ""in blue"")` * An arbitrarily chosen dotted `r if_else(is_latex_output(), """", ""red"")` line * Another arbitrarily chosen dashed `r if_else(is_latex_output(), """", ""green"")` line example <- tibble( x = c(0, 0.5, 1), y = c(2, 1, 3) ) ggplot(example, aes(x = x, y = y)) + geom_smooth(method = ""lm"", se = FALSE, fullrange = TRUE) + geom_hline(yintercept = 2.5, col = ""red"", linetype = ""dotted"", size = 1) + geom_abline( intercept = 2, slope = -1, col = ""forestgreen"", linetype = ""dashed"", size = 1 ) + geom_point(size = 4) Compute the sum of squared residuals by hand for each line and show that of these three lines, the regression line `r if_else(is_latex_output(), """", ""in blue"")` has the smallest value.",0.05024363359278562
06,new,1,1,What is the goal of including an interaction term in a multiple regression model? - A. To create more variables for analysis. - B. To account for the effect of one explanatory variable on the response while considering the influence of another explanatory variable. - C. To make the model more complex without any real benefit. - D. To automatically improve the fit of the regression line.,NA,NA,NA,0.9
06,new,2,6,"How does the inclusion of both main effects and interaction terms in a regression model affect the interpretation of individual coefficients? - A. They represent simple marginal effects. - B. They become meaningless. - C. They are conditional effects, depending on the level of the interacting variables. - D. They are interpreted in the same way as in models without interactions.",NA,NA,NA,0.9
06,new,3,11,Which statement about the use of dummy variables in regression models is correct? - A. Dummy variables are used to represent numerical variables. - B. Dummy variables are used to represent categorical variables at least two levels. - C. Dummy variables always decrease the R-squared value. - D. Dummy variables are unnecessary in regression models.,NA,NA,NA,0.9
06,new,4,16,"How should a model with one categorical regressor and one numerical regressor, but no interactions, be interpreted? - A. The slope of the model for each category is different. - B. The slope of the model for each category is the same. - C. There is no relationship between the categorical regressor and the response. - D. There is no relationship between the numerical regressor and the response.",NA,NA,NA,0.9
06,edited,5,21,"Compute the observed response values, fitted values, and residuals for the model without interactions.",1,1,"Compute the observed values, fitted values, and residuals not for the interaction model as we just did, but rather for the parallel slopes model we saved in `score_model_parallel_slopes`.",0.3273725112029356
06,new,6,26,"What is the main benefit of visualizing the fitted values and residuals of a multiple regression model? - A. To find errors in the dataset. - B. To check the assumptions of the regression model, such as linearity and homoscedasticity. - C. To always improve the model's accuracy. - D. To increase the complexity of the model.",NA,NA,NA,0.9
06,edited,7,31,Conduct a new exploratory data analysis with the same outcome variable $y$ `debt` but with `credit_rating` and `age` as the new explanatory variables $x_1$ and $x_2$. What can you say about the relationship between a credit card holder's debt and their credit rating and age?,2,6,Conduct a new exploratory data analysis with the same outcome variable $y$ `debt` but with `credit_rating` and `age` as the new explanatory variables $x_1$ and $x_2$. What can you say about the relationship between a credit card holder's debt and their credit rating and age?,0.03333333333333333
06,edited,8,36,"Fit a new simple linear regression using `lm(debt ~ credit_rating + age, data = credit_ch6)` where `credit_rating` and `age` are the new numerical explanatory variables $x_1$ and $x_2$. Get information about the ""best-fitting"" regression plane from the regression table by finding the coefficient of the model. How do the regression results match up with the results from your previous exploratory data analysis?",3,11,"Fit a new simple linear regression using `lm(debt ~ credit_rating + age, data = credit_ch6)` where `credit_rating` and `age` are the new numerical explanatory variables $x_1$ and $x_2$. Get information about the ""best-fitting"" regression plane from the regression table by applying the `get_regression_table()` function. How do the regression results match up with the results from your previous exploratory data analysis?",0.07237949395050292
06,new,9,41,Which of the following statements best describes the interpretation of a regression coefficient in a multiple regression model? - A. It is the additional effect of a regressor on the response when other regressors have already been taken into account. - B. It is the average response variable value when all explanatory variables are zero. - C. It is always positive if the correlation is strong. - D. It cannot be interpreted if there are more than two explanatory variables.,NA,NA,NA,0.9
06,new,10,46,"What is a characteristic of the ""best-fitting"" plane in a multiple regression model with two numerical explanatory variables? - A. It represents the line of best fit for each explanatory variable separately. - B. It minimizes the product of residuals. - C. It minimizes the sum of squared residuals for all combinations of regressors. - D. It shows the exact predictions for every data point.",NA,NA,NA,0.9
06,new,11,51,"What does the intercept represent in a multiple regression model with two explanatory variables? - A. The effect of one explanatory variable, keeping the other constant. - B. The change in the response variable per unit change in the explanatory variable. - C. The correlation between the two explanatory variables. - D. The expected value of the response variable when all regressors are zero.",NA,NA,NA,0.9
06,new,12,56,"What does the term ""partial slope"" refer to in a multiple regression model? - A. The additional effect of a regressor on the response variable, when all the other regressors have been taken into account. - B. The total slope of all variables combined. - C. The slope when all variables are zero. - D. The average of all slopes in the model.",NA,NA,NA,0.9
07,edited,1,1,Why is it important to mix the balls in the bowl before we take a new sample?,1,1,Why was it important to mix the bowl before we sampled the balls?,0.20937713379560885
07,edited,2,6,Why is it that students did not all have the same sample proportion of red balls?,2,6,"Why is it that our 33 groups of friends did not all have the same numbers of balls that were red out of 50, and hence different proportions red?",0.4690387482260423
07,unchanged,3,11,"Why couldn't we study the effects of sampling variation when we used the virtual shovel only once? Why did we need to take more than one virtual sample (in our case, 33 virtual samples)?",3,11,Why couldn't we study the effects of sampling variation when we used the virtual shovel only once? Why did we need to take more than one virtual sample (in our case 33 virtual samples)?,0
07,edited,4,16,Why did we not take 1000 samples of 50 balls by hand?,4,16,"Why did we not take 1000 ""tactile"" samples of 50 balls by hand?",0.07309389387194953
07,unchanged,5,21,"Looking at Figure \@ref(fig:samplingdistribution-virtual-1000), would you say that sampling 50 balls where 30% of them were red is likely or not? What about sampling 50 balls where 10% of them were red?",5,21,"Looking at Figure \@ref(fig:samplingdistribution-virtual-1000), would you say that sampling 50 balls where 30% of them were red is likely or not? What about sampling 50 balls where 10% of them were red?",0
07,edited,6,26,"As shown in Figure \@ref(fig:comparing-sampling-distributions) the histograms of sample proportions are somewhat bell-shaped. What can you say about the center of the histograms? - A. The smaller the sample size the more concentrated the center of the histogram. - B. The larger the sample size the smaller the center of the histogram. - C. The center of each histogram seems to be about the same, regardless of the sample size.",9,41,What would performing a census in our bowl activity correspond to? Why did we not perform a census?,0.8937620570432399
07,edited,7,31,"As shown in Figure \@ref(fig:comparing-sampling-distributions) as the sample size increases, the histogram gets narrower. What happens with the sample proportions? - A. They vary less. - B. They vary by the same amount. - C. They vary more.",6,26,"In Figure \@ref(fig:comparing-sampling-distributions), we used shovels to take 1000 samples each, computed the resulting 1000 proportions of the shovel's balls that were red, and then visualized the distribution of these 1000 proportions in a histogram. We did this for shovels with 25, 50, and 100 slots in them. As the size of the shovels increased, the histograms got narrower. In other words, as the size of the shovels increased from 25 to 50 to 100, did the 1000 proportions - A. vary less, - B. vary by the same amount, or - C. vary more?",0.4977142134357368
07,edited,8,36,Why do we use random sampling when constructing sampling distributions? - A. To always get the same sample - B. To minimize bias and make inferences about the population - C. To make the process easier - D. To reduce the number of samples needed,13,61,What are we *inferring* about the bowl based on the samples using the shovel?,0.65624586503356
07,edited,9,41,Why is it important to construct a histogram of sample means or proportions in a simulation study? - A. To visualize the distribution and assess normality or other patterns - B. To increase the accuracy of the sample means - C. To ensure all sample means are exactly the same - D. To remove any outliers from the data,12,56,Why is it important that sampling be done *at random*?,0.7083894903662489
07,edited,10,46,"In the case of our bowl activity, what is the *population parameter*? Do we know its value? How can we know its value exactly?",8,36,"In the case of our bowl activity, what is the *population parameter*? Do we know its value?",0.13016568648811128
07,edited,11,51,How did we ensure that the samples collected with the shovel were random?,11,51,How did we ensure that our tactile samples using the shovel were random?,0.2483277571213064
07,edited,12,56,What is the expected value of the sample mean in the context of sampling distributions? - A. The observed value of the sample mean - B. The population mean - C. The median of the sample distribution - D. The midpoint of the range,14,66,What purpose did the *sampling distributions* serve?,0.5262939881886867
07,edited,13,61,"What is the role of the Central Limit Theorem (CLT) in statistical inference? - A. It provides the formula for calculating the standard deviation of any given sample, allowing for an understanding of the sample's spread or variability. - B. It states that the sampling distribution of the sample mean will approach a normal distribution, regardless of the population's distribution, as the sample size becomes large. - C. It determines the actual mean of the population directly by calculating it from a randomly selected sample, without needing additional data or assumptions. - D. It is a principle that applies strictly and exclusively to populations that are normally distributed, ensuring that only in such cases the sample means will follow a normal distribution pattern.",16,76,"The table that follows is a version of Table \@ref(tab:comparing-n-2) matching sample sizes $n$ to different *standard errors* of the sample proportion $\widehat{p}$, but with the rows randomly re-ordered and the sample sizes removed. Fill in the table by matching the correct sample sizes to the correct standard errors. set.seed(76) comparing_n_table <- virtual_prop %>% group_by(n) %>% summarize(sd = sd(prop_red)) %>% mutate( n = str_c(""n = "") ) %>% rename(`Sample size` = n, `Standard error of $\\widehat{p}$` = sd) %>% sample_frac(1) comparing_n_table %>% kbl( digits = 3, caption = ""Standard errors of $\\widehat{p}$ based on n = 25, 50, 100"", booktabs = TRUE, escape = FALSE, linesep = """" ) %>% kable_styling( font_size = ifelse(is_latex_output(), 10, 16), latex_options = c(""hold_position"") ) For the following four *Learning checks*, let the *estimate* be the sample proportion $\widehat{p}$: the proportion of a shovel's balls that were red. It estimates the population proportion $p$: the proportion of the bowl's balls that were red.",0.5556874465792256
07,edited,14,66,"What does the term ""sampling variation"" refer to? - A. Variability in the population data. - B. Differences in sample statistics due to random sampling. - C. Changes in the population parameter over time. - D. Variation caused by errors in data collection.",7,31,What summary statistic did we use to quantify how much the 1000 proportions red varied? - A. The interquartile range - B. The standard deviation - C. The range: the largest value minus the smallest.,0.6968300422487741
07,edited,15,71,How does increasing the sample size affect the standard error of the sample mean? - A. It increases the standard error - B. It decreases the standard error - C. It has no effect on the standard error - D. It only affects the standard deviation,15,71,What does the *standard error* of the sample proportion $\widehat{p}$ quantify?,0.5337181616824008
07,edited,16,76,"For each of the following cases, explain whether the sampling distribution of the sample mean approximates a normal distribution. - When the population distribution is normal. - When the sample size is very large. - When the sample size is sufficiently large, regardless of the population distribution. - When the population distribution is uniform.",19,91,"In a real-life situation, we would not take 1000 different samples to infer about a population, but rather only one. Then, what was the purpose of our exercises where we took 1000 different samples?",0.6322895638558177
07,edited,17,81,"In the context of comparing two samples, why do we add variances (squared standard deviations) instead of subtracting them when finding the standard error of the difference? - A. Because variances always cancel each other out - B. Because adding variances reflects the total uncertainty from both samples - C. Because subtracting variances always gives negative results - D. Because variances are not related to the standard error",23,111,"You want to know the prevalence of illegal downloading of TV shows among students at a local college. You get the emails of 100 randomly chosen students and ask them, ""How many times did you download a pirated TV show last week?"".",0.8613260508253168
07,edited,18,86,"What is the sampling distribution of the difference in sample proportions expected to look like if both samples are large enough? - A. Uniform. - B. Bell-shaped, approximating a normal distribution. - C. Bimodal. - D. Skewed to the right.",20,96,"Figure \@ref(fig:accuracy-vs-precision) with the targets shows four combinations of ""accurate versus precise"" estimates. Draw four corresponding *sampling distributions* of the sample proportion $\widehat{p}$, like the one in the leftmost plot in Figure \@ref(fig:comparing-sampling-distributions-3).",0.5358610549558046
07,removed,NA,NA,NA,10,46,What purpose do *point estimates* serve in general? What is the name of the point estimate specific to our bowl activity? What is its mathematical notation?,NA
07,removed,NA,NA,NA,17,81,What is the difference between an *accurate* and a *precise* estimate?,NA
07,removed,NA,NA,NA,18,86,How do we ensure that an estimate is *accurate*? How do we ensure that an estimate is *precise*?,NA
07,removed,NA,NA,NA,21,101,The Royal Air Force wants to study how resistant all their airplanes are to bullets. They study the bullet holes on all the airplanes on the tarmac after an air battle against the Luftwaffe (German Air Force).,NA
07,removed,NA,NA,NA,22,106,"Imagine it is 1993, a time when almost all households had landlines. You want to know the average number of people in each household in your city. You randomly pick out 500 phone numbers from the phone book and conduct a phone survey.",NA
07,removed,NA,NA,NA,24,116,"A local college administrator wants to know the average income of all graduates in the last 10 years. So they get the records of five randomly chosen graduates, contact them, and obtain their answers.",NA
08,new,1,1,What is the expected value of the sample mean weight of almonds in a large sample according to the sampling distribution theory? - A. It is always larger than the population mean. - B. It is always smaller than the population mean. - C. It is exactly equal to the population mean. - D. It is equal to the population mean on average but may vary in any single sample.,NA,NA,NA,0.9
08,new,2,6,What is a **point estimate** and how does it differ from an **interval estimate** in the context of statistical estimation? - A. A point estimate uses multiple values to estimate a parameter; an interval estimate uses a single value. - B. A point estimate is a single value used to estimate a parameter; an interval estimate provides a range of values within which the parameter likely falls. - C. A point estimate is the mean of multiple samples; an interval estimate is the median. - D. A point estimate and an interval estimate are the same and can be used interchangeably.,NA,NA,NA,0.9
08,new,3,11,"What does the population mean ($\mu$) represent in the context of the almond activity? - A. The average weight of 100 randomly sampled almonds. - B. The weight of the heaviest almond in the bowl. - C. The average weight of all 5,000 almonds in the bowl. - D. The total weight of all almonds in the bowl.",NA,NA,NA,0.9
08,new,4,16,Which of the following statements best describes the population standard deviation ($\sigma$) in the almond activity? - A. It measures the average difference between each almond's weight and the sample mean weight. - B. It measures the average difference between each almond's weight and the population mean weight. - C. It is equal to the square root of the sample variance. - D. It is always smaller than the population mean.,NA,NA,NA,0.9
08,new,5,21,Why do we use the sample mean to estimate the population mean in the almond activity? - A. Because the sample mean is always larger than the population mean. - B. Because the sample mean is a good estimator of the population mean due to its unbiasedness. - C. Because the sample mean requires less computational effort than the population mean. - D. Because the sample mean eliminates all sampling variation.,NA,NA,NA,0.9
08,new,6,26,How is the standard error of the sample mean weight of almonds calculated in the context of this example? - A. By dividing the sample mean by the population standard deviation. - B. By dividing the population standard deviation by the square root of the sample size. - C. By multiplying the sample mean by the square root of the sample size. - D. By dividing the population mean by the sample size.,NA,NA,NA,0.9
08,new,7,31,What does a 95% confidence interval represent in the context of the almond weight estimation? - A. There is a 95% chance that the sample mean is within 1.96 standard deviations from the population mean. - B. The interval will contain 95% of the almond weights from the sample. - C. There is a 95% chance that the population mean falls within 1.96 standard errors from the sample mean. - D. The sample mean is exactly equal to the population mean 95% of the time.,NA,NA,NA,0.9
08,new,8,36,Why does the $t$ distribution have thicker tails compared to the standard normal distribution? - A. Because the sample mean is considered more likely to match the population mean closely. - B. Because the $t$ distribution is designed to work when the data does not follow a normal distribution. - C. Because it assumes that the sample size is always smaller when applying the $t$ distribution. - D. Because it accounts for the extra uncertainty that comes from using the sample standard deviation instead of the population standard deviation. \newpage,NA,NA,NA,0.9
08,new,9,41,What is the effect of increasing the degrees of freedom on the $t$ distribution? - A. The tails of the distribution become thicker. - B. The tails of the distribution become thinner. - C. The distribution does not change with degrees of freedom. - D. The distribution becomes skewed to the right.,NA,NA,NA,0.9
08,edited,10,46,What is the chief difference between a bootstrap distribution and a sampling distribution?,1,1,What is the chief difference between a bootstrap distribution and a sampling distribution?,0.04
08,edited,11,51,"Looking at the bootstrap distribution for the sample mean in Figure \@ref(fig:one-thousand-sample-means), between what two values would you say *most* values lie?",2,6,"Looking at the bootstrap distribution for the sample mean in Figure \@ref(fig:one-thousand-sample-means), between what two values would you say *most* values lie?",0.04
08,edited,12,56,"Which of the following is true about the confidence level when constructing a confidence interval? - A. The confidence level determines the width of the interval and affects how likely it is to contain the population parameter. - B. The confidence level is always fixed at 95% for all statistical analyses involving confidence intervals. - C. A higher confidence level always results in a narrower confidence interval, making it more useful for practical purposes. - D. The confidence level is only relevant when the population standard deviation is known.",4,16,Say we wanted to construct a 68% confidence interval instead of a 95% confidence interval for $\mu$. Describe what changes are needed to make this happen. Hint: we suggest you look at Appendix \@ref(appendix-normal-curve) on the normal distribution.,0.5692973940140779
08,new,13,61,"How does increasing the sample size affect the width of a confidence interval for a given confidence level? - A. It increases the width of the confidence interval, making it less precise. - B. It has no effect on the width of the confidence interval since the confidence level is fixed. - C. It decreases the width of the confidence interval, making it more precise by reducing the margin of error. - D. It changes the confidence level directly, regardless of other factors.",NA,NA,NA,0.9
08,edited,14,66,Construct a 95% confidence interval for the *median* weight of *all* almonds with the percentile method. Is it appropriate to also use the standard-error method?,5,21,"Construct a 95% confidence interval for the *median* year of minting of *all* US pennies. Use the percentile method and, if appropriate, then use the standard-error method.",0.2634818790544146
08,new,15,71,What are the advantages of using `infer` for building confidence intervals?,NA,NA,NA,0.9
08,new,16,76,What is the main purpose of bootstrapping in statistical inference? - A. To visualize data distributions and identify outliers. - B. To generate multiple samples from the original data for estimating parameters. - C. To replace missing data points with the mean of the dataset. - D. To validate the assumptions of a regression model.,NA,NA,NA,0.9
08,new,17,81,"""Which function denotes the variables of interest for inference?"" - A. `rep_sample_n()` - B. `calculate()` - C. `specify()` - D. `visualize()`",NA,NA,NA,0.9
08,edited,18,86,"What is a key difference between the percentile method and the standard error method for constructing confidence intervals using bootstrap samples? - A. The percentile method requires the population standard deviation. - B. The percentile method uses the middle 95% of bootstrap statistics, while the standard error method relies on the estimated standard error. - C. The standard error method always results in a narrower confidence interval. - D. The percentile method requires more bootstrap samples.",3,11,What condition about the bootstrap distribution must be met for us to be able to construct confidence intervals using the standard error method?,0.5160891994632114
09,edited,1,1,"Why does the following code produce an error? In other words, what about the response and predictor variables make this not a possible computation with the `infer` package? library(moderndive) library(infer) null_distribution_mean <- spotify_metal_deephouse |> specify(formula = popular_or_not ~ track_genre, success = ""popular"") |> hypothesize(null = ""independence"") |> generate(reps = 1000, type = ""permute"") |> calculate(stat = ""diff in means"", order = c(""metal"", ""deep-house""))",1,1,"Why does the following code produce an error? In other words, what about the response and predictor variables make this not a possible computation with the `infer` package? library(moderndive) library(infer) null_distribution_mean <- promotions %>% specify(formula = decision ~ gender, success = ""promoted"") %>% hypothesize(null = ""independence"") %>% generate(reps = 1000, type = ""permute"") %>% calculate(stat = ""diff in means"", order = c(""male"", ""female""))",0.17669314538241032
09,edited,2,6,Why are we relatively confident that the distributions of the sample proportions will be good approximations of the population distributions of popularity proportions for the two genres?,2,6,Why are we relatively confident that the distributions of the sample proportions will be good approximations of the population distributions of promotion proportions for the two genders?,0.043225334580659025
09,edited,3,11,"Using the definition of _p-value_, write in words what the $p$-value represents for the hypothesis test comparing the popularity rates for metal and deep house.",3,11,"Using the definition of _p-value_, write in words what the $p$-value represents for the hypothesis test comparing the promotion rates for males and females.",0.18485502127760345
09,edited,4,16,Describe in a paragraph how we used Allen Downey's diagram to conclude if a statistical difference existed between the popularity rate of metal and deep house for the Spotify example.,4,16,Describe in a paragraph how we used Allen Downey's diagram to conclude if a statistical difference existed between the promotion rate of males and females using this study.,0.24105828707121812
09,unchanged,5,21,"What is wrong about saying, ""The defendant is innocent."" based on the US system of criminal trials?",5,21,"What is wrong about saying, ""The defendant is innocent."" based on the US system of criminal trials?",0
09,unchanged,6,26,What is the purpose of hypothesis testing?,6,26,What is the purpose of hypothesis testing?,0
09,unchanged,7,31,What are some flaws with hypothesis testing? How could we alleviate them?,7,31,What are some flaws with hypothesis testing? How could we alleviate them?,0
09,edited,8,36,"Consider two $\alpha$ significance levels of 0.1 and 0.01. Of the two, which would lead to a higher chance of committing a Type I Error?",8,36,"Consider two $\alpha$ significance levels of 0.1 and 0.01. Of the two, which would lead to a more *liberal* hypothesis testing procedure? In other words, one that will, all things being equal, lead to more rejections of the null hypothesis $H_0$.",0.33849907009998215
09,unchanged,9,41,Conduct the same analysis comparing action movies versus romantic movies using the median rating instead of the mean rating. What was different and what was the same?,9,41,Conduct the same analysis comparing action movies versus romantic movies using the median rating instead of the mean rating. What was different and what was the same?,0
09,edited,10,46,What conclusions can you make from viewing the faceted histogram looking at `rating` versus `genre` that you could not see when looking at the boxplot?,10,46,What conclusions can you make from viewing the faceted histogram looking at `rating` versus `genre` that you couldn't see when looking at the boxplot?,0.028566533454703502
09,unchanged,11,51,Describe in a paragraph how we used Allen Downey's diagram to conclude if a statistical difference existed between mean movie ratings for action and romance movies.,11,51,Describe in a paragraph how we used Allen Downey's diagram to conclude if a statistical difference existed between mean movie ratings for action and romance movies.,0
09,unchanged,12,56,Why are we relatively confident that the distributions of the sample ratings will be good approximations of the population distributions of ratings for the two genres?,12,56,Why are we relatively confident that the distributions of the sample ratings will be good approximations of the population distributions of ratings for the two genres?,0
09,unchanged,13,61,"Using the definition of $p$-value, write in words what the $p$-value represents for the hypothesis test comparing the mean rating of romance to action movies.",13,61,"Using the definition of $p$-value, write in words what the $p$-value represents for the hypothesis test comparing the mean rating of romance to action movies.",0
09,edited,14,66,What is the value of the $p$-value for the two-sided hypothesis test comparing the mean rating of romance to action movies?,14,66,What is the value of the $p$-value for the hypothesis test comparing the mean rating of romance to action movies?,0.057690700626636615
09,unchanged,15,71,Test your data-wrangling knowledge and EDA skills: - Use `dplyr` and `tidyr` to create the necessary data frame focused on only action and romance movies (but not both) from the `movies` data frame in the `ggplot2movies` package. - Make a boxplot and a faceted histogram of this population data comparing ratings of action and romance movies from IMDb. - Discuss how these plots compare to the similar plots produced for the `movies_sample` data.,15,71,Test your data wrangling knowledge and EDA skills: - Use `dplyr` and `tidyr` to create the necessary data frame focused on only action and romance movies (but not both) from the `movies` data frame in the `ggplot2movies` package. - Make a boxplot and a faceted histogram of this population data comparing ratings of action and romance movies from IMDb. - Discuss how these plots compare to the similar plots produced for the `movies_sample` data.,0
10,new,1,1,What does the error term $\epsilon$ in the linear model $Y = \beta_0 + \beta_1 \cdot X + \epsilon$ represent? - A. The exact value of the response variable. - B. The predicted value of the response variable based on the model. - C. The part of the response variable not explained by the line. - D. The slope of the linear relationship between $X$ and $Y$.,NA,NA,NA,0.9
10,new,2,6,"Which of the following is a property of the least squares estimators $b_0$ and $b_1$? - A. They are biased estimators of the population parameters $\beta_0$ and $\beta_1$. - B. They are linear combinations of the observed responses $y_1, y_2, \ldots, y_n$. - C. They are always equal to the population parameters $\beta_0$ and $\beta_1$. - D. They depend on the specific values of the explanatory variable $X$ only.",NA,NA,NA,0.9
10,new,3,11,How can the difference in means between two groups be represented in a linear regression model? - A. By adding an interaction term between the groups and the response variable. - B. By fitting separate regression lines for each group and comparing their slopes. - C. By including a dummy variable to represent the groups. - D. By subtracting the mean of one group from the mean of the other and using this difference as the predictor.,NA,NA,NA,0.9
10,new,4,16,"In the context of a linear regression model, what does the null hypothesis $H_0: \beta_1 = 0$ represent? - A. There is no linear association between the response and the explanatory variable. - B. The difference between the observed and predicted values is zero. - C. The linear association between response and explanatory variable crosses the origin. - D. The probability of committing a Type II Error is zero. <!-- question above was repeated. I changed it -->",NA,NA,NA,0.9
10,new,5,21,Which of the following is an assumption of the linear regression model? - A. The error terms $\epsilon_i$ are normally distributed with constant variance. - B. The error terms $\epsilon_i$ have a non-zero mean. - C. The error terms $\epsilon_i$ are dependent on each other. - D. The explanatory variable must be normally distributed.,NA,NA,NA,0.9
10,new,6,26,What does it mean when we say that the slope estimator $b_1$ is a random variable? - A. $b_1$ will be the same for every sample taken from the population. - B. $b_1$ is a fixed value that does not change with different samples. - C. $b_1$ can vary from sample to sample due to sampling variation. - D. $b_1$ is always equal to the population slope $\beta_1$.,NA,NA,NA,0.9
10,edited,7,31,"Use the the `un_member_states_2024` data frame included in the `moderndive` package with response variable fertility rate (`fert_rate`) and the regressor life expectancy (`life_exp`). - Use the `get_regression_points()` function to get the observed values, fitted values, and residuals for all UN member countries. - Perform a residual analysis and look for any systematic patterns in the residuals. Ideally, there should be little to no pattern but comment on what you find here.",1,1,"Continuing with our regression using `age` as the explanatory variable and teaching `score` as the outcome variable. - Use the `get_regression_points()` function to get the observed values, fitted values, and residuals for all `r n_evals_ch5` instructors. - Perform a residual analysis and look for any systematic patterns in the residuals. Ideally, there should be little to no pattern but comment on what you find here.",0.22931432106910205
10,new,8,36,"In the context of linear regression, a `p_value` of near zero for the slope coefficient suggests which of the following? - A. The intercept is statistically significant at a 95% confidence level. - B. There is strong evidence against the null hypothesis that the slope coefficient is zero, suggesting there exists a linear relationship between the explanatory and response variables. - C. The variance of the response variable is significantly greater than the variance of the explanatory variable. - D. The residuals are normally distributed with mean zero and constant variance.",NA,NA,NA,0.9
10,new,9,41,Explain whether or not the residual plot helps assess each one of the following assumptions. - Linearity of the relationship between variables - Independence of the error terms - Normality of the error terms - Equality or constancy of variance,NA,NA,NA,0.9
10,new,10,46,"If the residual plot against fitted values shows a ""U-shaped"" pattern, what does this suggest? - A. The variance of the residuals is constant. - B. The linearity assumption is violated. - C. The independence assumption is violated. - D. The normality assumption is satisfied.",NA,NA,NA,0.9
10,edited,11,51,"Repeat the inference but this time for the correlation coefficient instead of the slope. Note the implementation of `stat = ""correlation""` in the `calculate()` function of the `infer` package.",2,6,"Repeat the inference but this time for the correlation coefficient instead of the slope. Note the implementation of `stat = ""correlation""` in the `calculate()` function of the `infer` package.",0.027692307692307693
10,new,12,56,Why is it appropriate to use the bootstrap percentile method to construct a 95% confidence interval for the population slope $\beta_1$ in the Old Faithful data? - A. Because it assumes the slope follows a perfect normal distribution. - B. Because it relies on resampling the residuals instead of the original data points. - C. Because it requires the original data to be uniformly distributed. - D. Because it does not require the bootstrap distribution to be normally shaped.,NA,NA,NA,0.9
10,new,13,61,What is the role of the permutation test in the hypothesis testing for the population slope $\beta_1$? - A. It generates new samples to confirm the confidence interval boundaries. - B. It assesses whether the observed slope could have occurred by chance under the null hypothesis of no relationship. - C. It adjusts the sample size to reduce sampling variability. - D. It ensures the residuals of the regression model are normally distributed.,NA,NA,NA,0.9
10,new,14,66,"After generating a null distribution for the slope using `infer`, you find the $p$-value to be near 0. What does this indicate about the relationship between `waiting` and `duration` in the Old Faithful data? - A. There is no evidence of a relationship between `waiting` and `duration`. - B. The observed slope is likely due to random variation under the null hypothesis. - C. The observed slope is significantly different from zero, suggesting a meaningful relationship between `waiting` and `duration`. - D. The null hypothesis cannot be rejected because the $p$-value is too small.",NA,NA,NA,0.9
10,new,15,71,"In a multiple linear regression model, what does the coefficient $\beta_j$ represent? - A. The intercept of the model. - B. The standard error of the estimate. - C. The total variance explained by the model. - D. The partial slope related to the regressor $X_j$, accounting for all other regressors.",NA,NA,NA,0.9
10,new,16,76,Why is it necessary to convert `continent_of_origin` to a factor when preparing the `coffee_data` data frame for regression analysis? - A. To allow the regression model to interpret `continent_of_origin` as a numerical variable. - B. To create dummy variables that represent different categories of `continent_of_origin`. - C. To reduce the number of observations in the dataset. - D. To ensure the variable is included in the correlation matrix.,NA,NA,NA,0.9
10,new,17,81,What is the purpose of creating a scatterplot matrix in the context of multiple linear regression? - A. To identify outliers that need to be removed from the dataset. - B. To test for normality of the residuals. - C. To examine linear relationships between all variable pairs and identify multicollinearity among regressors. - D. To determine the appropriate number of dummy variables.,NA,NA,NA,0.9
10,new,18,86,"In the multiple regression model for the `coffee_data`, what is the role of dummy variables for `continent_of_origin`? - A. They are used to predict the values of the numerical regressors. - B. They modify the intercept based on the specific category of `continent_of_origin`. - C. They serve to test the independence of residuals. - D. They indicate which observations should be excluded from the model.",NA,NA,NA,0.9
10,new,19,91,"Why is it essential to know that the estimators ($b_0, b_1, \dots, b_p$) in multiple linear regression are unbiased? - A. It ensures that the variance of the estimators is always zero. - B. It means that, on average, the estimators will equal the true population parameters they estimate. - C. It implies that the estimators have a standard error of zero. - D. It suggests that the regression model will always have a perfect fit.",NA,NA,NA,0.9
10,new,20,96,"Why do the least-squares estimates of coefficients change when different sets of regressors are used in multiple linear regression? - A. Because the coefficients are recalculated each time, irrespective of the regressors. - B. Because the residuals are always zero when regressors are changed. - C. Because the value of each coefficient depends on the specific combination of regressors included in the model. - D. Because all models with different regressors will produce identical estimates.",NA,NA,NA,0.9
10,new,21,101,"How is a 95% confidence interval for a coefficient in multiple linear regression constructed? - A. By using the point estimate, the critical value from the t-distribution, and the standard error of the coefficient. - B. By taking the standard deviation of the coefficients only. - C. By resampling the data without replacement. - D. By calculating the mean of all the coefficients.",NA,NA,NA,0.9
10,new,22,106,What does the ANOVA test for comparing two models in multiple linear regression evaluate? - A. Whether all regressors in both models have the same coefficients. - B. Whether the reduced model is adequate or if the full model is needed. - C. Whether the residuals of the two models follow a normal distribution. - D. Whether the regression coefficients of one model are unbiased estimators.,NA,NA,NA,0.9
10,new,23,111,"Why might one prefer to use simulation-based methods (e.g., bootstrapping) for inference in multiple linear regression? - A. Because simulation-based methods require larger sample sizes than theory-based methods. - B. Because simulation-based methods are always faster to compute than theory-based methods. - C. Because simulation-based methods guarantee the correct model is used. - D. Because simulation-based methods do not rely on the assumptions of normality or large sample sizes.",NA,NA,NA,0.9
10,new,24,116,What is the purpose of constructing a bootstrap distribution for the partial slopes in multiple linear regression? - A. To replace the original data with random numbers. - B. To approximate the sampling distribution of the partial slopes by resampling with replacement. - C. To calculate the exact values of the coefficients in the population. - D. To test if the model assumptions are violated.,NA,NA,NA,0.9
10,new,25,121,"If a 95% confidence interval for a partial slope in multiple linear regression includes 0, what does this suggest about the variable? - A. The variable does not have a statistically significant relationship with the response variable. - B. The variable is statistically significant. - C. The variable's coefficient estimate is always negative. - D. The variable was removed from the model during bootstrapping.",NA,NA,NA,0.9
10,new,26,126,"In hypothesis testing for the partial slopes using permutation tests, what does it mean if an observed test statistic falls far to the right of the null distribution? - A. The variable is likely to have no effect on the response. - B. The null hypothesis should be accepted. - C. The variable is likely statistically significant, and we should reject the null. - D. The observed data should be discarded.",NA,NA,NA,0.9
11,new,1,1,"Check that the LINE conditions are met for inference to be made in this Seattle house prices example with `price_interaction <- lm(log10_price ~ log10_size * condition, data = house_prices)`.",NA,NA,NA,0.9
11,edited,2,6,"Repeat the regression modeling in Subsection \@ref(house-prices-regression) and the prediction making you just did on the house of condition `r ex_condition` and size `r ex_size` square feet in Subsection \@ref(house-prices-making-predictions), but using the parallel slopes model you visualized in Figure \@ref(fig:house-price-parallel-slopes).",1,1,"Repeat the regression modeling in Subsection \@ref(house-prices-regression) and the prediction making you just did on the house of condition `r ex_condition` and size `r ex_size` square feet in Subsection \@ref(house-prices-making-predictions), but using the parallel slopes model you visualized in Figure \@ref(fig:house-price-parallel-slopes). Show that it's `r 10^5.72 %>% dollar()`!",0.023494690443458074
11,new,3,11,Interpret the results of the other rows in terms of inference in the `get_regression_table(price_interaction)` output in Table \@ref(tab:seattle-interaction) that we did not interpret in Subsection \@ref(house-prices-inference-for-regression).,NA,NA,NA,0.9
11,new,4,16,"Create, visualize, and interpret confidence intervals using both theory-based and simulation-based approaches to mirror the hypothesis testing done in Subsection \@ref(house-prices-inference-for-regression).",NA,NA,NA,0.9
11,edited,5,21,What date between 1994 and 2003 has the fewest number of births in the US? What story could you tell about why this is the case?,2,6,What date between 1994 and 2003 has the fewest number of births in the US? What story could you tell about why this is the case?,0.048
