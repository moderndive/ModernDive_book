# Inference for Regression {#inference-for-regression}

---

```{block, type='learncheck', purl=FALSE}
**Note: This chapter is still under construction. If you would like to contribute, please check us out on GitHub at <https://github.com/moderndive/moderndive_book>**.

<center>
<img src="images/sign-2408065_1920.png" alt="Drawing" style="height: 100px;"/>
</center>
```

---

## Refresher: Professor evaluations data

Let's revisit the professor evaluations data that we analyzed using multiple regression with one numerical and one categorical predictor. In particular

* $y$: outcome variable of instructor evaluation `score`
* predictor variables
    + $x_1$: numerical explanatory/predictor variable of `age`
    + $x_2$: categorical explanatory/predictor variable of `gender`

```{r, echo=FALSE}
library(tidyr)
```
    
```{r eval=FALSE}
library(ggplot2)
library(dplyr)
library(moderndive)

load(url("http://www.openintro.org/stat/data/evals.RData"))
evals <- evals %>%
  select(score, ethnicity, gender, language, age, bty_avg, rank)
```

```{r echo=FALSE}
library(ggplot2)
library(dplyr)
library(moderndive)
if(!file.exists("data/evals.RData")){
  download.file(url = "http://www.openintro.org/stat/data/evals.RData", 
                destfile = "data/evals.RData")
}
load(file = "data/evals.RData")
evals <- evals %>%
  select(score, ethnicity, gender, language, age, bty_avg, rank)
```


First, recall that we had two competing potential models to explain professors'
teaching scores:

1. Model 1: No interaction term. i.e. both male and female profs have the same slope describing the associated effect of age on teaching score
1. Model 2: Includes an interaction term. i.e. we allow for male and female profs to have different slopes describing the associated effect of age on teaching score

### Refresher: Visualizations

Recall the plots we made for both these models:

```{r model1, echo=FALSE, warning=FALSE, fig.cap="Model 1: no interaction effect included"}
coeff <- lm(score ~ age + gender, data = evals) %>% coef() %>% as.numeric()
slopes <- evals %>%
  group_by(gender) %>%
  summarise(min = min(age), max = max(age)) %>%
  mutate(intercept = coeff[1]) %>%
  mutate(intercept = ifelse(gender == "male", intercept + coeff[3], intercept)) %>%
  gather(point, age, -c(gender, intercept)) %>%
  mutate(y_hat = intercept + age * coeff[2])
  
  ggplot(evals, aes(x = age, y = score, col = gender)) +
  geom_jitter() +
  labs(x = "Age", y = "Teaching Score", color = "Gender") +
  geom_line(data = slopes, aes(y = y_hat), size = 1)
```

```{r model2, echo=FALSE, warning=FALSE, fig.cap="Model 2: interaction effect included"}
ggplot(evals, aes(x = age, y = score, col = gender)) +
  geom_jitter() +
  labs(x = "Age", y = "Teaching Score", color = "Gender") +
  geom_smooth(method = "lm", se = FALSE)
```

### Refresher: Regression tables

Last, let's recall the regressions we fit. First, the regression with no 
interaction effect: note the use of `+` in the formula.

```{r, eval=FALSE}
score_model_2 <- lm(score ~ age + gender, data = evals)
get_regression_table(score_model_2)
```
```{r, echo=FALSE}
score_model_2 <- lm(score ~ age + gender, data = evals)
get_regression_table(score_model_2) %>% 
  knitr::kable(
    digits = 3,
    caption = "Model 1: Regression table with no interaction effect included", 
    booktabs = TRUE
  )
```

Second, the regression with an interaction effect: note the use of `*` in the formula.

```{r, eval=FALSE}
score_model_3 <- lm(score ~ age * gender, data = evals)
get_regression_table(score_model_3)
```
```{r, echo=FALSE}
score_model_3 <- lm(score ~ age * gender, data = evals)
get_regression_table(score_model_3) %>% 
  knitr::kable(
    digits = 3,
    caption = "Model 2: Regression table with interaction effect included", 
    booktabs = TRUE
  )
```





### Script of R code

An R script file of all R code used in this chapter is available [here](https://moderndive.netlify.com/scripts/11-inference-for-regression.R).
