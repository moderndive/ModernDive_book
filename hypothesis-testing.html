<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 9 Hypothesis Testing | Statistical Inference via Data Science</title>
<meta name="author" content="Chester Ismay, Albert Y. Kim, and Arturo Valdivia   Foreword by Kelly S. McConville">
<meta name="generator" content="bookdown 0.46 with bs4_book()">
<meta property="og:title" content="Chapter 9 Hypothesis Testing | Statistical Inference via Data Science">
<meta property="og:type" content="book">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 9 Hypothesis Testing | Statistical Inference via Data Science">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.9.0/transition.js"></script><script src="libs/bs3compat-0.9.0/tabs.js"></script><script src="libs/bs3compat-0.9.0/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/kePrint-0.0.1/kePrint.js"></script><link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet">
<link href="libs/htmltools-fill-0.5.9/fill.css" rel="stylesheet">
<script src="libs/htmlwidgets-1.6.4/htmlwidgets.js"></script><link href="libs/dygraphs-1.1.1/dygraph.css" rel="stylesheet">
<script src="libs/dygraphs-1.1.1/dygraph-combined.js"></script><script src="libs/dygraphs-1.1.1/shapes.js"></script><script src="libs/moment-2.8.4/moment.js"></script><script src="libs/moment-timezone-0.2.5/moment-timezone-with-data.js"></script><script src="libs/moment-fquarter-1.0.0/moment-fquarter.min.js"></script><script src="libs/dygraphs-binding-1.1.1.6/dygraphs.js"></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-YVFBK9P73R"></script><script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-YVFBK9P73R');
    </script><!-- Open Graph Meta Tags --><meta property="og:title" content="ModernDive V2">
<meta property="og:description" content="We have studied confidence intervals in Chapter 8. We now introduce hypothesis testing, another widely used method for statistical inference. A claim is made about a value or characteristic of the...">
<meta property="og:image" content="https://moderndive.com/v2/images/logos/v2_cover.jpg">
<meta property="og:url" content="https://moderndive.com/v2/hypothesis-testing.html">
<meta name="twitter:card" content="summary_large_image">
<!-- Set up favicon --><link rel="icon" href="images/logos/favicons/favicon.ico" type="image/x-icon">
<!-- Redirect to ModernDive V2 --><script>
      if (window.location.pathname === '/v2') {
        window.location.replace(window.location.pathname + '/');
      }
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
          margin-bottom: 0em;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
<link rel="stylesheet" href="style.css">
<meta name="description" content="We have studied confidence intervals in Chapter 8. We now introduce hypothesis testing, another widely used method for statistical inference. A claim is made about a value or characteristic of the...">
<meta property="og:description" content="A book created with bookdown.">
<meta name="twitter:description" content="We have studied confidence intervals in Chapter 8. We now introduce hypothesis testing, another widely used method for statistical inference. A claim is made about a value or characteristic of the...">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="A ModernDive into R and the Tidyverse &lt;br&gt; (Second Edition)">Statistical Inference via Data Science</a>:
        <small class="text-muted">A ModernDive into R and the Tidyverse <br> (Second Edition)</small>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Welcome to ModernDive (v2)</a></li>
<li><a class="" href="foreword.html">Foreword</a></li>
<li><a class="" href="preface.html">Preface</a></li>
<li><a class="" href="about-the-authors.html">About the authors</a></li>
<li><a class="" href="getting-started.html"><span class="header-section-number">1</span> Getting Started with Data in R</a></li>
<li class="book-part">Data Science with tidyverse</li>
<li><a class="" href="viz.html"><span class="header-section-number">2</span> Data Visualization</a></li>
<li><a class="" href="wrangling.html"><span class="header-section-number">3</span> Data Wrangling</a></li>
<li><a class="" href="tidy.html"><span class="header-section-number">4</span> Data Importing and Tidy Data</a></li>
<li class="book-part">Statistical Modeling with moderndive</li>
<li><a class="" href="regression.html"><span class="header-section-number">5</span> Simple Linear Regression</a></li>
<li><a class="" href="multiple-regression.html"><span class="header-section-number">6</span> Multiple Regression</a></li>
<li class="book-part">Statistical Inference with infer</li>
<li><a class="" href="sampling.html"><span class="header-section-number">7</span> Sampling</a></li>
<li><a class="" href="confidence-intervals.html"><span class="header-section-number">8</span> Estimation, Confidence Intervals, and Bootstrapping</a></li>
<li><a class="active" href="hypothesis-testing.html"><span class="header-section-number">9</span> Hypothesis Testing</a></li>
<li><a class="" href="inference-for-regression.html"><span class="header-section-number">10</span> Inference for Regression</a></li>
<li class="book-part">Conclusion</li>
<li><a class="" href="thinking-with-data.html"><span class="header-section-number">11</span> Tell Your Story with Data</a></li>
<li class="book-part">Appendix</li>
<li><a class="" href="appendixA.html"><span class="header-section-number">A</span> Statistical Background</a></li>
<li><a class="" href="appendixB.html"><span class="header-section-number">B</span> Inference Examples</a></li>
<li><a class="" href="appendixC.html"><span class="header-section-number">C</span> Tips and Tricks</a></li>
<li><a class="" href="appendixD.html"><span class="header-section-number">D</span> Learning Check Solutions</a></li>
<li><a class="" href="the-theory-behind-the-bootstrap-method.html"><span class="header-section-number">E</span> The Theory Behind the Bootstrap Method</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/moderndive/ModernDive_book/">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><img src="https://moderndive.com/wide_format.png" alt="ModernDive" style="max-width: 100%; width: 100%; height: auto; display: block; margin: 0 auto; padding-top: 10px;"><div id="hypothesis-testing" class="section level1" number="9">
<h1>
<span class="header-section-number">9</span> Hypothesis Testing<a class="anchor" aria-label="anchor" href="#hypothesis-testing"><i class="fas fa-link"></i></a>
</h1>
<p>We have studied confidence intervals in Chapter <a href="confidence-intervals.html#confidence-intervals">8</a>. We now introduce hypothesis testing, another widely used method for statistical inference. A claim is made about a value or characteristic of the population and then a random sample is used to infer about the plausibility of this claim or hypothesis. For example, in Section <a href="hypothesis-testing.html#ht-activity">9.2</a>, we use data collected from Spotify to investigate whether metal music is more popular than deep-house music.</p>
<p>Many of the relevant concepts, ideas, and we have already introduced many of the necessary concepts to understand hypothesis testing in Chapters <a href="sampling.html#sampling">7</a> and <a href="confidence-intervals.html#confidence-intervals">8</a>. We can now expand further on these ideas and provide a general framework for understanding hypothesis tests. By understanding this general framework, you will be able to adapt it to many different scenarios.</p>
<p>The same can be said for confidence intervals. There was one general framework that applies to confidence intervals, and the <code>infer</code> package was designed around this framework. While the specifics may change slightly for different types of confidence intervals, the general framework stays the same.</p>
<p>We believe that this approach is better for long-term learning than focusing on specific details for specific confidence intervals. We prefer this approach also for hypothesis tests as well, but we will tie the ideas into the traditional theory-based methods as well for completeness.</p>
<p>In Section <a href="hypothesis-testing.html#tying-CI-hypo">9.1</a> we review confidence intervals and introduce hypothesis tests for one-sample problems; in particular, for the mean <span class="math inline">\(\mu\)</span>. We use both theory-based and simulation-based approaches, and we provide some justification why we consider it a better idea to carefully unpack the simulation-based approach for hypothesis testing in the context of two-sample problems. We also show the direct link between confidence intervals and hypothesis tests. In Section <a href="hypothesis-testing.html#ht-activity">9.2</a> we introduce the activity that motivates the simulation-based approach for two-sample problems, data collected from Spotify to investigate whether metal music is more popular than deep-house music. In Sections <a href="hypothesis-testing.html#understanding-ht">9.3</a>, <a href="hypothesis-testing.html#ht-infer">9.4</a>, and <a href="hypothesis-testing.html#ht-interpretation">9.5</a> we explain, conduct, and interpret hypothesis tests, respectively, using the simulation-based approach of permutation. We introduce a case study in Section <a href="hypothesis-testing.html#ht-case-study">9.6</a>, and in Section <a href="hypothesis-testing.html#nhst-conclusion">9.7</a> we conclude with a discussion of the theory-based approach for two-sample problems and some additional remarks.</p>
<p>If you’d like more practice or you are curious to see how this framework applies to different scenarios, you can find fully-worked out examples for many common hypothesis tests and their corresponding confidence intervals in the Appendices online.We recommend that you carefully review these examples as they also cover how the general frameworks apply to traditional theory-based methods like the <span class="math inline">\(t\)</span>-test and normal-theory confidence intervals. You will see there that these traditional methods are just approximations for the computer-based methods we have been focusing on. However, they also require conditions to be met for their results to be valid. Computer-based methods using randomization, simulation, and bootstrapping have much fewer restrictions. Furthermore, they help develop your computational thinking, which is one big reason they are emphasized throughout this book.</p>
<div id="nhst-packages" class="section level2 unnumbered">
<h2>Needed packages<a class="anchor" aria-label="anchor" href="#nhst-packages"><i class="fas fa-link"></i></a>
</h2>
<p>If needed, read Section <a href="getting-started.html#packages">1.3</a> for information on how to install and load R packages.</p>
<div class="sourceCode" id="cb389"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tidyverse.tidyverse.org">tidyverse</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://moderndive.github.io/moderndive/">moderndive</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/tidymodels/infer">infer</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://moderndive.github.io/nycflights23/">nycflights23</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">ggplot2movies</span><span class="op">)</span></span></code></pre></div>
<p>Recall that loading the <code>tidyverse</code> package loads many packages that we have encountered earlier. For details refer to Section <a href="tidy.html#tidyverse-package">4.4</a>. The packages <code>moderndive</code> and <code>infer</code> contain functions and data frames that will be used in this chapter.</p>
</div>
<div id="tying-CI-hypo" class="section level2" number="9.1">
<h2>
<span class="header-section-number">9.1</span> Tying confidence intervals to hypothesis testing<a class="anchor" aria-label="anchor" href="#tying-CI-hypo"><i class="fas fa-link"></i></a>
</h2>
<p>In Chapter <a href="confidence-intervals.html#confidence-intervals">8</a>, we used a random sample to construct an
interval estimate of the population mean.
When using the theory-based approach, we relied on the Central Limit Theorem
to form these intervals and when using the simulation-based approach we do it,
for example, using the bootstrap percentile method.
Hypothesis testing takes advantages of similar tools but the nature and the goal
of the problem are different. Still, there is a direct link between confidence
intervals and hypothesis testing.</p>
<p>In this section, we first describe the one-sample hypothesis test for the
population mean. We then establish the connection between confidence intervals
and hypothesis test. This connection is direct when using the theory-based
approach but requires careful consideration when using the simulation-based
approach.</p>
<p>We proceed by describing hypothesis testing in the case of two-sample problems.</p>
<div id="one-sample-hyp" class="section level3" number="9.1.1">
<h3>
<span class="header-section-number">9.1.1</span> The one-sample hypothesis test for the population mean<a class="anchor" aria-label="anchor" href="#one-sample-hyp"><i class="fas fa-link"></i></a>
</h3>
<p>Let’s continue working with the population mean, <span class="math inline">\(\mu\)</span>.
In Chapter <a href="confidence-intervals.html#confidence-intervals">8</a>, we used a random sample to construct a
95% confidence interval for <span class="math inline">\(\mu\)</span>.</p>
<p>When performing hypothesis testing, we test a claim about <span class="math inline">\(\mu\)</span> by collecting a
random sample and using it to determine if the sample obtained is consistent
with the claim made. To illustrate this idea we return to the chocolate-covered
almonds activity. Assume that the almonds’ company has stated on its
website that the average weight of a chocolate-covered almond is exactly 3.6
grams. We are not so sure about this claim and as researchers believe that it is
different than 3.6 grams on average. To test these competing claims,
we again use the random sample <code>almonds_sample_100</code> from the <code>moderndive</code>
package, and the first 10 lines are shown:</p>
<div class="sourceCode" id="cb390"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">almonds_sample_100</span></span></code></pre></div>
<pre><code># A tibble: 100 × 2
      ID weight
   &lt;int&gt;  &lt;dbl&gt;
 1   166    4.2
 2  1215    4.2
 3  1899    3.9
 4  1912    3.8
 5  4637    3.3
 6   511    3.5
 7   127    4  
 8  4419    3.5
 9  4729    4.2
10  2574    4.1
# ℹ 90 more rows</code></pre>
<p>The goal of hypothesis testing is to answer the question: “Assuming that this
claim is true, how likely is it to observe a sample as extreme as or more
extreme than the one we have observed?” When the answer to the question is:
“If the claim was true, it would be very
unlikely to observe a sample such as the one we have obtained” we would conclude
that the claim cannot be true and we would reject it. Otherwise, we would
fail to reject the claim.</p>
<p>The claim is a statement called the <strong>null
hypothesis</strong>, <span class="math inline">\(H_0\)</span>. It is a statement about <span class="math inline">\(\mu\)</span>, and it is
initially assumed to be true.
A competing statement called the <strong>alternative hypothesis</strong>, <span class="math inline">\(H_A\)</span>, is also a
statement about <span class="math inline">\(\mu\)</span> and contains all the possible values not included under
the null hypothesis. In the almonds’ activity the hypotheses are:</p>
<p><span class="math display">\[\begin{aligned}
&amp;H_0: &amp;\mu = 3.6\\
&amp;H_A: &amp;\mu \ne 3.6
\end{aligned}\]</span></p>
<p>Evidence against the null may appear if the estimate of <span class="math inline">\(\mu\)</span> in the random
sample collected, the sample mean, is much greater or much less than the value
of <span class="math inline">\(\mu\)</span> under the null hypothesis.</p>
<p>How do we determine which claim should be the null hypothesis and which one
the alternative hypothesis? Always remember that the null hypothesis has a privileged status since we assume it to be true until we find evidence against it. We only rule in favor of the alternative hypothesis if we find evidence in the data to reject the null hypothesis. In this context, a researcher who wants to show some results or conclusions for new findings, needs to <em>prove</em> that the null hypothesis
is not true by finding evidence against it. We often say that the
researcher bears the <em>burden of proof</em>.</p>
<p>The hypothesis shown above represents a <em>two-sided test</em> because
evidence against the null hypothesis could come from either direction (greater
or less).
Sometimes it is convenient to work with a
<em>left-sided test</em>. In our example, the
claim under the null hypothesis becomes: “the average weight is <em>at least</em>
3.6 grams” and the researcher’s goal is to find evidence against this claim in
favor of the competing claim “the weight is <em>less</em> than 3.6 grams.” The
competing hypotheses can now be written as <span class="math inline">\(H_0: \mu \ge 3.6\)</span> versus <span class="math inline">\(H_A: \mu &lt; 3.6\)</span> or
even as <span class="math inline">\(H_0: \mu = 3.6\)</span> versus <span class="math inline">\(H_A: \mu &lt; 3.6\)</span>.
Notice that we can drop the inequality part from the null hypothesis. We
find this simplification convenient as we focus on the equal part of the null
hypothesis only and becomes clearer that evidence against the null hypothesis
may come only with values to the left of 3.6, hence a left-sided test.</p>
<p>Similarly, a <em>right-sided test</em> can be stated <span class="math inline">\(H_0: \mu = 3.6\)</span> versus
<span class="math inline">\(H_A: \mu &gt; 3.6\)</span>. Claims under the null hypothesis for this type of test could be stated as “the average weight is <em>at most</em> 3.6 grams” or even “the average weight is <em>less</em> than 3.6 grams.” But observe that <em>less</em> does not contain the <em>equal</em> part, how can the null then be
<span class="math inline">\(H_0: \mu = 3.6\)</span>? The reason is related to the method used more than the semantics of the statement.
Let’s break this down: If, under the null hypothesis, the average weight is less than 3.6 grams, we can only find evidence against the null if we find sample means that are much greater than 3.6 grams, hence the alternative hypothesis is <span class="math inline">\(H_A: \mu &gt; 3.6\)</span>.
Now, to find the evidence we are looking for, the methods we use require a point of reference, “less than 3.6” is not a fixed number since 2 is less than 3.6 but so too is 3.59.
On the other hand, if we can find evidence that the average is greater than 3.6, then it is also true that the average is greater than 3.5, 2, or any other number less than 3.6.
Thus, as a convention, we include the equal sign <strong>always</strong> in the statement under the null hypothesis.</p>
<p>Let’s return to the test. We work with the two-sided test in what follows, but we will
comment about the changes needed in the process if we are instead working with the left-
or right-sided alternatives.</p>
<div id="the-theory-based-approach" class="section level4 unnumbered">
<h4>The theory-based approach<a class="anchor" aria-label="anchor" href="#the-theory-based-approach"><i class="fas fa-link"></i></a>
</h4>
<p>We use the theory-based approach to illustrate how a hypothesis test is
conducted. We first calculate the sample mean and sample standard deviation from
this sample:</p>
<div class="sourceCode" id="cb392"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">almonds_sample_100</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/summarise.html">summarize</a></span><span class="op">(</span>sample_mean <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">weight</span><span class="op">)</span>,</span>
<span>            sample_sd <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">weight</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code># A tibble: 1 × 2
  sample_mean sample_sd
        &lt;dbl&gt;     &lt;dbl&gt;
1       3.682  0.362199</code></pre>
<p>We recall that due to the Central Limit Theorem described in Subsection
<a href="sampling.html#central-limit-theorem">7.3</a>, the sample mean weight of almonds, <span class="math inline">\(\overline X\)</span>,
is approximately normally distributed with expected value equal to <span class="math inline">\(\mu\)</span> and
standard deviation equal to <span class="math inline">\(\sigma/\sqrt{n}\)</span>. Since the population standard
deviation is unknown,
we use the sample standard deviation, <span class="math inline">\(s\)</span>, to calculate the standard error
<span class="math inline">\(s/\sqrt{n}\)</span>. As presented in Subsection <a href="confidence-intervals.html#t-distribution-CI">8.1.4</a>, the <span class="math inline">\(t\)</span>-test
statistic</p>
<p><span class="math display">\[t = \frac{\overline{x} - \mu}{s/\sqrt{n}}\]</span>
follows a <span class="math inline">\(t\)</span> distribution with <span class="math inline">\(n-1\)</span> degrees of freedom.
Of course, we do not know what <span class="math inline">\(\mu\)</span> is. But since we assume that the null
hypothesis is true, we can use this value to obtain the test statistic as shown
in this code next. Table <a href="hypothesis-testing.html#tab:hypo-test-1">9.1</a> presents these values.</p>
<div class="sourceCode" id="cb394"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">almonds_sample_100</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/summarise.html">summarize</a></span><span class="op">(</span>x_bar <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">weight</span><span class="op">)</span>,</span>
<span>            s <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">weight</span><span class="op">)</span>,</span>
<span>            n <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">weight</span><span class="op">)</span>,</span>
<span>            t <span class="op">=</span> <span class="op">(</span><span class="va">x_bar</span> <span class="op">-</span> <span class="fl">3.6</span><span class="op">)</span><span class="op">/</span><span class="op">(</span><span class="va">s</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<div class="inline-table"><table class="table" style="font-size: 16px; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:hypo-test-1">TABLE 9.1: </span>Sample mean, standard deviation, size, and the t-test statistic
</caption>
<thead><tr>
<th style="text-align:right;">
x_bar
</th>
<th style="text-align:right;">
s
</th>
<th style="text-align:right;">
n
</th>
<th style="text-align:right;">
t
</th>
</tr></thead>
<tbody><tr>
<td style="text-align:right;">
3.68
</td>
<td style="text-align:right;">
0.362
</td>
<td style="text-align:right;">
100
</td>
<td style="text-align:right;">
2.26
</td>
</tr></tbody>
</table></div>
<p>The value of <span class="math inline">\(t = 2.26\)</span> is the sample mean
standardized such that the claim <span class="math inline">\(\mu = 3.6\)</span> grams corresponds to the center of the
<span class="math inline">\(t\)</span> distribution (<span class="math inline">\(t = 0\)</span>), and the sample mean observed,
<span class="math inline">\(\overline x = 0.36\)</span>, corresponds to the <span class="math inline">\(t\)</span> test
statistic (t = 2.26).</p>
<p>Assuming that the null hypothesis is true (<span class="math inline">\(\mu = 3.6\)</span> grams) how likely is it
to observe a sample as extreme as or more extreme than <code>almonds_sample_100</code>?
Or correspondingly, how likely is it to observe a sample mean as extreme
as or more extreme than <span class="math inline">\(\overline x = 0.36\)</span>? Or even,
how likely is it to observe a test statistic that is
<span class="math inline">\(t = 2.26\)</span> units or more away from the center of
the <span class="math inline">\(t\)</span> distribution?</p>
<p>Because this is a two-sided test, we care about extreme values that are
2.26 away in either direction of the distribution.
The shaded regions on both tails of the <span class="math inline">\(t\)</span> distribution in Figure
<a href="hypothesis-testing.html#fig:t-curve-hypo">9.1</a> represent the probability of these extreme values.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:t-curve-hypo"></span>
<img src="ModernDive_files/figure-html/t-curve-hypo-1.png" alt="The tails of a t curve for this hypothesis test." width="\textwidth"><p class="caption">
FIGURE 9.1: The tails of a t curve for this hypothesis test.
</p>
</div>
<p>The function <code><a href="https://rdrr.io/r/stats/TDist.html">pt()</a></code> finds the area under a <span class="math inline">\(t\)</span> curve to the left of a given
value. The function requires the argument <code>q</code> (quantile) that in our example is
the value of <span class="math inline">\(t\)</span> on the left part of the plot (-2.26)
and the argument <code>df</code>, the degrees of freedom that for a one-sample test are
<span class="math inline">\(n-1\)</span>.
The sample size of <code>almonds_sample_100</code> was <span class="math inline">\(n = 100\)</span>.
Finally, since we need the area on both tails and the <span class="math inline">\(t\)</span> distribution is
symmetric, we simply multiply the results by 2:</p>
<div class="sourceCode" id="cb395"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fl">2</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/stats/TDist.html">pt</a></span><span class="op">(</span>q <span class="op">=</span> <span class="op">-</span><span class="fl">2.26</span>, df <span class="op">=</span> <span class="fl">100</span> <span class="op">-</span> <span class="fl">1</span><span class="op">)</span></span></code></pre></div>
<p>We have determined that, assuming that the null hypothesis is true, the
probability of getting a sample as extreme as or more extreme than
<code>almonds_sample_100</code> is 0.026. This probability is called
the <span class="math inline">\(p\)</span>-value.</p>
<p>What does this mean? Well, most statistics textbooks will state that, given
a significance level, often set as <span class="math inline">\(\alpha = 0.05\)</span>, if the <span class="math inline">\(p\)</span>-value is less than <span class="math inline">\(\alpha\)</span>,
we reject the null hypothesis. While technically not incorrect, this type of statement
does not provide enough insight for students to fully understand the conclusion.</p>
<p>Let’s unpack some of these elements and provide additional context to them:</p>
<p>The key element of the conclusion is to determine whether the statement under
the null hypothesis can be rejected. If assuming that the null hypothesis is
true, it is very unlikely (almost impossible) to observe a random sample such as
the one we have observed, we <em>need</em> to reject the null hypothesis, but we would
not reject the null hypothesis in any other situation. In that sense, the null
hypothesis has a privileged status. The reason for this is that we do not want
to make a mistake and reject the null hypothesis when the claim under it is
actually true. In statistics, making this mistake is called a Type I Error. So, we
only reject the null hypothesis if the chances of committing a Type I Error are
truly small. The significance level, denoted by the Greek letter <span class="math inline">\(\alpha\)</span>
(pronounced “alpha”), is precisely the probability of
committing a Type I Error.</p>
<p>What are the chances you are willing to take? Again, <span class="math inline">\(\alpha = 0.05\)</span> is what
most textbooks use and many research communities have adopted for decades. While
we should be able to work with this number, after all we may need to interact
with people that are used to it, we want to treat it as one of many possible
numbers.</p>
<p>The significance level, <span class="math inline">\(\alpha\)</span>, is a predefined level of accepted
uncertainty. This value should be defined well before the <span class="math inline">\(p\)</span>-value has been
calculated, or even before data has been collected. Ideally, it should represent
our tolerance for uncertainty. But, how can we determine what this value should
be?</p>
<p>We provide an example. Assume that you are a student and
have to take a test in your statistics class worth 100 points. You have studied
for it, and you expect to get a passing grade (score in the 80s) but not better
than that.
The day of the exam the instructor gives you one additional option. You can take
the exam and receive a grade based on your performance or you can play the
following game: the instructor rolls a six-sided fair die. If the top face shows
a “one” you score zero on your test, otherwise you score 100. There is a 1 in 6
chance that you get zero. Would you play this game?</p>
<p>If you would not play the game, let’s change it. Now the instructor rolls the
die twice, you score 0 in the test only if both rolls are “one.” Otherwise, you
score 100. There is only a 1 in 36 chance to get zero. Would you now play this
game?</p>
<p>What if the instructor rolls the die five times and you score zero in the test
only if each roll is a “one,” and you score 100 otherwise. The is only a 1 in
7776 chance to get zero. Would you play this game?</p>
<p>Converted to probabilities, the three games shown above give you the
probabilities of getting a zero equal to <span class="math inline">\(1/6 = 0.167\)</span>, <span class="math inline">\(1/36 = 0.028\)</span>, and
<span class="math inline">\(1/7776 = 0.0001\)</span>, respectively. Think of these as <span class="math inline">\(p\)</span>-values and getting a zero
in the test as committing a Type I Error.</p>
<p>In the context of a hypothesis test, when the random sample collected is extreme, the <span class="math inline">\(p\)</span>-value is really small, and
we reject the null hypothesis, there is always a chance that the null hypothesis was true, the random sample collected was very atypical, and these results led us to commit a Type I Error.
There is always uncertainty when using random samples to make inferences about populations. All we can do is decide what is our
level of tolerance for this uncertainty. Is it <span class="math inline">\(1/6 = 0.167\)</span>, <span class="math inline">\(1/36 = 0.028\)</span>, <span class="math inline">\(1/7776 = 0.0001\)</span>, or some other level? This is precisely the significance level <span class="math inline">\(\alpha\)</span>.</p>
<p>Returning to the almond example, if we had set <span class="math inline">\(\alpha = 0.04\)</span> and we observed the <span class="math inline">\(p\)</span>-value = 0.026, we would reject the null hypothesis and conclude that
the population mean <span class="math inline">\(\mu\)</span> is not equal to 3.6 grams. When the null hypothesis is rejected we say that the result of the test is <strong>statistically significant</strong>.</p>
<p>Let’s summarize the steps for hypothesis testing:</p>
<ol style="list-style-type: decimal">
<li>Based on the claim we are planning to test, state the null and alternative hypothesis in terms of <span class="math inline">\(\mu\)</span>.
<ul>
<li>Remember that the equal sign should go under the null hypothesis as this is needed for the method.</li>
<li>The statement under the null hypothesis is assumed to be true during the process.</li>
<li>Typically, researchers want to conclude in favor of the alternative hypothesis; that is, they try to see if the data provides evidence against the null hypothesis.</li>
</ul>
</li>
<li>Set a significance level <span class="math inline">\(\alpha\)</span>, based on your tolerance for committing a Type I Error, always before working with the sample.<br>
</li>
<li>Obtain the sample mean, sample standard deviation, <span class="math inline">\(t\)</span>-test statistic, and <span class="math inline">\(p\)</span>-value.
<ul>
<li>When working with a two-sided test, as in the almond example above, the <span class="math inline">\(p\)</span>-value is the area on both tails.</li>
<li>For a left-sided test, find the area under the <span class="math inline">\(t\)</span> distribution to the left of the observed <span class="math inline">\(t\)</span> test statistic.</li>
<li>For a right-sided test, find the area under the <span class="math inline">\(t\)</span> distribution to the right of the observed <span class="math inline">\(t\)</span> test statistic.</li>
</ul>
</li>
<li>Determine whether the result of the test is statistically significant (if the null is rejected) or non-significant (the null is not rejected).</li>
</ol>
</div>
<div id="the-simulation-based-approach" class="section level4 unnumbered">
<h4>The simulation-based approach<a class="anchor" aria-label="anchor" href="#the-simulation-based-approach"><i class="fas fa-link"></i></a>
</h4>
<p>When using a simulation-based approach such as the bootstrap percentile method,
we repeat the first two steps of the theory-based approach:</p>
<ol style="list-style-type: decimal">
<li>State the null and alternative hypothesis in terms of <span class="math inline">\(\mu\)</span>. The statement under the null hypothesis is assumed to be true during the process.</li>
<li>Set a significance level, <span class="math inline">\(\alpha\)</span>, based on your tolerance for committing a Type I Error.</li>
</ol>
<p>In step 1 we need to assume the null hypothesis is true. This presents a technical complication in the bootstrap percentile method as the sample collected and corresponding bootstrap samples are based on the real distribution and if the null hypothesis is not true they cannot reflect this. The solution is to shift the sample values by a constant so as to make the sample mean equal to the claimed population mean under the null hypothesis.</p>
<p>The <code>infer</code> workflow takes this into account automatically, but when introduced to students for the first time, the additional shifting tends to create some confusion in the intuition of the method. We have determined that it is easier to introduce the elements of the simulation-based approach to hypothesis testing via the two-sample problem context using another resampling technique called <em>permutation</em>. Details of this method are presented in Sections <a href="hypothesis-testing.html#understanding-ht">9.3</a>, <a href="hypothesis-testing.html#ht-infer">9.4</a>, and
<a href="hypothesis-testing.html#ht-interpretation">9.5</a>. Once we are very comfortable using this method, we can then explore the bootstrap percentile method for one-sample problems. Observe that more examples with explanations for the simulation-based approach are presented in the Appendices online including an example of a one-sample mean hypothesis test using simulation-based methods.</p>
<p>For completeness, we present here the code and results of the one-sample hypothesis test for the almonds’ problem.</p>
<div class="sourceCode" id="cb396"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">null_dist</span> <span class="op">&lt;-</span> <span class="va">almonds_sample_100</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://infer.tidymodels.org/reference/specify.html">specify</a></span><span class="op">(</span>response <span class="op">=</span> <span class="va">weight</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://infer.tidymodels.org/reference/hypothesize.html">hypothesize</a></span><span class="op">(</span>null <span class="op">=</span> <span class="st">"point"</span>, mu <span class="op">=</span> <span class="fl">3.6</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://infer.tidymodels.org/reference/generate.html">generate</a></span><span class="op">(</span>reps <span class="op">=</span> <span class="fl">1000</span>, type <span class="op">=</span> <span class="st">"bootstrap"</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://infer.tidymodels.org/reference/calculate.html">calculate</a></span><span class="op">(</span>stat <span class="op">=</span> <span class="st">"mean"</span><span class="op">)</span></span></code></pre></div>
<div class="sourceCode" id="cb397"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">x_bar_almonds</span> <span class="op">&lt;-</span> <span class="va">almonds_sample_100</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/summarise.html">summarize</a></span><span class="op">(</span>sample_mean <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">weight</span><span class="op">)</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="va">sample_mean</span><span class="op">)</span></span>
<span><span class="va">null_dist</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://infer.tidymodels.org/reference/get_p_value.html">get_p_value</a></span><span class="op">(</span>obs_stat <span class="op">=</span> <span class="va">x_bar_almonds</span>, direction <span class="op">=</span> <span class="st">"two-sided"</span><span class="op">)</span></span></code></pre></div>
<pre><code># A tibble: 1 × 1
  p_value
    &lt;dbl&gt;
1   0.032</code></pre>
<p>The <span class="math inline">\(p\)</span>-value is 0.032. This is fairly similar to the <span class="math inline">\(p\)</span>-value obtained using the theory-based approach. Using the same significance level <span class="math inline">\(\alpha = 0.04\)</span> we again reject the null hypothesis.</p>
</div>
</div>
<div id="hypothesis-tests-and-confidence-intervals" class="section level3" number="9.1.2">
<h3>
<span class="header-section-number">9.1.2</span> Hypothesis tests and confidence intervals<a class="anchor" aria-label="anchor" href="#hypothesis-tests-and-confidence-intervals"><i class="fas fa-link"></i></a>
</h3>
<p>Even though hypothesis tests and confidence intervals are two different approaches that have different goals, they complement each other.
For example, in Subsection <a href="confidence-intervals.html#t-distribution-CI">8.1.4</a> we calculated the 95% confidence interval for the almonds’ mean weight, <span class="math inline">\(\mu\)</span>, using the sample <code>almonds_sample_100</code>. The theory-based approach was given by</p>
<p><span class="math display">\[
\begin{aligned}
\left(\overline{x} - 1.98 \frac{s}{\sqrt{n}},\quad \overline{x} + 1.98 \frac{s}{\sqrt{n}}\right)
\end{aligned}
\]</span></p>
<p>and the 95% confidence interval is:</p>
<div class="sourceCode" id="cb399"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">almonds_sample_100</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/summarise.html">summarize</a></span><span class="op">(</span>lower_bound <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">weight</span><span class="op">)</span> <span class="op">-</span> <span class="fl">1.98</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">weight</span><span class="op">)</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">weight</span><span class="op">)</span><span class="op">)</span>,</span>
<span>            upper_bound <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">weight</span><span class="op">)</span> <span class="op">+</span> <span class="fl">1.98</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">weight</span><span class="op">)</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">weight</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code># A tibble: 1 × 2
  lower_bound upper_bound
        &lt;dbl&gt;       &lt;dbl&gt;
1     3.61028     3.75372</code></pre>
<p>Using the simulation-based approach via the bootstrap percentile method, the 95% confidence interval is</p>
<div class="sourceCode" id="cb401"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">bootstrap_means</span> <span class="op">&lt;-</span> <span class="va">almonds_sample_100</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://infer.tidymodels.org/reference/specify.html">specify</a></span><span class="op">(</span>response <span class="op">=</span> <span class="va">weight</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://infer.tidymodels.org/reference/generate.html">generate</a></span><span class="op">(</span>reps <span class="op">=</span> <span class="fl">1000</span>, type <span class="op">=</span> <span class="st">"bootstrap"</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://infer.tidymodels.org/reference/calculate.html">calculate</a></span><span class="op">(</span>stat <span class="op">=</span> <span class="st">"mean"</span><span class="op">)</span></span></code></pre></div>
<div class="sourceCode" id="cb402"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">bootstrap_means</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://infer.tidymodels.org/reference/get_confidence_interval.html">get_confidence_interval</a></span><span class="op">(</span>level <span class="op">=</span> <span class="fl">0.95</span>, type <span class="op">=</span> <span class="st">"percentile"</span><span class="op">)</span></span></code></pre></div>
<pre><code># A tibble: 1 × 2
  lower_ci upper_ci
     &lt;dbl&gt;    &lt;dbl&gt;
1  3.61198    3.756</code></pre>
<p>Both 95% confidence intervals are very similar and, more importantly, both
intervals do not contain <span class="math inline">\(\mu = 3.6\)</span> grams.
Recall that when performing hypothesis testing we rejected the null hypothesis,
<span class="math inline">\(H_0: \mu = 3.6\)</span>.
The results obtained using confidence intervals are consistent to the
conclusions of hypothesis testing.</p>
<p>In general, if the values for <span class="math inline">\(\mu\)</span> under the null hypothesis are not part of
the confidence interval, the null hypothesis is rejected.
Note, however, that the confidence level used when constructing the interval,
95% in our example, needs to be consistent with the significance level,
<span class="math inline">\(\alpha\)</span>, used for the hypothesis test.
In particular, when the hypothesis test is two-sided and a significance level
<span class="math inline">\(\alpha\)</span> is used, we calculate a confidence interval for a confidence level equal
to <span class="math inline">\((1 - \alpha)\times 100\%\)</span>. For example, if <span class="math inline">\(\alpha = 0.05\)</span> then the
corresponding confidence level is <span class="math inline">\((1 - 0.05) = 0.95\)</span> or <span class="math inline">\(95\%\)</span>.
The correspondence is direct because the confidence intervals that we calculate
are always two-sided.
On the other hand, if the hypothesis test used is one-sided (left or right),
calculate a confidence interval with a confidence level equal to
<span class="math inline">\((1 - 2\alpha)\times 100\%\)</span>. For example, if <span class="math inline">\(\alpha = 0.05\)</span> then, the
corresponding confidence level needed is <span class="math inline">\((1 - 2\cdot 0.05) = 0.9\)</span> or <span class="math inline">\(90\%\)</span>.</p>
<p>This section concludes our discussion about one-sample hypothesis tests.
Observe that, as we have done for confidence intervals, we can also construct
hypothesis tests for proportions, and when using the bootstrap percentile method,
we can do it also for other quantities, such as the population median, quartiles, etc.</p>
<p>We focus now on building hypothesis tests for two-sample problems.</p>
</div>
</div>
<div id="ht-activity" class="section level2" number="9.2">
<h2>
<span class="header-section-number">9.2</span> Music popularity activity<a class="anchor" aria-label="anchor" href="#ht-activity"><i class="fas fa-link"></i></a>
</h2>
<p>Let’s start with an activity studying the effect of music genre on Spotify song popularity.</p>
<div id="is-metal-music-more-popular-than-deep-house-music" class="section level3" number="9.2.1">
<h3>
<span class="header-section-number">9.2.1</span> Is metal music more popular than deep house music?<a class="anchor" aria-label="anchor" href="#is-metal-music-more-popular-than-deep-house-music"><i class="fas fa-link"></i></a>
</h3>
<p>Imagine you are a music analyst for Spotify, and you are curious about whether fans of metal or deep house are more passionate about their favorite genres. You want to determine if there’s a significant difference in the popularity of these two genres. Popularity, in this case, is measured by Spotify, say, as the average number of streams and recent user interactions on tracks classified under each genre. (Note that Spotify does not actually disclose how this metric is calculated, so we have to take our best guess.) This question sets the stage for our exploration into hypothesis testing.</p>
<p>Metal music, characterized by its aggressive sounds, powerful vocals, and complex instrumentals, has cultivated a loyal fanbase that often prides itself on its deep appreciation for the genre’s intensity and technical skill. On the other hand, deep house music, with its smooth, soulful rhythms and steady beats, attracts listeners who enjoy the genre’s calming and immersive vibe, often associated with late-night clubs and chill-out sessions.</p>
<p>By comparing the popularity metrics between these two genres, we can determine if one truly resonates more with listeners on Spotify. This exploration not only deepens our understanding of musical preferences but also serves as a practical introduction to the principles of hypothesis testing.</p>
<p>To begin the analysis, 2000 tracks were selected at random from Spotify’s song archive. We will use “song” and “track” interchangeably going forward. There were 1000 metal tracks and 1000 deep house tracks selected.</p>
<p>The <code>moderndive</code> package contains the data on the songs by genre in the <code>spotify_by_genre</code> data frame. There are six genres selected in that data (<code>country</code>, <code>deep-house</code>, <code>dubstep</code>, <code>hip-hop</code>, <code>metal</code>, and <code>rock</code>). You will have the opportunity to explore relationships with the other genres and popularity in the <em>Learning checks</em>. Let’s explore this data by focusing on just <code>metal</code> and <code>deep-house</code> by looking at 12 randomly selected rows and our columns of interest in Table <a href="hypothesis-testing.html#tab:twelve-spotify">9.2</a>. Note that we also group our selection so that each of the four possible groupings of <code>track_genre</code> and <code>popular_or_not</code> are selected.</p>
<div class="sourceCode" id="cb404"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">spotify_metal_deephouse</span> <span class="op">&lt;-</span> <span class="va">spotify_by_genre</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html">filter</a></span><span class="op">(</span><span class="va">track_genre</span> <span class="op"><a href="https://rdrr.io/r/base/match.html">%in%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"metal"</span>, <span class="st">"deep-house"</span><span class="op">)</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="va">track_genre</span>, <span class="va">artists</span>, <span class="va">track_name</span>, <span class="va">popularity</span>, <span class="va">popular_or_not</span><span class="op">)</span> </span>
<span><span class="va">spotify_metal_deephouse</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/group_by.html">group_by</a></span><span class="op">(</span><span class="va">track_genre</span>, <span class="va">popular_or_not</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/sample_n.html">sample_n</a></span><span class="op">(</span>size <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span></code></pre></div>
<div class="inline-table"><table class="table" style="font-size: 16px; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:twelve-spotify">TABLE 9.2: </span>Sample of twelve songs from the Spotify data frame.
</caption>
<thead><tr>
<th style="text-align:left;">
track_genre
</th>
<th style="text-align:left;">
artists
</th>
<th style="text-align:left;">
track_name
</th>
<th style="text-align:right;">
popularity
</th>
<th style="text-align:left;">
popular_or_not
</th>
</tr></thead>
<tbody>
<tr>
<td style="text-align:left;">
deep-house
</td>
<td style="text-align:left;">
LYOD;Tom Auton
</td>
<td style="text-align:left;width: 1.5in; ">
On My Way
</td>
<td style="text-align:right;">
51
</td>
<td style="text-align:left;">
popular
</td>
</tr>
<tr>
<td style="text-align:left;">
deep-house
</td>
<td style="text-align:left;">
Sunmoon
</td>
<td style="text-align:left;width: 1.5in; ">
Just the Two of Us
</td>
<td style="text-align:right;">
52
</td>
<td style="text-align:left;">
popular
</td>
</tr>
<tr>
<td style="text-align:left;">
deep-house
</td>
<td style="text-align:left;">
Tensnake;Nazzereene
</td>
<td style="text-align:left;width: 1.5in; ">
Latching Onto You
</td>
<td style="text-align:right;">
51
</td>
<td style="text-align:left;">
popular
</td>
</tr>
<tr>
<td style="text-align:left;">
metal
</td>
<td style="text-align:left;">
Slipknot
</td>
<td style="text-align:left;width: 1.5in; ">
Psychosocial
</td>
<td style="text-align:right;">
66
</td>
<td style="text-align:left;">
popular
</td>
</tr>
<tr>
<td style="text-align:left;">
deep-house
</td>
<td style="text-align:left;">
BCX
</td>
<td style="text-align:left;width: 1.5in; ">
Miracle In The Middle Of My Heart - Original Mix
</td>
<td style="text-align:right;">
41
</td>
<td style="text-align:left;">
not popular
</td>
</tr>
<tr>
<td style="text-align:left;">
metal
</td>
<td style="text-align:left;">
blessthefall
</td>
<td style="text-align:left;width: 1.5in; ">
I Wouldn’t Quit If Everyone Quit
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:left;">
not popular
</td>
</tr>
<tr>
<td style="text-align:left;">
deep-house
</td>
<td style="text-align:left;">
Junge Junge;Tyron Hapi
</td>
<td style="text-align:left;width: 1.5in; ">
I’m The One - Tyron Hapi Remix
</td>
<td style="text-align:right;">
49
</td>
<td style="text-align:left;">
not popular
</td>
</tr>
<tr>
<td style="text-align:left;">
metal
</td>
<td style="text-align:left;">
Poison
</td>
<td style="text-align:left;width: 1.5in; ">
Every Rose Has Its Thorn - Remastered 2003
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:left;">
not popular
</td>
</tr>
<tr>
<td style="text-align:left;">
metal
</td>
<td style="text-align:left;">
Armored Dawn
</td>
<td style="text-align:left;width: 1.5in; ">
S.O.S.
</td>
<td style="text-align:right;">
54
</td>
<td style="text-align:left;">
popular
</td>
</tr>
<tr>
<td style="text-align:left;">
deep-house
</td>
<td style="text-align:left;">
James Hype;Pia Mia;PS1
</td>
<td style="text-align:left;width: 1.5in; ">
Good Luck (feat. Pia Mia) - PS1 Remix
</td>
<td style="text-align:right;">
47
</td>
<td style="text-align:left;">
not popular
</td>
</tr>
<tr>
<td style="text-align:left;">
metal
</td>
<td style="text-align:left;">
Hollywood Undead
</td>
<td style="text-align:left;width: 1.5in; ">
Riot
</td>
<td style="text-align:right;">
26
</td>
<td style="text-align:left;">
not popular
</td>
</tr>
<tr>
<td style="text-align:left;">
metal
</td>
<td style="text-align:left;">
Breaking Benjamin
</td>
<td style="text-align:left;width: 1.5in; ">
Ashes of Eden
</td>
<td style="text-align:right;">
61
</td>
<td style="text-align:left;">
popular
</td>
</tr>
</tbody>
</table></div>
<p>The <code>track_genre</code> variable indicates what genre the song is classified under, the <code>artists</code> and <code>track_name</code> columns provide additional information about the track by providing the artist and the name of the song, <code>popularity</code> is the metric mentioned earlier given by Spotify, and <code>popular_or_not</code> is a categorical representation of the <code>popularity</code> column with any value of 50 (the 75th percentile of <code>popularity</code>) referring to <code>popular</code> and anything at or below 50 as <code>not_popular</code>. The decision made by the authors to call a song “popular” if it is above the 75th percentile (3rd quartile) of <code>popularity</code> is arbitrary and could be changed to any other value.)</p>
<p>Let’s perform an exploratory data analysis of the relationship between the two categorical variables <code>track_genre</code> and <code>popular_or_not</code>. Recall that we saw in Subsection <a href="viz.html#two-categ-barplot">2.8.3</a> that one way we can visualize such a relationship is by using a stacked barplot.</p>
<div class="sourceCode" id="cb405"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">spotify_metal_deephouse</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">track_genre</span>, fill <span class="op">=</span> <span class="va">popular_or_not</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_bar.html">geom_bar</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>x <span class="op">=</span> <span class="st">"Genre of track"</span><span class="op">)</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:spotify-genre-barplot"></span>
<img src="ModernDive_files/figure-html/spotify-genre-barplot-1.png" alt="Barplot relating genre to popularity." width="\textwidth"><p class="caption">
FIGURE 9.2: Barplot relating genre to popularity.
</p>
</div>
<p>Observe in Figure <a href="hypothesis-testing.html#fig:spotify-genre-barplot">9.2</a> that, in this sample, metal songs are only slightly more popular than deep house songs by looking at the height of the <code>popular</code> bars. Let’s quantify these popularity rates by computing the proportion of songs classified as <code>popular</code> for each of the two genres using the <code>dplyr</code> package for data wrangling. Note the use of the <code><a href="https://dplyr.tidyverse.org/reference/count.html">tally()</a></code> function here which is a shortcut for <code>summarize(n = n())</code> to get counts.</p>
<div class="sourceCode" id="cb406"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">spotify_metal_deephouse</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/group_by.html">group_by</a></span><span class="op">(</span><span class="va">track_genre</span>, <span class="va">popular_or_not</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/count.html">tally</a></span><span class="op">(</span><span class="op">)</span> <span class="co"># Same as summarize(n = n())</span></span></code></pre></div>
<pre><code># A tibble: 4 × 3
# Groups:   track_genre [2]
  track_genre popular_or_not     n
  &lt;chr&gt;       &lt;chr&gt;          &lt;int&gt;
1 deep-house  not popular      471
2 deep-house  popular          529
3 metal       not popular      437
4 metal       popular          563</code></pre>
<p>So of the 1000 metal songs, 563 were popular, for a proportion of 563/1000 = 0.563 = 56.3%. On the other hand, of the 1000 deep house songs, 529 were popular, for a proportion of 529/1000 = 0.529 = 52.9%. Comparing these two rates of popularity, it appears that metal songs were popular at a rate 0.563 <span class="math inline">\(-\)</span> 0.529 = 0.034 = 3.4% higher than deep house songs. This is suggestive of an advantage for metal songs in terms of popularity.</p>
<p>The question is, however, does this provide <em>conclusive</em> evidence that there is greater popularity for metal songs compared to deep house songs? Could a difference in popularity rates of 3.4% still occur by chance, even in a hypothetical world where no difference in popularity existed between the two genres? In other words, what is the role of <em>sampling variation</em> in this hypothesized world? To answer this question, we will again rely on a computer to run <em>simulations</em>.</p>
</div>
<div id="shuffling-once" class="section level3" number="9.2.2">
<h3>
<span class="header-section-number">9.2.2</span> Shuffling once<a class="anchor" aria-label="anchor" href="#shuffling-once"><i class="fas fa-link"></i></a>
</h3>
<p>First, try to imagine a hypothetical universe where there was no difference in the popularity of metal and deep house. In such a hypothetical universe, the genre of a song would have no bearing on their chances of popularity. Bringing things back to our <code>spotify_metal_deephouse</code> data frame, the <code>popular_or_not</code> variable would thus be an irrelevant label. If these <code>popular_or_not</code> labels were irrelevant, then we could randomly reassign them by “shuffling” them to no consequence!</p>
<p>To illustrate this idea, let’s narrow our focus to 52 chosen songs of the 2000 that you saw earlier. The <code>track_genre</code> column shows what the original genre of the song was. Note that to keep this smaller dataset of 52 rows to be a representative sample of the 2000 rows, we have sampled such that the popularity rate for each of <code>metal</code> and <code>deep-house</code> is close to the original rates of 0.563 and 0.529, respectively, prior to shuffling. This data is available in the <code>spotify_52_original</code> data frame in the <code>moderndive</code> package. We also remove the <code>track_id</code> column for simplicity. It is an identification variable that is not relevant for our analysis. A sample of this is shown in Table <a href="hypothesis-testing.html#tab:spotify-52-sample">9.3</a>.</p>
<div class="sourceCode" id="cb408"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">spotify_52_original</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="op">-</span><span class="va">track_id</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="fl">10</span><span class="op">)</span></span></code></pre></div>
<div class="inline-table"><table class="table" style="font-size: 16px; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:spotify-52-sample">TABLE 9.3: </span>Representative sample of metal and deep-house songs
</caption>
<thead><tr>
<th style="text-align:left;">
track_genre
</th>
<th style="text-align:left;">
artists
</th>
<th style="text-align:left;">
track_name
</th>
<th style="text-align:right;">
popularity
</th>
<th style="text-align:left;">
popular_or_not
</th>
</tr></thead>
<tbody>
<tr>
<td style="text-align:left;">
deep-house
</td>
<td style="text-align:left;">
Jess Bays;Poppy Baskcomb
</td>
<td style="text-align:left;width: 1.5in; ">
Temptation (feat. Poppy Baskcomb)
</td>
<td style="text-align:right;">
63
</td>
<td style="text-align:left;">
popular
</td>
</tr>
<tr>
<td style="text-align:left;">
metal
</td>
<td style="text-align:left;">
Whitesnake
</td>
<td style="text-align:left;width: 1.5in; ">
Here I Go Again - 2018 Remaster
</td>
<td style="text-align:right;">
69
</td>
<td style="text-align:left;">
popular
</td>
</tr>
<tr>
<td style="text-align:left;">
metal
</td>
<td style="text-align:left;">
Blind Melon
</td>
<td style="text-align:left;width: 1.5in; ">
No Rain
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:left;">
not popular
</td>
</tr>
<tr>
<td style="text-align:left;">
metal
</td>
<td style="text-align:left;">
Avenged Sevenfold
</td>
<td style="text-align:left;width: 1.5in; ">
Shepherd of Fire
</td>
<td style="text-align:right;">
70
</td>
<td style="text-align:left;">
popular
</td>
</tr>
<tr>
<td style="text-align:left;">
deep-house
</td>
<td style="text-align:left;">
Nora Van Elken
</td>
<td style="text-align:left;width: 1.5in; ">
I Wanna Dance With Somebody (Who Loves Me) - Summer Edit
</td>
<td style="text-align:right;">
56
</td>
<td style="text-align:left;">
popular
</td>
</tr>
<tr>
<td style="text-align:left;">
metal
</td>
<td style="text-align:left;">
Breaking Benjamin
</td>
<td style="text-align:left;width: 1.5in; ">
Ashes of Eden
</td>
<td style="text-align:right;">
61
</td>
<td style="text-align:left;">
popular
</td>
</tr>
<tr>
<td style="text-align:left;">
metal
</td>
<td style="text-align:left;">
Bon Jovi
</td>
<td style="text-align:left;width: 1.5in; ">
Thank You For Loving Me
</td>
<td style="text-align:right;">
67
</td>
<td style="text-align:left;">
popular
</td>
</tr>
<tr>
<td style="text-align:left;">
deep-house
</td>
<td style="text-align:left;">
Starley;Bad Paris
</td>
<td style="text-align:left;width: 1.5in; ">
Arms Around Me - Bad Paris Remix
</td>
<td style="text-align:right;">
55
</td>
<td style="text-align:left;">
popular
</td>
</tr>
<tr>
<td style="text-align:left;">
deep-house
</td>
<td style="text-align:left;">
The Him;LissA
</td>
<td style="text-align:left;width: 1.5in; ">
I Wonder
</td>
<td style="text-align:right;">
43
</td>
<td style="text-align:left;">
not popular
</td>
</tr>
<tr>
<td style="text-align:left;">
metal
</td>
<td style="text-align:left;">
Deftones
</td>
<td style="text-align:left;width: 1.5in; ">
Ohms
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:left;">
not popular
</td>
</tr>
</tbody>
</table></div>
<p>In our hypothesized universe of no difference in genre popularity, popularity is irrelevant and thus it is of no consequence to randomly “shuffle” the values of <code>popular_or_not</code>. The <code>popular_or_not</code> column in the <code>spotify_52_shuffled</code> data frame in the <code>moderndive</code> package shows one such possible random shuffling.</p>
<div class="sourceCode" id="cb409"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">spotify_52_shuffled</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="op">-</span><span class="va">track_id</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="fl">10</span><span class="op">)</span></span></code></pre></div>

<div class="inline-table"><table class="table" style="font-size: 16px; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:spotify-shuffled-52-sample">TABLE 9.4: </span>Shuffled version of <code>popular_or_not</code> in sample
</caption>
<thead><tr>
<th style="text-align:left;">
track_genre
</th>
<th style="text-align:left;">
artists
</th>
<th style="text-align:left;">
track_name
</th>
<th style="text-align:right;">
popularity
</th>
<th style="text-align:left;">
popular_or_not
</th>
</tr></thead>
<tbody>
<tr>
<td style="text-align:left;">
deep-house
</td>
<td style="text-align:left;">
Jess Bays;Poppy Baskcomb
</td>
<td style="text-align:left;width: 1.5in; ">
Temptation (feat. Poppy Baskcomb)
</td>
<td style="text-align:right;">
63
</td>
<td style="text-align:left;">
popular
</td>
</tr>
<tr>
<td style="text-align:left;">
metal
</td>
<td style="text-align:left;">
Whitesnake
</td>
<td style="text-align:left;width: 1.5in; ">
Here I Go Again - 2018 Remaster
</td>
<td style="text-align:right;">
69
</td>
<td style="text-align:left;">
not popular
</td>
</tr>
<tr>
<td style="text-align:left;">
metal
</td>
<td style="text-align:left;">
Blind Melon
</td>
<td style="text-align:left;width: 1.5in; ">
No Rain
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:left;">
popular
</td>
</tr>
<tr>
<td style="text-align:left;">
metal
</td>
<td style="text-align:left;">
Avenged Sevenfold
</td>
<td style="text-align:left;width: 1.5in; ">
Shepherd of Fire
</td>
<td style="text-align:right;">
70
</td>
<td style="text-align:left;">
not popular
</td>
</tr>
<tr>
<td style="text-align:left;">
deep-house
</td>
<td style="text-align:left;">
Nora Van Elken
</td>
<td style="text-align:left;width: 1.5in; ">
I Wanna Dance With Somebody (Who Loves Me) - Summer Edit
</td>
<td style="text-align:right;">
56
</td>
<td style="text-align:left;">
popular
</td>
</tr>
<tr>
<td style="text-align:left;">
metal
</td>
<td style="text-align:left;">
Breaking Benjamin
</td>
<td style="text-align:left;width: 1.5in; ">
Ashes of Eden
</td>
<td style="text-align:right;">
61
</td>
<td style="text-align:left;">
not popular
</td>
</tr>
<tr>
<td style="text-align:left;">
metal
</td>
<td style="text-align:left;">
Bon Jovi
</td>
<td style="text-align:left;width: 1.5in; ">
Thank You For Loving Me
</td>
<td style="text-align:right;">
67
</td>
<td style="text-align:left;">
not popular
</td>
</tr>
<tr>
<td style="text-align:left;">
deep-house
</td>
<td style="text-align:left;">
Starley;Bad Paris
</td>
<td style="text-align:left;width: 1.5in; ">
Arms Around Me - Bad Paris Remix
</td>
<td style="text-align:right;">
55
</td>
<td style="text-align:left;">
not popular
</td>
</tr>
<tr>
<td style="text-align:left;">
deep-house
</td>
<td style="text-align:left;">
The Him;LissA
</td>
<td style="text-align:left;width: 1.5in; ">
I Wonder
</td>
<td style="text-align:right;">
43
</td>
<td style="text-align:left;">
not popular
</td>
</tr>
<tr>
<td style="text-align:left;">
metal
</td>
<td style="text-align:left;">
Deftones
</td>
<td style="text-align:left;width: 1.5in; ">
Ohms
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:left;">
not popular
</td>
</tr>
</tbody>
</table></div>
<p>Observe in Table <a href="hypothesis-testing.html#tab:spotify-shuffled-52-sample">9.4</a> that the <code>popular_or_not</code> column how the <code>popular</code> and <code>not popular</code> results are now listed in a different order. Some of the original <code>popular</code> now are <code>not popular</code>, some of the <code>not popular</code> are <code>popular</code>, and others are the same as the original.</p>
<p>Again, such random shuffling of the <code>popular_or_not</code> label only makes sense in our hypothesized universe of no difference in popularity between genres. Is there a tactile way for us to understand what is going on with this shuffling? One way would be by using a standard deck of 52 playing cards, which we display in Figure <a href="hypothesis-testing.html#fig:deck-of-cards">9.3</a>.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:deck-of-cards"></span>
<img src="images/shutterstock/shutterstock_670789453.jpg" alt="Standard deck of 52 playing cards." width="60%"><p class="caption">
FIGURE 9.3: Standard deck of 52 playing cards.
</p>
</div>
<p>Since we started with equal sample sizes of 1000 songs for each genre, we can think about splitting the deck in half to have 26 cards in two piles (one for <code>metal</code> and another for <code>deep-house</code>). After shuffling these 52 cards as seen in Figure <a href="hypothesis-testing.html#fig:shuffling">9.4</a>, we split the deck equally into the two piles of 26 cards each. Then, we can flip the cards over one-by-one, assigning “popular” for each red card and “not popular” for each black card keeping a tally of how many of each genre are popular.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:shuffling"></span>
<img src="images/shutterstock/shutterstock_128283971.jpg" alt="Shuffling a deck of cards." width="50%"><p class="caption">
FIGURE 9.4: Shuffling a deck of cards.
</p>
</div>
<p>Let’s repeat the same exploratory data analysis we did for the original <code>spotify_metal_deephouse</code> data on our <code>spotify_52_original</code> and <code>spotify_52_shuffled</code> data frames. Let’s create a barplot visualizing the relationship between <code>track_genre</code> and the new shuffled <code>popular_or_not</code> variable, and compare this to the original un-shuffled version in Figure <a href="hypothesis-testing.html#fig:spotify-genre-barplot-permuted">9.5</a>.</p>
<div class="sourceCode" id="cb410"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">spotify_52_shuffled</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">track_genre</span>, fill <span class="op">=</span> <span class="va">popular_or_not</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_bar.html">geom_bar</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>x <span class="op">=</span> <span class="st">"Genre of track"</span><span class="op">)</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:spotify-genre-barplot-permuted"></span>
<img src="ModernDive_files/figure-html/spotify-genre-barplot-permuted-1.png" alt="Barplots of relationship of genre with `popular or not' (left) and shuffled `popular or not' (right)." width="\textwidth"><p class="caption">
FIGURE 9.5: Barplots of relationship of genre with <code>popular or not' (left) and shuffled</code>popular or not’ (right).
</p>
</div>
<p>The difference in metal versus deep house popularity rates is now different. Compared to the original data in the left barplot, the new “shuffled” data in the right barplot has popularity rates that are actually in the opposite direction as they were originally. This is because the shuffling process has removed any relationship between genre and popularity.</p>
<p>Let’s also compute the proportion of tracks that are now “popular” in the <code>popular_or_not</code> column for each genre:</p>
<div class="sourceCode" id="cb411"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">spotify_52_shuffled</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/group_by.html">group_by</a></span><span class="op">(</span><span class="va">track_genre</span>, <span class="va">popular_or_not</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/count.html">tally</a></span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<pre><code># A tibble: 4 × 3
# Groups:   track_genre [2]
  track_genre popular_or_not     n
  &lt;chr&gt;       &lt;chr&gt;          &lt;int&gt;
1 deep-house  not popular       10
2 deep-house  popular           16
3 metal       not popular       13
4 metal       popular           13</code></pre>
<p>So in this one sample of a hypothetical universe of no difference in genre popularity, <span class="math inline">\(13/26 = 0.5 = 50\%\)</span> of metal songs were popular. On the other hand, <span class="math inline">\(16/26 = 0.615 = 61.5\%\)</span> of deep house songs were popular. Let’s next compare these two values. It appears that metal tracks were popular at a rate that was <span class="math inline">\(0.5 - 0.615 = -0.115 = -11.5\)</span> percentage points different than deep house songs.</p>
<p>Observe how this difference in rates is not the same as the difference in rates of 0.034 = 3.4% we originally observed. This is once again due to <em>sampling variation</em>. How can we better understand the effect of this sampling variation? By repeating this shuffling several times!</p>
</div>
<div id="ht-what-did-we-just-do" class="section level3" number="9.2.3">
<h3>
<span class="header-section-number">9.2.3</span> What did we just do?<a class="anchor" aria-label="anchor" href="#ht-what-did-we-just-do"><i class="fas fa-link"></i></a>
</h3>
<p>What we just demonstrated in this activity is the statistical procedure known as <em>hypothesis testing</em> using a <em>permutation test</em>. The term “permutation” is the mathematical term for “shuffling”: taking a series of values and reordering them randomly, as you did with the playing cards. In fact, permutations are another form of <em>resampling</em>, like the bootstrap method you performed in Chapter <a href="confidence-intervals.html#confidence-intervals">8</a>. While the bootstrap method involves resampling <em>with</em> replacement, permutation methods involve resampling <em>without</em> replacement.</p>
<p>We do not need restrict our analysis to a dataset of 52 rows only. It is useful to manually shuffle the deck of cards and assign values of popular or not popular to different songs, but the same ideas can be applied to each of the 2000 tracks in our <code>spotify_metal_deephouse</code> data. We can think with this data about an inference about an unknown difference in population proportions with the 2000 tracks being our sample. We denote this as <span class="math inline">\(p_{m} - p_{d}\)</span>, where <span class="math inline">\(p_{m}\)</span> is the population proportion of songs with metal names being popular and <span class="math inline">\(p_{d}\)</span> is the equivalent for deep house songs. Recall that this is one of the scenarios for inference we have seen so far in Table <a href="hypothesis-testing.html#tab:table-diff-prop">9.5</a>.</p>
<div class="inline-table"><table class="table" style="font-size: 16px; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:table-diff-prop">TABLE 9.5: </span>Scenarios of sampling for inference
</caption>
<thead><tr>
<th style="text-align:right;">
Scenario
</th>
<th style="text-align:left;">
Population parameter
</th>
<th style="text-align:left;">
Notation
</th>
<th style="text-align:left;">
Point estimate
</th>
<th style="text-align:left;">
Symbol(s)
</th>
</tr></thead>
<tbody>
<tr>
<td style="text-align:right;width: 0.5in; ">
1
</td>
<td style="text-align:left;width: 0.7in; ">
Population proportion
</td>
<td style="text-align:left;width: 1in; ">
<span class="math inline">\(p\)</span>
</td>
<td style="text-align:left;width: 1.1in; ">
Sample proportion
</td>
<td style="text-align:left;width: 1in; ">
<span class="math inline">\(\widehat{p}\)</span>
</td>
</tr>
<tr>
<td style="text-align:right;width: 0.5in; ">
2
</td>
<td style="text-align:left;width: 0.7in; ">
Population mean
</td>
<td style="text-align:left;width: 1in; ">
<span class="math inline">\(\mu\)</span>
</td>
<td style="text-align:left;width: 1.1in; ">
Sample mean
</td>
<td style="text-align:left;width: 1in; ">
<span class="math inline">\(\overline{x}\)</span> or <span class="math inline">\(\widehat{\mu}\)</span>
</td>
</tr>
<tr>
<td style="text-align:right;width: 0.5in; ">
3
</td>
<td style="text-align:left;width: 0.7in; ">
Difference in population proportions
</td>
<td style="text-align:left;width: 1in; ">
<span class="math inline">\(p_1 - p_2\)</span>
</td>
<td style="text-align:left;width: 1.1in; ">
Difference in sample proportions
</td>
<td style="text-align:left;width: 1in; ">
<span class="math inline">\(\widehat{p}_1 - \widehat{p}_2\)</span>
</td>
</tr>
</tbody>
</table></div>
<p>So, based on our sample of <span class="math inline">\(n_m = 1000\)</span> metal tracks and <span class="math inline">\(n_f = 1000\)</span> deep house tracks, the <em>point estimate</em> for <span class="math inline">\(p_{m} - p_{d}\)</span> is the <em>difference in sample proportions</em></p>
<p><span class="math display">\[\widehat{p}_{m} -\widehat{p}_{f} = 0.563 - 0.529 = 0.034.\]</span></p>
<p>This difference in favor of metal songs of 0.034 (3.4 percentage points) is greater than 0, suggesting metal songs are more popular than deep house songs.</p>
<p>However, the question we ask ourselves was “is this difference meaningfully greater than 0?”. In other words, is that difference indicative of true popularity, or can we just attribute it to <em>sampling variation</em>? Hypothesis testing allows us to make such distinctions.</p>
</div>
</div>
<div id="understanding-ht" class="section level2" number="9.3">
<h2>
<span class="header-section-number">9.3</span> Understanding hypothesis tests<a class="anchor" aria-label="anchor" href="#understanding-ht"><i class="fas fa-link"></i></a>
</h2>
<p>Much like the terminology, notation, and definitions relating to sampling you saw in Section <a href="sampling.html#sampling-framework">7.2</a>, there are a lot of terminology, notation, and definitions related to hypothesis testing as well. Some of this was introduced in Section <a href="hypothesis-testing.html#tying-CI-hypo">9.1</a>. Learning these may seem like a very daunting task at first. However, with practice, practice, and more practice, anyone can master them.</p>
<p>First, a <strong>hypothesis</strong> is a statement about the value of an unknown population parameter. In our genre popularity activity, our population parameter of interest is the difference in population proportions <span class="math inline">\(p_{m} - p_{d}\)</span>. Hypothesis tests can involve any of the population parameters in Table <a href="confidence-intervals.html#tab:table-ch8-c">8.1</a> of the five inference scenarios we will cover in this book and also more advanced types we will not cover here.</p>
<p>Second, a <strong>hypothesis test</strong> consists of a test between two competing hypotheses: (1) a <strong>null hypothesis</strong> <span class="math inline">\(H_0\)</span> (pronounced “H-naught”) versus (2) an <strong>alternative hypothesis</strong> <span class="math inline">\(H_A\)</span> (also denoted <span class="math inline">\(H_1\)</span>).</p>
<p>When working with the comparison of two populations parameters, typically, the null hypothesis is a claim that there is “no effect” or “no difference of interest.” In many cases, the null hypothesis represents the status quo. Furthermore, the alternative hypothesis is the claim the experimenter or researcher wants to establish or find evidence to support. It is viewed as a “challenger” hypothesis to the null hypothesis <span class="math inline">\(H_0\)</span>. In our genre popularity activity, an appropriate hypothesis test would be:</p>
<p><span class="math display">\[
\begin{aligned}
H_0 &amp;: \text{metal and deep house have the same popularity rate}\\
\text{vs } H_A &amp;: \text{metal is popular at a higher rate than deep house}
\end{aligned}
\]</span></p>
<p>Note some of the choices we have made. First, we set the null hypothesis <span class="math inline">\(H_0\)</span> to be that there is no difference in popularity rate and the “challenger” alternative hypothesis <span class="math inline">\(H_A\)</span> to be that there is a difference in favor of metal. As discussed earlier, the null hypothesis is set to reflect a situation of “no change.” As we discussed earlier, in this case, <span class="math inline">\(H_0\)</span> corresponds to there being no difference in popularity. Furthermore, we set <span class="math inline">\(H_A\)</span> to be that metal is popular at a <em>higher</em> rate, a subjective choice reflecting a prior suspicion we have that this is the case. As discussed earlier this is a <em>one-sided test</em>. It can be left- or right-sided, and this becomes clear once we express it in terms of proportions. If someone else however does not share such suspicions and only wants to investigate that there is a difference, whether higher or lower, they would construct a <em>two-sided test</em>.</p>
<p>We can re-express the formulation of our hypothesis test using the mathematical notation for our population parameter of interest, the difference in population proportions <span class="math inline">\(p_{m} - p_{d}\)</span>:</p>
<p><span class="math display">\[
\begin{aligned}
H_0 &amp;: p_{m} - p_{d} = 0\\
\text{vs } H_A&amp;: p_{m} - p_{d} &gt; 0
\end{aligned}
\]</span></p>
<p>Observe how the alternative hypothesis <span class="math inline">\(H_A\)</span> is written <span class="math inline">\(p_{m} - p_{d} &gt; 0\)</span>. Since we have chosen this particular formulation, the one-sided test becomes <em>right-sided</em> because we are looking for a difference that is greater than zero as evidence to reject the null hypothesis. Had we opted for a two-sided alternative, we would have set <span class="math inline">\(p_{m} - p_{d} \neq 0\)</span>. We work here with the right-sided test and will present an example of a two-sided test in Section <a href="hypothesis-testing.html#ht-case-study">9.6</a>.</p>
<p>Third, a <strong>test statistic</strong> is a <em>point estimate/sample statistic</em> formula used for hypothesis testing. Note that a sample statistic is merely a summary statistic based on a sample of observations. Recall we saw in Section <a href="wrangling.html#summarize">3.3</a> that a summary statistic takes in many values and returns only one. Here, the samples would be the <span class="math inline">\(n_m = 1000\)</span> metal songs and the <span class="math inline">\(n_f = 1000\)</span> deep house songs. Hence, the point estimate of interest is the difference in sample proportions <span class="math inline">\(\widehat{p}_{m} - \widehat{p}_{d}\)</span>.</p>
<p>Fourth, the <strong>observed test statistic</strong> is the value of the test statistic that we observed in real life. In our case, we computed this value using the data saved in the <code>spotify_metal_deephouse</code> data frame. It was the observed difference of <span class="math inline">\(\widehat{p}_{m} -\widehat{p}_{d} = 0.563 - 0.529 = 0.034 = 3.4\%\)</span> in favor of metal songs.</p>
<p>Fifth, the <strong>null distribution</strong> is the sampling distribution of the test statistic <em>assuming the null hypothesis <span class="math inline">\(H_0\)</span> is true</em>. Let’s unpack these ideas slowly. The key to understanding the null distribution is that the null hypothesis <span class="math inline">\(H_0\)</span> is <em>assumed</em> to be true. We are not saying that <span class="math inline">\(H_0\)</span> is true at this point, we are only assuming it to be true for hypothesis-testing purposes. In our case, this corresponds to our hypothesized universe of no difference in popularity rates. Assuming the null hypothesis <span class="math inline">\(H_0\)</span>, also stated as “Under <span class="math inline">\(H_0\)</span>,” how does the test statistic vary due to sampling variation? In our case, how will the difference in sample proportions <span class="math inline">\(\widehat{p}_{m} - \widehat{p}_{f}\)</span> vary due to sampling under <span class="math inline">\(H_0\)</span>? Recall from Subsection <a href="sampling.html#sampling-variation">7.3.4</a> that distributions displaying how point estimates vary due to sampling variation are called <em>sampling distributions</em>. The only additional thing to keep in mind about null distributions is that they are sampling distributions <em>assuming the null hypothesis <span class="math inline">\(H_0\)</span> is true</em>.</p>
<p>Sixth, the <strong><span class="math inline">\(p\)</span>-value</strong> is the probability of obtaining a test statistic just as extreme as or more extreme than the observed test statistic <em>assuming the null hypothesis <span class="math inline">\(H_0\)</span> is true</em>. You can think of the <span class="math inline">\(p\)</span>-value as a quantification of “surprise”: assuming <span class="math inline">\(H_0\)</span> is true, how surprised are we with what we observed? Or in our case, in our hypothesized universe of no difference in genre popularity, how surprised are we that we observed higher popularity rates of 0.034 from our collected samples if no difference in genre popularity exists? Very surprised? Somewhat surprised?</p>
<p>The <span class="math inline">\(p\)</span>-value quantifies this probability, or what proportion had a more “extreme” result? Here, extreme is defined in terms of the alternative hypothesis <span class="math inline">\(H_A\)</span> that metal popularity is at a higher rate than deep house. In other words, how often was the popularity of metal <em>even more</em> pronounced than <span class="math inline">\(0.563 - 0.529 = 0.034 = 3.4\%\)</span>?</p>
<p>Seventh and lastly, in many hypothesis testing procedures, it is commonly recommended to set the <strong>significance level</strong> of the test beforehand. It is denoted by <span class="math inline">\(\alpha\)</span>. Please review our discussion of <span class="math inline">\(\alpha\)</span> in Section <a href="hypothesis-testing.html#one-sample-hyp">9.1.1</a> when we discussed the theory-based approach. For now, it is sufficient to recall that if the <span class="math inline">\(p\)</span>-value is less than or equal to <span class="math inline">\(\alpha\)</span>, we reject the null hypothesis <span class="math inline">\(H_0\)</span>.</p>
<p>Alternatively, if the <span class="math inline">\(p\)</span>-value is greater than <span class="math inline">\(\alpha\)</span>, we would “fail to reject <span class="math inline">\(H_0\)</span>.” Note the latter statement is not quite the same as saying we “accept <span class="math inline">\(H_0\)</span>.” This distinction is rather subtle and not immediately obvious. So we will revisit it later in Section <a href="hypothesis-testing.html#ht-interpretation">9.5</a>.</p>
<p>While different fields tend to use different values of <span class="math inline">\(\alpha\)</span>, some commonly used values for <span class="math inline">\(\alpha\)</span> are 0.1, 0.01, and 0.05; with 0.05 being the choice people often make without putting much thought into it. We will talk more about <span class="math inline">\(\alpha\)</span> significance levels in Section <a href="hypothesis-testing.html#ht-interpretation">9.5</a>, but first let’s fully conduct a hypothesis test corresponding to our genre popularity activity using the <code>infer</code> package.</p>
</div>
<div id="ht-infer" class="section level2" number="9.4">
<h2>
<span class="header-section-number">9.4</span> Conducting hypothesis tests<a class="anchor" aria-label="anchor" href="#ht-infer"><i class="fas fa-link"></i></a>
</h2>
<p>In Section <a href="confidence-intervals.html#bootstrap-process">8.2.2</a>, we showed you how to construct confidence intervals. We first illustrated how to do this using <code>dplyr</code> data wrangling verbs and the <code><a href="https://infer.tidymodels.org/reference/rep_sample_n.html">rep_sample_n()</a></code> function from Subsection <a href="sampling.html#sampling-simulation">7.1.3</a> which we used as a virtual shovel. In particular, we constructed confidence intervals by resampling with replacement by setting the <code>replace = TRUE</code> argument to the <code><a href="https://infer.tidymodels.org/reference/rep_sample_n.html">rep_sample_n()</a></code> function.</p>
<p>We then showed you how to perform the same task using the <code>infer</code> package workflow. While both workflows resulted in the same bootstrap distribution from which we can construct confidence intervals, the <code>infer</code> package workflow emphasizes each of the steps in the overall process in Figure <a href="hypothesis-testing.html#fig:infer-ci">9.6</a>. It does so using function names that are intuitively named with verbs:</p>
<ol style="list-style-type: decimal">
<li>
<code><a href="https://infer.tidymodels.org/reference/specify.html">specify()</a></code> the variables of interest in your data frame.</li>
<li>
<code><a href="https://infer.tidymodels.org/reference/generate.html">generate()</a></code> replicates of bootstrap resamples with replacement.</li>
<li>
<code><a href="https://infer.tidymodels.org/reference/calculate.html">calculate()</a></code> the summary statistic of interest.</li>
<li>
<code><a href="https://infer.tidymodels.org/reference/visualize.html">visualize()</a></code> the resulting bootstrap distribution and confidence interval.</li>
</ol>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:infer-ci"></span>
<img src="images/flowcharts/infer/visualize.png" alt="Confidence intervals with the infer package." width="90%"><p class="caption">
FIGURE 9.6: Confidence intervals with the infer package.
</p>
</div>
<p>In this section, we will now show you how to seamlessly modify the previously seen <code>infer</code> code for constructing confidence intervals to conduct hypothesis tests. You will notice that the basic outline of the workflow is almost identical, except for an additional <code><a href="https://infer.tidymodels.org/reference/hypothesize.html">hypothesize()</a></code> step between the <code><a href="https://infer.tidymodels.org/reference/specify.html">specify()</a></code> and <code><a href="https://infer.tidymodels.org/reference/generate.html">generate()</a></code> steps, as can be seen in Figure <a href="hypothesis-testing.html#fig:inferht">9.7</a>.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:inferht"></span>
<img src="images/flowcharts/infer/ht.png" alt="Hypothesis testing with the infer package." width="90%"><p class="caption">
FIGURE 9.7: Hypothesis testing with the infer package.
</p>
</div>
<p>Furthermore, we will use a pre-specified significance level <span class="math inline">\(\alpha\)</span> = 0.1 for this hypothesis test. Please read the discussion about <span class="math inline">\(\alpha\)</span> in Subsection <a href="hypothesis-testing.html#one-sample-hyp">9.1.1</a> or later on in Section <a href="hypothesis-testing.html#ht-interpretation">9.5</a>.</p>
<div id="infer-workflow-ht" class="section level3" number="9.4.1">
<h3>
<span class="header-section-number">9.4.1</span> <code>infer</code> package workflow<a class="anchor" aria-label="anchor" href="#infer-workflow-ht"><i class="fas fa-link"></i></a>
</h3>
<div id="specify-variables-2" class="section level4 unnumbered">
<h4>1. <code>specify</code> variables<a class="anchor" aria-label="anchor" href="#specify-variables-2"><i class="fas fa-link"></i></a>
</h4>
<p>Recall that we use the <code><a href="https://infer.tidymodels.org/reference/specify.html">specify()</a></code> verb to specify the response variable and, if needed, any explanatory variables for our study. In this case, since we are interested in any potential effects of genre on popularity rates, we set <code>popular_or_not</code> as the response variable and <code>track_genre</code> as the explanatory variable. We do so using <code>formula = response ~ explanatory</code> where <code>response</code> is the name of the response variable in the data frame and <code>explanatory</code> is the name of the explanatory variable. So in our case it is <code>popular_or_not ~ track_genre</code>.</p>
<p>Furthermore, since we are interested in the proportion of songs <code>"popular"</code>, and not the proportion of songs <code>not</code> popular, we set the argument <code>success</code> to <code>"popular"</code>.</p>
<div class="sourceCode" id="cb413"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">spotify_metal_deephouse</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://infer.tidymodels.org/reference/specify.html">specify</a></span><span class="op">(</span>formula <span class="op">=</span> <span class="va">popular_or_not</span> <span class="op">~</span> <span class="va">track_genre</span>, success <span class="op">=</span> <span class="st">"popular"</span><span class="op">)</span></span></code></pre></div>
<pre><code>Response: popular_or_not (factor)
Explanatory: track_genre (factor)
# A tibble: 2,000 × 2
   popular_or_not track_genre
   &lt;fct&gt;          &lt;fct&gt;      
 1 popular        deep-house 
 2 popular        deep-house 
 3 popular        deep-house 
 4 popular        deep-house 
 5 popular        deep-house 
 6 popular        deep-house 
 7 popular        deep-house 
 8 popular        deep-house 
 9 popular        deep-house 
10 popular        deep-house 
# ℹ 1,990 more rows</code></pre>
<p>Again, notice how the <code>spotify_metal_deephouse</code> data itself does not change, but the <code>Response: popular_or_not (factor)</code> and <code>Explanatory: track_genre (factor)</code> <em>meta-data</em> do. This is similar to how the <code><a href="https://dplyr.tidyverse.org/reference/group_by.html">group_by()</a></code> verb from <code>dplyr</code> does not change the data, but only adds “grouping” meta-data, as we saw in Section <a href="wrangling.html#groupby">3.4</a>. We also now focus on only the two columns of interest in the data for our problem at hand with <code>popular_or_not</code> and <code>track_genre</code>.</p>
</div>
<div id="hypothesize-the-null" class="section level4 unnumbered">
<h4>2. <code>hypothesize</code> the null<a class="anchor" aria-label="anchor" href="#hypothesize-the-null"><i class="fas fa-link"></i></a>
</h4>
<p>In order to conduct hypothesis tests using the <code>infer</code> workflow, we need a new step not present for confidence intervals: <code><a href="https://infer.tidymodels.org/reference/hypothesize.html">hypothesize()</a></code>. Recall from Section <a href="hypothesis-testing.html#understanding-ht">9.3</a> that our hypothesis test was</p>
<p><span class="math display">\[
\begin{aligned}
H_0 &amp;: p_{m} - p_{d} = 0\\
\text{vs. } H_A&amp;: p_{m} - p_{d} &gt; 0
\end{aligned}
\]</span></p>
<p>In other words, the null hypothesis <span class="math inline">\(H_0\)</span> corresponding to our “hypothesized universe” stated that there was no difference in genre popularity rates. We set this null hypothesis <span class="math inline">\(H_0\)</span> in our <code>infer</code> workflow using the <code>null</code> argument of the <code><a href="https://infer.tidymodels.org/reference/hypothesize.html">hypothesize()</a></code> function to either:</p>
<ul>
<li>
<code>"point"</code> for hypotheses involving a single sample or</li>
<li>
<code>"independence"</code> for hypotheses involving two samples.</li>
</ul>
<p>In our case, since we have two samples (the metal songs and the deep house songs), we set <code>null = "independence"</code>.</p>
<div class="sourceCode" id="cb415"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">spotify_metal_deephouse</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://infer.tidymodels.org/reference/specify.html">specify</a></span><span class="op">(</span>formula <span class="op">=</span> <span class="va">popular_or_not</span> <span class="op">~</span> <span class="va">track_genre</span>, success <span class="op">=</span> <span class="st">"popular"</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://infer.tidymodels.org/reference/hypothesize.html">hypothesize</a></span><span class="op">(</span>null <span class="op">=</span> <span class="st">"independence"</span><span class="op">)</span></span></code></pre></div>
<pre><code>Response: popular_or_not (factor)
Explanatory: track_genre (factor)
Null Hypothesis: independence
# A tibble: 2,000 × 2
   popular_or_not track_genre
   &lt;fct&gt;          &lt;fct&gt;      
 1 popular        deep-house 
 2 popular        deep-house 
 3 popular        deep-house 
 4 popular        deep-house 
 5 popular        deep-house 
 6 popular        deep-house 
 7 popular        deep-house 
 8 popular        deep-house 
 9 popular        deep-house 
10 popular        deep-house 
# ℹ 1,990 more rows</code></pre>
<p>Again, the data has not changed yet. This will occur at the upcoming <code><a href="https://infer.tidymodels.org/reference/generate.html">generate()</a></code> step; we are merely setting meta-data for now.</p>
<p>Where do the terms <code>"point"</code> and <code>"independence"</code> come from? These are two technical statistical terms. The term “point” relates from the fact that for a single group of observations, you will test the value of a single point. Going back to the pennies example from Chapter <a href="confidence-intervals.html#confidence-intervals">8</a>, say we wanted to test if the mean weight of all chocolate-covered almonds was equal to 3.5 grams or not. We would be testing the value of a “point” <span class="math inline">\(\mu\)</span>, the mean weight in grams of <em>all</em> chocolate-covered almonds, as follows</p>
<p><span class="math display">\[
\begin{aligned}
H_0 &amp;: \mu = 3.5\\
\text{vs } H_A&amp;: \mu \neq 3.5
\end{aligned}
\]</span></p>
<p>The term “independence” relates to the fact that for two groups of observations, you are testing whether or not the response variable is <em>independent</em> of the explanatory variable that assigns the groups. In our case, we are testing whether the <code>popular_or_not</code> response variable is “independent” of the explanatory variable <code>track_genre</code>.</p>
</div>
<div id="generate-replicates-2" class="section level4 unnumbered">
<h4>3. <code>generate</code> replicates<a class="anchor" aria-label="anchor" href="#generate-replicates-2"><i class="fas fa-link"></i></a>
</h4>
<p>After we <code><a href="https://infer.tidymodels.org/reference/hypothesize.html">hypothesize()</a></code> the null hypothesis, we <code><a href="https://infer.tidymodels.org/reference/generate.html">generate()</a></code> replicates of “shuffled” datasets assuming the null hypothesis is true. We do this by repeating the shuffling exercise you performed in Section <a href="hypothesis-testing.html#ht-activity">9.2</a> several times on the full dataset of 2000 rows. Let’s use the computer to repeat this 1000 times by setting <code>reps = 1000</code> in the <code><a href="https://infer.tidymodels.org/reference/generate.html">generate()</a></code> function. However, unlike for confidence intervals where we generated replicates using <code>type = "bootstrap"</code> resampling with replacement, we will now perform shuffles/permutations by setting <code>type = "permute"</code>. Recall that shuffles/permutations are a kind of resampling, but unlike the bootstrap method, they involve resampling <em>without</em> replacement.</p>
<div class="sourceCode" id="cb417"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">spotify_generate</span> <span class="op">&lt;-</span> <span class="va">spotify_metal_deephouse</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://infer.tidymodels.org/reference/specify.html">specify</a></span><span class="op">(</span>formula <span class="op">=</span> <span class="va">popular_or_not</span> <span class="op">~</span> <span class="va">track_genre</span>, success <span class="op">=</span> <span class="st">"popular"</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://infer.tidymodels.org/reference/hypothesize.html">hypothesize</a></span><span class="op">(</span>null <span class="op">=</span> <span class="st">"independence"</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://infer.tidymodels.org/reference/generate.html">generate</a></span><span class="op">(</span>reps <span class="op">=</span> <span class="fl">1000</span>, type <span class="op">=</span> <span class="st">"permute"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">spotify_generate</span><span class="op">)</span></span></code></pre></div>
<pre><code>[1] 2000000</code></pre>
<p>The resulting data frame has 2,000,000 rows. This is because we performed shuffles/permutations for each of the 2000 rows 1000 times and <span class="math inline">\(2,000,000 = 1000 \cdot 2000\)</span>. If you explore the <code>spotify_generate</code> data frame with <code><a href="https://rdrr.io/r/utils/View.html">View()</a></code>, you will notice that the variable <code>replicate</code> indicates which resample each row belongs to. So it has the value <code>1</code> 2000 times, the value <code>2</code> 2000 times, all the way through to the value <code>1000</code> 2000 times.</p>
</div>
<div id="calculate-summary-statistics-2" class="section level4 unnumbered">
<h4>4. <code>calculate</code> summary statistics<a class="anchor" aria-label="anchor" href="#calculate-summary-statistics-2"><i class="fas fa-link"></i></a>
</h4>
<p>Now that we have generated 1000 replicates of “shuffles” assuming the null hypothesis is true, let’s <code><a href="https://infer.tidymodels.org/reference/calculate.html">calculate()</a></code> the appropriate summary statistic for each of our 1000 shuffles. From Section <a href="hypothesis-testing.html#understanding-ht">9.3</a>, point estimates related to hypothesis testing have a specific name: <em>test statistics</em>. Since the unknown population parameter of interest is the difference in population proportions <span class="math inline">\(p_{m} - p_{d}\)</span>, the test statistic here is the difference in sample proportions <span class="math inline">\(\widehat{p}_{m} - \widehat{p}_{f}\)</span>.</p>
<p>For each of our 1000 shuffles, we can calculate this test statistic by setting <code>stat = "diff in props"</code>. Furthermore, since we are interested in <span class="math inline">\(\widehat{p}_{m} - \widehat{p}_{d}\)</span> we set <code>order = c("metal", "deep-house")</code>. As we stated earlier, the order of the subtraction does not matter, so long as you stay consistent throughout your analysis and tailor your interpretations accordingly. Let’s save the result in a data frame called <code>null_distribution</code>:</p>
<div class="sourceCode" id="cb419"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">null_distribution</span> <span class="op">&lt;-</span> <span class="va">spotify_metal_deephouse</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://infer.tidymodels.org/reference/specify.html">specify</a></span><span class="op">(</span>formula <span class="op">=</span> <span class="va">popular_or_not</span> <span class="op">~</span> <span class="va">track_genre</span>, success <span class="op">=</span> <span class="st">"popular"</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://infer.tidymodels.org/reference/hypothesize.html">hypothesize</a></span><span class="op">(</span>null <span class="op">=</span> <span class="st">"independence"</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://infer.tidymodels.org/reference/generate.html">generate</a></span><span class="op">(</span>reps <span class="op">=</span> <span class="fl">1000</span>, type <span class="op">=</span> <span class="st">"permute"</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://infer.tidymodels.org/reference/calculate.html">calculate</a></span><span class="op">(</span>stat <span class="op">=</span> <span class="st">"diff in props"</span>, order <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"metal"</span>, <span class="st">"deep-house"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">null_distribution</span></span></code></pre></div>
<pre><code>Response: popular_or_not (factor)
Explanatory: track_genre (factor)
Null Hypothesis: independence
# A tibble: 1,000 × 2
   replicate       stat
       &lt;int&gt;      &lt;dbl&gt;
 1         1  0.0140000
 2         2 -0.0420000
 3         3  0.0220000
 4         4 -0.0140000
 5         5 -0.0180000
 6         6 -0.0160000
 7         7  0.0160000
 8         8 -0.0400000
 9         9  0.0140000
10        10  0.0120000
# ℹ 990 more rows</code></pre>
<p>Observe that we have 1000 values of <code>stat</code>, each representing one instance of <span class="math inline">\(\widehat{p}_{m} - \widehat{p}_{d}\)</span> in a hypothesized world of no difference in genre popularity. Observe as well that we chose the name of this data frame carefully: <code>null_distribution</code>. Recall once again from Section <a href="hypothesis-testing.html#understanding-ht">9.3</a> that sampling distributions when the null hypothesis <span class="math inline">\(H_0\)</span> is assumed to be true have a special name: the <em>null distribution</em>.</p>
<p>What was the <em>observed</em> difference in popularity rates? In other words, what was the <em>observed test statistic</em> <span class="math inline">\(\widehat{p}_{m} - \widehat{p}_{f}\)</span>? Recall from Section <a href="hypothesis-testing.html#ht-activity">9.2</a> that we computed this observed difference by hand to be 0.563 - 0.529 = 0.034 = 3.4%. We can also compute this value using the previous <code>infer</code> code but with the <code><a href="https://infer.tidymodels.org/reference/hypothesize.html">hypothesize()</a></code> and <code><a href="https://infer.tidymodels.org/reference/generate.html">generate()</a></code> steps removed. Let’s save this in <code>obs_diff_prop</code>:</p>
<div class="sourceCode" id="cb421"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">obs_diff_prop</span> <span class="op">&lt;-</span> <span class="va">spotify_metal_deephouse</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://infer.tidymodels.org/reference/specify.html">specify</a></span><span class="op">(</span>formula <span class="op">=</span> <span class="va">popular_or_not</span> <span class="op">~</span> <span class="va">track_genre</span>, success <span class="op">=</span> <span class="st">"popular"</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://infer.tidymodels.org/reference/calculate.html">calculate</a></span><span class="op">(</span>stat <span class="op">=</span> <span class="st">"diff in props"</span>, order <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"metal"</span>, <span class="st">"deep-house"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">obs_diff_prop</span></span></code></pre></div>
<pre><code>Response: popular_or_not (factor)
Explanatory: track_genre (factor)
# A tibble: 1 × 1
       stat
      &lt;dbl&gt;
1 0.0340000</code></pre>
<p>Note that there is also a wrapper function in <code>infer</code> called <code><a href="https://infer.tidymodels.org/reference/observe.html">observe()</a></code> that can be used to calculate the observed test statistic. However, we chose to use the <code><a href="https://infer.tidymodels.org/reference/specify.html">specify()</a></code>, <code><a href="https://infer.tidymodels.org/reference/calculate.html">calculate()</a></code>, and <code><a href="https://infer.tidymodels.org/reference/hypothesize.html">hypothesize()</a></code> functions to help you continue to use the common verbs and build practice with them.</p>
<div class="sourceCode" id="cb423"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">spotify_metal_deephouse</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://infer.tidymodels.org/reference/observe.html">observe</a></span><span class="op">(</span>formula <span class="op">=</span> <span class="va">popular_or_not</span> <span class="op">~</span> <span class="va">track_genre</span>, </span>
<span>          success <span class="op">=</span> <span class="st">"popular"</span>, </span>
<span>          stat <span class="op">=</span> <span class="st">"diff in props"</span>, </span>
<span>          order <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"metal"</span>, <span class="st">"deep-house"</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code>Response: popular_or_not (factor)
Explanatory: track_genre (factor)
# A tibble: 1 × 1
       stat
      &lt;dbl&gt;
1 0.0340000</code></pre>
</div>
<div id="visualize-the-p-value" class="section level4 unnumbered">
<h4>5. <code>visualize</code> the p-value<a class="anchor" aria-label="anchor" href="#visualize-the-p-value"><i class="fas fa-link"></i></a>
</h4>
<p>The final step is to measure how surprised we are by a difference of 3.4% in a hypothesized universe of no difference in genre popularity. If the observed difference of 0.034 is highly unlikely, then we would be inclined to reject the validity of our hypothesized universe.</p>
<p>We start by visualizing the <em>null distribution</em> of our 1000 values of <span class="math inline">\(\widehat{p}_{m} - \widehat{p}_{d}\)</span> using <code><a href="https://infer.tidymodels.org/reference/visualize.html">visualize()</a></code> in Figure <a href="hypothesis-testing.html#fig:null-distribution-infer">9.8</a>. Recall that these are values of the difference in popularity rates assuming <span class="math inline">\(H_0\)</span> is true. This corresponds to being in our hypothesized universe of no difference in genre popularity.</p>
<div class="sourceCode" id="cb425"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://infer.tidymodels.org/reference/visualize.html">visualize</a></span><span class="op">(</span><span class="va">null_distribution</span>, bins <span class="op">=</span> <span class="fl">25</span><span class="op">)</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:null-distribution-infer"></span>
<img src="ModernDive_files/figure-html/null-distribution-infer-1.png" alt="Null distribution." width="\textwidth"><p class="caption">
FIGURE 9.8: Null distribution.
</p>
</div>
<p>Let’s now add what happened in real life to Figure <a href="hypothesis-testing.html#fig:null-distribution-infer">9.8</a>, the observed difference in popularity rates of 0.563 - 0.529 = 0.034 = 3.4%. However, instead of merely adding a vertical line using <code><a href="https://ggplot2.tidyverse.org/reference/geom_abline.html">geom_vline()</a></code>, let’s use the <code><a href="https://infer.tidymodels.org/reference/shade_p_value.html">shade_p_value()</a></code> function with <code>obs_stat</code> set to the observed test statistic value we saved in <code>obs_diff_prop</code>.</p>
<p>Furthermore, we will set the <code>direction = "right"</code> reflecting our alternative hypothesis <span class="math inline">\(H_A: p_{m} - p_{d} &gt; 0\)</span>. Recall our alternative hypothesis <span class="math inline">\(H_A\)</span> is that <span class="math inline">\(p_{m} - p_{d} &gt; 0\)</span>, stating that there is a difference in popularity rates in favor of metal songs. “More extreme” here corresponds to differences that are “bigger” or “more positive” or “more to the right.” Hence we set the <code>direction</code> argument of <code><a href="https://infer.tidymodels.org/reference/shade_p_value.html">shade_p_value()</a></code> to be <code>"right"</code>.</p>
<p>On the other hand, had our alternative hypothesis <span class="math inline">\(H_A\)</span> been the other possible one-sided alternative <span class="math inline">\(p_{m} - p_{d} &lt; 0\)</span>, suggesting popularity in favor of deep house songs, we would have set <code>direction = "left"</code>. Had our alternative hypothesis <span class="math inline">\(H_A\)</span> been two-sided <span class="math inline">\(p_{m} - p_{d} \neq 0\)</span>, suggesting discrimination in either direction, we would have set <code>direction = "both"</code>.</p>
<div class="sourceCode" id="cb426"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://infer.tidymodels.org/reference/visualize.html">visualize</a></span><span class="op">(</span><span class="va">null_distribution</span>, bins <span class="op">=</span> <span class="fl">25</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://infer.tidymodels.org/reference/shade_p_value.html">shade_p_value</a></span><span class="op">(</span>obs_stat <span class="op">=</span> <span class="va">obs_diff_prop</span>, direction <span class="op">=</span> <span class="st">"right"</span><span class="op">)</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:null-distribution-infer-2"></span>
<img src="ModernDive_files/figure-html/null-distribution-infer-2-1.png" alt="Shaded histogram to show $p$-value." width="\textwidth"><p class="caption">
FIGURE 9.9: Shaded histogram to show <span class="math inline">\(p\)</span>-value.
</p>
</div>
<p>In the resulting Figure <a href="hypothesis-testing.html#fig:null-distribution-infer-2">9.9</a>, the solid dark line marks 0.034 = 3.4%. However, what does the shaded-region correspond to? This is the <em><span class="math inline">\(p\)</span>-value</em>. Recall the definition of the <span class="math inline">\(p\)</span>-value from Section <a href="hypothesis-testing.html#understanding-ht">9.3</a>:</p>
<blockquote>
<p>A <span class="math inline">\(p\)</span>-value is the probability of obtaining a test statistic just as or more extreme than the observed test statistic <em>assuming the null hypothesis <span class="math inline">\(H_0\)</span> is true</em>.</p>
</blockquote>
<p>So judging by the shaded region in Figure <a href="hypothesis-testing.html#fig:null-distribution-infer-2">9.9</a>, it seems we would somewhat rarely observe differences in popularity rates of 0.034 = 3.4% or more in a hypothesized universe of no difference in genre popularity. In other words, the <span class="math inline">\(p\)</span>-value is somewhat small. Hence, we would be inclined to reject this hypothesized universe, or using statistical language we would “reject <span class="math inline">\(H_0\)</span>.”</p>
<p>What fraction of the null distribution is shaded? In other words, what is the exact value of the <span class="math inline">\(p\)</span>-value? We can compute it using the <code><a href="https://infer.tidymodels.org/reference/get_p_value.html">get_p_value()</a></code> function with the same arguments as the previous <code><a href="https://infer.tidymodels.org/reference/shade_p_value.html">shade_p_value()</a></code> code:</p>
<div class="sourceCode" id="cb427"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">null_distribution</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://infer.tidymodels.org/reference/get_p_value.html">get_p_value</a></span><span class="op">(</span>obs_stat <span class="op">=</span> <span class="va">obs_diff_prop</span>, direction <span class="op">=</span> <span class="st">"right"</span><span class="op">)</span></span></code></pre></div>
<pre><code># A tibble: 1 × 1
  p_value
    &lt;dbl&gt;
1   0.065</code></pre>
<p>Keeping the definition of a <span class="math inline">\(p\)</span>-value in mind, the probability of observing a difference in popularity rates as large as 0.034 = 3.4% due to sampling variation alone in the null distribution is 0.065 = 6.5%. Since this <span class="math inline">\(p\)</span>-value is smaller than our pre-specified significance level <span class="math inline">\(\alpha\)</span> = 0.1, we reject the null hypothesis <span class="math inline">\(H_0: p_{m} - p_{d} = 0\)</span>. In other words, this <span class="math inline">\(p\)</span>-value is sufficiently small to reject our hypothesized universe of no difference in genre popularity. We instead have enough evidence to change our mind in favor of difference in genre popularity being a likely culprit here. Observe that whether we reject the null hypothesis <span class="math inline">\(H_0\)</span> or not depends in large part on our choice of significance level <span class="math inline">\(\alpha\)</span>. We will discuss this more in Subsection <a href="hypothesis-testing.html#choosing-alpha">9.5.3</a>.</p>
</div>
</div>
<div id="comparing-infer-workflows" class="section level3" number="9.4.2">
<h3>
<span class="header-section-number">9.4.2</span> Comparison with confidence intervals<a class="anchor" aria-label="anchor" href="#comparing-infer-workflows"><i class="fas fa-link"></i></a>
</h3>
<p>One of the great things about the <code>infer</code> package is that we can jump seamlessly between conducting hypothesis tests and constructing confidence intervals with minimal changes! Recall the code from the previous section that creates the null distribution, which in turn is needed to compute the <span class="math inline">\(p\)</span>-value:</p>
<div class="sourceCode" id="cb429"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">null_distribution</span> <span class="op">&lt;-</span> <span class="va">spotify_metal_deephouse</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://infer.tidymodels.org/reference/specify.html">specify</a></span><span class="op">(</span>formula <span class="op">=</span> <span class="va">popular_or_not</span> <span class="op">~</span> <span class="va">track_genre</span>, success <span class="op">=</span> <span class="st">"popular"</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://infer.tidymodels.org/reference/hypothesize.html">hypothesize</a></span><span class="op">(</span>null <span class="op">=</span> <span class="st">"independence"</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://infer.tidymodels.org/reference/generate.html">generate</a></span><span class="op">(</span>reps <span class="op">=</span> <span class="fl">1000</span>, type <span class="op">=</span> <span class="st">"permute"</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://infer.tidymodels.org/reference/calculate.html">calculate</a></span><span class="op">(</span>stat <span class="op">=</span> <span class="st">"diff in props"</span>, order <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"metal"</span>, <span class="st">"deep-house"</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>To create the corresponding bootstrap distribution needed to construct a 90% confidence interval for <span class="math inline">\(p_{m} - p_{d}\)</span>, we only need to make two changes. First, we remove the <code><a href="https://infer.tidymodels.org/reference/hypothesize.html">hypothesize()</a></code> step since we are no longer assuming a null hypothesis <span class="math inline">\(H_0\)</span> is true. We can do this by deleting or commenting out the <code><a href="https://infer.tidymodels.org/reference/hypothesize.html">hypothesize()</a></code> line of code. Second, we switch the <code>type</code> of resampling in the <code><a href="https://infer.tidymodels.org/reference/generate.html">generate()</a></code> step to be <code>"bootstrap"</code> instead of <code>"permute"</code>.</p>
<div class="sourceCode" id="cb430"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">bootstrap_distribution</span> <span class="op">&lt;-</span> <span class="va">spotify_metal_deephouse</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://infer.tidymodels.org/reference/specify.html">specify</a></span><span class="op">(</span>formula <span class="op">=</span> <span class="va">popular_or_not</span> <span class="op">~</span> <span class="va">track_genre</span>, success <span class="op">=</span> <span class="st">"popular"</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="co"># Change 1 - Remove hypothesize():</span></span>
<span>  <span class="co"># hypothesize(null = "independence") |&gt; </span></span>
<span>  <span class="co"># Change 2 - Switch type from "permute" to "bootstrap":</span></span>
<span>  <span class="fu"><a href="https://infer.tidymodels.org/reference/generate.html">generate</a></span><span class="op">(</span>reps <span class="op">=</span> <span class="fl">1000</span>, type <span class="op">=</span> <span class="st">"bootstrap"</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://infer.tidymodels.org/reference/calculate.html">calculate</a></span><span class="op">(</span>stat <span class="op">=</span> <span class="st">"diff in props"</span>, order <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"metal"</span>, <span class="st">"deep-house"</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>Using this <code>bootstrap_distribution</code>, let’s first compute the percentile-based confidence intervals, as we did in Section <a href="confidence-intervals.html#bootstrap-process">8.2.2</a>:</p>
<div class="sourceCode" id="cb431"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">percentile_ci</span> <span class="op">&lt;-</span> <span class="va">bootstrap_distribution</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://infer.tidymodels.org/reference/get_confidence_interval.html">get_confidence_interval</a></span><span class="op">(</span>level <span class="op">=</span> <span class="fl">0.90</span>, type <span class="op">=</span> <span class="st">"percentile"</span><span class="op">)</span></span>
<span><span class="va">percentile_ci</span></span></code></pre></div>
<pre><code># A tibble: 1 × 2
     lower_ci  upper_ci
        &lt;dbl&gt;     &lt;dbl&gt;
1 0.000355780 0.0701690</code></pre>
<p>Using our shorthand interpretation for 90% confidence intervals, we are 90% “confident” that the true difference in population proportions <span class="math inline">\(p_{m} - p_{d}\)</span> is between (0, 0.07). Let’s visualize <code>bootstrap_distribution</code> and this percentile-based 90% confidence interval for <span class="math inline">\(p_{m} - p_{d}\)</span> in Figure <a href="hypothesis-testing.html#fig:bootstrap-distribution-two-prop-percentile">9.10</a>.</p>
<div class="sourceCode" id="cb433"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://infer.tidymodels.org/reference/visualize.html">visualize</a></span><span class="op">(</span><span class="va">bootstrap_distribution</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://infer.tidymodels.org/reference/shade_confidence_interval.html">shade_confidence_interval</a></span><span class="op">(</span>endpoints <span class="op">=</span> <span class="va">percentile_ci</span><span class="op">)</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:bootstrap-distribution-two-prop-percentile"></span>
<img src="ModernDive_files/figure-html/bootstrap-distribution-two-prop-percentile-1.png" alt="Percentile-based 90\% confidence interval." width="\textwidth"><p class="caption">
FIGURE 9.10: Percentile-based 90% confidence interval.
</p>
</div>
<p>Notice a key value that is not included in the 90% confidence interval for <span class="math inline">\(p_{m} - p_{d}\)</span>: the value 0 (but just barely!). In other words, a difference of 0 is not included in our net, suggesting that <span class="math inline">\(p_{m}\)</span> and <span class="math inline">\(p_{d}\)</span> are truly different! Furthermore, observe how the entirety of the 90% confidence interval for <span class="math inline">\(p_{m} - p_{d}\)</span> lies above 0, suggesting that this difference is in favor of metal.</p>
<!--

CI: Cutting since Arturo moved away from standard error method

Since the bootstrap distribution appears to be roughly normally shaped, we can also use the standard error method as we did in Section \@ref(bootstrap-process). In this case, we must specify the `point_estimate` argument as the observed difference in promotion rates 0.034 = 3.4% saved in `obs_diff_prop`. This value acts as the center of the confidence interval.


``` r
se_ci <- bootstrap_distribution |> 
get_confidence_interval(level = 0.95, type = "se", 
point_estimate = obs_diff_prop)
se_ci
```

Let's visualize `bootstrap_distribution` again, but now the standard error based 95% confidence interval for $p_{m} - p_{d}$ in Figure \@ref(fig:bootstrap-distribution-two-prop-se). Again, notice how the value 0 is not included in our confidence interval, again suggesting that $p_{m}$ and $p_{d}$ are truly different!


``` r
visualize(bootstrap_distribution) + 
shade_confidence_interval(endpoints = se_ci)
```


-->
<div class="learncheck">
<p>
<strong><em>Learning check</em></strong>
</p>
</div>
<p><strong>(LC9.1)</strong> Why does the following code produce an error? In other words, what about the response and predictor variables make this not a possible computation with the <code>infer</code> package?</p>
<div class="sourceCode" id="cb434"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://moderndive.github.io/moderndive/">moderndive</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/tidymodels/infer">infer</a></span><span class="op">)</span></span>
<span><span class="va">null_distribution_mean</span> <span class="op">&lt;-</span> <span class="va">spotify_metal_deephouse</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://infer.tidymodels.org/reference/specify.html">specify</a></span><span class="op">(</span>formula <span class="op">=</span> <span class="va">popular_or_not</span> <span class="op">~</span> <span class="va">track_genre</span>, success <span class="op">=</span> <span class="st">"popular"</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://infer.tidymodels.org/reference/hypothesize.html">hypothesize</a></span><span class="op">(</span>null <span class="op">=</span> <span class="st">"independence"</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://infer.tidymodels.org/reference/generate.html">generate</a></span><span class="op">(</span>reps <span class="op">=</span> <span class="fl">1000</span>, type <span class="op">=</span> <span class="st">"permute"</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://infer.tidymodels.org/reference/calculate.html">calculate</a></span><span class="op">(</span>stat <span class="op">=</span> <span class="st">"diff in means"</span>, order <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"metal"</span>, <span class="st">"deep-house"</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p><strong>(LC9.2)</strong> Why are we relatively confident that the distributions of the sample proportions will be good approximations of the population distributions of popularity proportions for the two genres?</p>
<p><strong>(LC9.3)</strong> Using the definition of <em>p-value</em>, write in words what the <span class="math inline">\(p\)</span>-value represents for the hypothesis test comparing the popularity rates for metal and deep house.</p>
<div class="learncheck">

</div>
</div>
<div id="only-one-test" class="section level3" number="9.4.3">
<h3>
<span class="header-section-number">9.4.3</span> There is only one test<a class="anchor" aria-label="anchor" href="#only-one-test"><i class="fas fa-link"></i></a>
</h3>
<p>Let’s recap the steps necessary to conduct a hypothesis test using the terminology, notation, and definitions related to sampling you saw in Section <a href="hypothesis-testing.html#understanding-ht">9.3</a> and the <code>infer</code> workflow from Subsection <a href="hypothesis-testing.html#infer-workflow-ht">9.4.1</a>:</p>
<ol style="list-style-type: decimal">
<li>
<code><a href="https://infer.tidymodels.org/reference/specify.html">specify()</a></code> the variables of interest in your data frame.</li>
<li>
<code><a href="https://infer.tidymodels.org/reference/hypothesize.html">hypothesize()</a></code> the null hypothesis <span class="math inline">\(H_0\)</span>. In other words, set a “model for the universe” assuming <span class="math inline">\(H_0\)</span> is true.</li>
<li>
<code><a href="https://infer.tidymodels.org/reference/generate.html">generate()</a></code> shuffles assuming <span class="math inline">\(H_0\)</span> is true. In other words, <em>simulate</em> data assuming <span class="math inline">\(H_0\)</span> is true.</li>
<li>
<code><a href="https://infer.tidymodels.org/reference/calculate.html">calculate()</a></code> the <em>test statistic</em> of interest, both for the observed data and your <em>simulated</em> data.</li>
<li>
<code><a href="https://infer.tidymodels.org/reference/visualize.html">visualize()</a></code> the resulting <em>null distribution</em> and compute the <em><span class="math inline">\(p\)</span>-value</em> by comparing the null distribution to the observed test statistic.</li>
</ol>
<p>While this is a lot to digest, especially the first time you encounter hypothesis testing, the nice thing is that once you understand this general framework, then you can understand <em>any</em> hypothesis test. In a famous blog post, computer scientist Allen Downey called this the <a href="http://allendowney.blogspot.com/2016/06/there-is-still-only-one-test.html">“There is only one test”</a> framework, for which he created the flowchart displayed in Figure <a href="hypothesis-testing.html#fig:htdowney">9.11</a>.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:htdowney"></span>
<img src="images/copyright/there_is_only_one_test.png" alt="Allen Downey's hypothesis testing framework." width="100%"><p class="caption">
FIGURE 9.11: Allen Downey’s hypothesis testing framework.
</p>
</div>
<p>Notice its similarity with the “hypothesis testing with <code>infer</code>” diagram you saw in Figure <a href="hypothesis-testing.html#fig:inferht">9.7</a>. That is because the <code>infer</code> package was explicitly designed to match the “There is only one test” framework. So if you can understand the framework, you can easily generalize these ideas for all hypothesis-testing scenarios. Whether for population proportions <span class="math inline">\(p\)</span>, population means <span class="math inline">\(\mu\)</span>, differences in population proportions <span class="math inline">\(p_1 - p_2\)</span>, differences in population means <span class="math inline">\(\mu_1 - \mu_2\)</span>, and as you will see in Chapter <a href="inference-for-regression.html#inference-for-regression">10</a> on inference for regression, population regression slopes <span class="math inline">\(\beta_1\)</span> as well. In fact, it applies more generally even than just these examples to more complicated hypothesis tests and test statistics as well.</p>
<div class="learncheck">
<p>
<strong><em>Learning check</em></strong>
</p>
</div>
<p><strong>(LC9.4)</strong> Describe in a paragraph how we used Allen Downey’s diagram to conclude if a statistical difference existed between the popularity rate of metal and deep house for the Spotify example.</p>
<div class="learncheck">

</div>
</div>
</div>
<div id="ht-interpretation" class="section level2" number="9.5">
<h2>
<span class="header-section-number">9.5</span> Interpreting hypothesis tests<a class="anchor" aria-label="anchor" href="#ht-interpretation"><i class="fas fa-link"></i></a>
</h2>
<p>Interpreting the results of hypothesis tests is one of the more challenging aspects of this method for statistical inference. In this section, we will focus on ways to help with deciphering the process and address some common misconceptions.</p>
<div id="trial" class="section level3" number="9.5.1">
<h3>
<span class="header-section-number">9.5.1</span> Two possible outcomes<a class="anchor" aria-label="anchor" href="#trial"><i class="fas fa-link"></i></a>
</h3>
<p>In Section <a href="hypothesis-testing.html#understanding-ht">9.3</a>, we mentioned that given a pre-specified significance level <span class="math inline">\(\alpha\)</span> there are two possible outcomes of a hypothesis test:</p>
<ul>
<li>If the <span class="math inline">\(p\)</span>-value is less than <span class="math inline">\(\alpha\)</span>, then we <em>reject</em> the null hypothesis <span class="math inline">\(H_0\)</span> in favor of <span class="math inline">\(H_A\)</span>.</li>
<li>If the <span class="math inline">\(p\)</span>-value is greater than or equal to <span class="math inline">\(\alpha\)</span>, we <em>fail to reject</em> the null hypothesis <span class="math inline">\(H_0\)</span>.</li>
</ul>
<p>Unfortunately, the latter result is often misinterpreted as “accepting the null hypothesis <span class="math inline">\(H_0\)</span>.” While at first glance it may seem that the statements “failing to reject <span class="math inline">\(H_0\)</span>” and “accepting <span class="math inline">\(H_0\)</span>” are equivalent, there actually is a subtle difference. Saying that we “accept the null hypothesis <span class="math inline">\(H_0\)</span>” is equivalent to stating that “we think the null hypothesis <span class="math inline">\(H_0\)</span> is true.” However, saying that we “fail to reject the null hypothesis <span class="math inline">\(H_0\)</span>” is saying something else: “While <span class="math inline">\(H_0\)</span> might still be false, we do not have enough evidence to say so.” In other words, there is an absence of enough proof. However, the absence of proof is not proof of absence.</p>
<p>To further shed light on this distinction, let’s use the United States criminal justice system as an analogy. A criminal trial in the United States is a similar situation to hypothesis tests whereby a choice between two contradictory claims must be made about a defendant who is on trial:</p>
<ol style="list-style-type: decimal">
<li>The defendant is truly either “innocent” or “guilty.”</li>
<li>The defendant is presumed “innocent until proven guilty.”</li>
<li>The defendant is found guilty only if there is <em>strong evidence</em> that the defendant is guilty. The phrase “beyond a reasonable doubt” is often used as a guideline for determining a cutoff for when enough evidence exists to find the defendant guilty.</li>
<li>The defendant is found to be either “not guilty” or “guilty” in the ultimate verdict.</li>
</ol>
<p>In other words, <em>not guilty</em> verdicts are not suggesting the defendant is <em>innocent</em>, but instead that “while the defendant may still actually be guilty, there was not enough evidence to prove this fact.” Now let’s make the connection with hypothesis tests:</p>
<ol style="list-style-type: decimal">
<li>Either the null hypothesis <span class="math inline">\(H_0\)</span> or the alternative hypothesis <span class="math inline">\(H_A\)</span> is true.</li>
<li>Hypothesis tests are conducted assuming the null hypothesis <span class="math inline">\(H_0\)</span> is true.</li>
<li>We reject the null hypothesis <span class="math inline">\(H_0\)</span> in favor of <span class="math inline">\(H_A\)</span> only if the evidence found in the sample suggests that <span class="math inline">\(H_A\)</span> is true. The significance level <span class="math inline">\(\alpha\)</span> is used as a guideline to set the threshold on just how strong of evidence we require.</li>
<li>We ultimately decide to either “fail to reject <span class="math inline">\(H_0\)</span>” or “reject <span class="math inline">\(H_0\)</span>.”</li>
</ol>
<p>So while gut instinct may suggest “failing to reject <span class="math inline">\(H_0\)</span>” and “accepting <span class="math inline">\(H_0\)</span>” are equivalent statements, they are not. “Accepting <span class="math inline">\(H_0\)</span>” is equivalent to finding a defendant innocent. However, courts do not find defendants “innocent,” but rather they find them “not guilty.” Putting things differently, defense attorneys do not need to prove that their clients are innocent, rather they only need to prove that clients are not “guilty beyond a reasonable doubt.”</p>
<p>So going back to our songs activity in Section <a href="hypothesis-testing.html#ht-infer">9.4</a>, recall that our hypothesis test was <span class="math inline">\(H_0: p_{m} - p_{d} = 0\)</span> versus <span class="math inline">\(H_A: p_{m} - p_{d} &gt; 0\)</span> and that we used a pre-specified significance level of <span class="math inline">\(\alpha\)</span> = 0.1. We found a <span class="math inline">\(p\)</span>-value of 0.065. Since the <span class="math inline">\(p\)</span>-value was smaller than <span class="math inline">\(\alpha\)</span> = 0.1, we rejected <span class="math inline">\(H_0\)</span>. In other words, we found needed levels of evidence in this particular sample to say that <span class="math inline">\(H_0\)</span> is false at the <span class="math inline">\(\alpha\)</span> = 0.1 significance level. We also state this conclusion using non-statistical language: we found enough evidence in this data to suggest that there was a difference in the popularity of our two genres of music.</p>
</div>
<div id="types-of-errors" class="section level3" number="9.5.2">
<h3>
<span class="header-section-number">9.5.2</span> Types of errors<a class="anchor" aria-label="anchor" href="#types-of-errors"><i class="fas fa-link"></i></a>
</h3>
<p>Unfortunately, there is some chance a jury or a judge can make an incorrect decision in a criminal trial by reaching the wrong verdict. For example, finding a truly innocent defendant “guilty.” Or on the other hand, finding a truly guilty defendant “not guilty.” This can often stem from the fact that prosecutors do not have access to all the relevant evidence, but instead are limited to whatever evidence the police can find.</p>
<p>The same holds for hypothesis tests. We can make incorrect decisions about a population parameter because we only have a sample of data from the population and thus sampling variation can lead us to incorrect conclusions.</p>
<p>There are two possible erroneous conclusions in a criminal trial: either (1) a truly innocent person is found guilty or (2) a truly guilty person is found not guilty. Similarly, there are two possible errors in a hypothesis test: either (1) rejecting <span class="math inline">\(H_0\)</span> when in fact <span class="math inline">\(H_0\)</span> is true, called a <strong>Type I error</strong> or (2) failing to reject <span class="math inline">\(H_0\)</span> when in fact <span class="math inline">\(H_0\)</span> is false, called a <strong>Type II error</strong>. Another term used for “Type I error” is “false positive,” while another term for “Type II error” is “false negative.”</p>
<p>This risk of error is the price researchers pay for basing inference on a sample instead of performing a census on the entire population. But as we have seen in our numerous examples and activities so far, censuses are often very expensive and other times impossible, and thus researchers have no choice but to use a sample. Thus in any hypothesis test based on a sample, we have no choice but to tolerate some chance that a Type I error will be made and some chance that a Type II error will occur.</p>
<p>To help understand the concepts of Type I error and Type II errors, we apply these terms to our criminal justice analogy in Figure <a href="hypothesis-testing.html#fig:trial-errors-table">9.12</a>.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:trial-errors-table"></span>
<img src="images/gt_error_table_v2.png" alt="Type I and Type II errors in criminal trials." width="95%"><p class="caption">
FIGURE 9.12: Type I and Type II errors in criminal trials.
</p>
</div>
<p>Thus, a Type I error corresponds to incorrectly putting a truly innocent person in jail, whereas a Type II error corresponds to letting a truly guilty person go free. Let’s show the corresponding table in Figure <a href="hypothesis-testing.html#fig:hypo-test-errors">9.13</a> for hypothesis tests.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:hypo-test-errors"></span>
<img src="images/gt_error_table_ht_v2.png" alt="Type I and Type II errors in hypothesis tests." width="95%"><p class="caption">
FIGURE 9.13: Type I and Type II errors in hypothesis tests.
</p>
</div>
</div>
<div id="choosing-alpha" class="section level3" number="9.5.3">
<h3>
<span class="header-section-number">9.5.3</span> How do we choose alpha?<a class="anchor" aria-label="anchor" href="#choosing-alpha"><i class="fas fa-link"></i></a>
</h3>
<p>If we are using a sample to make inferences about a population, we are operating under uncertainty and run the risk of making statistical errors. These are not errors in calculations or in the procedure used, but errors in the sense that the sample used may lead us to construct a confidence interval that does not contain the true value of the population parameter, for example.
In the case of hypothesis testing, there are two well-defined errors: a Type I and a Type II error:</p>
<ul>
<li>A Type I Error is rejecting the null hypothesis when it is true. The probability of a Type I Error occurring is <span class="math inline">\(\alpha\)</span>, the <em>significance level</em>, which we defined in Subsection <a href="hypothesis-testing.html#one-sample-hyp">9.1.1</a> and in Section <a href="hypothesis-testing.html#understanding-ht">9.3</a>
</li>
<li>A Type II Error is failing to reject the null hypothesis when it is false. The probability of a Type II Error is denoted by <span class="math inline">\(\beta\)</span>. The value of <span class="math inline">\(1-\beta\)</span> is known as the <em>power</em> of the test.</li>
</ul>
<p>Ideally, we would like to minimize the errors, and we would like <span class="math inline">\(\alpha = 0\)</span> and <span class="math inline">\(\beta = 0\)</span>. However, this is not possible as there will always be the possibility of committing one of these error when making a decision based on sample data. Furthermore, these two error probabilities are inversely related. As the probability of a Type I error goes down, the probability of a Type II error goes up.</p>
<p>When constructing a hypothesis test, we have control of the probability of committing a Type I Error because we can decide what is the significance level <span class="math inline">\(\alpha\)</span> we want to use. Once <span class="math inline">\(\alpha\)</span> has been pre-specified, we try to minimize <span class="math inline">\(\beta\)</span>, the fraction of incorrect non-rejections of the null hypothesis.</p>
<p>So for example if we used <span class="math inline">\(\alpha\)</span> = 0.01, we would be using a hypothesis testing procedure that in the long run would incorrectly reject the null hypothesis <span class="math inline">\(H_0\)</span> one percent of the time. This is analogous to setting the confidence level of a confidence interval.</p>
<p>So what value should you use for <span class="math inline">\(\alpha\)</span>? While different fields of study have adopted different conventions, although <span class="math inline">\(\alpha = 0.05\)</span> is perhaps the most popular threshold, there is nothing special about this or any other number. Please review Subsection <a href="hypothesis-testing.html#one-sample-hyp">9.1.1</a> and our discussion about <span class="math inline">\(\alpha\)</span> and our tolerance for uncertainty. In addition, observe that choosing a relatively small value of <span class="math inline">\(\alpha\)</span> reduces our chances of rejecting the null hypothesis, and also of committing a Type I Error; but increases the probability of committing a Type II Error.</p>
<p>On the other hand, choosing a relatively large value of <span class="math inline">\(\alpha\)</span> increases the chances of failing to reject the null hypothesis, and also of committing a Type I Error; but reduces the probability of committing a Type II Error. Depending on the problem at hand, we may be willing to have a larger significance level in certain scenarios and a smaller significance level in others.</p>
<div class="learncheck">
<p>
<strong><em>Learning check</em></strong>
</p>
</div>
<p><strong>(LC9.5)</strong> What is wrong about saying, “The defendant is innocent.” based on the US system of criminal trials?</p>
<p><strong>(LC9.6)</strong> What is the purpose of hypothesis testing?</p>
<p><strong>(LC9.7)</strong> What are some flaws with hypothesis testing? How could we alleviate them?</p>
<p><strong>(LC9.8)</strong> Consider two <span class="math inline">\(\alpha\)</span> significance levels of 0.1 and 0.01. Of the two, which would lead to a higher chance of committing a Type I Error?</p>
<div class="learncheck">

</div>
</div>
</div>
<div id="ht-case-study" class="section level2" number="9.6">
<h2>
<span class="header-section-number">9.6</span> Case study: are action or romance movies rated higher?<a class="anchor" aria-label="anchor" href="#ht-case-study"><i class="fas fa-link"></i></a>
</h2>
<p>Let’s apply our knowledge of hypothesis testing to answer the question: “Are action or romance movies rated higher on IMDb?”. <a href="https://www.imdb.com/">IMDb</a> is a database on the internet providing information on movie and television show casts, plot summaries, trivia, and ratings. We will investigate if, on average, action or romance movies get higher ratings on IMDb.</p>
<div id="imdb-data" class="section level3" number="9.6.1">
<h3>
<span class="header-section-number">9.6.1</span> IMDb ratings data<a class="anchor" aria-label="anchor" href="#imdb-data"><i class="fas fa-link"></i></a>
</h3>
<p>The <code>movies</code> dataset in the <code>ggplot2movies</code> package contains information on 58,788 movies that have been rated by users of IMDb.com.</p>
<div class="sourceCode" id="cb435"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">movies</span></span></code></pre></div>
<pre><code># A tibble: 58,788 × 24
   title        year length budget rating votes    r1    r2    r3    r4    r5    r6    r7    r8    r9   r10 mpaa  Action
   &lt;chr&gt;       &lt;int&gt;  &lt;int&gt;  &lt;int&gt;  &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;  &lt;int&gt;
 1 $            1971    121     NA    6.4   348   4.5   4.5   4.5   4.5  14.5  24.5  24.5  14.5   4.5   4.5 ""         0
 2 $1000 a To…  1939     71     NA    6      20   0    14.5   4.5  24.5  14.5  14.5  14.5   4.5   4.5  14.5 ""         0
 3 $21 a Day …  1941      7     NA    8.2     5   0     0     0     0     0    24.5   0    44.5  24.5  24.5 ""         0
 4 $40,000      1996     70     NA    8.2     6  14.5   0     0     0     0     0     0     0    34.5  45.5 ""         0
 5 $50,000 Cl…  1975     71     NA    3.4    17  24.5   4.5   0    14.5  14.5   4.5   0     0     0    24.5 ""         0
 6 $pent        2000     91     NA    4.3    45   4.5   4.5   4.5  14.5  14.5  14.5   4.5   4.5  14.5  14.5 ""         0
 7 $windle      2002     93     NA    5.3   200   4.5   0     4.5   4.5  24.5  24.5  14.5   4.5   4.5  14.5 "R"        1
 8 '15'         2002     25     NA    6.7    24   4.5   4.5   4.5   4.5   4.5  14.5  14.5  14.5   4.5  14.5 ""         0
 9 '38          1987     97     NA    6.6    18   4.5   4.5   4.5   0     0     0    34.5  14.5   4.5  24.5 ""         0
10 '49-'17      1917     61     NA    6      51   4.5   0     4.5   4.5   4.5  44.5  14.5   4.5   4.5   4.5 ""         0
# ℹ 58,778 more rows
# ℹ 6 more variables: Animation &lt;int&gt;, Comedy &lt;int&gt;, Drama &lt;int&gt;, Documentary &lt;int&gt;, Romance &lt;int&gt;, Short &lt;int&gt;</code></pre>
<p>We will focus on a random sample of 68 movies that are classified as either “action” or “romance” movies but not both. We disregard movies that are classified as both so that we can assign all 68 movies into either category. Furthermore, since the original <code>movies</code> dataset was a little messy, we provide a pre-wrangled version of our data in the <code>movies_sample</code> data frame included in the <code>moderndive</code> package. If you are curious, you can look at the necessary data-wrangling code to do this on <a href="https://github.com/moderndive/moderndive/blob/master/data-raw/process_data_sets.R">GitHub</a>.</p>
<div class="sourceCode" id="cb437"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">movies_sample</span></span></code></pre></div>
<pre><code># A tibble: 68 × 4
   title                     year rating genre  
   &lt;chr&gt;                    &lt;int&gt;  &lt;dbl&gt; &lt;chr&gt;  
 1 Underworld                1985    3.1 Action 
 2 Love Affair               1932    6.3 Romance
 3 Junglee                   1961    6.8 Romance
 4 Eversmile, New Jersey     1989    5   Romance
 5 Search and Destroy        1979    4   Action 
 6 Secreto de Romelia, El    1988    4.9 Romance
 7 Amants du Pont-Neuf, Les  1991    7.4 Romance
 8 Illicit Dreams            1995    3.5 Action 
 9 Kabhi Kabhie              1976    7.7 Romance
10 Electric Horseman, The    1979    5.8 Romance
# ℹ 58 more rows</code></pre>
<p>The variables include the <code>title</code> and <code>year</code> the movie was filmed. Furthermore, we have a numerical variable <code>rating</code>, which is the IMDb rating out of 10 stars, and a binary categorical variable <code>genre</code> indicating if the movie was an <code>Action</code> or <code>Romance</code> movie. We are interested in whether <code>Action</code> or <code>Romance</code> movies got a higher <code>rating</code> on average.</p>
<p>Let’s perform an exploratory data analysis of this data. Recall from Subsection <a href="viz.html#geomboxplot">2.7.1</a> that a boxplot is a visualization we can use to show the relationship between a numerical and a categorical variable. Another option you saw in Section <a href="viz.html#facets">2.6</a> would be to use a faceted histogram. However, in the interest of brevity, let’s only present the boxplot in Figure <a href="hypothesis-testing.html#fig:action-romance-boxplot">9.14</a>.</p>
<div class="sourceCode" id="cb439"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span>data <span class="op">=</span> <span class="va">movies_sample</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">genre</span>, y <span class="op">=</span> <span class="va">rating</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_boxplot.html">geom_boxplot</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>y <span class="op">=</span> <span class="st">"IMDb rating"</span><span class="op">)</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:action-romance-boxplot"></span>
<img src="ModernDive_files/figure-html/action-romance-boxplot-1.png" alt="Boxplot of IMDb rating vs. genre." width="\textwidth"><p class="caption">
FIGURE 9.14: Boxplot of IMDb rating vs. genre.
</p>
</div>
<p>Eyeballing Figure <a href="hypothesis-testing.html#fig:action-romance-boxplot">9.14</a>, romance movies have a higher median rating. Do we have reason to believe, however, that there is a <em>significant</em> difference between the mean <code>rating</code> for action movies compared to romance movies? It is hard to say just based on this plot. The boxplot does show that the median sample rating is higher for romance movies.</p>
<p>However, there is a large amount of overlap between the boxes. Recall that the median is not necessarily the same as the mean either, depending on whether the distribution is skewed.</p>
<p>Let’s calculate some summary statistics split by the binary categorical variable <code>genre</code>: the number of movies, the mean rating, and the standard deviation split by <code>genre</code>. We will do this using <code>dplyr</code> data wrangling verbs. Notice in particular how we count the number of each type of movie using the <code><a href="https://dplyr.tidyverse.org/reference/context.html">n()</a></code> summary function.</p>
<div class="sourceCode" id="cb440"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">movies_sample</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/group_by.html">group_by</a></span><span class="op">(</span><span class="va">genre</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/summarise.html">summarize</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/context.html">n</a></span><span class="op">(</span><span class="op">)</span>, mean_rating <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">rating</span><span class="op">)</span>, std_dev <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">rating</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code># A tibble: 2 × 4
  genre       n mean_rating std_dev
  &lt;chr&gt;   &lt;int&gt;       &lt;dbl&gt;   &lt;dbl&gt;
1 Action     32     5.275   1.36121
2 Romance    36     6.32222 1.60963</code></pre>
<p>Observe that we have 36 movies with an average rating of 6.322 stars and 32 movies with an average rating of 5.275 stars. The difference in these average ratings is thus 6.322 - 5.275 = 1.047. So there appears to be an edge of 1.047 stars in favor of romance movies. The question is, however, are these results indicative of a true difference for <em>all</em> romance and action movies? Or could we attribute this difference to chance <em>sampling variation</em>?</p>
</div>
<div id="sampling-scenario-1" class="section level3" number="9.6.2">
<h3>
<span class="header-section-number">9.6.2</span> Sampling scenario<a class="anchor" aria-label="anchor" href="#sampling-scenario-1"><i class="fas fa-link"></i></a>
</h3>
<p>Let’s now revisit this study in terms of terminology and notation related to sampling we studied in Subsection <a href="sampling.html#terminology-and-notation">7.2.1</a>. The <em>study population</em> is all movies in the IMDb database that are either action or romance (but not both). The <em>sample</em> from this population is the 68 movies included in the <code>movies_sample</code> dataset.</p>
<p>Since this sample was randomly taken from the population <code>movies</code>, it is representative of all romance and action movies on IMDb. Thus, any analysis and results based on <code>movies_sample</code> can generalize to the entire population. What are the relevant <em>population parameter</em> and <em>point estimates</em>? We introduce the fourth sampling scenario in Table <a href="hypothesis-testing.html#tab:summarytable-ch10">9.6</a>.</p>
<div class="inline-table"><table class="table" style="font-size: 16px; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:summarytable-ch10">TABLE 9.6: </span>Scenarios of sampling for inference
</caption>
<thead><tr>
<th style="text-align:right;">
Scenario
</th>
<th style="text-align:left;">
Population parameter
</th>
<th style="text-align:left;">
Notation
</th>
<th style="text-align:left;">
Point estimate
</th>
<th style="text-align:left;">
Symbol(s)
</th>
</tr></thead>
<tbody>
<tr>
<td style="text-align:right;width: 0.5in; ">
1
</td>
<td style="text-align:left;width: 0.7in; ">
Population proportion
</td>
<td style="text-align:left;width: 1in; ">
<span class="math inline">\(p\)</span>
</td>
<td style="text-align:left;width: 1.1in; ">
Sample proportion
</td>
<td style="text-align:left;width: 1in; ">
<span class="math inline">\(\widehat{p}\)</span>
</td>
</tr>
<tr>
<td style="text-align:right;width: 0.5in; ">
2
</td>
<td style="text-align:left;width: 0.7in; ">
Population mean
</td>
<td style="text-align:left;width: 1in; ">
<span class="math inline">\(\mu\)</span>
</td>
<td style="text-align:left;width: 1.1in; ">
Sample mean
</td>
<td style="text-align:left;width: 1in; ">
<span class="math inline">\(\overline{x}\)</span> or <span class="math inline">\(\widehat{\mu}\)</span>
</td>
</tr>
<tr>
<td style="text-align:right;width: 0.5in; ">
3
</td>
<td style="text-align:left;width: 0.7in; ">
Difference in population proportions
</td>
<td style="text-align:left;width: 1in; ">
<span class="math inline">\(p_1 - p_2\)</span>
</td>
<td style="text-align:left;width: 1.1in; ">
Difference in sample proportions
</td>
<td style="text-align:left;width: 1in; ">
<span class="math inline">\(\widehat{p}_1 - \widehat{p}_2\)</span>
</td>
</tr>
<tr>
<td style="text-align:right;width: 0.5in; ">
4
</td>
<td style="text-align:left;width: 0.7in; ">
Difference in population means
</td>
<td style="text-align:left;width: 1in; ">
<span class="math inline">\(\mu_1 - \mu_2\)</span>
</td>
<td style="text-align:left;width: 1.1in; ">
Difference in sample means
</td>
<td style="text-align:left;width: 1in; ">
<span class="math inline">\(\overline{x}_1 - \overline{x}_2\)</span> or <span class="math inline">\(\widehat{\mu}_1 - \widehat{\mu}_2\)</span>
</td>
</tr>
</tbody>
</table></div>
<p>So, whereas the sampling bowl exercise in Section <a href="sampling.html#sampling-activity">7.1</a> concerned <em>proportions</em>, the almonds exercise in Section <a href="confidence-intervals.html#revisit-almond-bootstrap">8.2.1</a> concerned <em>means</em>, the case study on whether yawning is contagious in Section <a href="confidence-intervals.html#case-study-two-prop-ci">8.4</a> and the music genre activity in Section <a href="hypothesis-testing.html#ht-activity">9.2</a> concerned <em>differences in proportions</em>, we are now concerned with <em>differences in means</em>.</p>
<p>In other words, the population parameter of interest is the difference in population mean ratings <span class="math inline">\(\mu_a - \mu_r\)</span>, where <span class="math inline">\(\mu_a\)</span> is the mean rating of all action movies on IMDb and similarly <span class="math inline">\(\mu_r\)</span> is the mean rating of all romance movies. Additionally the point estimate/sample statistic of interest is the difference in sample means <span class="math inline">\(\overline{x}_a - \overline{x}_r\)</span>, where <span class="math inline">\(\overline{x}_a\)</span> is the mean rating of the <span class="math inline">\(n_a\)</span> = 32 movies in our sample and <span class="math inline">\(\overline{x}_r\)</span> is the mean rating of the <span class="math inline">\(n_r\)</span> = 36 in our sample. Based on our earlier exploratory data analysis, our estimate <span class="math inline">\(\overline{x}_a - \overline{x}_r\)</span> is <span class="math inline">\(5.275 - 6.322 = -1.047\)</span>.</p>
<p>So there appears to be a slight difference of -1.047 in favor of romance movies. The question is, however, could this difference of -1.047 be merely due to chance and sampling variation? Or are these results indicative of a true difference in mean ratings for <em>all</em> romance and action movies on IMDb? To answer this question, we will use hypothesis testing.</p>
</div>
<div id="conducting-the-hypothesis-test" class="section level3" number="9.6.3">
<h3>
<span class="header-section-number">9.6.3</span> Conducting the hypothesis test<a class="anchor" aria-label="anchor" href="#conducting-the-hypothesis-test"><i class="fas fa-link"></i></a>
</h3>
<p>We will be testing:</p>
<p><span class="math display">\[
\begin{aligned}
H_0 &amp;: \mu_a - \mu_r = 0\\
\text{vs } H_A&amp;: \mu_a - \mu_r \neq 0
\end{aligned}
\]</span></p>
<p>In other words, the null hypothesis <span class="math inline">\(H_0\)</span> suggests that both romance and action movies have the same mean rating. This is the “hypothesized universe” we will <em>assume</em> is true. On the other hand, the alternative hypothesis <span class="math inline">\(H_A\)</span> suggests that there is a difference. Unlike the one-sided alternative we used in the popularity exercise <span class="math inline">\(H_A: p_m - p_f &gt; 0\)</span>, we are now considering a two-sided alternative of <span class="math inline">\(H_A: \mu_a - \mu_r \neq 0\)</span>.</p>
<p>Furthermore, we will pre-specify a low significance level of <span class="math inline">\(\alpha\)</span> = 0.001. By setting this value low, all things being equal, there is a lower chance that the <span class="math inline">\(p\)</span>-value will be less than <span class="math inline">\(\alpha\)</span>. Thus, there is a lower chance that we will reject the null hypothesis <span class="math inline">\(H_0\)</span> in favor of the alternative hypothesis <span class="math inline">\(H_A\)</span>. In other words, we will reject the hypothesis that there is no difference in mean ratings for all action and romance movies, only if we have quite strong evidence. This is known as a “conservative” hypothesis testing procedure.</p>
<div id="specify-variables-3" class="section level4 unnumbered">
<h4>1. <code>specify</code> variables<a class="anchor" aria-label="anchor" href="#specify-variables-3"><i class="fas fa-link"></i></a>
</h4>
<p>Let’s now perform all the steps of the <code>infer</code> workflow. We first <code><a href="https://infer.tidymodels.org/reference/specify.html">specify()</a></code> the variables of interest in the <code>movies_sample</code> data frame using the formula <code>rating ~ genre</code>. This tells <code>infer</code> that the numerical variable <code>rating</code> is the outcome variable, while the binary variable <code>genre</code> is the explanatory variable. Note that unlike previously when we were interested in proportions, since we are now interested in the mean of a numerical variable, we do not need to set the <code>success</code> argument.</p>
<div class="sourceCode" id="cb442"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">movies_sample</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://infer.tidymodels.org/reference/specify.html">specify</a></span><span class="op">(</span>formula <span class="op">=</span> <span class="va">rating</span> <span class="op">~</span> <span class="va">genre</span><span class="op">)</span></span></code></pre></div>
<pre><code>Response: rating (numeric)
Explanatory: genre (factor)
# A tibble: 68 × 2
   rating genre  
    &lt;dbl&gt; &lt;fct&gt;  
 1    3.1 Action 
 2    6.3 Romance
 3    6.8 Romance
 4    5   Romance
 5    4   Action 
 6    4.9 Romance
 7    7.4 Romance
 8    3.5 Action 
 9    7.7 Romance
10    5.8 Romance
# ℹ 58 more rows</code></pre>
<p>Observe at this point that the data in <code>movies_sample</code> has not changed. The only change so far is the newly defined <code>Response: rating (numeric)</code> and <code>Explanatory: genre (factor)</code> <em>meta-data</em>.</p>
</div>
<div id="hypothesize-the-null-1" class="section level4 unnumbered">
<h4>2. <code>hypothesize</code> the null<a class="anchor" aria-label="anchor" href="#hypothesize-the-null-1"><i class="fas fa-link"></i></a>
</h4>
<p>We set the null hypothesis <span class="math inline">\(H_0: \mu_a - \mu_r = 0\)</span> by using the <code><a href="https://infer.tidymodels.org/reference/hypothesize.html">hypothesize()</a></code> function. Since we have two samples, action and romance movies, we set <code>null</code> to be <code>"independence"</code> as we described in Section <a href="hypothesis-testing.html#ht-infer">9.4</a>.</p>
<div class="sourceCode" id="cb444"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">movies_sample</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://infer.tidymodels.org/reference/specify.html">specify</a></span><span class="op">(</span>formula <span class="op">=</span> <span class="va">rating</span> <span class="op">~</span> <span class="va">genre</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://infer.tidymodels.org/reference/hypothesize.html">hypothesize</a></span><span class="op">(</span>null <span class="op">=</span> <span class="st">"independence"</span><span class="op">)</span></span></code></pre></div>
<pre><code>Response: rating (numeric)
Explanatory: genre (factor)
Null Hypothesis: independence
# A tibble: 68 × 2
   rating genre  
    &lt;dbl&gt; &lt;fct&gt;  
 1    3.1 Action 
 2    6.3 Romance
 3    6.8 Romance
 4    5   Romance
 5    4   Action 
 6    4.9 Romance
 7    7.4 Romance
 8    3.5 Action 
 9    7.7 Romance
10    5.8 Romance
# ℹ 58 more rows</code></pre>
</div>
<div id="generate-replicates-3" class="section level4 unnumbered">
<h4>3. <code>generate</code> replicates<a class="anchor" aria-label="anchor" href="#generate-replicates-3"><i class="fas fa-link"></i></a>
</h4>
<p>After we have set the null hypothesis, we generate “shuffled” replicates assuming the null hypothesis is true by repeating the shuffling/permutation exercise you performed in Section <a href="hypothesis-testing.html#ht-activity">9.2</a>.</p>
<p>We will repeat this resampling without replacement of <code>type = "permute"</code> a total of <code>reps = 1000</code> times. Feel free to run the code to check out what the <code><a href="https://infer.tidymodels.org/reference/generate.html">generate()</a></code> step produces.</p>
<div class="sourceCode" id="cb446"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">movies_sample</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://infer.tidymodels.org/reference/specify.html">specify</a></span><span class="op">(</span>formula <span class="op">=</span> <span class="va">rating</span> <span class="op">~</span> <span class="va">genre</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://infer.tidymodels.org/reference/hypothesize.html">hypothesize</a></span><span class="op">(</span>null <span class="op">=</span> <span class="st">"independence"</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://infer.tidymodels.org/reference/generate.html">generate</a></span><span class="op">(</span>reps <span class="op">=</span> <span class="fl">1000</span>, type <span class="op">=</span> <span class="st">"permute"</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/utils/View.html">View</a></span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
</div>
<div id="calculate-summary-statistics-3" class="section level4 unnumbered">
<h4>4. <code>calculate</code> summary statistics<a class="anchor" aria-label="anchor" href="#calculate-summary-statistics-3"><i class="fas fa-link"></i></a>
</h4>
<p>Now that we have 1000 replicated “shuffles” assuming the null hypothesis <span class="math inline">\(H_0\)</span> that both <code>Action</code> and <code>Romance</code> movies on average have the same ratings on IMDb, let’s <code><a href="https://infer.tidymodels.org/reference/calculate.html">calculate()</a></code> the appropriate summary statistic for these 1000 replicated shuffles. From Section <a href="hypothesis-testing.html#understanding-ht">9.3</a>, summary statistics relating to hypothesis testing have a specific name: <em>test statistics</em>. Since the unknown population parameter of interest is the difference in population means <span class="math inline">\(\mu_{a} - \mu_{r}\)</span>, the test statistic of interest here is the difference in sample means <span class="math inline">\(\overline{x}_{a} - \overline{x}_{r}\)</span>.</p>
<p>For each of our 1000 shuffles, we can calculate this test statistic by setting <code>stat = "diff in means"</code>. Furthermore, since we are interested in <span class="math inline">\(\overline{x}_{a} - \overline{x}_{r}\)</span>, we set <code>order = c("Action", "Romance")</code>. Let’s save the results in a data frame called <code>null_distribution_movies</code>:</p>
<div class="sourceCode" id="cb447"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">null_distribution_movies</span> <span class="op">&lt;-</span> <span class="va">movies_sample</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://infer.tidymodels.org/reference/specify.html">specify</a></span><span class="op">(</span>formula <span class="op">=</span> <span class="va">rating</span> <span class="op">~</span> <span class="va">genre</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://infer.tidymodels.org/reference/hypothesize.html">hypothesize</a></span><span class="op">(</span>null <span class="op">=</span> <span class="st">"independence"</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://infer.tidymodels.org/reference/generate.html">generate</a></span><span class="op">(</span>reps <span class="op">=</span> <span class="fl">1000</span>, type <span class="op">=</span> <span class="st">"permute"</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://infer.tidymodels.org/reference/calculate.html">calculate</a></span><span class="op">(</span>stat <span class="op">=</span> <span class="st">"diff in means"</span>, order <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"Action"</span>, <span class="st">"Romance"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">null_distribution_movies</span></span></code></pre></div>
<pre><code># A tibble: 1,000 × 2
   replicate      stat
       &lt;int&gt;     &lt;dbl&gt;
 1         1  0.511111
 2         2  0.345833
 3         3 -0.327083
 4         4 -0.209028
 5         5 -0.433333
 6         6 -0.102778
 7         7  0.387153
 8         8  0.168750
 9         9  0.257292
10        10  0.334028
# ℹ 990 more rows</code></pre>
<p>Observe that we have 1000 values of <code>stat</code>, each representing one instance of <span class="math inline">\(\overline{x}_{a} - \overline{x}_{r}\)</span>. The 1000 values form the <em>null distribution</em>, which is the technical term for the sampling distribution of the difference in sample means <span class="math inline">\(\overline{x}_{a} - \overline{x}_{r}\)</span> assuming <span class="math inline">\(H_0\)</span> is true. What happened in real life? What was the observed difference in popularity rates? What was the <em>observed test statistic</em> <span class="math inline">\(\overline{x}_{a} - \overline{x}_{r}\)</span>? Recall from our earlier data wrangling, this observed difference in means was <span class="math inline">\(5.275 - 6.322 = -1.047\)</span>. We can also achieve this using the code that constructed the null distribution <code>null_distribution_movies</code> but with the <code><a href="https://infer.tidymodels.org/reference/hypothesize.html">hypothesize()</a></code> and <code><a href="https://infer.tidymodels.org/reference/generate.html">generate()</a></code> steps removed. We save this in <code>obs_diff_means</code>:</p>
<div class="sourceCode" id="cb449"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">obs_diff_means</span> <span class="op">&lt;-</span> <span class="va">movies_sample</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://infer.tidymodels.org/reference/specify.html">specify</a></span><span class="op">(</span>formula <span class="op">=</span> <span class="va">rating</span> <span class="op">~</span> <span class="va">genre</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://infer.tidymodels.org/reference/calculate.html">calculate</a></span><span class="op">(</span>stat <span class="op">=</span> <span class="st">"diff in means"</span>, order <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"Action"</span>, <span class="st">"Romance"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">obs_diff_means</span></span></code></pre></div>
<pre><code>Response: rating (numeric)
Explanatory: genre (factor)
# A tibble: 1 × 1
      stat
     &lt;dbl&gt;
1 -1.04722</code></pre>
</div>
<div id="visualize-the-p-value-1" class="section level4 unnumbered">
<h4>5. <code>visualize</code> the p-value<a class="anchor" aria-label="anchor" href="#visualize-the-p-value-1"><i class="fas fa-link"></i></a>
</h4>
<p>Lastly, in order to compute the <span class="math inline">\(p\)</span>-value, we have to assess how “extreme” the observed difference in means of -1.047 is. We do this by comparing -1.047 to our null distribution, which was constructed in a hypothesized universe of no true difference in movie ratings. We visualize both the null distribution and the <span class="math inline">\(p\)</span>-value in Figure <a href="hypothesis-testing.html#fig:null-distribution-movies-2">9.15</a>. Unlike our example in Subsection <a href="hypothesis-testing.html#infer-workflow-ht">9.4.1</a> involving music popularity, since we have a two-sided <span class="math inline">\(H_A: \mu_a - \mu_r \neq 0\)</span>, we have to allow for both possibilities for <em>more extreme</em>, so we set <code>direction = "both"</code>.</p>
<div class="sourceCode" id="cb451"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://infer.tidymodels.org/reference/visualize.html">visualize</a></span><span class="op">(</span><span class="va">null_distribution_movies</span>, bins <span class="op">=</span> <span class="fl">10</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://infer.tidymodels.org/reference/shade_p_value.html">shade_p_value</a></span><span class="op">(</span>obs_stat <span class="op">=</span> <span class="va">obs_diff_means</span>, direction <span class="op">=</span> <span class="st">"both"</span><span class="op">)</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:null-distribution-movies-2"></span>
<img src="ModernDive_files/figure-html/null-distribution-movies-2-1.png" alt="Null distribution, observed test statistic, and $p$-value." width="\textwidth"><p class="caption">
FIGURE 9.15: Null distribution, observed test statistic, and <span class="math inline">\(p\)</span>-value.
</p>
</div>
<p>Let’s go over the elements of this plot. First, the histogram is the <em>null distribution</em>. Second, the solid line is the <em>observed test statistic</em>, or the difference in sample means we observed in real life of <span class="math inline">\(5.275 - 6.322 = -1.047\)</span>. Third, the two shaded areas of the histogram form the <em><span class="math inline">\(p\)</span>-value</em>, or the probability of obtaining a test statistic just as or more extreme than the observed test statistic <em>assuming the null hypothesis <span class="math inline">\(H_0\)</span> is true</em>.</p>
<p>What proportion of the null distribution is shaded? In other words, what is the numerical value of the <span class="math inline">\(p\)</span>-value? We use the <code><a href="https://infer.tidymodels.org/reference/get_p_value.html">get_p_value()</a></code> function to compute this value:</p>
<div class="sourceCode" id="cb452"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">null_distribution_movies</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://infer.tidymodels.org/reference/get_p_value.html">get_p_value</a></span><span class="op">(</span>obs_stat <span class="op">=</span> <span class="va">obs_diff_means</span>, direction <span class="op">=</span> <span class="st">"both"</span><span class="op">)</span></span></code></pre></div>
<pre><code># A tibble: 1 × 1
  p_value
    &lt;dbl&gt;
1   0.004</code></pre>
<p>This <span class="math inline">\(p\)</span>-value of 0.004 is very small. In other words, there is a very small chance that we would observe a difference of 5.275 - 6.322 = -1.047 in a hypothesized universe where there was truly no difference in ratings.</p>
<p>But this <span class="math inline">\(p\)</span>-value is larger than our (even smaller) pre-specified <span class="math inline">\(\alpha\)</span> significance level of 0.001. Thus, we are inclined to fail to reject the null hypothesis <span class="math inline">\(H_0: \mu_a - \mu_r = 0\)</span>. In non-statistical language, the conclusion is: we do not have the evidence needed in this sample of data to suggest that we should reject the hypothesis that there is no difference in mean IMDb ratings between romance and action movies. We, thus, cannot say that a difference exists in romance and action movie ratings, on average, for all IMDb movies.</p>
<div class="learncheck">
<p>
<strong><em>Learning check</em></strong>
</p>
</div>
<p><strong>(LC9.9)</strong> Conduct the same analysis comparing action movies versus romantic movies using the median rating instead of the mean rating. What was different and what was the same?</p>
<p><strong>(LC9.10)</strong> What conclusions can you make from viewing the faceted histogram looking at <code>rating</code> versus <code>genre</code> that you could not see when looking at the boxplot?</p>
<p><strong>(LC9.11)</strong> Describe in a paragraph how we used Allen Downey’s diagram to conclude if a statistical difference existed between mean movie ratings for action and romance movies.</p>
<p><strong>(LC9.12)</strong> Why are we relatively confident that the distributions of the sample ratings will be good approximations of the population distributions of ratings for the two genres?</p>
<p><strong>(LC9.13)</strong> Using the definition of <span class="math inline">\(p\)</span>-value, write in words what the <span class="math inline">\(p\)</span>-value represents for the hypothesis test comparing the mean rating of romance to action movies.</p>
<p><strong>(LC9.14)</strong> What is the value of the <span class="math inline">\(p\)</span>-value for the two-sided hypothesis test comparing the mean rating of romance to action movies?</p>
<p><strong>(LC9.15)</strong> Test your data-wrangling knowledge and EDA skills:</p>
<ul>
<li>Use <code>dplyr</code> and <code>tidyr</code> to create the necessary data frame focused on only action and romance movies (but not both) from the <code>movies</code> data frame in the <code>ggplot2movies</code> package.</li>
<li>Make a boxplot and a faceted histogram of this population data comparing ratings of action and romance movies from IMDb.</li>
<li>Discuss how these plots compare to the similar plots produced for the <code>movies_sample</code> data.</li>
</ul>
<div class="learncheck">

</div>
</div>
</div>
</div>
<div id="nhst-conclusion" class="section level2" number="9.7">
<h2>
<span class="header-section-number">9.7</span> Summary and Final Remarks<a class="anchor" aria-label="anchor" href="#nhst-conclusion"><i class="fas fa-link"></i></a>
</h2>
<div id="theory-hypo" class="section level3" number="9.7.1">
<h3>
<span class="header-section-number">9.7.1</span> Theory-based approach for two-sample hypothesis tests<a class="anchor" aria-label="anchor" href="#theory-hypo"><i class="fas fa-link"></i></a>
</h3>
<p>As we did previously when we discussed the theory-based approach for confidence intervals or hypothesis tests for the one-sample problem, we discuss now some of the theory needed to perform two-sample hypothesis tests. We present an example of a traditional theory-based method to conduct hypothesis tests. This method relies on the Central Limit Theorem and properties of random variables, expected value, variance, and standard deviation. It is also a direct extension of the one-sample problem discussed in Section <a href="hypothesis-testing.html#tying-CI-hypo">9.1</a>.</p>
<p>Theory-based methods have been used for decades when researchers did not have access to computers that could run thousands of calculations quickly and efficiently. Now computing power is more accessible and simulation-based methods are becoming more popular, but researchers in many fields continue to use theory-based methods.</p>
<p>The theory-based method we focus on is known as the <em>Welch’s two-sample <span class="math inline">\(t\)</span>-test</em> for testing differences in sample means. The test statistic we use is the <em>two-sample <span class="math inline">\(t\)</span>-statistic</em>, a standardized version of the difference in sample means <span class="math inline">\(\overline{x}_1 - \overline{x}_2\)</span>. The data we use is once again the <code>movies_sample</code> data of action and romance movies from Section <a href="hypothesis-testing.html#ht-case-study">9.6</a>.</p>
<div id="welchs-two-sample-t-statistic" class="section level4 unnumbered">
<h4>Welch’s two-sample t-statistic<a class="anchor" aria-label="anchor" href="#welchs-two-sample-t-statistic"><i class="fas fa-link"></i></a>
</h4>
<p>In Section <a href="sampling.html#sampling-other-scenarios">7.5</a> we introduced the sampling distribution for the difference of two sample means. If we let <span class="math inline">\(\overline X_a\)</span> be the random variable for the sample mean of action films’ rating and <span class="math inline">\(\overline X_r\)</span> the one for romance film’s rating, the distribution of the difference of these random variables is</p>
<p><span class="math display">\[\overline X_a - \overline X_r \sim Normal \left(\mu_a - \mu_r, \sqrt{\frac{\sigma_a^2}{n_a} + \frac{\sigma^2_r}{n_r}} \right)\]</span></p>
<p>where <span class="math inline">\(\mu_a\)</span> and <span class="math inline">\(\mu_r\)</span> are the population mean ratings, <span class="math inline">\(\sigma_a\)</span> and <span class="math inline">\(\sigma_r\)</span> the population standard deviations, and <span class="math inline">\(n_a\)</span> and <span class="math inline">\(n_r\)</span> the sample sizes for action and romance genres, respectively.</p>
<p>When using the samples, as we did for one-sample problems, we standardize the difference in sample means, <span class="math inline">\(\overline{x}_a - \overline{x}_r\)</span>, by subtracting its mean (the differences in population means) and dividing by its standard error. This construct a test statistic known as the <em>Welch’s two-sample <span class="math inline">\(t\)</span>-test statistic</em>:</p>
<p><span class="math display">\[t = \dfrac{ (\bar{x}_a - \bar{x}_r) - (\mu_a - \mu_r)}{ \text{SE}(\bar{x}_a - \bar{x}_r) } = \dfrac{ (\bar{x}_a - \bar{x}_r) - (\mu_a - \mu_r)}{ \sqrt{\dfrac{{s_a}^2}{n_a} + \dfrac{{s_r}^2}{n_r}}  }\]</span></p>
<p>Observe that the formula for <span class="math inline">\(\text{SE}(\bar{x}_a - \bar{x}_r)\)</span> has the sample sizes <span class="math inline">\(n_a\)</span> and <span class="math inline">\(n_r\)</span> in them. So as the sample sizes increase, the standard error goes down. We have seen this characteristic for one-sample problems in Subsections <a href="sampling.html#sampling-variation">7.3.4</a> and <a href="sampling.html#random-variable-sample-mean">7.4.5</a> when describing the sample distribution of the sample mean or the sample proportion and in Section <a href="confidence-intervals.html#theory-based-CI">8.1</a> when discussing the sample size effect on confidence intervals.</p>
<p>Let’s state the null and alternative hypotheses for this test:</p>
<p><span class="math display">\[\begin{aligned}&amp;H_0: &amp;\mu_a - \mu_r = 0\\&amp;H_A: &amp;\mu_a - \mu_r \ne 0\end{aligned}\]</span></p>
<p>The claim under the null hypothesis is that the difference between the population means is zero. This is equivalent to claiming that the means are the same, <span class="math inline">\(\mu_a = \mu_r\)</span>, which is the typical test, as we try to determine whether or not the population means are different. Yet, the structure of the test allows for testing other differences as well, if needed.</p>
<p>The Welch’s two-sample <span class="math inline">\(t\)</span>-test becomes:</p>
<p><span class="math display">\[t = \dfrac{ (\bar{x}_a - \bar{x}_r) - 0}{ \sqrt{\dfrac{{s_a}^2}{n_a} + \dfrac{{s_r}^2}{n_r}}  } = \dfrac{ \bar{x}_a - \bar{x}_r}{ \sqrt{\dfrac{{s_a}^2}{n_a} + \dfrac{{s_r}^2}{n_r}}  }\]</span></p>
<p>Using results based on the Central Limit Theorem, linear combinations of independent random variables, and properties of the expected value, variance, and standard deviation, it can be shown that the Welch’s test statistic follows a <em><span class="math inline">\(t\)</span> distribution</em>.</p>
<p>In Section <a href="confidence-intervals.html#t-distribution-CI">8.1.4</a> we have discussed the properties of the <span class="math inline">\(t\)</span> distribution and in Figure <a href="confidence-intervals.html#fig:t-curve-1">8.7</a> we have shown different <span class="math inline">\(t\)</span> distributions with different degrees of freedom. Recall that the <span class="math inline">\(t\)</span> distribution is similar to the standard normal; its density curve is also bell-shaped, and it is symmetric around zero, but the tails of the <span class="math inline">\(t\)</span> distribution are a little thicker (or heavier) than those of the standard normal.
This is important for hypothesis testing, since the <span class="math inline">\(p\)</span>-value is calculated from the areas on those tails.
Also recall that as the degrees of freedom increase, the <span class="math inline">\(t\)</span>-distribution more and more approximates the standard normal curve.</p>
<p>In terms of the Welch’s two-sample <span class="math inline">\(t\)</span>-test, it has been shown that the test statistics follows a <span class="math inline">\(t\)</span> distribution with degrees of freedom that can be approximated by</p>
<p><span class="math display">\[
\widehat{df} = \left( \dfrac{s_a^2}{n_a} + \dfrac{s_r^2}{n_r} \right)^2 \Bigg/ \left( \dfrac{\left( \dfrac{s_a^2}{n_a} \right)^2}{n_a - 1} + \dfrac{\left( \dfrac{s_r^2}{n_r} \right)^2}{n_r - 1} \right)
\]</span></p>
<p>This formula is just too long to enter manually every time that is needed. (A suitable approximation for the degrees of freedom using <span class="math inline">\(n_a + n_r - 2\)</span> is often used instead for reasonably large sample sizes.) But, fortunately, R and other statistical software have already done the formula inputting for us by introducing relevant functions. While it is important to get good approximations to the degrees of freedom in order to get the appropriate <span class="math inline">\(p\)</span>-values, learning this formula goes beyond the reach of those new to statistical inference, and it does little to build the intuition of the <span class="math inline">\(t\)</span>-test. Therefore, we will trust the results that R or other statistical packages provide for us.</p>
<p>Let’s compute the <span class="math inline">\(t\)</span>-test statistic. Recall the summary statistics we computed during our exploratory data analysis in Section <a href="hypothesis-testing.html#imdb-data">9.6.1</a>.</p>
<div class="sourceCode" id="cb454"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">movies_sample</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/group_by.html">group_by</a></span><span class="op">(</span><span class="va">genre</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/summarise.html">summarize</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/context.html">n</a></span><span class="op">(</span><span class="op">)</span>, mean_rating <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">rating</span><span class="op">)</span>, std_dev <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">rating</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code># A tibble: 2 × 4
  genre       n mean_rating std_dev
  &lt;chr&gt;   &lt;int&gt;       &lt;dbl&gt;   &lt;dbl&gt;
1 Action     32     5.275   1.36121
2 Romance    36     6.32222 1.60963</code></pre>
<p>Using these values, the observed two-sample <span class="math inline">\(t\)</span>-test statistic is</p>
<p><span class="math display">\[
\dfrac{ \bar{x}_a - \bar{x}_r}{ \sqrt{\dfrac{{s_a}^2}{n_a} + \dfrac{{s_r}^2}{n_r}}  } =
\dfrac{5.28 - 6.32}{ \sqrt{\dfrac{{1.36}^2}{32} + \dfrac{{1.61}^2}{36}}  } =
-2.906
\]</span></p>
<p>How can we compute the <span class="math inline">\(p\)</span>-value using this theory-based test statistic? We could do it by calculating the degrees of freedom and using the function <code><a href="https://rdrr.io/r/stats/TDist.html">pt()</a></code> as we did earlier. Instead, we use the function <code><a href="https://infer.tidymodels.org/reference/t_test.html">t_test()</a></code> from the package <code>infer</code> with the appropriate <code>formula</code> and <code>order</code>, as we did for the simulation-based approach.</p>
<p>The results are shown next:</p>
<div class="sourceCode" id="cb456"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">movies_sample</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://infer.tidymodels.org/reference/t_test.html">t_test</a></span><span class="op">(</span>formula <span class="op">=</span> <span class="va">rating</span> <span class="op">~</span> <span class="va">genre</span>, </span>
<span>         order <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"Action"</span>, <span class="st">"Romance"</span><span class="op">)</span>, </span>
<span>         alternative <span class="op">=</span> <span class="st">"two-sided"</span><span class="op">)</span></span></code></pre></div>
<pre><code># A tibble: 1 × 7
  statistic    t_df    p_value alternative estimate lower_ci  upper_ci
      &lt;dbl&gt;   &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;          &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;
1  -2.90589 65.8496 0.00498319 two.sided   -1.04722 -1.76677 -0.327671</code></pre>
<p>Based on the <span class="math inline">\(p\)</span>-value = 0.005 we reject the null hypothesis, the average rating for the <code>Romance</code> movies is not the same as the average rating for the <code>Action</code> movies. This result is similar to the one calculated using the simulation-based approach.</p>
<p>To be able to use the Welch’s <span class="math inline">\(t\)</span>-test, there are some conditions that are necessary so that the underlying mathematical theory holds:</p>
<ol style="list-style-type: decimal">
<li>The populations should be close to normal or the samples should be large. Many textbooks suggest the sample sizes to be greater than 30, but there is no clear mathematical foundation for this rule of thumb. In general, as long as the distribution of the samples appear to be close to symmetric, the Welch’s <span class="math inline">\(t\)</span>-test may provide useful results.</li>
<li>The samples should be random samples.</li>
<li>The sample of one population should be independent from the sample of the other population.</li>
</ol>
<p>Let’s see if these conditions hold for our <code>movies_sample</code> data:</p>
<ol style="list-style-type: decimal">
<li>This is met since <span class="math inline">\(n_a\)</span> = 32 and <span class="math inline">\(n_r\)</span> = 36 do not seem to be highly skewed and therefore are somewhat symmetric.</li>
<li>This is met since we sampled the action and romance movies at random and in an unbiased fashion from the database of all IMDb movies.</li>
<li>Unfortunately, we do not know how IMDb computes the ratings. For example, if the same person can rate multiple movies, then those observations may be related. This does not appear to be a major problem in this context though.</li>
</ol>
<p>Assuming all three conditions are not clearly broken, we can be reasonably certain that the theory-based <span class="math inline">\(t\)</span>-test results are valid.</p>
</div>
</div>
<div id="when-inference-is-not-needed" class="section level3" number="9.7.2">
<h3>
<span class="header-section-number">9.7.2</span> When inference is not needed<a class="anchor" aria-label="anchor" href="#when-inference-is-not-needed"><i class="fas fa-link"></i></a>
</h3>
<p>We have now walked through several different examples of how to use the <code>infer</code> package to perform statistical inference: constructing confidence intervals and conducting hypothesis tests. For each of these examples, we made it a point to always perform an exploratory data analysis (EDA) first; specifically, by looking at the raw data values, by using data visualization with <code>ggplot2</code>, and by data wrangling with <code>dplyr</code> beforehand. We <em>highly</em> encourage you to always do the same. As a beginner to statistics, EDA helps you develop intuition as to what statistical methods like confidence intervals and hypothesis tests can tell us. Even as a seasoned practitioner of statistics, EDA helps guide your statistical investigations. In particular, is statistical inference even needed?</p>
<p>Let’s consider an example. Say we are interested in the following question: Of <em>all</em> flights leaving a New York City airport, are Hawaiian Airlines flights in the air for longer than Alaska Airlines flights? Furthermore, let’s assume that 2023 flights are a representative sample of all such flights. Then we can use the <code>flights</code> data frame in the <code>nycflights23</code> package we introduced in Section <a href="getting-started.html#nycflights">1.4</a> to answer our question. Let’s filter this data frame to only include Hawaiian and Alaska Airlines using their <code>carrier</code> codes <code>HA</code> and <code>AS</code>:</p>
<div class="sourceCode" id="cb458"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">flights_sample</span> <span class="op">&lt;-</span> <span class="va">flights</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html">filter</a></span><span class="op">(</span><span class="va">carrier</span> <span class="op"><a href="https://rdrr.io/r/base/match.html">%in%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"HA"</span>, <span class="st">"AS"</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>There are two possible statistical inference methods we could use to answer such questions. First, we could construct a 95% confidence interval for the difference in population means <span class="math inline">\(\mu_{HA} - \mu_{AS}\)</span>, where <span class="math inline">\(\mu_{HA}\)</span> is the mean air time of all Hawaiian Airlines flights and <span class="math inline">\(\mu_{AS}\)</span> is the mean air time of all Alaska Airlines flights. We could then check if the entirety of the interval is greater than 0, suggesting that <span class="math inline">\(\mu_{HA} - \mu_{AS} &gt; 0\)</span>, or, in other words suggesting that <span class="math inline">\(\mu_{HA} &gt; \mu_{AS}\)</span>. Second, we could perform a hypothesis test of the null hypothesis <span class="math inline">\(H_0: \mu_{HA} - \mu_{AS} = 0\)</span> versus the alternative hypothesis <span class="math inline">\(H_A: \mu_{HA} - \mu_{AS} &gt; 0\)</span>.</p>
<p>However, let’s first construct an exploratory visualization as we suggested earlier. Since <code>air_time</code> is numerical and <code>carrier</code> is categorical, a boxplot can display the relationship between these two variables, which we display in Figure <a href="hypothesis-testing.html#fig:ha-as-flights-boxplot">9.16</a>.</p>
<div class="sourceCode" id="cb459"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span>data <span class="op">=</span> <span class="va">flights_sample</span>, mapping <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">carrier</span>, y <span class="op">=</span> <span class="va">air_time</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_boxplot.html">geom_boxplot</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>x <span class="op">=</span> <span class="st">"Carrier"</span>, y <span class="op">=</span> <span class="st">"Air Time"</span><span class="op">)</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:ha-as-flights-boxplot"></span>
<img src="ModernDive_files/figure-html/ha-as-flights-boxplot-1.png" alt="Air time for Hawaiian and Alaska Airlines flights departing NYC in 2023." width="\textwidth"><p class="caption">
FIGURE 9.16: Air time for Hawaiian and Alaska Airlines flights departing NYC in 2023.
</p>
</div>
<p>This is what we like to call “no PhD in Statistics needed” moments. You do not have to be an expert in statistics to know that Alaska Airlines and Hawaiian Airlines have <em>notably</em> different air times. The two boxplots do not even overlap! Constructing a confidence interval or conducting a hypothesis test would frankly not provide much more insight than Figure <a href="hypothesis-testing.html#fig:ha-as-flights-boxplot">9.16</a>.</p>
<p>Let’s investigate why we observe such a clear-cut difference between these two airlines using data wrangling. Let’s first group the rows of <code>flights_sample</code> not only by <code>carrier</code> but also by destination <code>dest</code>. Subsequently, we will compute two summary statistics: the number of observations using <code><a href="https://dplyr.tidyverse.org/reference/context.html">n()</a></code> and the mean airtime:</p>
<div class="sourceCode" id="cb460"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">flights_sample</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/group_by.html">group_by</a></span><span class="op">(</span><span class="va">carrier</span>, <span class="va">dest</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/summarise.html">summarize</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/context.html">n</a></span><span class="op">(</span><span class="op">)</span>, mean_time <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">air_time</span>, na.rm <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>, .groups <span class="op">=</span> <span class="st">"keep"</span><span class="op">)</span></span></code></pre></div>
<pre><code># A tibble: 8 × 4
# Groups:   carrier, dest [8]
  carrier dest      n mean_time
  &lt;chr&gt;   &lt;chr&gt; &lt;int&gt;     &lt;dbl&gt;
1 AS      LAS       1   299    
2 AS      LAX     980   323.929
3 AS      PDX     710   326.383
4 AS      PSP      18   309.611
5 AS      SAN    1034   325.457
6 AS      SEA    2417   324.787
7 AS      SFO    2683   343.542
8 HA      HNL     366   623.287</code></pre>
<p>It turns out that from New York City in 2023 Alaska flew to seven different airports on the West Coast region of the US while Hawaiian only flew to <code>HNL</code> (Honolulu) from NYC. Given the clear difference in distance from New York City to the West Coast versus New York City to Honolulu, it is not surprising that we observe such different (<em>statistically significantly different</em>, in fact) air times in flights.</p>
<p>This is a clear example of not needing to do anything more than a simple exploratory data analysis using data visualization and descriptive statistics to get an appropriate conclusion. This is why we highly recommend you perform an EDA of any sample data before running statistical inference methods like confidence intervals and hypothesis tests.</p>
</div>
<div id="problems-with-p-values" class="section level3" number="9.7.3">
<h3>
<span class="header-section-number">9.7.3</span> Problems with p-values<a class="anchor" aria-label="anchor" href="#problems-with-p-values"><i class="fas fa-link"></i></a>
</h3>
<p>On top of the many common misunderstandings about hypothesis testing and <span class="math inline">\(p\)</span>-values we listed in Section <a href="hypothesis-testing.html#ht-interpretation">9.5</a>, another unfortunate consequence of the expanded use of <span class="math inline">\(p\)</span>-values and hypothesis testing is a phenomenon known as “p-hacking.” p-hacking is the act of “cherry-picking” only results that are “statistically significant” while dismissing those that are not, even if at the expense of the scientific ideas. There are lots of articles written recently about misunderstandings and the problems with <span class="math inline">\(p\)</span>-values. We encourage you to check some of them out:</p>
<ol style="list-style-type: decimal">
<li><a href="https://en.wikipedia.org/wiki/Misuse_of_p-values">Misuse of <span class="math inline">\(p\)</span>-values</a></li>
<li><a href="https://www.vox.com/science-and-health/2017/7/31/16021654/p-values-statistical-significance-redefine-0005">What a nerdy debate about <span class="math inline">\(p\)</span>-values shows about science – and how to fix it</a></li>
<li><a href="https://www.nature.com/articles/nature.2016.19503">Statisticians issue warning over misuse of <span class="math inline">\(P\)</span> values</a></li>
<li><a href="https://fivethirtyeight.com/features/you-cant-trust-what-you-read-about-nutrition/">You Cannot Trust What You Read About Nutrition</a></li>
<li><a href="http://www.fharrell.com/post/pval-litany/">A Litany of Problems with p-values</a></li>
</ol>
<p>Such issues were getting so problematic that the American Statistical Association (ASA) put out a statement in 2016 titled, <a href="https://www.amstat.org/asa/files/pdfs/P-ValueStatement.pdf">“The ASA Statement on Statistical Significance and <span class="math inline">\(P\)</span>-Values,”</a> with six principles underlying the proper use and interpretation of <span class="math inline">\(p\)</span>-values. The ASA released this guidance on <span class="math inline">\(p\)</span>-values to improve the conduct and interpretation of quantitative science and to inform the growing emphasis on reproducibility of science research.</p>
<p>We as authors much prefer the use of confidence intervals for statistical inference, since in our opinion they are much less prone to large misinterpretation. However, many fields still exclusively use <span class="math inline">\(p\)</span>-values for statistical inference and this is one reason for including them in this text. We encourage you to learn more about “p-hacking” as well and its implication for science.</p>
</div>
<div id="additional-resources-7" class="section level3" number="9.7.4">
<h3>
<span class="header-section-number">9.7.4</span> Additional resources<a class="anchor" aria-label="anchor" href="#additional-resources-7"><i class="fas fa-link"></i></a>
</h3>
<p>An R script file of all R code used in this chapter is available <a href="scripts/09-hypothesis-testing.R">here</a>.</p>
<p>If you want more examples of the <code>infer</code> workflow for conducting hypothesis tests, we suggest you check out the <code>infer</code> package homepage, in particular, a series of example analyses available at <a href="https://infer.netlify.app/articles/" class="uri">https://infer.netlify.app/articles/</a>.</p>
</div>
<div id="whats-to-come-8" class="section level3" number="9.7.5">
<h3>
<span class="header-section-number">9.7.5</span> What’s to come<a class="anchor" aria-label="anchor" href="#whats-to-come-8"><i class="fas fa-link"></i></a>
</h3>
<p>We conclude with the <code>infer</code> pipeline for hypothesis testing in Figure <a href="hypothesis-testing.html#fig:infer-workflow-ht">9.17</a>.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:infer-workflow-ht"></span>
<img src="images/flowcharts/infer/ht_diagram_trimmed.png" alt="infer package workflow for hypothesis testing." width="100%"><p class="caption">
FIGURE 9.17: infer package workflow for hypothesis testing.
</p>
</div>
<p>Now that we have armed ourselves with an understanding of confidence intervals from Chapter <a href="confidence-intervals.html#confidence-intervals">8</a> and hypothesis tests from this chapter, we will now study inference for regression in the upcoming Chapter <a href="inference-for-regression.html#inference-for-regression">10</a>.</p>

</div>
</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="confidence-intervals.html"><span class="header-section-number">8</span> Estimation, Confidence Intervals, and Bootstrapping</a></div>
<div class="next"><a href="inference-for-regression.html"><span class="header-section-number">10</span> Inference for Regression</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#hypothesis-testing"><span class="header-section-number">9</span> Hypothesis Testing</a></li>
<li><a class="nav-link" href="#nhst-packages">Needed packages</a></li>
<li>
<a class="nav-link" href="#tying-CI-hypo"><span class="header-section-number">9.1</span> Tying confidence intervals to hypothesis testing</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#one-sample-hyp"><span class="header-section-number">9.1.1</span> The one-sample hypothesis test for the population mean</a></li>
<li><a class="nav-link" href="#hypothesis-tests-and-confidence-intervals"><span class="header-section-number">9.1.2</span> Hypothesis tests and confidence intervals</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#ht-activity"><span class="header-section-number">9.2</span> Music popularity activity</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#is-metal-music-more-popular-than-deep-house-music"><span class="header-section-number">9.2.1</span> Is metal music more popular than deep house music?</a></li>
<li><a class="nav-link" href="#shuffling-once"><span class="header-section-number">9.2.2</span> Shuffling once</a></li>
<li><a class="nav-link" href="#ht-what-did-we-just-do"><span class="header-section-number">9.2.3</span> What did we just do?</a></li>
</ul>
</li>
<li><a class="nav-link" href="#understanding-ht"><span class="header-section-number">9.3</span> Understanding hypothesis tests</a></li>
<li>
<a class="nav-link" href="#ht-infer"><span class="header-section-number">9.4</span> Conducting hypothesis tests</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#infer-workflow-ht"><span class="header-section-number">9.4.1</span> infer package workflow</a></li>
<li><a class="nav-link" href="#comparing-infer-workflows"><span class="header-section-number">9.4.2</span> Comparison with confidence intervals</a></li>
<li><a class="nav-link" href="#only-one-test"><span class="header-section-number">9.4.3</span> There is only one test</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#ht-interpretation"><span class="header-section-number">9.5</span> Interpreting hypothesis tests</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#trial"><span class="header-section-number">9.5.1</span> Two possible outcomes</a></li>
<li><a class="nav-link" href="#types-of-errors"><span class="header-section-number">9.5.2</span> Types of errors</a></li>
<li><a class="nav-link" href="#choosing-alpha"><span class="header-section-number">9.5.3</span> How do we choose alpha?</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#ht-case-study"><span class="header-section-number">9.6</span> Case study: are action or romance movies rated higher?</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#imdb-data"><span class="header-section-number">9.6.1</span> IMDb ratings data</a></li>
<li><a class="nav-link" href="#sampling-scenario-1"><span class="header-section-number">9.6.2</span> Sampling scenario</a></li>
<li><a class="nav-link" href="#conducting-the-hypothesis-test"><span class="header-section-number">9.6.3</span> Conducting the hypothesis test</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#nhst-conclusion"><span class="header-section-number">9.7</span> Summary and Final Remarks</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#theory-hypo"><span class="header-section-number">9.7.1</span> Theory-based approach for two-sample hypothesis tests</a></li>
<li><a class="nav-link" href="#when-inference-is-not-needed"><span class="header-section-number">9.7.2</span> When inference is not needed</a></li>
<li><a class="nav-link" href="#problems-with-p-values"><span class="header-section-number">9.7.3</span> Problems with p-values</a></li>
<li><a class="nav-link" href="#additional-resources-7"><span class="header-section-number">9.7.4</span> Additional resources</a></li>
<li><a class="nav-link" href="#whats-to-come-8"><span class="header-section-number">9.7.5</span> What’s to come</a></li>
</ul>
</li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/moderndive/ModernDive_book//blob/v2/09-hypothesis-testing.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/moderndive/ModernDive_book//edit/v2/09-hypothesis-testing.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Statistical Inference via Data Science</strong>: A ModernDive into R and the Tidyverse <br> (Second Edition)" was written by Chester Ismay, Albert Y. Kim, and Arturo Valdivia <br> Foreword by Kelly S. McConville. It was last built on January 29, 2026.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
