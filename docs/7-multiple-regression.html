<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Chapter 7 Multiple Regression | Statistical Inference via Data Science</title>
  <meta name="description" content="An open-source and fully-reproducible electronic textbook for teaching statistical inference using tidyverse data science tools.">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="Chapter 7 Multiple Regression | Statistical Inference via Data Science" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://moderndive.com/" />
  <meta property="og:image" content="https://moderndive.com/images/logos/book_cover.png" />
  <meta property="og:description" content="An open-source and fully-reproducible electronic textbook for teaching statistical inference using tidyverse data science tools." />
  <meta name="github-repo" content="moderndive/moderndive_book" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 7 Multiple Regression | Statistical Inference via Data Science" />
  
  <meta name="twitter:description" content="An open-source and fully-reproducible electronic textbook for teaching statistical inference using tidyverse data science tools." />
  <meta name="twitter:image" content="https://moderndive.com/images/logos/book_cover.png" />

<meta name="author" content="Chester Ismay and Albert Y. Kim">


<meta name="date" content="2019-03-31">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  <link rel="apple-touch-icon-precomposed" sizes="152x152" href="images/logos/favicons/apple-touch-icon.png">
  <link rel="shortcut icon" href="images/logos/favicons/favicon.ico" type="image/x-icon">
<link rel="prev" href="6-regression.html">
<link rel="next" href="8-sampling.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/htmlwidgets-1.3/htmlwidgets.js"></script>
<link href="libs/dygraphs-1.1.1/dygraph.css" rel="stylesheet" />
<script src="libs/dygraphs-1.1.1/dygraph-combined.js"></script>
<script src="libs/dygraphs-1.1.1/shapes.js"></script>
<script src="libs/moment-2.8.4/moment.js"></script>
<script src="libs/moment-timezone-0.2.5/moment-timezone-with-data.js"></script>
<script src="libs/moment-fquarter-1.0.0/moment-fquarter.min.js"></script>
<script src="libs/dygraphs-binding-1.1.1.6/dygraphs.js"></script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-89938436-1', 'auto');
  ga('send', 'pageview');

</script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#sec:intro-for-students"><i class="fa fa-check"></i><b>1.1</b> Introduction for students</a><ul>
<li class="chapter" data-level="1.1.1" data-path="index.html"><a href="index.html#subsec:learning-goals"><i class="fa fa-check"></i><b>1.1.1</b> What you will learn from this book</a></li>
<li class="chapter" data-level="1.1.2" data-path="index.html"><a href="index.html#subsec:pipeline"><i class="fa fa-check"></i><b>1.1.2</b> Data/science pipeline</a></li>
<li class="chapter" data-level="1.1.3" data-path="index.html"><a href="index.html#subsec:reproducible"><i class="fa fa-check"></i><b>1.1.3</b> Reproducible research</a></li>
<li class="chapter" data-level="1.1.4" data-path="index.html"><a href="index.html#final-note-for-students"><i class="fa fa-check"></i><b>1.1.4</b> Final note for students</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#sec:intro-instructors"><i class="fa fa-check"></i><b>1.2</b> Introduction for instructors</a><ul>
<li class="chapter" data-level="1.2.1" data-path="index.html"><a href="index.html#who-is-this-book-for"><i class="fa fa-check"></i><b>1.2.1</b> Who is this book for?</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#datacamp"><i class="fa fa-check"></i><b>1.3</b> DataCamp</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#sec:connect-contribute"><i class="fa fa-check"></i><b>1.4</b> Connect and contribute</a></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#sec:about-book"><i class="fa fa-check"></i><b>1.5</b> About this book</a></li>
<li class="chapter" data-level="1.6" data-path="index.html"><a href="index.html#sec:about-authors"><i class="fa fa-check"></i><b>1.6</b> About the authors</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="2-getting-started.html"><a href="2-getting-started.html"><i class="fa fa-check"></i><b>2</b> Getting Started with Data in R</a><ul>
<li class="chapter" data-level="2.1" data-path="2-getting-started.html"><a href="2-getting-started.html#r-rstudio"><i class="fa fa-check"></i><b>2.1</b> What are R and RStudio?</a><ul>
<li class="chapter" data-level="2.1.1" data-path="2-getting-started.html"><a href="2-getting-started.html#installing-r-and-rstudio"><i class="fa fa-check"></i><b>2.1.1</b> Installing R and RStudio</a></li>
<li class="chapter" data-level="2.1.2" data-path="2-getting-started.html"><a href="2-getting-started.html#using-r-via-rstudio"><i class="fa fa-check"></i><b>2.1.2</b> Using R via RStudio</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="2-getting-started.html"><a href="2-getting-started.html#code"><i class="fa fa-check"></i><b>2.2</b> How do I code in R?</a><ul>
<li class="chapter" data-level="2.2.1" data-path="2-getting-started.html"><a href="2-getting-started.html#programming-concepts"><i class="fa fa-check"></i><b>2.2.1</b> Basic programming concepts and terminology</a></li>
<li class="chapter" data-level="2.2.2" data-path="2-getting-started.html"><a href="2-getting-started.html#errors-warnings-and-messages"><i class="fa fa-check"></i><b>2.2.2</b> Errors, warnings, and messages</a></li>
<li class="chapter" data-level="2.2.3" data-path="2-getting-started.html"><a href="2-getting-started.html#tips-on-learning-to-code"><i class="fa fa-check"></i><b>2.2.3</b> Tips on learning to code</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="2-getting-started.html"><a href="2-getting-started.html#packages"><i class="fa fa-check"></i><b>2.3</b> What are R packages?</a><ul>
<li class="chapter" data-level="2.3.1" data-path="2-getting-started.html"><a href="2-getting-started.html#package-installation"><i class="fa fa-check"></i><b>2.3.1</b> Package installation</a></li>
<li class="chapter" data-level="2.3.2" data-path="2-getting-started.html"><a href="2-getting-started.html#package-loading"><i class="fa fa-check"></i><b>2.3.2</b> Package loading</a></li>
<li class="chapter" data-level="2.3.3" data-path="2-getting-started.html"><a href="2-getting-started.html#package-use"><i class="fa fa-check"></i><b>2.3.3</b> Package use</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="2-getting-started.html"><a href="2-getting-started.html#nycflights13"><i class="fa fa-check"></i><b>2.4</b> Explore your first datasets</a><ul>
<li class="chapter" data-level="2.4.1" data-path="2-getting-started.html"><a href="2-getting-started.html#nycflights13-package"><i class="fa fa-check"></i><b>2.4.1</b> <code>nycflights13</code> package</a></li>
<li class="chapter" data-level="2.4.2" data-path="2-getting-started.html"><a href="2-getting-started.html#flights-data-frame"><i class="fa fa-check"></i><b>2.4.2</b> <code>flights</code> data frame</a></li>
<li class="chapter" data-level="2.4.3" data-path="2-getting-started.html"><a href="2-getting-started.html#exploredataframes"><i class="fa fa-check"></i><b>2.4.3</b> Exploring data frames</a></li>
<li class="chapter" data-level="2.4.4" data-path="2-getting-started.html"><a href="2-getting-started.html#identification-vs-measurement-variables"><i class="fa fa-check"></i><b>2.4.4</b> Identification &amp; measurement variables</a></li>
<li class="chapter" data-level="2.4.5" data-path="2-getting-started.html"><a href="2-getting-started.html#help-files"><i class="fa fa-check"></i><b>2.4.5</b> Help files</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="2-getting-started.html"><a href="2-getting-started.html#conclusion"><i class="fa fa-check"></i><b>2.5</b> Conclusion</a><ul>
<li class="chapter" data-level="2.5.1" data-path="2-getting-started.html"><a href="2-getting-started.html#additional-resources"><i class="fa fa-check"></i><b>2.5.1</b> Additional resources</a></li>
<li class="chapter" data-level="2.5.2" data-path="2-getting-started.html"><a href="2-getting-started.html#whats-to-come"><i class="fa fa-check"></i><b>2.5.2</b> What’s to come?</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>I Data Science via the tidyverse</b></span></li>
<li class="chapter" data-level="3" data-path="3-viz.html"><a href="3-viz.html"><i class="fa fa-check"></i><b>3</b> Data Visualization</a><ul>
<li class="chapter" data-level="" data-path="3-viz.html"><a href="3-viz.html#needed-packages"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="3.1" data-path="3-viz.html"><a href="3-viz.html#grammarofgraphics"><i class="fa fa-check"></i><b>3.1</b> The Grammar of Graphics</a><ul>
<li class="chapter" data-level="3.1.1" data-path="3-viz.html"><a href="3-viz.html#components-of-the-grammar"><i class="fa fa-check"></i><b>3.1.1</b> Components of the Grammar</a></li>
<li class="chapter" data-level="3.1.2" data-path="3-viz.html"><a href="3-viz.html#gapminder"><i class="fa fa-check"></i><b>3.1.2</b> Gapminder data</a></li>
<li class="chapter" data-level="3.1.3" data-path="3-viz.html"><a href="3-viz.html#other-components"><i class="fa fa-check"></i><b>3.1.3</b> Other components</a></li>
<li class="chapter" data-level="3.1.4" data-path="3-viz.html"><a href="3-viz.html#ggplot2-package"><i class="fa fa-check"></i><b>3.1.4</b> ggplot2 package</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="3-viz.html"><a href="3-viz.html#FiveNG"><i class="fa fa-check"></i><b>3.2</b> Five Named Graphs - The 5NG</a></li>
<li class="chapter" data-level="3.3" data-path="3-viz.html"><a href="3-viz.html#scatterplots"><i class="fa fa-check"></i><b>3.3</b> 5NG#1: Scatterplots</a><ul>
<li class="chapter" data-level="3.3.1" data-path="3-viz.html"><a href="3-viz.html#geompoint"><i class="fa fa-check"></i><b>3.3.1</b> Scatterplots via geom_point</a></li>
<li class="chapter" data-level="3.3.2" data-path="3-viz.html"><a href="3-viz.html#overplotting"><i class="fa fa-check"></i><b>3.3.2</b> Over-plotting</a></li>
<li class="chapter" data-level="3.3.3" data-path="3-viz.html"><a href="3-viz.html#summary"><i class="fa fa-check"></i><b>3.3.3</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="3-viz.html"><a href="3-viz.html#linegraphs"><i class="fa fa-check"></i><b>3.4</b> 5NG#2: Linegraphs</a><ul>
<li class="chapter" data-level="3.4.1" data-path="3-viz.html"><a href="3-viz.html#geomline"><i class="fa fa-check"></i><b>3.4.1</b> Linegraphs via geom_line</a></li>
<li class="chapter" data-level="3.4.2" data-path="3-viz.html"><a href="3-viz.html#summary-1"><i class="fa fa-check"></i><b>3.4.2</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="3-viz.html"><a href="3-viz.html#histograms"><i class="fa fa-check"></i><b>3.5</b> 5NG#3: Histograms</a><ul>
<li class="chapter" data-level="3.5.1" data-path="3-viz.html"><a href="3-viz.html#geomhistogram"><i class="fa fa-check"></i><b>3.5.1</b> Histograms via geom_histogram</a></li>
<li class="chapter" data-level="3.5.2" data-path="3-viz.html"><a href="3-viz.html#adjustbins"><i class="fa fa-check"></i><b>3.5.2</b> Adjusting the bins</a></li>
<li class="chapter" data-level="3.5.3" data-path="3-viz.html"><a href="3-viz.html#summary-2"><i class="fa fa-check"></i><b>3.5.3</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="3-viz.html"><a href="3-viz.html#facets"><i class="fa fa-check"></i><b>3.6</b> Facets</a></li>
<li class="chapter" data-level="3.7" data-path="3-viz.html"><a href="3-viz.html#boxplots"><i class="fa fa-check"></i><b>3.7</b> 5NG#4: Boxplots</a><ul>
<li class="chapter" data-level="3.7.1" data-path="3-viz.html"><a href="3-viz.html#geomboxplot"><i class="fa fa-check"></i><b>3.7.1</b> Boxplots via geom_boxplot</a></li>
<li class="chapter" data-level="3.7.2" data-path="3-viz.html"><a href="3-viz.html#summary-3"><i class="fa fa-check"></i><b>3.7.2</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="3-viz.html"><a href="3-viz.html#geombar"><i class="fa fa-check"></i><b>3.8</b> 5NG#5: Barplots</a><ul>
<li class="chapter" data-level="3.8.1" data-path="3-viz.html"><a href="3-viz.html#barplots-via-geom_bar-or-geom_col"><i class="fa fa-check"></i><b>3.8.1</b> Barplots via geom_bar or geom_col</a></li>
<li class="chapter" data-level="3.8.2" data-path="3-viz.html"><a href="3-viz.html#must-avoid-pie-charts"><i class="fa fa-check"></i><b>3.8.2</b> Must avoid pie charts!</a></li>
<li class="chapter" data-level="3.8.3" data-path="3-viz.html"><a href="3-viz.html#two-categ-barplot"><i class="fa fa-check"></i><b>3.8.3</b> Two categorical variables</a></li>
<li class="chapter" data-level="3.8.4" data-path="3-viz.html"><a href="3-viz.html#summary-4"><i class="fa fa-check"></i><b>3.8.4</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="3-viz.html"><a href="3-viz.html#conclusion-1"><i class="fa fa-check"></i><b>3.9</b> Conclusion</a><ul>
<li class="chapter" data-level="3.9.1" data-path="3-viz.html"><a href="3-viz.html#summary-table"><i class="fa fa-check"></i><b>3.9.1</b> Summary table</a></li>
<li class="chapter" data-level="3.9.2" data-path="3-viz.html"><a href="3-viz.html#argument-specification"><i class="fa fa-check"></i><b>3.9.2</b> Argument specification</a></li>
<li class="chapter" data-level="3.9.3" data-path="3-viz.html"><a href="3-viz.html#additional-resources-1"><i class="fa fa-check"></i><b>3.9.3</b> Additional resources</a></li>
<li class="chapter" data-level="3.9.4" data-path="3-viz.html"><a href="3-viz.html#whats-to-come-3"><i class="fa fa-check"></i><b>3.9.4</b> What’s to come</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="4-wrangling.html"><a href="4-wrangling.html"><i class="fa fa-check"></i><b>4</b> Data Wrangling</a><ul>
<li class="chapter" data-level="" data-path="4-wrangling.html"><a href="4-wrangling.html#needed-packages-1"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="4.1" data-path="4-wrangling.html"><a href="4-wrangling.html#piping"><i class="fa fa-check"></i><b>4.1</b> The pipe operator: <code>%&gt;%</code></a></li>
<li class="chapter" data-level="4.2" data-path="4-wrangling.html"><a href="4-wrangling.html#filter"><i class="fa fa-check"></i><b>4.2</b> <code>filter</code> rows</a></li>
<li class="chapter" data-level="4.3" data-path="4-wrangling.html"><a href="4-wrangling.html#summarize"><i class="fa fa-check"></i><b>4.3</b> <code>summarize</code> variables</a></li>
<li class="chapter" data-level="4.4" data-path="4-wrangling.html"><a href="4-wrangling.html#groupby"><i class="fa fa-check"></i><b>4.4</b> <code>group_by</code> rows</a><ul>
<li class="chapter" data-level="4.4.1" data-path="4-wrangling.html"><a href="4-wrangling.html#grouping-by-more-than-one-variable"><i class="fa fa-check"></i><b>4.4.1</b> Grouping by more than one variable</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="4-wrangling.html"><a href="4-wrangling.html#mutate"><i class="fa fa-check"></i><b>4.5</b> <code>mutate</code> existing variables</a></li>
<li class="chapter" data-level="4.6" data-path="4-wrangling.html"><a href="4-wrangling.html#arrange"><i class="fa fa-check"></i><b>4.6</b> <code>arrange</code> and sort rows</a></li>
<li class="chapter" data-level="4.7" data-path="4-wrangling.html"><a href="4-wrangling.html#joins"><i class="fa fa-check"></i><b>4.7</b> <code>join</code> data frames</a><ul>
<li class="chapter" data-level="4.7.1" data-path="4-wrangling.html"><a href="4-wrangling.html#matching-key-variable-names"><i class="fa fa-check"></i><b>4.7.1</b> Matching “key” variable names</a></li>
<li class="chapter" data-level="4.7.2" data-path="4-wrangling.html"><a href="4-wrangling.html#diff-key"><i class="fa fa-check"></i><b>4.7.2</b> Different “key” variable names</a></li>
<li class="chapter" data-level="4.7.3" data-path="4-wrangling.html"><a href="4-wrangling.html#multiple-key-variables"><i class="fa fa-check"></i><b>4.7.3</b> Multiple “key” variables</a></li>
<li class="chapter" data-level="4.7.4" data-path="4-wrangling.html"><a href="4-wrangling.html#normal-forms"><i class="fa fa-check"></i><b>4.7.4</b> Normal forms</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="4-wrangling.html"><a href="4-wrangling.html#other-verbs"><i class="fa fa-check"></i><b>4.8</b> Other verbs</a><ul>
<li class="chapter" data-level="4.8.1" data-path="4-wrangling.html"><a href="4-wrangling.html#select"><i class="fa fa-check"></i><b>4.8.1</b> <code>select</code> variables</a></li>
<li class="chapter" data-level="4.8.2" data-path="4-wrangling.html"><a href="4-wrangling.html#rename"><i class="fa fa-check"></i><b>4.8.2</b> <code>rename</code> variables</a></li>
<li class="chapter" data-level="4.8.3" data-path="4-wrangling.html"><a href="4-wrangling.html#top_n-values-of-a-variable"><i class="fa fa-check"></i><b>4.8.3</b> <code>top_n</code> values of a variable</a></li>
</ul></li>
<li class="chapter" data-level="4.9" data-path="4-wrangling.html"><a href="4-wrangling.html#conclusion-2"><i class="fa fa-check"></i><b>4.9</b> Conclusion</a><ul>
<li class="chapter" data-level="4.9.1" data-path="4-wrangling.html"><a href="4-wrangling.html#summary-table-1"><i class="fa fa-check"></i><b>4.9.1</b> Summary table</a></li>
<li class="chapter" data-level="4.9.2" data-path="4-wrangling.html"><a href="4-wrangling.html#additional-resources-2"><i class="fa fa-check"></i><b>4.9.2</b> Additional resources</a></li>
<li class="chapter" data-level="4.9.3" data-path="4-wrangling.html"><a href="4-wrangling.html#whats-to-come-1"><i class="fa fa-check"></i><b>4.9.3</b> What’s to come?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="5-tidy.html"><a href="5-tidy.html"><i class="fa fa-check"></i><b>5</b> Data Importing &amp; “Tidy” Data</a><ul>
<li class="chapter" data-level="" data-path="5-tidy.html"><a href="5-tidy.html#needed-packages-2"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="5.1" data-path="5-tidy.html"><a href="5-tidy.html#csv"><i class="fa fa-check"></i><b>5.1</b> Importing data</a><ul>
<li class="chapter" data-level="5.1.1" data-path="5-tidy.html"><a href="5-tidy.html#using-the-console"><i class="fa fa-check"></i><b>5.1.1</b> Using the console</a></li>
<li class="chapter" data-level="5.1.2" data-path="5-tidy.html"><a href="5-tidy.html#using-rstudios-interface"><i class="fa fa-check"></i><b>5.1.2</b> Using RStudio’s interface</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="5-tidy.html"><a href="5-tidy.html#tidy-data-ex"><i class="fa fa-check"></i><b>5.2</b> Tidy data</a><ul>
<li class="chapter" data-level="5.2.1" data-path="5-tidy.html"><a href="5-tidy.html#definition-of-tidy-data"><i class="fa fa-check"></i><b>5.2.1</b> Definition of “tidy” data</a></li>
<li class="chapter" data-level="5.2.2" data-path="5-tidy.html"><a href="5-tidy.html#converting-to-tidy-data"><i class="fa fa-check"></i><b>5.2.2</b> Converting to “tidy” data</a></li>
<li class="chapter" data-level="5.2.3" data-path="5-tidy.html"><a href="5-tidy.html#nycflights13-package-1"><i class="fa fa-check"></i><b>5.2.3</b> <code>nycflights13</code> package</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="5-tidy.html"><a href="5-tidy.html#case-study-tidy"><i class="fa fa-check"></i><b>5.3</b> Case study: Democracy in Guatemala</a></li>
<li class="chapter" data-level="5.4" data-path="5-tidy.html"><a href="5-tidy.html#conclusion-3"><i class="fa fa-check"></i><b>5.4</b> Conclusion</a><ul>
<li class="chapter" data-level="5.4.1" data-path="5-tidy.html"><a href="5-tidy.html#tidyverse-package"><i class="fa fa-check"></i><b>5.4.1</b> <code>tidyverse</code> package</a></li>
<li class="chapter" data-level="5.4.2" data-path="5-tidy.html"><a href="5-tidy.html#additional-resources-3"><i class="fa fa-check"></i><b>5.4.2</b> Additional resources</a></li>
<li class="chapter" data-level="5.4.3" data-path="5-tidy.html"><a href="5-tidy.html#whats-to-come-2"><i class="fa fa-check"></i><b>5.4.3</b> What’s to come?</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II Data Modeling via moderndive</b></span></li>
<li class="chapter" data-level="6" data-path="6-regression.html"><a href="6-regression.html"><i class="fa fa-check"></i><b>6</b> Basic Regression</a><ul>
<li class="chapter" data-level="" data-path="6-regression.html"><a href="6-regression.html#needed-packages-3"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="6.1" data-path="6-regression.html"><a href="6-regression.html#model1"><i class="fa fa-check"></i><b>6.1</b> One numerical explanatory variable</a><ul>
<li class="chapter" data-level="6.1.1" data-path="6-regression.html"><a href="6-regression.html#model1EDA"><i class="fa fa-check"></i><b>6.1.1</b> Exploratory data analysis</a></li>
<li class="chapter" data-level="6.1.2" data-path="6-regression.html"><a href="6-regression.html#model1table"><i class="fa fa-check"></i><b>6.1.2</b> Simple linear regression</a></li>
<li class="chapter" data-level="6.1.3" data-path="6-regression.html"><a href="6-regression.html#model1points"><i class="fa fa-check"></i><b>6.1.3</b> Observed/fitted values and residuals</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="6-regression.html"><a href="6-regression.html#model2"><i class="fa fa-check"></i><b>6.2</b> One categorical explanatory variable</a><ul>
<li class="chapter" data-level="6.2.1" data-path="6-regression.html"><a href="6-regression.html#model2EDA"><i class="fa fa-check"></i><b>6.2.1</b> Exploratory data analysis</a></li>
<li class="chapter" data-level="6.2.2" data-path="6-regression.html"><a href="6-regression.html#model2table"><i class="fa fa-check"></i><b>6.2.2</b> Linear regression</a></li>
<li class="chapter" data-level="6.2.3" data-path="6-regression.html"><a href="6-regression.html#model2points"><i class="fa fa-check"></i><b>6.2.3</b> Observed/fitted values and residuals</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="6-regression.html"><a href="6-regression.html#related-topics"><i class="fa fa-check"></i><b>6.3</b> Related topics</a><ul>
<li class="chapter" data-level="6.3.1" data-path="6-regression.html"><a href="6-regression.html#correlation-is-not-causation"><i class="fa fa-check"></i><b>6.3.1</b> Correlation is not necessarily causation</a></li>
<li class="chapter" data-level="6.3.2" data-path="6-regression.html"><a href="6-regression.html#leastsquares"><i class="fa fa-check"></i><b>6.3.2</b> Best fitting line</a></li>
<li class="chapter" data-level="6.3.3" data-path="6-regression.html"><a href="6-regression.html#underthehood"><i class="fa fa-check"></i><b>6.3.3</b> <code>get_regression_x()</code> functions</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="6-regression.html"><a href="6-regression.html#conclusion-4"><i class="fa fa-check"></i><b>6.4</b> Conclusion</a><ul>
<li class="chapter" data-level="6.4.1" data-path="6-regression.html"><a href="6-regression.html#additional-resources-basic-regression"><i class="fa fa-check"></i><b>6.4.1</b> Additional resources</a></li>
<li class="chapter" data-level="6.4.2" data-path="6-regression.html"><a href="6-regression.html#whats-to-come-4"><i class="fa fa-check"></i><b>6.4.2</b> What’s to come?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html"><i class="fa fa-check"></i><b>7</b> Multiple Regression</a><ul>
<li class="chapter" data-level="" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html#needed-packages-4"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="7.1" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html#model4"><i class="fa fa-check"></i><b>7.1</b> One numerical &amp; one categorical explanatory variable</a><ul>
<li class="chapter" data-level="7.1.1" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html#model4EDA"><i class="fa fa-check"></i><b>7.1.1</b> Exploratory data analysis</a></li>
<li class="chapter" data-level="7.1.2" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html#model4interactiontable"><i class="fa fa-check"></i><b>7.1.2</b> Interaction model</a></li>
<li class="chapter" data-level="7.1.3" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html#model4table"><i class="fa fa-check"></i><b>7.1.3</b> Parallel slopes model</a></li>
<li class="chapter" data-level="7.1.4" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html#model4points"><i class="fa fa-check"></i><b>7.1.4</b> Observed/fitted values and residuals</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html#model3"><i class="fa fa-check"></i><b>7.2</b> Two numerical explanatory variables</a><ul>
<li class="chapter" data-level="7.2.1" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html#model3EDA"><i class="fa fa-check"></i><b>7.2.1</b> Exploratory data analysis</a></li>
<li class="chapter" data-level="7.2.2" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html#model3table"><i class="fa fa-check"></i><b>7.2.2</b> Regression plane</a></li>
<li class="chapter" data-level="7.2.3" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html#model3points"><i class="fa fa-check"></i><b>7.2.3</b> Observed/fitted values and residuals</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html#related-topics-1"><i class="fa fa-check"></i><b>7.3</b> Related topics</a><ul>
<li class="chapter" data-level="7.3.1" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html#model-selection"><i class="fa fa-check"></i><b>7.3.1</b> Model selection</a></li>
<li class="chapter" data-level="7.3.2" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html#correlationcoefficient2"><i class="fa fa-check"></i><b>7.3.2</b> Correlation coefficient</a></li>
<li class="chapter" data-level="7.3.3" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html#simpsonsparadox"><i class="fa fa-check"></i><b>7.3.3</b> Simpson’s Paradox</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html#conclusion-5"><i class="fa fa-check"></i><b>7.4</b> Conclusion</a><ul>
<li class="chapter" data-level="7.4.1" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html#additional-resources-4"><i class="fa fa-check"></i><b>7.4.1</b> Additional resources</a></li>
<li class="chapter" data-level="7.4.2" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html#whats-to-come-5"><i class="fa fa-check"></i><b>7.4.2</b> What’s to come?</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III Statistical inference via infer</b></span></li>
<li class="chapter" data-level="8" data-path="8-sampling.html"><a href="8-sampling.html"><i class="fa fa-check"></i><b>8</b> Sampling</a><ul>
<li class="chapter" data-level="" data-path="8-sampling.html"><a href="8-sampling.html#needed-packages-5"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="8.1" data-path="8-sampling.html"><a href="8-sampling.html#sampling-activity"><i class="fa fa-check"></i><b>8.1</b> Sampling activity</a><ul>
<li class="chapter" data-level="8.1.1" data-path="8-sampling.html"><a href="8-sampling.html#what-proportion-of-this-bowls-balls-are-red"><i class="fa fa-check"></i><b>8.1.1</b> What proportion of this bowl’s balls are red?</a></li>
<li class="chapter" data-level="8.1.2" data-path="8-sampling.html"><a href="8-sampling.html#using-the-shovel-once"><i class="fa fa-check"></i><b>8.1.2</b> Using the shovel once</a></li>
<li class="chapter" data-level="8.1.3" data-path="8-sampling.html"><a href="8-sampling.html#student-shovels"><i class="fa fa-check"></i><b>8.1.3</b> Using the shovel 33 times</a></li>
<li class="chapter" data-level="8.1.4" data-path="8-sampling.html"><a href="8-sampling.html#what-are-we-doing-here"><i class="fa fa-check"></i><b>8.1.4</b> What are we doing here?</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="8-sampling.html"><a href="8-sampling.html#sampling-simulation"><i class="fa fa-check"></i><b>8.2</b> Computer simulation of sampling</a><ul>
<li class="chapter" data-level="8.2.1" data-path="8-sampling.html"><a href="8-sampling.html#using-the-virtual-shovel-once"><i class="fa fa-check"></i><b>8.2.1</b> Using the virtual shovel once</a></li>
<li class="chapter" data-level="8.2.2" data-path="8-sampling.html"><a href="8-sampling.html#using-the-virtual-shovel-33-times"><i class="fa fa-check"></i><b>8.2.2</b> Using the virtual shovel 33 times</a></li>
<li class="chapter" data-level="8.2.3" data-path="8-sampling.html"><a href="8-sampling.html#shovel-1000-times"><i class="fa fa-check"></i><b>8.2.3</b> Using the virtual shovel 1000 times</a></li>
<li class="chapter" data-level="8.2.4" data-path="8-sampling.html"><a href="8-sampling.html#different-shovels"><i class="fa fa-check"></i><b>8.2.4</b> Using different shovels</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="8-sampling.html"><a href="8-sampling.html#sampling-framework"><i class="fa fa-check"></i><b>8.3</b> Sampling framework</a><ul>
<li class="chapter" data-level="8.3.1" data-path="8-sampling.html"><a href="8-sampling.html#terminology-and-notation"><i class="fa fa-check"></i><b>8.3.1</b> Terminology &amp; notation</a></li>
<li class="chapter" data-level="8.3.2" data-path="8-sampling.html"><a href="8-sampling.html#statistical-definitions"><i class="fa fa-check"></i><b>8.3.2</b> Statistical definitions</a></li>
<li class="chapter" data-level="8.3.3" data-path="8-sampling.html"><a href="8-sampling.html#the-moral-of-the-story"><i class="fa fa-check"></i><b>8.3.3</b> The moral of the story</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="8-sampling.html"><a href="8-sampling.html#sampling-case-study"><i class="fa fa-check"></i><b>8.4</b> Case study: Polls</a></li>
<li class="chapter" data-level="8.5" data-path="8-sampling.html"><a href="8-sampling.html#sampling-conclusion"><i class="fa fa-check"></i><b>8.5</b> Conclusion</a><ul>
<li class="chapter" data-level="8.5.1" data-path="8-sampling.html"><a href="8-sampling.html#sampling-conclusion-central-limit-theorem"><i class="fa fa-check"></i><b>8.5.1</b> Central Limit Theorem</a></li>
<li class="chapter" data-level="8.5.2" data-path="8-sampling.html"><a href="8-sampling.html#sampling-conclusion-table"><i class="fa fa-check"></i><b>8.5.2</b> Summary table</a></li>
<li class="chapter" data-level="8.5.3" data-path="8-sampling.html"><a href="8-sampling.html#additional-resources-5"><i class="fa fa-check"></i><b>8.5.3</b> Additional resources</a></li>
<li class="chapter" data-level="8.5.4" data-path="8-sampling.html"><a href="8-sampling.html#whats-to-come-6"><i class="fa fa-check"></i><b>8.5.4</b> What’s to come?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html"><i class="fa fa-check"></i><b>9</b> Confidence Intervals</a><ul>
<li class="chapter" data-level="" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#needed-packages-6"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="9.1" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#resampling-activity"><i class="fa fa-check"></i><b>9.1</b> Resampling activity</a><ul>
<li class="chapter" data-level="9.1.1" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#what-is-the-average-year-of-circulated-us-pennies-in-2019"><i class="fa fa-check"></i><b>9.1.1</b> What is the average year of circulated US pennies in 2019?</a></li>
<li class="chapter" data-level="9.1.2" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#using-resampling-once"><i class="fa fa-check"></i><b>9.1.2</b> Using resampling once</a></li>
<li class="chapter" data-level="9.1.3" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#student-resamples"><i class="fa fa-check"></i><b>9.1.3</b> Using resampling 33 times</a></li>
<li class="chapter" data-level="9.1.4" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#whats-the-plan"><i class="fa fa-check"></i><b>9.1.4</b> What’s the plan?</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#resampling-simulation"><i class="fa fa-check"></i><b>9.2</b> Computer simulation of resampling</a><ul>
<li class="chapter" data-level="9.2.1" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#using-the-virtual-resample-once"><i class="fa fa-check"></i><b>9.2.1</b> Using the virtual resample once</a></li>
<li class="chapter" data-level="9.2.2" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#using-the-virtual-resample-33-times"><i class="fa fa-check"></i><b>9.2.2</b> Using the virtual resample 33 times</a></li>
<li class="chapter" data-level="9.2.3" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#using-the-virtual-resample-1000-times"><i class="fa fa-check"></i><b>9.2.3</b> Using the virtual resample 1000 times</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#ci-build-up"><i class="fa fa-check"></i><b>9.3</b> Confidence interval build-up</a><ul>
<li class="chapter" data-level="9.3.1" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#percentile-method"><i class="fa fa-check"></i><b>9.3.1</b> The percentile method</a></li>
<li class="chapter" data-level="9.3.2" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#the-standard-error-method"><i class="fa fa-check"></i><b>9.3.2</b> The standard error method</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#bootstrap-process"><i class="fa fa-check"></i><b>9.4</b> The bootstrapping framework</a><ul>
<li class="chapter" data-level="9.4.1" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#the-original-workflow-needed-for-this"><i class="fa fa-check"></i><b>9.4.1</b> The original workflow needed for this</a></li>
<li class="chapter" data-level="9.4.2" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#the-infer-package-for-statistical-inference"><i class="fa fa-check"></i><b>9.4.2</b> The infer package for statistical inference</a></li>
<li class="chapter" data-level="9.4.3" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#infer-ci"><i class="fa fa-check"></i><b>9.4.3</b> Building confidence intervals with the infer package</a></li>
<li class="chapter" data-level="9.4.4" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#percentile-method-infer"><i class="fa fa-check"></i><b>9.4.4</b> The percentile method with infer</a></li>
<li class="chapter" data-level="9.4.5" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#the-standard-error-method-with-infer"><i class="fa fa-check"></i><b>9.4.5</b> The standard error method with infer</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#one-prop-ci"><i class="fa fa-check"></i><b>9.5</b> Case study: Revisiting the red ball example</a><ul>
<li class="chapter" data-level="9.5.1" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#observed-statistic"><i class="fa fa-check"></i><b>9.5.1</b> Observed statistic</a></li>
<li class="chapter" data-level="9.5.2" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#one-prop-boot"><i class="fa fa-check"></i><b>9.5.2</b> Bootstrap distribution for one proportion</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#interpreting-the-confidence-interval"><i class="fa fa-check"></i><b>9.6</b> Interpreting the confidence interval</a><ul>
<li class="chapter" data-level="" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#the-width-of-confidence-intervals"><i class="fa fa-check"></i>The width of confidence intervals</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#case-study-two-prop-ci"><i class="fa fa-check"></i><b>9.7</b> Case study: Comparing two proportions</a><ul>
<li class="chapter" data-level="9.7.1" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#compute-the-point-estimate"><i class="fa fa-check"></i><b>9.7.1</b> Compute the point estimate</a></li>
<li class="chapter" data-level="9.7.2" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#bootstrap-distribution"><i class="fa fa-check"></i><b>9.7.2</b> Bootstrap distribution</a></li>
</ul></li>
<li class="chapter" data-level="9.8" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#ci-conclusion"><i class="fa fa-check"></i><b>9.8</b> Conclusion</a><ul>
<li class="chapter" data-level="9.8.1" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#comparing-bootstrap-and-sampling-distributions"><i class="fa fa-check"></i><b>9.8.1</b> Comparing bootstrap and sampling distributions</a></li>
<li class="chapter" data-level="9.8.2" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#theory-ci"><i class="fa fa-check"></i><b>9.8.2</b> Theory-based confidence intervals</a></li>
<li class="chapter" data-level="9.8.3" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#ci-conclusion-table"><i class="fa fa-check"></i><b>9.8.3</b> Summary table</a></li>
<li class="chapter" data-level="9.8.4" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#additional-resources-6"><i class="fa fa-check"></i><b>9.8.4</b> Additional resources</a></li>
<li class="chapter" data-level="9.8.5" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#whats-to-come-7"><i class="fa fa-check"></i><b>9.8.5</b> What’s to come?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html"><i class="fa fa-check"></i><b>10</b> Hypothesis Testing</a><ul>
<li class="chapter" data-level="" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#needed-packages-7"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="10.1" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#ht-activity"><i class="fa fa-check"></i><b>10.1</b> Hypothesis testing activity</a><ul>
<li class="chapter" data-level="10.1.1" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#question-of-interest"><i class="fa fa-check"></i><b>10.1.1</b> Question of interest</a></li>
<li class="chapter" data-level="10.1.2" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#what-did-we-actually-observe"><i class="fa fa-check"></i><b>10.1.2</b> What did we actually observe?</a></li>
<li class="chapter" data-level="10.1.3" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#using-permuting-once"><i class="fa fa-check"></i><b>10.1.3</b> Using permuting once</a></li>
<li class="chapter" data-level="10.1.4" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#using-permuting-33-times"><i class="fa fa-check"></i><b>10.1.4</b> Using permuting 33 times</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#ht-infer"><i class="fa fa-check"></i><b>10.2</b> Hypothesis testing with infer</a><ul>
<li class="chapter" data-level="10.2.1" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#revisiting-the-infer-verb-framework"><i class="fa fa-check"></i><b>10.2.1</b> Revisiting the infer verb framework</a></li>
<li class="chapter" data-level="10.2.2" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#the-infer-pipeline-for-the-activity"><i class="fa fa-check"></i><b>10.2.2</b> The <code>infer</code> pipeline for the activity</a></li>
<li class="chapter" data-level="10.2.3" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#only-one-test"><i class="fa fa-check"></i><b>10.2.3</b> The “There Is Only One Test” framework</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#p-value"><i class="fa fa-check"></i><b>10.3</b> The p-value</a><ul>
<li class="chapter" data-level="10.3.1" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#corresponding-confidence-interval"><i class="fa fa-check"></i><b>10.3.1</b> Corresponding confidence interval</a></li>
<li class="chapter" data-level="10.3.2" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#summary-5"><i class="fa fa-check"></i><b>10.3.2</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#ht-interpretation"><i class="fa fa-check"></i><b>10.4</b> Interpretation of hypothesis testing results</a><ul>
<li class="chapter" data-level="10.4.1" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#trial"><i class="fa fa-check"></i><b>10.4.1</b> Criminal trial analogy</a></li>
<li class="chapter" data-level="10.4.2" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#types-of-errors-in-hypothesis-testing"><i class="fa fa-check"></i><b>10.4.2</b> Types of errors in hypothesis testing</a></li>
<li class="chapter" data-level="10.4.3" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#statistical-significance"><i class="fa fa-check"></i><b>10.4.3</b> Statistical significance</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#ht-case-study"><i class="fa fa-check"></i><b>10.5</b> Case study: comparing two means</a><ul>
<li class="chapter" data-level="10.5.1" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#randomizationpermutation"><i class="fa fa-check"></i><b>10.5.1</b> Randomization/permutation</a></li>
<li class="chapter" data-level="10.5.2" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#comparing-action-and-romance-movies"><i class="fa fa-check"></i><b>10.5.2</b> Comparing action and romance movies</a></li>
<li class="chapter" data-level="10.5.3" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#sampling-rightarrow-randomization"><i class="fa fa-check"></i><b>10.5.3</b> Sampling <span class="math inline">\(\rightarrow\)</span> randomization</a></li>
<li class="chapter" data-level="10.5.4" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#data"><i class="fa fa-check"></i><b>10.5.4</b> Data</a></li>
<li class="chapter" data-level="10.5.5" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#model-of-h_0"><i class="fa fa-check"></i><b>10.5.5</b> Model of <span class="math inline">\(H_0\)</span></a></li>
<li class="chapter" data-level="10.5.6" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#test-statistic-delta"><i class="fa fa-check"></i><b>10.5.6</b> Test statistic <span class="math inline">\(\delta\)</span></a></li>
<li class="chapter" data-level="10.5.7" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#observed-effect-delta"><i class="fa fa-check"></i><b>10.5.7</b> Observed effect <span class="math inline">\(\delta^*\)</span></a></li>
<li class="chapter" data-level="10.5.8" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#simulated-data"><i class="fa fa-check"></i><b>10.5.8</b> Simulated data</a></li>
<li class="chapter" data-level="10.5.9" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#distribution-of-delta-under-h_0"><i class="fa fa-check"></i><b>10.5.9</b> Distribution of <span class="math inline">\(\delta\)</span> under <span class="math inline">\(H_0\)</span></a></li>
<li class="chapter" data-level="10.5.10" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#the-p-value"><i class="fa fa-check"></i><b>10.5.10</b> The p-value</a></li>
<li class="chapter" data-level="10.5.11" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#corresponding-confidence-interval-1"><i class="fa fa-check"></i><b>10.5.11</b> Corresponding confidence interval</a></li>
</ul></li>
<li class="chapter" data-level="10.6" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#conclusion-6"><i class="fa fa-check"></i><b>10.6</b> Conclusion</a><ul>
<li class="chapter" data-level="10.6.1" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#when-inference-is-not-needed"><i class="fa fa-check"></i><b>10.6.1</b> When inference is not needed</a></li>
<li class="chapter" data-level="10.6.2" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#problems-with-p-values"><i class="fa fa-check"></i><b>10.6.2</b> Problems with p-values</a></li>
<li class="chapter" data-level="10.6.3" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#comparing-confidence-intervals-and-hypothesis-tests"><i class="fa fa-check"></i><b>10.6.3</b> Comparing confidence intervals and hypothesis tests</a></li>
<li class="chapter" data-level="10.6.4" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#ht-conclusion-table"><i class="fa fa-check"></i><b>10.6.4</b> Summary table</a></li>
<li class="chapter" data-level="10.6.5" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#theory-hypo"><i class="fa fa-check"></i><b>10.6.5</b> Building theory-based methods using computation</a></li>
<li class="chapter" data-level="10.6.6" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#additional-resources-7"><i class="fa fa-check"></i><b>10.6.6</b> Additional resources</a></li>
<li class="chapter" data-level="10.6.7" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#whats-to-come-8"><i class="fa fa-check"></i><b>10.6.7</b> What’s to come</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html"><i class="fa fa-check"></i><b>11</b> Inference for Regression</a><ul>
<li class="chapter" data-level="" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#needed-packages-8"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="11.1" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#simulation-based-inference-for-regression"><i class="fa fa-check"></i><b>11.1</b> Simulation-based Inference for Regression</a><ul>
<li class="chapter" data-level="11.1.1" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#data-1"><i class="fa fa-check"></i><b>11.1.1</b> Data</a></li>
<li class="chapter" data-level="11.1.2" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#test-statistic-delta-1"><i class="fa fa-check"></i><b>11.1.2</b> Test statistic <span class="math inline">\(\delta\)</span></a></li>
<li class="chapter" data-level="11.1.3" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#observed-effect-delta-1"><i class="fa fa-check"></i><b>11.1.3</b> Observed effect <span class="math inline">\(\delta^*\)</span></a></li>
<li class="chapter" data-level="11.1.4" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#model-of-h_0-1"><i class="fa fa-check"></i><b>11.1.4</b> Model of <span class="math inline">\(H_0\)</span></a></li>
<li class="chapter" data-level="11.1.5" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#simulated-data-1"><i class="fa fa-check"></i><b>11.1.5</b> Simulated data</a></li>
<li class="chapter" data-level="11.1.6" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#distribution-of-delta-under-h_0-1"><i class="fa fa-check"></i><b>11.1.6</b> Distribution of <span class="math inline">\(\delta\)</span> under <span class="math inline">\(H_0\)</span></a></li>
<li class="chapter" data-level="11.1.7" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#the-p-value-1"><i class="fa fa-check"></i><b>11.1.7</b> The p-value</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#bootstrapping-for-the-regression-slope"><i class="fa fa-check"></i><b>11.2</b> Bootstrapping for the regression slope</a></li>
<li class="chapter" data-level="11.3" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#inference-for-multiple-regression"><i class="fa fa-check"></i><b>11.3</b> Inference for multiple regression</a><ul>
<li class="chapter" data-level="11.3.1" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#refresher-professor-evaluations-data"><i class="fa fa-check"></i><b>11.3.1</b> Refresher: Professor evaluations data</a></li>
<li class="chapter" data-level="11.3.2" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#refresher-visualizations"><i class="fa fa-check"></i><b>11.3.2</b> Refresher: Visualizations</a></li>
<li class="chapter" data-level="11.3.3" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#refresher-regression-tables"><i class="fa fa-check"></i><b>11.3.3</b> Refresher: Regression tables</a></li>
<li class="chapter" data-level="11.3.4" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#script-of-r-code"><i class="fa fa-check"></i><b>11.3.4</b> Script of R code</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#residual-analysis"><i class="fa fa-check"></i><b>11.4</b> Residual analysis</a><ul>
<li class="chapter" data-level="11.4.1" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#model1residuals"><i class="fa fa-check"></i><b>11.4.1</b> Residual analysis</a></li>
<li class="chapter" data-level="11.4.2" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#model2residuals"><i class="fa fa-check"></i><b>11.4.2</b> Residual analysis</a></li>
<li class="chapter" data-level="11.4.3" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#model3residuals"><i class="fa fa-check"></i><b>11.4.3</b> Residual analysis</a></li>
<li class="chapter" data-level="11.4.4" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#model4residuals"><i class="fa fa-check"></i><b>11.4.4</b> Residual analysis</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>IV Conclusion</b></span></li>
<li class="chapter" data-level="12" data-path="12-thinking-with-data.html"><a href="12-thinking-with-data.html"><i class="fa fa-check"></i><b>12</b> Thinking with Data</a><ul>
<li class="chapter" data-level="" data-path="12-thinking-with-data.html"><a href="12-thinking-with-data.html#needed-packages-9"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="12.1" data-path="12-thinking-with-data.html"><a href="12-thinking-with-data.html#seattle-house-prices"><i class="fa fa-check"></i><b>12.1</b> Case study: Seattle house prices</a><ul>
<li class="chapter" data-level="12.1.1" data-path="12-thinking-with-data.html"><a href="12-thinking-with-data.html#house-prices-EDA-I"><i class="fa fa-check"></i><b>12.1.1</b> Exploratory data analysis (EDA)</a></li>
<li class="chapter" data-level="12.1.2" data-path="12-thinking-with-data.html"><a href="12-thinking-with-data.html#log10-transformations"><i class="fa fa-check"></i><b>12.1.2</b> log10 transformations</a></li>
<li class="chapter" data-level="12.1.3" data-path="12-thinking-with-data.html"><a href="12-thinking-with-data.html#eda-part-ii"><i class="fa fa-check"></i><b>12.1.3</b> EDA Part II</a></li>
<li class="chapter" data-level="12.1.4" data-path="12-thinking-with-data.html"><a href="12-thinking-with-data.html#house-prices-regression"><i class="fa fa-check"></i><b>12.1.4</b> Regression modeling</a></li>
<li class="chapter" data-level="12.1.5" data-path="12-thinking-with-data.html"><a href="12-thinking-with-data.html#house-prices-making-predictions"><i class="fa fa-check"></i><b>12.1.5</b> Making predictions</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="12-thinking-with-data.html"><a href="12-thinking-with-data.html#data-journalism"><i class="fa fa-check"></i><b>12.2</b> Case study: Effective data storytelling</a><ul>
<li class="chapter" data-level="12.2.1" data-path="12-thinking-with-data.html"><a href="12-thinking-with-data.html#bechdel-test-for-hollywood-gender-representation"><i class="fa fa-check"></i><b>12.2.1</b> Bechdel test for Hollywood gender representation</a></li>
<li class="chapter" data-level="12.2.2" data-path="12-thinking-with-data.html"><a href="12-thinking-with-data.html#us-births-in-1999"><i class="fa fa-check"></i><b>12.2.2</b> US Births in 1999</a></li>
<li class="chapter" data-level="12.2.3" data-path="12-thinking-with-data.html"><a href="12-thinking-with-data.html#other-examples"><i class="fa fa-check"></i><b>12.2.3</b> Other examples</a></li>
<li class="chapter" data-level="12.2.4" data-path="12-thinking-with-data.html"><a href="12-thinking-with-data.html#script-of-r-code-1"><i class="fa fa-check"></i><b>12.2.4</b> Script of R code</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="12-thinking-with-data.html"><a href="12-thinking-with-data.html#concluding-remarks"><i class="fa fa-check"></i>Concluding remarks</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="A-appendixA.html"><a href="A-appendixA.html"><i class="fa fa-check"></i><b>A</b> Statistical Background</a><ul>
<li class="chapter" data-level="A.1" data-path="A-appendixA.html"><a href="A-appendixA.html#basic-statistical-terms"><i class="fa fa-check"></i><b>A.1</b> Basic statistical terms</a><ul>
<li class="chapter" data-level="A.1.1" data-path="A-appendixA.html"><a href="A-appendixA.html#mean"><i class="fa fa-check"></i><b>A.1.1</b> Mean</a></li>
<li class="chapter" data-level="A.1.2" data-path="A-appendixA.html"><a href="A-appendixA.html#median"><i class="fa fa-check"></i><b>A.1.2</b> Median</a></li>
<li class="chapter" data-level="A.1.3" data-path="A-appendixA.html"><a href="A-appendixA.html#standard-deviation"><i class="fa fa-check"></i><b>A.1.3</b> Standard deviation</a></li>
<li class="chapter" data-level="A.1.4" data-path="A-appendixA.html"><a href="A-appendixA.html#five-number-summary"><i class="fa fa-check"></i><b>A.1.4</b> Five-number summary</a></li>
<li class="chapter" data-level="A.1.5" data-path="A-appendixA.html"><a href="A-appendixA.html#distribution"><i class="fa fa-check"></i><b>A.1.5</b> Distribution</a></li>
<li class="chapter" data-level="A.1.6" data-path="A-appendixA.html"><a href="A-appendixA.html#outliers"><i class="fa fa-check"></i><b>A.1.6</b> Outliers</a></li>
</ul></li>
<li class="chapter" data-level="A.2" data-path="A-appendixA.html"><a href="A-appendixA.html#normal-curve"><i class="fa fa-check"></i><b>A.2</b> Normal distribution</a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="B-appendixB.html"><a href="B-appendixB.html"><i class="fa fa-check"></i><b>B</b> Inference Examples</a><ul>
<li class="chapter" data-level="" data-path="B-appendixB.html"><a href="B-appendixB.html#needed-packages-10"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="B.1" data-path="B-appendixB.html"><a href="B-appendixB.html#inference-mind-map"><i class="fa fa-check"></i><b>B.1</b> Inference mind map</a></li>
<li class="chapter" data-level="B.2" data-path="B-appendixB.html"><a href="B-appendixB.html#one-mean"><i class="fa fa-check"></i><b>B.2</b> One mean</a><ul>
<li class="chapter" data-level="B.2.1" data-path="B-appendixB.html"><a href="B-appendixB.html#problem-statement"><i class="fa fa-check"></i><b>B.2.1</b> Problem statement</a></li>
<li class="chapter" data-level="B.2.2" data-path="B-appendixB.html"><a href="B-appendixB.html#competing-hypotheses"><i class="fa fa-check"></i><b>B.2.2</b> Competing hypotheses</a></li>
<li class="chapter" data-level="B.2.3" data-path="B-appendixB.html"><a href="B-appendixB.html#exploring-the-sample-data"><i class="fa fa-check"></i><b>B.2.3</b> Exploring the sample data</a></li>
<li class="chapter" data-level="B.2.4" data-path="B-appendixB.html"><a href="B-appendixB.html#non-traditional-methods"><i class="fa fa-check"></i><b>B.2.4</b> Non-traditional methods</a></li>
<li class="chapter" data-level="B.2.5" data-path="B-appendixB.html"><a href="B-appendixB.html#traditional-methods"><i class="fa fa-check"></i><b>B.2.5</b> Traditional methods</a></li>
<li class="chapter" data-level="B.2.6" data-path="B-appendixB.html"><a href="B-appendixB.html#comparing-results"><i class="fa fa-check"></i><b>B.2.6</b> Comparing results</a></li>
</ul></li>
<li class="chapter" data-level="B.3" data-path="B-appendixB.html"><a href="B-appendixB.html#one-proportion"><i class="fa fa-check"></i><b>B.3</b> One proportion</a><ul>
<li class="chapter" data-level="B.3.1" data-path="B-appendixB.html"><a href="B-appendixB.html#problem-statement-1"><i class="fa fa-check"></i><b>B.3.1</b> Problem statement</a></li>
<li class="chapter" data-level="B.3.2" data-path="B-appendixB.html"><a href="B-appendixB.html#competing-hypotheses-1"><i class="fa fa-check"></i><b>B.3.2</b> Competing hypotheses</a></li>
<li class="chapter" data-level="B.3.3" data-path="B-appendixB.html"><a href="B-appendixB.html#exploring-the-sample-data-1"><i class="fa fa-check"></i><b>B.3.3</b> Exploring the sample data</a></li>
<li class="chapter" data-level="B.3.4" data-path="B-appendixB.html"><a href="B-appendixB.html#non-traditional-methods-1"><i class="fa fa-check"></i><b>B.3.4</b> Non-traditional methods</a></li>
<li class="chapter" data-level="B.3.5" data-path="B-appendixB.html"><a href="B-appendixB.html#traditional-methods-1"><i class="fa fa-check"></i><b>B.3.5</b> Traditional methods</a></li>
<li class="chapter" data-level="B.3.6" data-path="B-appendixB.html"><a href="B-appendixB.html#comparing-results-1"><i class="fa fa-check"></i><b>B.3.6</b> Comparing results</a></li>
</ul></li>
<li class="chapter" data-level="B.4" data-path="B-appendixB.html"><a href="B-appendixB.html#two-proportions"><i class="fa fa-check"></i><b>B.4</b> Two proportions</a><ul>
<li class="chapter" data-level="B.4.1" data-path="B-appendixB.html"><a href="B-appendixB.html#problem-statement-2"><i class="fa fa-check"></i><b>B.4.1</b> Problem statement</a></li>
<li class="chapter" data-level="B.4.2" data-path="B-appendixB.html"><a href="B-appendixB.html#competing-hypotheses-2"><i class="fa fa-check"></i><b>B.4.2</b> Competing hypotheses</a></li>
<li class="chapter" data-level="B.4.3" data-path="B-appendixB.html"><a href="B-appendixB.html#exploring-the-sample-data-2"><i class="fa fa-check"></i><b>B.4.3</b> Exploring the sample data</a></li>
<li class="chapter" data-level="B.4.4" data-path="B-appendixB.html"><a href="B-appendixB.html#non-traditional-methods-2"><i class="fa fa-check"></i><b>B.4.4</b> Non-traditional methods</a></li>
<li class="chapter" data-level="B.4.5" data-path="B-appendixB.html"><a href="B-appendixB.html#traditional-methods-2"><i class="fa fa-check"></i><b>B.4.5</b> Traditional methods</a></li>
<li class="chapter" data-level="B.4.6" data-path="B-appendixB.html"><a href="B-appendixB.html#check-conditions-2"><i class="fa fa-check"></i><b>B.4.6</b> Check conditions</a></li>
<li class="chapter" data-level="B.4.7" data-path="B-appendixB.html"><a href="B-appendixB.html#test-statistic-2"><i class="fa fa-check"></i><b>B.4.7</b> Test statistic</a></li>
<li class="chapter" data-level="B.4.8" data-path="B-appendixB.html"><a href="B-appendixB.html#state-conclusion-2"><i class="fa fa-check"></i><b>B.4.8</b> State conclusion</a></li>
<li class="chapter" data-level="B.4.9" data-path="B-appendixB.html"><a href="B-appendixB.html#comparing-results-2"><i class="fa fa-check"></i><b>B.4.9</b> Comparing results</a></li>
</ul></li>
<li class="chapter" data-level="B.5" data-path="B-appendixB.html"><a href="B-appendixB.html#two-means-independent-samples"><i class="fa fa-check"></i><b>B.5</b> Two means (independent samples)</a><ul>
<li class="chapter" data-level="B.5.1" data-path="B-appendixB.html"><a href="B-appendixB.html#problem-statement-3"><i class="fa fa-check"></i><b>B.5.1</b> Problem statement</a></li>
<li class="chapter" data-level="B.5.2" data-path="B-appendixB.html"><a href="B-appendixB.html#competing-hypotheses-3"><i class="fa fa-check"></i><b>B.5.2</b> Competing hypotheses</a></li>
<li class="chapter" data-level="B.5.3" data-path="B-appendixB.html"><a href="B-appendixB.html#exploring-the-sample-data-3"><i class="fa fa-check"></i><b>B.5.3</b> Exploring the sample data</a></li>
<li class="chapter" data-level="B.5.4" data-path="B-appendixB.html"><a href="B-appendixB.html#non-traditional-methods-3"><i class="fa fa-check"></i><b>B.5.4</b> Non-traditional methods</a></li>
<li class="chapter" data-level="B.5.5" data-path="B-appendixB.html"><a href="B-appendixB.html#traditional-methods-3"><i class="fa fa-check"></i><b>B.5.5</b> Traditional methods</a></li>
<li class="chapter" data-level="B.5.6" data-path="B-appendixB.html"><a href="B-appendixB.html#test-statistic-3"><i class="fa fa-check"></i><b>B.5.6</b> Test statistic</a></li>
<li class="chapter" data-level="B.5.7" data-path="B-appendixB.html"><a href="B-appendixB.html#compute-p-value-1"><i class="fa fa-check"></i><b>B.5.7</b> Compute <span class="math inline">\(p\)</span>-value</a></li>
<li class="chapter" data-level="B.5.8" data-path="B-appendixB.html"><a href="B-appendixB.html#state-conclusion-3"><i class="fa fa-check"></i><b>B.5.8</b> State conclusion</a></li>
<li class="chapter" data-level="B.5.9" data-path="B-appendixB.html"><a href="B-appendixB.html#comparing-results-3"><i class="fa fa-check"></i><b>B.5.9</b> Comparing results</a></li>
</ul></li>
<li class="chapter" data-level="B.6" data-path="B-appendixB.html"><a href="B-appendixB.html#two-means-paired-samples"><i class="fa fa-check"></i><b>B.6</b> Two means (paired samples)</a><ul>
<li class="chapter" data-level="B.6.1" data-path="B-appendixB.html"><a href="B-appendixB.html#competing-hypotheses-4"><i class="fa fa-check"></i><b>B.6.1</b> Competing hypotheses</a></li>
<li class="chapter" data-level="B.6.2" data-path="B-appendixB.html"><a href="B-appendixB.html#exploring-the-sample-data-4"><i class="fa fa-check"></i><b>B.6.2</b> Exploring the sample data</a></li>
<li class="chapter" data-level="B.6.3" data-path="B-appendixB.html"><a href="B-appendixB.html#non-traditional-methods-4"><i class="fa fa-check"></i><b>B.6.3</b> Non-traditional methods</a></li>
<li class="chapter" data-level="B.6.4" data-path="B-appendixB.html"><a href="B-appendixB.html#traditional-methods-4"><i class="fa fa-check"></i><b>B.6.4</b> Traditional methods</a></li>
<li class="chapter" data-level="B.6.5" data-path="B-appendixB.html"><a href="B-appendixB.html#comparing-results-4"><i class="fa fa-check"></i><b>B.6.5</b> Comparing results</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="C" data-path="C-appendixC.html"><a href="C-appendixC.html"><i class="fa fa-check"></i><b>C</b> Reach for the Stars</a><ul>
<li class="chapter" data-level="" data-path="C-appendixC.html"><a href="C-appendixC.html#needed-packages-11"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="C.1" data-path="C-appendixC.html"><a href="C-appendixC.html#sorted-barplots"><i class="fa fa-check"></i><b>C.1</b> Sorted barplots</a></li>
<li class="chapter" data-level="C.2" data-path="C-appendixC.html"><a href="C-appendixC.html#interactive-graphics"><i class="fa fa-check"></i><b>C.2</b> Interactive graphics</a><ul>
<li class="chapter" data-level="C.2.1" data-path="C-appendixC.html"><a href="C-appendixC.html#interactive-linegraphs"><i class="fa fa-check"></i><b>C.2.1</b> Interactive linegraphs</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="D" data-path="D-appendixD.html"><a href="D-appendixD.html"><i class="fa fa-check"></i><b>D</b> Learning Check Solutions</a><ul>
<li class="chapter" data-level="D.1" data-path="D-appendixD.html"><a href="D-appendixD.html#chapter-2-solutions"><i class="fa fa-check"></i><b>D.1</b> Chapter 2 Solutions</a></li>
<li class="chapter" data-level="D.2" data-path="D-appendixD.html"><a href="D-appendixD.html#chapter-3-solutions"><i class="fa fa-check"></i><b>D.2</b> Chapter 3 Solutions</a></li>
<li class="chapter" data-level="D.3" data-path="D-appendixD.html"><a href="D-appendixD.html#chapter-4-solutions"><i class="fa fa-check"></i><b>D.3</b> Chapter 4 Solutions</a></li>
<li class="chapter" data-level="D.4" data-path="D-appendixD.html"><a href="D-appendixD.html#chapter-5-solutions"><i class="fa fa-check"></i><b>D.4</b> Chapter 5 Solutions</a></li>
<li class="chapter" data-level="D.5" data-path="D-appendixD.html"><a href="D-appendixD.html#chapter-6-solutions"><i class="fa fa-check"></i><b>D.5</b> Chapter 6 Solutions</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Statistical Inference via Data Science</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<html>
<img src='https://moderndive.com/wide_format.png' alt="ModernDive">
</html>
<div id="multiple-regression" class="section level1">
<h1><span class="header-section-number">Chapter 7</span> Multiple Regression</h1>
<p>In Chapter <a href="6-regression.html#regression">6</a> we introduced ideas related to modeling for explanation, in particular that the goal of modeling is make explicit the relationship between some outcome variable <span class="math inline">\(y\)</span> and some explanatory variable <span class="math inline">\(x\)</span>. While there are many approaches to modeling, we focused on one particular technique: <em>linear regression</em>, one of the most commonly-used and easy-to-understand approaches to modeling. Furthermore to keep things simple we only considered models with one explanatory <span class="math inline">\(x\)</span> variable that was either numerical in Section <a href="6-regression.html#model1">6.1</a> or categorical in Section <a href="6-regression.html#model2">6.2</a>.</p>
<p>In this chapter on multiple regression we’ll start considering models that include more than one explanatory variable <span class="math inline">\(x\)</span>. You can imagine when trying to model a particular outcome variable, like teaching evaluation scores as in Section <a href="6-regression.html#model1">6.1</a> or life expectancy as in Section <a href="6-regression.html#model2">6.2</a>, that it would be very useful to include more than just one explanatory variable’s worth of information.</p>
<p>Since our regression models will now consider more than one explanatory variable, the interpretation of the associated effect of any one explanatory variable must be made in conjunction with the other explanatory variables included in your model. Let’s begin!</p>
<div id="needed-packages-4" class="section level3 unnumbered">
<h3>Needed packages</h3>
<p>Let’s load all the packages needed for this chapter (this assumes you’ve already installed them). Recall from our discussion in Section <a href="5-tidy.html#tidyverse-package">5.4.1</a> that loading the <code>tidyverse</code> package by running <code>library(tidyverse)</code> loads the following commonly used data science packages all at once:</p>
<ul>
<li><code>ggplot2</code> for data visualization</li>
<li><code>dplyr</code> for data wrangling</li>
<li><code>tidyr</code> for converting data to “tidy” format</li>
<li><code>readr</code> for importing spreadsheet data into R</li>
<li>As well as the more advanced <code>purrr</code>, <code>tibble</code>, <code>stringr</code>, and <code>forcats</code> packages</li>
</ul>
<p>If needed, read Section <a href="2-getting-started.html#packages">2.3</a> for information on how to install and load R packages.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(tidyverse)
<span class="kw">library</span>(moderndive)
<span class="kw">library</span>(skimr)
<span class="kw">library</span>(ISLR)</code></pre>
<hr />
</div>
<div id="model4" class="section level2">
<h2><span class="header-section-number">7.1</span> One numerical &amp; one categorical explanatory variable</h2>
<p>Let’s revisit the instructor evaluation data we introduced in Section <a href="6-regression.html#model1">6.1</a>, where we studied the relationship between instructor evaluation scores (as given by students) and their “beauty” scores for instructors teaching courses at the UT Austin; the variable teaching <code>score</code> was a numerical outcome variable <span class="math inline">\(y\)</span> and the variable beauty score <code>bty_avg</code> was a numerical explanatory <span class="math inline">\(x\)</span> variable.</p>
<p>In this section we are going to consider a different model. Our outcome variable will still be teaching score, but now including two different explanatory variables: age and gender. Could it be that instructors who are older receive better teaching evaluations from students? Or could it instead be that younger instructors receive better evaluations? Are there differences in evaluations given by students for instructors of different genders? We’ll answer these questions by modeling the relationship between these variables using <em>multiple regression</em> where we have:</p>
<ol style="list-style-type: decimal">
<li>A numerical outcome variable <span class="math inline">\(y\)</span>, as before the instructor’s teaching score and</li>
<li>Two explanatory variables:
<ol style="list-style-type: decimal">
<li>A numerical explanatory variable <span class="math inline">\(x_1\)</span>, the instructor’s age</li>
<li>A categorical explanatory variable <span class="math inline">\(x_2\)</span>, the instructor’s binary gender (male or female).</li>
</ol></li>
</ol>
<p>It is important to note that at the time of this study, due to then commonly held beliefs about gender, this variable was often recorded as a binary. While the results of a model that oversimplifies gender this way may be imperfect, we still found the results to be very pertinent and relevant today. An eminent statistician by the name George E.P. Box summarizes our thinking very nicely: <a href="https://en.wikipedia.org/wiki/All_models_are_wrong">“All models are wrong, but some are useful.”</a>.</p>
<div id="model4EDA" class="section level3">
<h3><span class="header-section-number">7.1.1</span> Exploratory data analysis</h3>
<p>The data on the 463 courses at the UT Austin can be found in the <code>evals</code> data frame included in the <code>moderndive</code> package. However, to keep things simple, let’s <code>select()</code> only the subset of the variables we’ll consider in this chapter, and save this data in a new data frame called <code>eval_ch7</code>. Note that these are different than the variables chosen in Chapter 6.</p>
<pre class="sourceCode r"><code class="sourceCode r">evals_ch7 &lt;-<span class="st"> </span>evals <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(ID, score, age, gender)</code></pre>
<p>Recall the three common steps in an exploratory data analysis we saw in Section <a href="6-regression.html#model1EDA">6.1.1</a></p>
<ol style="list-style-type: decimal">
<li>Looking at the raw data values.</li>
<li>Computing summary statistics, like means, medians, and interquartile ranges.</li>
<li>Creating data visualizations.</li>
</ol>
<p>Let’s first look at the raw data values both either looking at <code>evals_ch7</code> RStudio’s spreadsheet viewer or using the <code>glimpse()</code> function</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">glimpse</span>(evals_ch7)</code></pre>
<pre><code>Observations: 463
Variables: 4
$ ID     &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18,…
$ score  &lt;dbl&gt; 4.7, 4.1, 3.9, 4.8, 4.6, 4.3, 2.8, 4.1, 3.4, 4.5, 3.8, 4.5, 4.…
$ age    &lt;int&gt; 36, 36, 36, 36, 59, 59, 59, 51, 51, 40, 40, 40, 40, 40, 40, 40…
$ gender &lt;fct&gt; female, female, female, female, male, male, male, male, male, …</code></pre>
<p>Let’s also display a random sample of 5 rows of the 463 rows corresponding to different courses in Table <a href="#tab:model4-data-preview"><strong>??</strong></a>. Remember due to the random nature of the sampling, you will likely end up with a different subset of 5 rows.</p>
<pre class="sourceCode r"><code class="sourceCode r">evals_ch7 <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">sample_n</span>(<span class="dt">size =</span> <span class="dv">5</span>)</code></pre>

<p>Now that we’ve looked at the raw values in our <code>evals_ch7</code> data frame and obtained a sense of the data, let’s move on to next common step in an exploratory data analysis: computing summary statistics. As we did in our exploratory data analyses in Sections <a href="6-regression.html#model1EDA">6.1.1</a> and <a href="6-regression.html#model2EDA">6.2.1</a> from the previous chapter, let’s use the <code>skim()</code> function from the <code>skimr</code> package, being sure to only <code>select()</code> the variables of interest of model:</p>
<pre class="sourceCode r"><code class="sourceCode r">evals_ch7 <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">select</span>(score, age, gender) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">skim</span>()</code></pre>
<pre><code>Skim summary statistics
 n obs: 463 
 n variables: 3 

── Variable type:factor ──────────────────────────────────────────────────────────────────
 variable missing complete   n n_unique                top_counts ordered
   gender       0      463 463        2 mal: 268, fem: 195, NA: 0   FALSE

── Variable type:integer ─────────────────────────────────────────────────────────────────
 variable missing complete   n  mean  sd p0 p25 p50 p75 p100     hist
      age       0      463 463 48.37 9.8 29  42  48  57   73 ▅▅▅▇▅▇▂▁

── Variable type:numeric ─────────────────────────────────────────────────────────────────
 variable missing complete   n mean   sd  p0 p25 p50 p75 p100     hist
    score       0      463 463 4.17 0.54 2.3 3.8 4.3 4.6    5 ▁▁▂▃▅▇▇▆</code></pre>
<p>Observe for example that we have no missing data, courses taught by 268 male vs 195 female instructors, and and average age of 48.37. Recall however that each row in our data represents a particular course and that instructors can teach more than one course. Therefore the average age of the unique instructors may differ.</p>
<p>Furthermore, let’s compute the correlation between our two numerical variables: <code>score</code> and <code>age</code>. Recall from Section <a href="6-regression.html#model1EDA">6.1.1</a> that correlation coefficients only exist between numerical variables. We observe that they are weakly negatively correlated.</p>
<pre class="sourceCode r"><code class="sourceCode r">evals_ch7 <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">get_correlation</span>(<span class="dt">formula =</span> score <span class="op">~</span><span class="st"> </span>age)</code></pre>
<pre><code># A tibble: 1 x 1
  correlation
        &lt;dbl&gt;
1   -0.107032</code></pre>
<p>Let’s now perform the last of the three common steps in an exploratory data analysis: creating data visualizations. Given that the outcome variable <code>score</code> and explanatory variable <code>age</code> are both numerical, we’ll use a scatterplot to display their relationship. How can we incorporate the categorical variable <code>gender</code> however? By mapping the variable <code>gender</code> to the color aesthetic and creating a <em>colored</em> scatterplot! The following code is very similar to the code that created the scatterplot of teaching score and beauty score in Figure <a href="6-regression.html#fig:numxplot1">6.2</a>, but with <code>color = gender</code> added to the <code>aes()</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(evals_ch7, <span class="kw">aes</span>(<span class="dt">x =</span> age, <span class="dt">y =</span> score, <span class="dt">color =</span> gender)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Age&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Teaching Score&quot;</span>, <span class="dt">color =</span> <span class="st">&quot;Gender&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">se =</span> <span class="ot">FALSE</span>)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:numxcatxplot1"></span>
<img src="ismaykim_files/figure-html/numxcatxplot1-1.png" alt="Colored scatterplot of relationship of teaching and beauty scores" width="\textwidth" />
<p class="caption">
FIGURE 7.1: Colored scatterplot of relationship of teaching and beauty scores
</p>
</div>
<p>In the resulting Figure <a href="7-multiple-regression.html#fig:numxcatxplot1">7.1</a>, observe that <code>ggplot</code> assigns a default red/blue color scheme to the points and lines associated with each of the two levels of <code>gender</code>: <code>female</code> and <code>male</code>. Furthermore the <code>geom_smooth(method = &quot;lm&quot;, se = FALSE)</code> layer automatically fits a different regression line for each group since we have provided <code>color = gender</code> in the aesthetic mapping. This allows for all subsequent geometries to have the same aesthetic mappings.</p>
<p>We notice some interesting trends:</p>
<ol style="list-style-type: decimal">
<li>There are almost no women faculty over the age of 60 as evidenced by lack of red dots above <span class="math inline">\(x\)</span> = 60.</li>
<li>While both regression lines are negatively sloped with age (i.e. as instructor’s age, so also do they tend to receive lower teaching scores), the slope for age for the female instructors is <em>more</em> negative. In other words, the female instructors are paying a harsher penalty in their teaching scores then the male instructors do.</li>
</ol>
</div>
<div id="model4interactiontable" class="section level3">
<h3><span class="header-section-number">7.1.2</span> Interaction model</h3>
<p>Let’s now quantify the relationship of our outcome variable <span class="math inline">\(y\)</span> and two explanatory variables using one type of multiple regression model known as an “interaction model.” Unfortunately, we don’t have enough context at this point to explain where the term “interaction” comes from; we’ll explain why statisticians use this term at the end of this section.</p>
<p>In particular, we’ll write out the equation of the two regression lines in Figure <a href="7-multiple-regression.html#fig:numxcatxplot1">7.1</a> using the values from a regression table. Before we do this however, let’s go over a brief refresher of regression when you have a categorical explanatory variable <span class="math inline">\(x\)</span>.</p>
<p>Recall in Section <a href="6-regression.html#model2table">6.2.2</a> we fit a regression model for countries’ life expectancy as a function of which continent the country was in. In other words we had a numerical outcome variable <span class="math inline">\(y\)</span> = <code>lifeExp</code> and a categorical explanatory variable <span class="math inline">\(x\)</span> = <code>continent</code> which had 5 levels: <code>Africa</code>, <code>Americas</code>, <code>Asia</code>, <code>Europe</code>, and <code>Oceania</code>. Let’s redisplay the regression table you saw in Table <a href="#tab:catxplot4b"><strong>??</strong></a>:</p>

<p>Recall our interpretations of the <code>estimate</code> column. Since <code>Africa</code> was the “baseline for comparison” group since Africa comes first alphabetically, the <code>intercept</code> term corresponds to the mean life expectancy for all countries in Africa of 54.8 years. The other 4 values of <code>estimate</code> correspond to “offsets” relative to the baseline group. So for example, the “offset” corresponding to the Americas is +18.8 versus the baseline for comparison group Africa i.e. the average life expectancy for countries in the Americas is 18.8 years <em>higher</em>. Thus the mean life expectancy for all countries in the Americas is 54.8 + 18.8 = 73.6. The same interpretation holds for Asia, Europe, and Oceania.</p>
<p>Going to back to our multiple regression model for teaching <code>score</code> using <code>age</code> and <code>gender</code> in Figure <a href="7-multiple-regression.html#fig:numxcatxplot1">7.1</a>, we generate the regression table using the same two step approach from Chapter <a href="6-regression.html#regression">6</a>: we first “fit” the model using the <code>lm()</code> “linear model” function and then we apply the <code>get_regression_table()</code> function. This time however our model formula won’t be of form <code>y ~ x</code>, but rather of form <code>y ~ x1 * x2</code>. In other words our two explanatory variables <code>x1</code> and <code>x2</code> are separated by a <code>*</code> sign:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Fit regression model:</span>
score_model_interaction &lt;-<span class="st"> </span><span class="kw">lm</span>(score <span class="op">~</span><span class="st"> </span>age <span class="op">*</span><span class="st"> </span>gender, <span class="dt">data =</span> evals_ch7)
<span class="co"># Get regression table:</span>
<span class="kw">get_regression_table</span>(score_model_interaction)</code></pre>

<p>Looking the regression table output in Table <a href="#tab:regtable-interaction"><strong>??</strong></a>, we see there are four rows of values in the <code>estimate</code> column. While it is not immediately apparent, using these four values we can write out the equations of both the red and blue lines in Figure <a href="7-multiple-regression.html#fig:numxcatxplot1">7.1</a>. Let’s build these up.</p>
<p>First, since the word <code>female</code> is alphabetically before <code>male</code>, female instructors are the “baseline for comparison” group. Therefore <code>intercept</code> is the intercept and <code>age</code> is the slope for age <em>for only the female instructors</em>. In other words, the red regression line in Figure <a href="7-multiple-regression.html#fig:numxcatxplot1">7.1</a> has intercept 4.883 and slope for age of -0.018. Remember that for this particular data, while the intercept has a mathematical interpretation, it has no <em>practical</em> interpretation since there can’t be any instructors with age = 0.</p>
<p>What about the intercept and slope for age of the male instructors? In other words the blue line in Figure <a href="7-multiple-regression.html#fig:numxcatxplot1">7.1</a>? This is where our notion of “offsets” comes into play once again. The value for <code>gendermale</code> of -0.446 is not the intercept for the male instructors, but rather the <em>offset</em> (or difference) in intercept for male instructors relative to female instructors. Therefore, the intercept for the male instructors is <code>intercept + gendermale</code> = 4.883 + (-0.446) = 4.883 - 0.446 = 4.437.</p>
<p>Similarly, <code>age:gendermale</code> = 0.014 is not the slope for age for the male instructors, but rather the <em>offset</em> (or difference) in slope for the male instructors. Therefore, the slope for age for the male instructors is <code>age + age:gendermale</code> = -0.018 + 0.014 = -0.004. Therefore the blue regression line in Figure <a href="7-multiple-regression.html#fig:numxcatxplot1">7.1</a> has intercept 4.437 and slope for age of -0.004.</p>
<p>Let’s summarize these values in Table <a href="#tab:interaction-summary"><strong>??</strong></a> and focus on the two slopes for age:</p>

<p>Since the slope for age for the female instructors was -0.018, it means that for every additional year in age for female instructors, there is an associated <em>decrease</em> of on average 0.018 units in teaching score. For the male instructors however, the corresponding associated decrease was on average only 0.004 units. While both slopes for age were negative, the slope for age for the female instructors is <em>more negative</em>. This is consistent with our observation from Figure <a href="7-multiple-regression.html#fig:numxcatxplot1">7.1</a>, that this model is suggesting female instructors are paying a heavier price for aging in the evaluations they receive from students.</p>
<p>Let’s now write the equation for our regression lines, which we can use to compute our fitted values <span class="math inline">\(\widehat{y} = \widehat{\text{score}}\)</span>.</p>
<p><span class="math display">\[
\begin{aligned}
\widehat{y} = \widehat{\text{score}} &amp;= b_0 + b_{\mbox{age}} \cdot \mbox{age} + b_{\mbox{male}} \cdot \mathbb{1}_{\mbox{is male}}(x) + b_{\mbox{age,male}} \cdot \mbox{age} \cdot \mathbb{1}_{\mbox{is male}}\\
&amp;= 4.883 -0.018 \cdot \mbox{age} - 0.446 \cdot \mathbb{1}_{\mbox{is male}}(x) + 0.014 \cdot \mbox{age} \cdot \mathbb{1}_{\mbox{is male}}
\end{aligned}
\]</span></p>
<p>Whoa! That’s even more daunting than the equation you saw for the life expectancy as a function of continent in Section <a href="6-regression.html#model2table">6.2.2</a>! However if you recall what an “indicator function” AKA “dummy variable” does, the equation simplifies greatly. In the above equation, we have one indicator function of interest:</p>
<p><span class="math display">\[
\mathbb{1}_{\mbox{is male}}(x) = \left\{
\begin{array}{ll}
1 &amp; \text{if } \text{instructor } x \text{ is male} \\
0 &amp; \text{otherwise}\end{array}
\right.
\]</span></p>
<p>Second, let’s match coefficients in the above equation with values in the <code>estimate</code> column in our regression table in Table <a href="#tab:regtable-interaction"><strong>??</strong></a>:</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(b_0\)</span> is the <code>intercept</code> = 4.883 <em>for the female instructors</em></li>
<li><span class="math inline">\(b_{\mbox{age}}\)</span> is the slope for <code>age</code> = -0.018 <em>for the female instructors</em></li>
<li><span class="math inline">\(b_{\mbox{male}}\)</span> is the <em>offset in intercept for the male instructors</em></li>
<li><span class="math inline">\(b_{\mbox{age,male}}\)</span> is the <em>offset in slope for age for the male instructors</em></li>
</ol>
<p>Let’s put this all together and compute the fitted value <span class="math inline">\(\widehat{y} = \widehat{\text{score}}\)</span> for female instructors. Since for female instructors <span class="math inline">\(\mathbb{1}_{\mbox{is male}}(x)\)</span> = 0, the above equation becomes</p>
<p><span class="math display">\[
\begin{aligned}
\widehat{y} = \widehat{\text{score}} &amp;= b_0 + b_{\mbox{age}} \cdot \mbox{age} + b_{\mbox{male}} \cdot \mathbb{1}_{\mbox{is male}}(x) + b_{\mbox{age,male}} \cdot \mbox{age} \cdot \mathbb{1}_{\mbox{is male}}\\
&amp;= 4.883 - 0.018    \cdot \mbox{age} - 0.446 \cdot \mathbb{1}_{\mbox{is male}}(x) + 0.014 \cdot \mbox{age} \cdot \mathbb{1}_{\mbox{is male}}\\
&amp;= 4.883 - 0.018    \cdot \mbox{age} - 0.446 \cdot 0 + 0.014 \cdot \mbox{age} \cdot 0\\
&amp;= 4.883 - 0.018    \cdot \mbox{age} - 0 + 0\\
&amp;= 4.883 - 0.018    \cdot \mbox{age}\\
\end{aligned}
\]</span></p>
<p>which is the equation of the red regression line in Figure <a href="7-multiple-regression.html#fig:numxcatxplot1">7.1</a> corresponding to the female instructors. Correspondingly, since for male instructors <span class="math inline">\(\mathbb{1}_{\mbox{is male}}(x)\)</span> = 1, the above equation becomes</p>
<p><span class="math display">\[
\begin{aligned}
\widehat{y} = \widehat{\text{score}} &amp;= 4.883 - 0.018   \cdot \mbox{age} - 0.446 \cdot \mathbb{1}_{\mbox{is male}}(x) + 0.014 \cdot \mbox{age} \cdot \mathbb{1}_{\mbox{is male}}\\
&amp;= 4.883 - 0.018    \cdot \mbox{age} - 0.446 \cdot 1 + 0.014 \cdot \mbox{age} \cdot 1\\
&amp;= 4.883 - 0.018    \cdot \mbox{age} - 0.446 + 0.014 \cdot \mbox{age}\\
&amp;= (4.883 - 0.446) + (- 0.018 + 0.014) * \mbox{age}\\
&amp;= 4.437 - 0.004    \cdot \mbox{age}\\
\end{aligned}
\]</span></p>
<p>which is the equation of the blue regression line in Figure <a href="7-multiple-regression.html#fig:numxcatxplot1">7.1</a> corresponding to the male instructors.</p>
<p>Phew! That was a lot of arithmetic! Don’t fret however, this is as hard as modeling will get in this book. If you’re still a little unsure about using indicator functions and using categorical explanatory variables, we <em>highly</em> suggest you re-read Section <a href="6-regression.html#model2table">6.2.2</a> which involves only a single categorical explanatory variable and thus is much simpler.</p>
<p>Before we end this section, we explain why we refer to this type of model as an “interaction model.” The <span class="math inline">\(b_{\mbox{age,male}}\)</span> term in the equation for the fitted value <span class="math inline">\(\widehat{y}\)</span> = <span class="math inline">\(\widehat{\text{score}}\)</span> is what’s known in statistical modeling as an “interaction effect.” The interaction term corresponds to the <code>age:gendermale</code> = 0.014 in the final row of the regression table in Table <a href="#tab:regtable-interaction"><strong>??</strong></a>.</p>
<p>We say there is an interaction effect if the associated effect of one variable <em>depends on the value of another variable</em>, in other words the two variables are “interacting.” In our case, the associated effect of the variable age <em>depends</em> on the value of another variable, gender. This was evidenced by the difference in slopes for age of +0.014 of male instructors relative to female instructors.</p>
<p>Another way of thinking of interaction effects is as follows. For a given instructor at the UT Austin, there might be an associated effect of their age on their teaching scores, there might be an associated effect of the gender on their teaching scores, but when put together, there might an <em>additional effect due to the intersection</em> of their age and their gender.</p>
</div>
<div id="model4table" class="section level3">
<h3><span class="header-section-number">7.1.3</span> Parallel slopes model</h3>
<p>When creating regression models with one numerical and one categorical explanatory variable, we are not just limited to interaction models as we just saw. Another type of model we can use is known as the “parallel slopes” model. Unlike with interaction models where the regression line can have both different intercepts and different slopes, parallel slopes models still allow for different intercepts but <em>force</em> all lines to have the same slope. The resulting regression lines are thus parallel. Let’s visualize the best fitting parallel slopes model to our <code>evals_ch7</code> data.</p>
<p>Unfortunately, the <code>ggplot2</code> package does not have a convenient way to plot a parallel slopes model. We therefore created our own function <code>gg_parallel_slopes()</code> and included it in the <code>moderndive</code> package:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">gg_parallel_slopes</span>(<span class="dt">y =</span> <span class="st">&quot;score&quot;</span>, <span class="dt">num_x =</span> <span class="st">&quot;age&quot;</span>, <span class="dt">cat_x =</span> <span class="st">&quot;gender&quot;</span>, 
                   <span class="dt">data =</span> evals_ch7)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:numxcatx-parallel"></span>
<img src="ismaykim_files/figure-html/numxcatx-parallel-1.png" alt="Parallel slopes model of relationship of score with age and gender." width="\textwidth" />
<p class="caption">
FIGURE 7.2: Parallel slopes model of relationship of score with age and gender.
</p>
</div>
<p>Note the arguments i.e. inputs to this function: the outcome variable <code>y = &quot;score&quot;</code>, the numerical explanatory variable <code>num_x = &quot;age&quot;</code>, the categorical explanatory variable <code>cat_x = &quot;gender&quot;</code>, and the data frame that includes this <code>data = evals_ch7</code>. Be careful to include the quotation marks when specifying all variables, something you don’t have to do when creating a visualization with <code>ggplot()</code>.</p>
<p>Observe in Figure <a href="7-multiple-regression.html#fig:numxcatx-parallel">7.2</a> that we now have parallel red and blue lines corresponding to the female and male instructors respectively, in other words they have the same negative slope. In other words, as instructors age, so also do they tend to receive lower teaching evaluation scores from students. However these two lines have different intercepts as evidenced by the fact that the blue line corresponding to the male instructors is higher than the red line corresponding to the female instructors.</p>
<p>In order to obtain the precise numerical values of the intercepts and the common slope, we once again first “fit” the model using the <code>lm()</code> “linear model” function and then we apply the <code>get_regression_table()</code> function. However, unlike the interaction model which had a model formula of form <code>y ~ x1 * x2</code>, our model formula is now of form <code>y ~ x1 + x2</code>. In other words our two explanatory variables <code>x1</code> and <code>x2</code> are separated by a <code>+</code> sign:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Fit regression model:</span>
score_model_parallel_slopes &lt;-<span class="st"> </span><span class="kw">lm</span>(score <span class="op">~</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>gender, <span class="dt">data =</span> evals_ch7)
<span class="co"># Get regression table:</span>
<span class="kw">get_regression_table</span>(score_model_parallel_slopes)</code></pre>

<p>Similarly to the regression table for the interaction model from our earlier Table <a href="#tab:regtable-interaction"><strong>??</strong></a>, we have an <code>intercept</code> term corresponding to the intercept for the “baseline for comparison” female instructor group and a <code>gendermale</code> term corresponding to the <em>offset</em> (or difference) in intercept for the male instructors relative to female instructors. In other words in Figure <a href="7-multiple-regression.html#fig:numxcatx-parallel">7.2</a> the red regression line corresponding to the female instructors has an intercept of 4.484 while the blue regression line corresponding to the male instructors has an intercept of 4.484 + 0.191 = 4.67. Once again, since there aren’t any instructors of age 0, the intercepts only have a mathematical interpretation but no practical one.</p>
<p>Unlike in Table <a href="#tab:regtable-interaction"><strong>??</strong></a> we now only have a single term relating to the slope for age as we’ve forced both the female and male instructors to have a common slope for age of -0.009. In other words, for every increase of 1 year in instructor age, we observe an associated decrease of on average 0.009 units in teaching for <em>both</em> the female and male instructor.</p>
<p>Let’s now write the equation for our regression lines, which we can use to compute our fitted values <span class="math inline">\(\widehat{y} = \widehat{\text{score}}\)</span>.</p>
<p><span class="math display">\[
\begin{aligned}
\widehat{y} = \widehat{\text{score}} &amp;= b_0 + b_{\mbox{age}} \cdot \mbox{age} + b_{\mbox{male}} \cdot \mathbb{1}_{\mbox{is male}}(x)\\
&amp;= 4.484 -0.009 \cdot \mbox{age} + 0.191 \cdot \mathbb{1}_{\mbox{is male}}(x) 
\end{aligned}
\]</span></p>
<p>Let’s put this all together and compute the fitted value <span class="math inline">\(\widehat{y} = \widehat{\text{score}}\)</span> for female instructors. Since for female instructors <span class="math inline">\(\mathbb{1}_{\mbox{is male}}(x)\)</span> = 0, the above equation becomes</p>
<p><span class="math display">\[
\begin{aligned}
\widehat{y} = \widehat{\text{score}} &amp;= b_0 + b_{\mbox{age}} \cdot \mbox{age} + b_{\mbox{male}} \cdot \mathbb{1}_{\mbox{is male}}(x)\\
&amp;= 4.484 -0.009 \cdot \mbox{age} + 0.191 \cdot \mathbb{1}_{\mbox{is male}}(x)\\
&amp;= 4.484 -0.009 \cdot \mbox{age} + 0.191 \cdot 0\\
&amp;= 4.484 -0.009 \cdot \mbox{age}
\end{aligned}
\]</span></p>
<p>which is the equation of the red regression line in Figure <a href="7-multiple-regression.html#fig:numxcatx-parallel">7.2</a> corresponding to the female instructors. Correspondingly, since for male instructors <span class="math inline">\(\mathbb{1}_{\mbox{is male}}(x)\)</span> = 1, the above equation becomes</p>
<p><span class="math display">\[
\begin{aligned}
\widehat{y} = \widehat{\text{score}} &amp;= b_0 + b_{\mbox{age}} \cdot \mbox{age} + b_{\mbox{male}} \cdot \mathbb{1}_{\mbox{is male}}(x)\\
&amp;= 4.484 -0.009 \cdot \mbox{age} + 0.191 \cdot \mathbb{1}_{\mbox{is male}}(x)\\
&amp;= 4.484 -0.009 \cdot \mbox{age} + 0.191 \cdot 1\\
&amp;= (4.484 + 0.191) - 0.009 \cdot \mbox{age}\\
&amp;= 4.67 -0.009 \cdot \mbox{age}
\end{aligned}
\]</span></p>
<p>which is the equation of the blue regression line in Figure <a href="7-multiple-regression.html#fig:numxcatx-parallel">7.2</a> corresponding to the male instructors.</p>
<p>Great! We’ve considered both an interaction model and a parallel slopes model for our data. Let’s compare the visualizations for both models side-by-side in Figure <a href="7-multiple-regression.html#fig:numxcatx-comparison">7.3</a></p>
<div class="figure" style="text-align: center"><span id="fig:numxcatx-comparison"></span>
<img src="ismaykim_files/figure-html/numxcatx-comparison-1.png" alt="Comparison of interaction and parallel slopes models." width="\textwidth" />
<p class="caption">
FIGURE 7.3: Comparison of interaction and parallel slopes models.
</p>
</div>
<p>At this point, you might be asking yourself: “Why would we ever use an parallel slopes model?” Looking at the left-hand plot in Figure <a href="7-multiple-regression.html#fig:numxcatx-comparison">7.3</a>, the two lines definitely do not appear to be parallel, so why would we <em>force</em> them to be parallel as in the right-hand plot?&quot; For this data, we agree! It can easily be argued that the interaction model is more appropriate. However, in Section <a href="7-multiple-regression.html#model-selection">7.3.1</a> below on model selection, we’ll present an example where it can be argued that the case for a parallel slopes model might be stronger.</p>
</div>
<div id="model4points" class="section level3">
<h3><span class="header-section-number">7.1.4</span> Observed/fitted values and residuals</h3>
<p>For brevity’s sake, in this section we’ll only compute the observed values, fitted values, and residuals for the interaction model which we saved in <code>score_model_interaction</code>. You’ll have an opportunity to study these values for our parallel slopes model in the upcoming Learning Check.</p>
<p>Say you have a professor who is female and is 36 years old? What fitted value <span class="math inline">\(\widehat{y}\)</span> = <span class="math inline">\(\widehat{\text{score}}\)</span> would our model yield? Say you have another professor who is male and is 59 years old? What would their fitted value <span class="math inline">\(\widehat{y}\)</span> be? We answer this question visually by finding the intersection of the red regression line and a vertical line at <span class="math inline">\(x\)</span> = age = 36; we mark this value with a large red dot in Figure <a href="7-multiple-regression.html#fig:fitted-values">7.4</a>. Similarly we can identify the fitted value <span class="math inline">\(\widehat{y}\)</span> = <span class="math inline">\(\widehat{\text{score}}\)</span> for the male instructor by finding the intersection of the blue regression line and a vertical line at <span class="math inline">\(x\)</span> = age = 59; we mark this value with a large blue dot in Figure <a href="7-multiple-regression.html#fig:fitted-values">7.4</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:fitted-values"></span>
<img src="ismaykim_files/figure-html/fitted-values-1.png" alt="Fitted values for two new professors" width="\textwidth" />
<p class="caption">
FIGURE 7.4: Fitted values for two new professors
</p>
</div>
<p>However, what are these values precisely? We can use the equations of the two regression lines we computed in Section <a href="7-multiple-regression.html#model4interactiontable">7.1.2</a>, which in turn were based on values from the regression table in Table <a href="#tab:regtable-interaction"><strong>??</strong></a>:</p>
<ul>
<li>For all female instructors: <span class="math inline">\(\widehat{y} = \widehat{\text{score}} = 4.883 - 0.018 \cdot \mbox{age}\)</span></li>
<li>For all male instructors: <span class="math inline">\(\widehat{y} = \widehat{\text{score}} = 4.437 - 0.004 \cdot \mbox{age}\)</span></li>
</ul>
<p>So our fitted values would be: 4.883 - 0.018 <span class="math inline">\(\cdot\)</span> 36 = 4.25 and 4.437 - 0.004 <span class="math inline">\(\cdot\)</span> 59 = 4.20 respectively. What if however we wanted the fitted values not just for these two instructors, but the instructors for all 463 courses? Doing this by hand would be long and tedious! This is where the <code>get_regression_points()</code> function from the moderndive package can help: it will quickly automate this for all 463 courses. We present the results in Table <a href="#tab:model4-points-table"><strong>??</strong></a>.</p>
<pre class="sourceCode r"><code class="sourceCode r">regression_points &lt;-<span class="st"> </span><span class="kw">get_regression_points</span>(score_model_interaction)
regression_points</code></pre>

<p>In fact, it turns out that the female instructor of age 36 taught the first four courses while the male instructor taught the next 3. The resulting <span class="math inline">\(\widehat{y}\)</span> = <span class="math inline">\(\widehat{\text{score}}\)</span> fitted values are in the <code>score_hat</code> column. Furthermore, <code>get_regression_points()</code> function also returns the residuals <span class="math inline">\(y-\widehat{y}\)</span>. Notice for example the first and fourth courses the female instructor of age 36 taught had positive residuals, indicating that the actual teaching score they received from students was less than their fitted score of 4.25. On the other hand the second and third course this instructor taught had negative residuals, indicating that the actual teaching score they received from students was more than their fitted score of 4.25.</p>
<div class="learncheck">
<p>
<strong><em>Learning check</em></strong>
</p>
</div>
<p><strong>(LC7.1)</strong> Compute the observed values, fitted values, and residuals not for the interaction model as we just did, but rather for the parallel slopes model we saved in <code>score_model_interaction</code>.</p>
<div class="learncheck">

</div>
<hr />
</div>
</div>
<div id="model3" class="section level2">
<h2><span class="header-section-number">7.2</span> Two numerical explanatory variables</h2>
<p>Let’s now switch gears and consider multiple regression models where instead of one numerical and one categorical explanatory variable, we have two numerical explanatory variables! The dataset we’ll use is from <a href="http://www-bcf.usc.edu/~gareth/ISL/">An Introduction to Statistical Learning with Applications in R (ISLR)</a>, an intermediate-level textbook on statistical and machine learning. It’s accompanying <code>ISLR</code> R package contains datasets that the authors apply various machine learning methods to.</p>
<p>One frequently used dataset in this book <code>Credit</code> dataset, where the outcome variable of interest is the credit card debt, in other words credit card debt, of 400 individuals. Other variables like income, credit limit, credit rating, and age are included as well. Note that the <code>Credit</code> data is not based on real individuals’ financial information, but rather is a simulated dataset used for educational purposes.</p>
<p>In this section, we’ll fit a regression model where we have</p>
<ol style="list-style-type: decimal">
<li>A numerical outcome variable <span class="math inline">\(y\)</span>, the cardholder’s credit card debt</li>
<li>Two explanatory variables:
<ol style="list-style-type: decimal">
<li>One numerical explanatory variable <span class="math inline">\(x_1\)</span>, the cardholder’s credit limit</li>
<li>Another numerical explanatory variable <span class="math inline">\(x_2\)</span>, the cardholder’s income (in thousands of dollars).</li>
</ol></li>
</ol>
<p>In the forthcoming Learning Checks, we’ll consider a different regression model</p>
<ol style="list-style-type: decimal">
<li>The same numerical outcome variable <span class="math inline">\(y\)</span>, the cardholder’s credit card debt</li>
<li>Two different explanatory variables:
<ol style="list-style-type: decimal">
<li>One numerical explanatory variable <span class="math inline">\(x_1\)</span>, the cardholder’s credit rating</li>
<li>Another numerical explanatory variable <span class="math inline">\(x_2\)</span>, the cardholder’s age.</li>
</ol></li>
</ol>
<div id="model3EDA" class="section level3">
<h3><span class="header-section-number">7.2.1</span> Exploratory data analysis</h3>
<p>Let’s load the <code>Credit</code> data but to keep things simple to keep things simple, let’s <code>select()</code> only the subset of the variables we’ll consider in this chapter, and save this data in a new data frame called <code>credit_ch7</code>. Notice our slightly different use of the <code>select()</code> verb here: we’ll select the <code>Balance</code> variable from <code>Credit</code> for example, but we’ll save it with a new variable name <code>debt</code> since this name is a little easier to understand.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(ISLR)
credit_ch7 &lt;-<span class="st"> </span>Credit <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">select</span>(ID, <span class="dt">debt =</span> Balance, <span class="dt">credit_limit =</span> Limit, 
         <span class="dt">income =</span> Income, <span class="dt">credit_rating =</span> Rating, <span class="dt">age =</span> Age)</code></pre>
<p>You can observe the effect of our different use of the <code>select()</code> verb in the first common step of an EDA: looking at the raw values either in RStudio’s spreadsheet viewer or by using the <code>glimpse()</code></p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">glimpse</span>(credit_ch7)</code></pre>
<pre><code>Observations: 400
Variables: 6
$ ID            &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, …
$ debt          &lt;int&gt; 333, 903, 580, 964, 331, 1151, 203, 872, 279, 1350, 140…
$ credit_limit  &lt;int&gt; 3606, 6645, 7075, 9504, 4897, 8047, 3388, 7114, 3300, 6…
$ income        &lt;dbl&gt; 14.9, 106.0, 104.6, 148.9, 55.9, 80.2, 21.0, 71.4, 15.1…
$ credit_rating &lt;int&gt; 283, 483, 514, 681, 357, 569, 259, 512, 266, 491, 589, …
$ age           &lt;int&gt; 34, 82, 71, 36, 68, 77, 37, 87, 66, 41, 30, 64, 57, 49,…</code></pre>
<p>Furthermore, let’s look at a random sample of 5 out of the 400 credit card holders in Table <a href="#tab:model3-data-preview"><strong>??</strong></a>. Note due to the random nature of the sampling, you will likely end up with a different subset of 5 rows.</p>
<pre class="sourceCode r"><code class="sourceCode r">credit_ch7 <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">sample_n</span>(<span class="dt">size =</span> <span class="dv">5</span>)</code></pre>

<p>Now that we’ve looked at the raw values in our <code>credit_ch7</code> data frame and obtained a sense of the data, let’s move on to next common step in an exploratory data analysis: computing summary statistics. As you’re probably used to now, let’s use the <code>skim()</code> function from the <code>skimr</code> package, being sure to only <code>select()</code> the columns of interest for our model:</p>
<p>Let’s look at some summary statistics, again using the <code>skim()</code> function from the <code>skimr</code> package:</p>
<pre class="sourceCode r"><code class="sourceCode r">credit_ch7 <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">select</span>(debt, credit_limit, income) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">skim</span>()</code></pre>
<pre><code>Skim summary statistics
 n obs: 400 
 n variables: 3 

── Variable type:integer ─────────────────────────────────────────────────────────────────
     variable missing complete   n    mean      sd  p0     p25    p50     p75
 credit_limit       0      400 400 4735.6  2308.2  855 3088    4622.5 5872.75
         debt       0      400 400  520.01  459.76   0   68.75  459.5  863   
  p100     hist
 13913 ▅▇▇▃▂▁▁▁
  1999 ▇▃▃▃▂▁▁▁

── Variable type:numeric ─────────────────────────────────────────────────────────────────
 variable missing complete   n  mean    sd    p0   p25   p50   p75   p100
   income       0      400 400 45.22 35.24 10.35 21.01 33.12 57.47 186.63
     hist
 ▇▃▂▁▁▁▁▁</code></pre>
<p>Observe for example:</p>
<ol style="list-style-type: decimal">
<li>The mean and median credit card debt are $520.01 and $459.50 respectively.</li>
<li>25% of card holders had debts of $68.75 or less.</li>
<li>The mean and median credit card limit are $4735.6 and $4622.50 respectively.</li>
<li>75% of these card holders had incomes of $57,470 or less.</li>
</ol>
<p>Since our outcome variable <code>debt</code> and the explanatory variables <code>credit_limit</code> and <code>income</code> are numerical, we can compute the correlation coefficient between pairs of these variables. First, we could run the <code>get_correlation()</code> command as seen in Subsection <a href="6-regression.html#model1EDA">6.1.1</a> twice, once for each explanatory variable:</p>
<pre class="sourceCode r"><code class="sourceCode r">credit_ch7 <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">get_correlation</span>(debt <span class="op">~</span><span class="st"> </span>credit_limit)
credit_ch7 <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">get_correlation</span>(debt <span class="op">~</span><span class="st"> </span>income)</code></pre>
<p>Or we can simultaneously compute them by returning a <em>correlation matrix</em> which we display in Table <a href="#tab:model3-correlation"><strong>??</strong></a>. We can read off the correlation coefficient for any pair of variables by looking them up in the appropriate row/column combination.</p>
<pre class="sourceCode r"><code class="sourceCode r">credit_ch7 <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(debt, credit_limit, income) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">cor</span>()</code></pre>

<p>For example, the correlation coefficient of:</p>
<ol style="list-style-type: decimal">
<li><code>debt</code> with itself is 1 as we would expect based on the definition of the correlation coefficient.</li>
<li><code>debt</code> with <code>credit_limit</code> is 0.862. This indicates a strong positive linear relationship, which makes sense as only individuals with large credit limits can accrue large credit card debts.</li>
<li><code>debt</code> with <code>income</code> is 0.464. This is suggestive of another positive linear relationship, although not as strong as the relationship between <code>debt</code> and <code>credit_limit</code>.</li>
<li>As an added bonus, we can read off the correlation coefficient between the two explanatory variables, <code>credit_limit</code> and <code>income</code> of 0.792.</li>
</ol>
<!--
In the case of `credit_limit` and `income`, we say there is a high degree of *collinearity* between these two explanatory variables. Collinearity (or multicollinearity) is a phenomenon whereby one explanatory variable in a multiple regression model is highly correlated with another. In our case, since `credit_limit` and `income` are highly correlated, if we knew someone's`credit_limit` we could make fairly accurate guesses about their `income` as well. To put things different, these two variables provided somewhat redundant information. 
-->
<p>Let’s visualize the relationship of the outcome variable with each of the two explanatory variables in two separate plots:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(credit_ch7, <span class="kw">aes</span>(<span class="dt">x =</span> credit_limit, <span class="dt">y =</span> debt)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Credit limit (in $)&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Credit card debt (in $)&quot;</span>, 
       <span class="dt">title =</span> <span class="st">&quot;Debt and credit limit&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">se =</span> <span class="ot">FALSE</span>)
  
<span class="kw">ggplot</span>(credit_ch7, <span class="kw">aes</span>(<span class="dt">x =</span> income, <span class="dt">y =</span> debt)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Income (in $1000)&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Credit card debt (in $)&quot;</span>, 
       <span class="dt">title =</span> <span class="st">&quot;Debt and income&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">se =</span> <span class="ot">FALSE</span>)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:2numxplot1"></span>
<img src="ismaykim_files/figure-html/2numxplot1-1.png" alt="Relationship between credit card debt and credit limit/income" width="\textwidth" />
<p class="caption">
FIGURE 7.5: Relationship between credit card debt and credit limit/income
</p>
</div>
<p>Observe there is a positive relationship between credit limit and credit card debt: as credit limit increases so also does credit card debt. This is consistent with the strongly positive correlation coefficient of 0.862 we computed earlier. In the case of income, the positive relationship doesn’t appear as strong, given the weakly positive correlation coefficient of 0.464.</p>
<p>However the two plots in Figure <a href="7-multiple-regression.html#fig:2numxplot1">7.5</a> only focus on the relationship of the outcome variable with each of the two explanatory variables separately. To get a sense of the <em>joint</em> relationship of all three variables simultaneously through a visualization, we need a 3-dimensional (3D) scatterplot where for all 400 points we have</p>
<ol style="list-style-type: decimal">
<li>The numerical outcome variable <span class="math inline">\(y\)</span> <code>debt</code> is on the z-axis (the vertical axis)</li>
<li>The two numerical explanatory variables form the axes on the bottom:
<ol style="list-style-type: decimal">
<li>The first numerical explanatory variable <span class="math inline">\(x_1\)</span> <code>income</code></li>
<li>The second numerical explanatory variable <span class="math inline">\(x_2\)</span> <code>credit_limit</code></li>
</ol></li>
</ol>
<p>Furthermore, we also include a <em>regression plane</em>. In the case of regression models with a single numerical explanatory variable, we’ve seen in Section <a href="6-regression.html#leastsquares">6.3.2</a> that the regression line is “best fitting” in that of all possible lines we can draw through a cloud of points, it minimizes the sum of squared residuals. This concept now extends to when we have two numerical explanatory variables, only now we have a “best fitting” plane that cuts through the cloud of points that similarly minimizes the sum of squared residuals.</p>
<!-- This only activates if HTML build. Need to update the text for the PDF. -->
<pre><code>Click on the following image to open an interactive version of this plot in your browser:</code></pre>
<center>
<a target="_blank" class="page-link" href="https://beta.rstudioconnect.com/connect/#/apps/3214/"><img src="images/credit-card-balance-regression-plane.png" style="width=75%"/></a>
</center>
<div class="learncheck">
<p>
<strong><em>Learning check</em></strong>
</p>
</div>
<p><strong>(LC7.2)</strong> Conduct a new exploratory data analysis with the same outcome variable <span class="math inline">\(y\)</span> being <code>debt</code> but with <code>credit_rating</code> and <code>age</code> as the new explanatory variables <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span>. Remember, this involves three things:</p>
<ol style="list-style-type: decimal">
<li>Most crucially: Looking at the raw data values.</li>
<li>Computing summary statistics, like means, medians, and interquartile ranges.</li>
<li>Creating data visualizations.</li>
</ol>
<p>What can you say about the relationship between a credit card holder’s debt and their credit rating and age?</p>
<div class="learncheck">

</div>
</div>
<div id="model3table" class="section level3">
<h3><span class="header-section-number">7.2.2</span> Regression plane</h3>
<p>Let’s now fit a regression model and get the regression table corresponding to the regression plane above. For simplicity’s sake, we won’t consider the two numerical explanatory variable analogue of the interaction model from Section <a href="7-multiple-regression.html#model4interactiontable">7.1.2</a> which we fit with a model formula of the form <code>y ~ x1 * x2</code>, but rather only regression models with model formula of the form <code>y ~ x1 + x2</code>. Somewhat confusing however, since we now have a regression plane instead of multiple lines, the label “parallel slopes model” doesn’t apply when you have two numerical explanatory variables.</p>
<p>Just as we have done multiple times throughout Chapters <a href="6-regression.html#regression">6</a> and this chapter, let’s obtain the regression table for this model using our two-step process and display the results in Table <a href="#tab:model3-table-output"><strong>??</strong></a></p>
<ol style="list-style-type: decimal">
<li>We first “fit” the linear regression model using the <code>lm(y ~ x1 + x2, data)</code> function and save it in <code>debt_model</code>.</li>
<li>We get the regression table by applying the <code>get_regression_table()</code> from the <code>moderndive</code> package to <code>debt_model</code>.</li>
</ol>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Fit regression model:</span>
debt_model &lt;-<span class="st"> </span><span class="kw">lm</span>(debt <span class="op">~</span><span class="st"> </span>credit_limit <span class="op">+</span><span class="st"> </span>income, <span class="dt">data =</span> credit_ch7)
<span class="co"># Get regression table:</span>
<span class="kw">get_regression_table</span>(debt_model)</code></pre>

<p>How do we interpret the three values in the <code>estimate</code> column?</p>
<ul>
<li><code>intercept</code> = -$385.18 (rounded to two decimal points). The intercept in our case represents the credit card debt for an individual who has <code>credit_limit</code> of $0 and <code>income</code> of $0. In our data however, the intercept has limited practical interpretation since no individuals had <code>credit_limit</code> or <code>income</code> values of $0. Rather, the intercept is used to situate the regression plane in 3D space.</li>
<li><code>credit_limit</code> = $0.26. Taking into account all other the explanatory variables in our model, for every increase of one dollar in <code>credit_limit</code>, there is an associated increase of on average $0.26 in credit card debt. Note:
<ul>
<li>Just as we did in Subsection <a href="6-regression.html#model1table">6.1.2</a>, we are cautious not to make a causal statement by merely stating there there was an <em>associated</em> increase.</li>
<li>We preface our interpretation with the statement “taking into account all other the explanatory variables in our model”, here <code>income</code>, to emphasize that we are now jointly interpreting the associated effect of multiple explanatory variables in the same model at once.</li>
</ul></li>
<li><code>income</code> = -$7.66. Taking into account all other the explanatory variables in our model, for every increase of one unit in the variable <code>income</code>, in other words $1000 in actual income, there is an associated decrease of on average $7.66 in credit card debt.</li>
</ul>
<p>Putting these results together, the equation of the regression plane that gives us fitted values <span class="math inline">\(\widehat{y}\)</span> = <span class="math inline">\(\widehat{\text{debt}}\)</span>.</p>
<p><span class="math display">\[
\begin{aligned}
\widehat{y} &amp;= b_0 + b_1 \cdot x_1 +  b_2 \cdot x_2\\
\widehat{\text{debt}} &amp;= b_0 + b_{\text{limit}} \cdot \text{limit} + b_{\text{income}} \cdot \text{income}\\
&amp;= -387.179 + 0.263 \cdot\text{limit} - 7.663 \cdot\text{income}
\end{aligned}
\]</span></p>
<p>Recall in the right-hand plot of Figure <a href="7-multiple-regression.html#fig:2numxplot1">7.5</a> that when plotting the relationship between <code>debt</code> and <code>income</code> in isolation, there appeared to be a positive relationship. In the above multiple regression however, when jointly modeling the relationship between <code>debt</code>, <code>credit_limit</code>, and <code>income</code>, there appears to be a negative relationship of <code>debt</code> and <code>income</code> as evidenced by the negative slope for <code>income</code> of -$7.66. What explains these contradictory results? A phenomenon known as Simpson’s Paradox whereby overall trends that exist in aggregate either disappear or reverse when the data are broken down into groups. In Subsection <a href="7-multiple-regression.html#simpsonsparadox">7.3.3</a> we elaborate on this by looking at the relationship between <code>credit_limit</code> and credit card <code>debt</code>, but split by different income brackets.</p>
<div class="learncheck">
<p>
<strong><em>Learning check</em></strong>
</p>
</div>
<p><strong>(LC7.3)</strong> Fit a new simple linear regression using <code>lm(debt ~ credit_rating + age, data = credit_ch7)</code> where <code>credit_rating</code> and <code>age</code> are the new numerical explanatory variables <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span>. Get information about the “best-fitting” regression plane from the regression table by applying the <code>get_regression_table()</code> function. How do the regression results match up with the results from your exploratory data analysis above?</p>
<div class="learncheck">

</div>
</div>
<div id="model3points" class="section level3">
<h3><span class="header-section-number">7.2.3</span> Observed/fitted values and residuals</h3>
<p>Let’s also compute all fitted values and residuals for our regression model using the <code>get_regression_points()</code> function and present only the first 10 rows of output in Table <a href="#tab:model3-points-table"><strong>??</strong></a>. Remember that the (x, y, z) coordinates of each of the blue points in our 3D scatterplot can be found in the <code>income</code>, <code>credit_limit</code>, and <code>debt</code> columns. The fitted values on the regression plane are found in the <code>debt_hat</code> column and are computed using our equation for the regression plane in the previous section:</p>
<p><span class="math display">\[
\begin{aligned}
\widehat{y} = \widehat{\text{debt}} &amp;= -387.179 + 0.263 \cdot \text{limit} - 7.663 \cdot \text{income}
\end{aligned}
\]</span></p>
<pre class="sourceCode r"><code class="sourceCode r">regression_points &lt;-<span class="st"> </span><span class="kw">get_regression_points</span>(debt_model)
regression_points</code></pre>

<hr />
</div>
</div>
<div id="related-topics-1" class="section level2">
<h2><span class="header-section-number">7.3</span> Related topics</h2>
<div id="model-selection" class="section level3">
<h3><span class="header-section-number">7.3.1</span> Model selection</h3>
<p>When do we use an interaction model versus a parallel slopes model? Recall in Sections <a href="7-multiple-regression.html#model4interactiontable">7.1.2</a> and <a href="7-multiple-regression.html#model4table">7.1.3</a> we fit both interaction and parallel slopes models for the outcome variable <span class="math inline">\(y\)</span> teaching score using a numerical explanatory variable <span class="math inline">\(x_1\)</span> age and a categorical explanatory variable <span class="math inline">\(x_2\)</span> gender. We compared these models in Figure <a href="7-multiple-regression.html#fig:numxcatx-comparison">7.3</a>, which we display again below.</p>
<p><img src="ismaykim_files/figure-html/unnamed-chunk-224-1.png" width="\textwidth" style="display: block; margin: auto;" /></p>
<p>A lot of you might have asked yourselves: “Why would I force the lines to have parallel slopes (as seen in the right-hand plot) when they clearly have different slopes (as seen in the left-hand plot).”</p>
<p>The answer lies in a philosophical principle known as “Occam’s Razor” which states that “all other things being equal, simpler solutions are more likely to be correct than complex ones.” When viewed in a modeling framework, Occam’s Razor can be recast as “all other things being equal, simpler models are to be preferred over complex ones.” In other words, we should only favor the more complex model if the additional complexity is warranted.</p>
<p>Let’s revisit the equations for the regression line for both the interaction and parallel slopes model:</p>
<p><span class="math display">\[
\begin{aligned}
\text{Interaction} &amp;: \widehat{y} = \widehat{\text{score}} = b_0 + b_{\mbox{age}} \cdot \mbox{age} + b_{\mbox{male}} \cdot \mathbb{1}_{\mbox{is male}}(x) + \\
&amp; \qquad b_{\mbox{age,male}} \cdot \mbox{age} \cdot \mathbb{1}_{\mbox{is male}}\\
\text{Parallel slopes} &amp;: \widehat{y} = \widehat{\text{score}} = b_0 + b_{\mbox{age}} \cdot \mbox{age} + b_{\mbox{male}} \cdot \mathbb{1}_{\mbox{is male}}(x)
\end{aligned}
\]</span></p>
<p>The interaction model is “more complex” in that there is an additional <span class="math inline">\(b_{\mbox{age,male}} \cdot \mbox{age} \cdot \mathbb{1}_{\mbox{is male}}\)</span> element to the equation not present for the parallel slopes model. Or viewed alternatively, the regression table for the interaction model in Table <a href="#tab:regtable-interaction"><strong>??</strong></a> has <em>four</em> rows, whereas the regression table for the parallel slopes model in Table <a href="#tab:regtable-parallel-slopes"><strong>??</strong></a> has <em>three</em> rows. The question becomes: “Is this additional complexity warranted?” In this case, it can be argued that it is.</p>
<p>However, let’s consider an example where it might not be. Let’s consider the <code>MA_schools</code> data which contains 2017 data on Massachusetts public high schools provided by Massachusetts Department of Education; read the help file for this data by running <code>?MA_schools</code> if you would like more details. Let’s model</p>
<ol style="list-style-type: decimal">
<li>A numerical outcome variable <span class="math inline">\(y\)</span>, average SAT math score for that high school</li>
<li>Two explanatory variables:
<ol style="list-style-type: decimal">
<li>A numerical explanatory variable <span class="math inline">\(x_1\)</span>, the percentage of that high school’s student body that are economically disadvantaged</li>
<li>A categorical explanatory variable <span class="math inline">\(x_2\)</span>, the school size as measured by enrollment: small (13-341 students), medium (342-541 students), and large (542-4264 students)</li>
</ol></li>
</ol>
<p>Let’s create visualizations of both the interaction and parallel slopes model once again and display the output in Figure <a href="7-multiple-regression.html#fig:numxcatx-comparison-2">7.6</a>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Interaction model</span>
<span class="kw">ggplot</span>(MA_schools, <span class="kw">aes</span>(<span class="dt">x =</span> perc_disadvan, <span class="dt">y =</span> average_sat_math, <span class="dt">color =</span> size)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">alpha =</span> <span class="fl">0.25</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">se =</span> <span class="ot">FALSE</span> ) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Percent economically disadvantaged&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Math SAT Score&quot;</span>, 
       <span class="dt">color =</span> <span class="st">&quot;School size&quot;</span>, <span class="dt">title =</span> <span class="st">&quot;Interaction model&quot;</span>)

<span class="co"># Parallel slopes model</span>
<span class="kw">gg_parallel_slopes</span>(<span class="dt">y =</span> <span class="st">&quot;average_sat_math&quot;</span>, <span class="dt">num_x =</span> <span class="st">&quot;perc_disadvan&quot;</span>, 
                   <span class="dt">cat_x =</span> <span class="st">&quot;size&quot;</span>, <span class="dt">data =</span> MA_schools, <span class="dt">alpha =</span> <span class="fl">0.25</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Percent economically disadvantaged&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Math SAT Score&quot;</span>, 
       <span class="dt">color =</span> <span class="st">&quot;School size&quot;</span>, <span class="dt">title =</span> <span class="st">&quot;Parallel slopes model&quot;</span>) </code></pre>
<div class="figure" style="text-align: center"><span id="fig:numxcatx-comparison-2"></span>
<img src="ismaykim_files/figure-html/numxcatx-comparison-2-1.png" alt="Comparison of interaction and parallel slopes models." width="\textwidth" />
<p class="caption">
FIGURE 7.6: Comparison of interaction and parallel slopes models.
</p>
</div>
<p>Looking closely at the left-hand plot of Figure <a href="7-multiple-regression.html#fig:numxcatx-comparison-2">7.6</a>, while the slopes are indeed different they are not different <em>by much</em>, in other words they are near identical. Comparing the left-hand plot with the right-hand plot, they don’t appear all that different at all. In this case, it can be argued that the additional complexity of the interaction model is <em>not warranted</em> and thus by Occam’s Razor the simpler parallel slopes model is to be preferred.</p>
<p>This additional complexity is apparent when comparing the corresponding regression tables in Tables <a href="#tab:model2-interaction"><strong>??</strong></a> and <a href="#tab:model2-parallel-slopes"><strong>??</strong></a>; the regression table for the interaction model has 2 more rows. Furthermore, the <em>offsets</em> in slopes for percentage of students that are disadvantaged <code>perc_disadvan:sizemedium</code> = 0.146 and <code>perc_disadvan:sizelarge</code> = 0.189 are very small relative to the slope for the baseline group of small schools.</p>
<pre class="sourceCode r"><code class="sourceCode r">model_<span class="dv">2</span>_interaction &lt;-<span class="st"> </span><span class="kw">lm</span>(average_sat_math <span class="op">~</span><span class="st"> </span>perc_disadvan <span class="op">*</span><span class="st"> </span>size, 
                          <span class="dt">data =</span> MA_schools)
<span class="kw">get_regression_table</span>(model_<span class="dv">2</span>_interaction)</code></pre>

<pre class="sourceCode r"><code class="sourceCode r">model_<span class="dv">2</span>_parallel_slopes &lt;-<span class="st"> </span><span class="kw">lm</span>(average_sat_math <span class="op">~</span><span class="st"> </span>perc_disadvan <span class="op">+</span><span class="st"> </span>size, 
                              <span class="dt">data =</span> MA_schools)
<span class="kw">get_regression_table</span>(model_<span class="dv">2</span>_parallel_slopes)</code></pre>

<p>These results are suggesting that irrespective of school size, the relationship between average math SAT scores and the percent of the student body that is economically disadvantaged is alas very negative.</p>
<p>What you have just performed is a rudimentary <em>model selection</em>: choosing which model fits data best among a set of candidate models. While the model selection you just performed was somewhat qualitative fashion, more statistically rigorous methods exist. If you’re curious, take a course on multiple regression!</p>
</div>
<div id="correlationcoefficient2" class="section level3">
<h3><span class="header-section-number">7.3.2</span> Correlation coefficient</h3>
<p>Recall from Table <a href="#tab:model3-correlation"><strong>??</strong></a> that the correlation coefficient between <code>income</code> in thousands of dollars and credit card <code>debt</code> was 0.464. What if in instead we looked at the correlation coefficient between <code>income</code> and credit card <code>debt</code>, but where <code>income</code> was in dollars and not thousands of dollars? This can be done by multiplying <code>income</code> by 1000.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(ISLR)
credit_ch7 <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">select</span>(debt, income) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">income =</span> income <span class="op">*</span><span class="st"> </span><span class="dv">1000</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">cor</span>()</code></pre>

<p>We see it is the same! We say that the correlation coefficient is invariant to linear transformations! In other words, the correlation between <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> will be the same as the correlation between <span class="math inline">\(a\times x + b\)</span> and <span class="math inline">\(y\)</span> for any numerical values <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>.</p>
</div>
<div id="simpsonsparadox" class="section level3">
<h3><span class="header-section-number">7.3.3</span> Simpson’s Paradox</h3>
<p>Recall in Section <a href="7-multiple-regression.html#model3">7.2</a>, we saw the two following seemingly contradictory results when studying the relationship between credit card debt, credit limit, and income. On the one hand, the right hand plot of Figure <a href="7-multiple-regression.html#fig:2numxplot1">7.5</a> suggested that credit card debt and income were positively related:</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-229"></span>
<img src="ismaykim_files/figure-html/unnamed-chunk-229-1.png" alt="Relationship between credit card debt and credit limit/income" width="\textwidth" />
<p class="caption">
FIGURE 7.7: Relationship between credit card debt and credit limit/income
</p>
</div>
<p>On the other hand, the multiple regression in Table <a href="#tab:model3-table-output"><strong>??</strong></a>, suggested that when modeling credit card debt as a function of <em>both</em> <code>credit_limit</code> and <code>income</code> at the same time, credit limit has a negative relationship with credit card debt as evidenced by the slope of -7.66. How can this be?</p>
<p>First, let’s dive a little deeper into the explanatory variable <code>credit_limit</code>. Figure <a href="7-multiple-regression.html#fig:credit-limit-quartiles">7.8</a> shows a histogram of all 400 values of <code>credit_limit</code>, along with vertical red lines that cut up the data into quartiles, meaning:</p>
<ol style="list-style-type: decimal">
<li>25% of credit limits were between $0 and $3088. Let’s call this the <code>low</code> credit limit group.</li>
<li>25% of credit limits were between $3088 and $4622. Let’s call this the <code>medium-low</code> credit limit group.</li>
<li>25% of credit limits were between $4622 and $5873. Let’s call this the <code>medium-high</code> credit limit group.</li>
<li>25% of credit limits were over $5873. Let’s call this the <code>high</code> credit limit group.</li>
</ol>
<div class="figure" style="text-align: center"><span id="fig:credit-limit-quartiles"></span>
<img src="ismaykim_files/figure-html/credit-limit-quartiles-1.png" alt="Histogram of credit limits and quartiles" width="\textwidth" />
<p class="caption">
FIGURE 7.8: Histogram of credit limits and quartiles
</p>
</div>
<p>In Figure <a href="7-multiple-regression.html#fig:2numxplot4">7.9</a> let’s display</p>
<ol style="list-style-type: decimal">
<li>In the left-hand plot: The scatterplot showing the relationship between credit card <code>debt</code> and <code>credit_limit</code> from earlier.</li>
<li>In the right-hand plot: The same exact same scatterplot both now with color indicating</li>
</ol>
<div class="figure" style="text-align: center"><span id="fig:2numxplot4"></span>
<img src="ismaykim_files/figure-html/2numxplot4-1.png" alt="Relationship between credit card debt and income for different credit limit groups" width="\textwidth" />
<p class="caption">
FIGURE 7.9: Relationship between credit card debt and income for different credit limit groups
</p>
</div>
<p>The left-hand plot focuses of the relationship between debt and income in <em>aggregate</em>, which suggests a positive relationship between income and credit card debt. However, the right-hand plot focuses on the relationship between debt and income <em>broken down by credit limit group</em>, where we observe that the <code>low</code> (red points), <code>medium-low</code> (green points), and <code>medium-high</code> (blue points) income groups, the strong positive relationship between credit card debt and income disappears! Only for the high bracket does the relationship stay somewhat positive. In this example, credit limit is a <em>confounding variable</em> for credit card debt and income. This is a phenomenon known as <a href="https://en.wikipedia.org/wiki/Simpson%27s_paradox">Simpson’s Paradox</a> whereby overall trends that exist in aggregate either disappear or reverse when the data are broken down into groups.</p>
<hr />
</div>
</div>
<div id="conclusion-5" class="section level2">
<h2><span class="header-section-number">7.4</span> Conclusion</h2>
<div id="additional-resources-4" class="section level3">
<h3><span class="header-section-number">7.4.1</span> Additional resources</h3>
<p>An R script file of all R code used in this chapter is available <a href="scripts/07-multiple-regression.R">here</a>.</p>
</div>
<div id="whats-to-come-5" class="section level3">
<h3><span class="header-section-number">7.4.2</span> What’s to come?</h3>
<p>Congratulations! We’ve completed the “Data Modeling via moderndive” portion of this book! We’re ready to proceed to the third and final portion of this book: &quot;Statistical Inference via infer. Statistical inference is the science of inferring about some unknown quantity using sampling. Among the most well-known example of sampling are polls. Because asking an entire population about their opinions would be a long and arduous task, pollsters often take a smaller sample that is hopefully representative of the population. Based on the results of the sample, pollsters hope to make claims about the greater population.</p>
<p>Once we’ve covered Chapters <a href="8-sampling.html#sampling">8</a> on sampling, <a href="9-confidence-intervals.html#confidence-intervals">9</a> on confidence intervals, and <a href="10-hypothesis-testing.html#hypothesis-testing">10</a> on hypothesis testing, in Chapter <a href="11-inference-for-regression.html#inference-for-regression">11</a> on inference for regression we’ll revisit the regression models we studied in Chapter <a href="6-regression.html#regression">6</a> and <a href="7-multiple-regression.html#multiple-regression">7</a>. So far we’ve only studied the <code>estimate</code> column of all our regression tables. The next 4 chapters focus on what the remaining columns mean: <code>std_error</code> standard error, <code>statistic</code> test statistic, <code>p_value</code> p-value, <code>lower_ci</code> lower 95% confidence interval bound, and <code>upper_ci</code> upper 95% confidence interval bound.</p>
<p>Furthermore, we’ll talk about the importance of residuals <span class="math inline">\(y - \widehat{y}\)</span> play in interpreting the results of a regression. We’ll perform what is known as <em>residual analyses</em> of the <code>residual</code> variable of all <code>get_regression_points()</code> output to verify what are known as the &quot;assumptions for inference for regression. On to the next one!</p>
<center>
<img src="images/flowcharts/flowchart/flowchart.006.png" title="ModernDive flowchart" width="800"/>
</center>

</div>
</div>
</div>



            </section>

          </div>
        </div>
      </div>
<a href="6-regression.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="8-sampling.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/moderndive/moderndive_book/edit/master/07-multiple-regression.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": ["ismaykim.pdf"],
"toc": {
"collapse": "section",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
