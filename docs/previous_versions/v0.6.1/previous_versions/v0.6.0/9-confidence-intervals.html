<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 9 Bootstrapping and Confidence Intervals | Statistical Inference via Data Science</title>
  <meta name="description" content="An open-source and fully-reproducible electronic textbook for teaching statistical inference using tidyverse data science tools." />
  <meta name="generator" content="bookdown 0.11 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 9 Bootstrapping and Confidence Intervals | Statistical Inference via Data Science" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://moderndive.com/" />
  <meta property="og:image" content="https://moderndive.com/images/logos/book_cover.png" />
  <meta property="og:description" content="An open-source and fully-reproducible electronic textbook for teaching statistical inference using tidyverse data science tools." />
  <meta name="github-repo" content="moderndive/moderndive_book" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 9 Bootstrapping and Confidence Intervals | Statistical Inference via Data Science" />
  
  <meta name="twitter:description" content="An open-source and fully-reproducible electronic textbook for teaching statistical inference using tidyverse data science tools." />
  <meta name="twitter:image" content="https://moderndive.com/images/logos/book_cover.png" />

<meta name="author" content="Chester Ismay and Albert Y. Kim" />


<meta name="date" content="2019-08-07" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  <link rel="apple-touch-icon-precomposed" sizes="152x152" href="images/logos/favicons/apple-touch-icon.png" />
  <link rel="shortcut icon" href="images/logos/favicons/favicon.ico" type="image/x-icon" />
<link rel="prev" href="8-sampling.html">
<link rel="next" href="10-hypothesis-testing.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<script src="libs/htmlwidgets-1.3/htmlwidgets.js"></script>
<link href="libs/dygraphs-1.1.1/dygraph.css" rel="stylesheet" />
<script src="libs/dygraphs-1.1.1/dygraph-combined.js"></script>
<script src="libs/dygraphs-1.1.1/shapes.js"></script>
<script src="libs/moment-2.8.4/moment.js"></script>
<script src="libs/moment-timezone-0.2.5/moment-timezone-with-data.js"></script>
<script src="libs/moment-fquarter-1.0.0/moment-fquarter.min.js"></script>
<script src="libs/dygraphs-binding-1.1.1.6/dygraphs.js"></script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-89938436-1', 'auto');
  ga('send', 'pageview');

</script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#sec:intro-for-students"><i class="fa fa-check"></i><b>1.1</b> Introduction for students</a><ul>
<li class="chapter" data-level="1.1.1" data-path="index.html"><a href="index.html#subsec:learning-goals"><i class="fa fa-check"></i><b>1.1.1</b> What you will learn from this book</a></li>
<li class="chapter" data-level="1.1.2" data-path="index.html"><a href="index.html#subsec:pipeline"><i class="fa fa-check"></i><b>1.1.2</b> Data/science pipeline</a></li>
<li class="chapter" data-level="1.1.3" data-path="index.html"><a href="index.html#subsec:reproducible"><i class="fa fa-check"></i><b>1.1.3</b> Reproducible research</a></li>
<li class="chapter" data-level="1.1.4" data-path="index.html"><a href="index.html#final-note-for-students"><i class="fa fa-check"></i><b>1.1.4</b> Final note for students</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#sec:intro-instructors"><i class="fa fa-check"></i><b>1.2</b> Introduction for instructors</a><ul>
<li class="chapter" data-level="1.2.1" data-path="index.html"><a href="index.html#who-is-this-book-for"><i class="fa fa-check"></i><b>1.2.1</b> Who is this book for?</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#sec:connect-contribute"><i class="fa fa-check"></i><b>1.3</b> Connect and contribute</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#sec:about-book"><i class="fa fa-check"></i><b>1.4</b> About this book</a></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#sec:about-authors"><i class="fa fa-check"></i><b>1.5</b> About the authors</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="2-getting-started.html"><a href="2-getting-started.html"><i class="fa fa-check"></i><b>2</b> Getting Started with Data in R</a><ul>
<li class="chapter" data-level="2.1" data-path="2-getting-started.html"><a href="2-getting-started.html#r-rstudio"><i class="fa fa-check"></i><b>2.1</b> What are R and RStudio?</a><ul>
<li class="chapter" data-level="2.1.1" data-path="2-getting-started.html"><a href="2-getting-started.html#installing-r-and-rstudio"><i class="fa fa-check"></i><b>2.1.1</b> Installing R and RStudio</a></li>
<li class="chapter" data-level="2.1.2" data-path="2-getting-started.html"><a href="2-getting-started.html#using-r-via-rstudio"><i class="fa fa-check"></i><b>2.1.2</b> Using R via RStudio</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="2-getting-started.html"><a href="2-getting-started.html#code"><i class="fa fa-check"></i><b>2.2</b> How do I code in R?</a><ul>
<li class="chapter" data-level="2.2.1" data-path="2-getting-started.html"><a href="2-getting-started.html#programming-concepts"><i class="fa fa-check"></i><b>2.2.1</b> Basic programming concepts and terminology</a></li>
<li class="chapter" data-level="2.2.2" data-path="2-getting-started.html"><a href="2-getting-started.html#errors-warnings-and-messages"><i class="fa fa-check"></i><b>2.2.2</b> Errors, warnings, and messages</a></li>
<li class="chapter" data-level="2.2.3" data-path="2-getting-started.html"><a href="2-getting-started.html#tips-on-learning-to-code"><i class="fa fa-check"></i><b>2.2.3</b> Tips on learning to code</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="2-getting-started.html"><a href="2-getting-started.html#packages"><i class="fa fa-check"></i><b>2.3</b> What are R packages?</a><ul>
<li class="chapter" data-level="2.3.1" data-path="2-getting-started.html"><a href="2-getting-started.html#package-installation"><i class="fa fa-check"></i><b>2.3.1</b> Package installation</a></li>
<li class="chapter" data-level="2.3.2" data-path="2-getting-started.html"><a href="2-getting-started.html#package-loading"><i class="fa fa-check"></i><b>2.3.2</b> Package loading</a></li>
<li class="chapter" data-level="2.3.3" data-path="2-getting-started.html"><a href="2-getting-started.html#package-use"><i class="fa fa-check"></i><b>2.3.3</b> Package use</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="2-getting-started.html"><a href="2-getting-started.html#nycflights13"><i class="fa fa-check"></i><b>2.4</b> Explore your first datasets</a><ul>
<li class="chapter" data-level="2.4.1" data-path="2-getting-started.html"><a href="2-getting-started.html#nycflights13-package"><i class="fa fa-check"></i><b>2.4.1</b> <code>nycflights13</code> package</a></li>
<li class="chapter" data-level="2.4.2" data-path="2-getting-started.html"><a href="2-getting-started.html#flights-data-frame"><i class="fa fa-check"></i><b>2.4.2</b> <code>flights</code> data frame</a></li>
<li class="chapter" data-level="2.4.3" data-path="2-getting-started.html"><a href="2-getting-started.html#exploredataframes"><i class="fa fa-check"></i><b>2.4.3</b> Exploring data frames</a></li>
<li class="chapter" data-level="2.4.4" data-path="2-getting-started.html"><a href="2-getting-started.html#identification-vs-measurement-variables"><i class="fa fa-check"></i><b>2.4.4</b> Identification &amp; measurement variables</a></li>
<li class="chapter" data-level="2.4.5" data-path="2-getting-started.html"><a href="2-getting-started.html#help-files"><i class="fa fa-check"></i><b>2.4.5</b> Help files</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="2-getting-started.html"><a href="2-getting-started.html#conclusion"><i class="fa fa-check"></i><b>2.5</b> Conclusion</a><ul>
<li class="chapter" data-level="2.5.1" data-path="2-getting-started.html"><a href="2-getting-started.html#additional-resources"><i class="fa fa-check"></i><b>2.5.1</b> Additional resources</a></li>
<li class="chapter" data-level="2.5.2" data-path="2-getting-started.html"><a href="2-getting-started.html#whats-to-come"><i class="fa fa-check"></i><b>2.5.2</b> What’s to come?</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>I Data Science via the tidyverse</b></span></li>
<li class="chapter" data-level="3" data-path="3-viz.html"><a href="3-viz.html"><i class="fa fa-check"></i><b>3</b> Data Visualization</a><ul>
<li class="chapter" data-level="" data-path="3-viz.html"><a href="3-viz.html#needed-packages"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="3.1" data-path="3-viz.html"><a href="3-viz.html#grammarofgraphics"><i class="fa fa-check"></i><b>3.1</b> The Grammar of Graphics</a><ul>
<li class="chapter" data-level="3.1.1" data-path="3-viz.html"><a href="3-viz.html#components-of-the-grammar"><i class="fa fa-check"></i><b>3.1.1</b> Components of the Grammar</a></li>
<li class="chapter" data-level="3.1.2" data-path="3-viz.html"><a href="3-viz.html#gapminder"><i class="fa fa-check"></i><b>3.1.2</b> Gapminder data</a></li>
<li class="chapter" data-level="3.1.3" data-path="3-viz.html"><a href="3-viz.html#other-components"><i class="fa fa-check"></i><b>3.1.3</b> Other components</a></li>
<li class="chapter" data-level="3.1.4" data-path="3-viz.html"><a href="3-viz.html#ggplot2-package"><i class="fa fa-check"></i><b>3.1.4</b> ggplot2 package</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="3-viz.html"><a href="3-viz.html#FiveNG"><i class="fa fa-check"></i><b>3.2</b> Five Named Graphs - The 5NG</a></li>
<li class="chapter" data-level="3.3" data-path="3-viz.html"><a href="3-viz.html#scatterplots"><i class="fa fa-check"></i><b>3.3</b> 5NG#1: Scatterplots</a><ul>
<li class="chapter" data-level="3.3.1" data-path="3-viz.html"><a href="3-viz.html#geompoint"><i class="fa fa-check"></i><b>3.3.1</b> Scatterplots via geom_point</a></li>
<li class="chapter" data-level="3.3.2" data-path="3-viz.html"><a href="3-viz.html#overplotting"><i class="fa fa-check"></i><b>3.3.2</b> Over-plotting</a></li>
<li class="chapter" data-level="3.3.3" data-path="3-viz.html"><a href="3-viz.html#summary"><i class="fa fa-check"></i><b>3.3.3</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="3-viz.html"><a href="3-viz.html#linegraphs"><i class="fa fa-check"></i><b>3.4</b> 5NG#2: Linegraphs</a><ul>
<li class="chapter" data-level="3.4.1" data-path="3-viz.html"><a href="3-viz.html#geomline"><i class="fa fa-check"></i><b>3.4.1</b> Linegraphs via geom_line</a></li>
<li class="chapter" data-level="3.4.2" data-path="3-viz.html"><a href="3-viz.html#summary-1"><i class="fa fa-check"></i><b>3.4.2</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="3-viz.html"><a href="3-viz.html#histograms"><i class="fa fa-check"></i><b>3.5</b> 5NG#3: Histograms</a><ul>
<li class="chapter" data-level="3.5.1" data-path="3-viz.html"><a href="3-viz.html#geomhistogram"><i class="fa fa-check"></i><b>3.5.1</b> Histograms via geom_histogram</a></li>
<li class="chapter" data-level="3.5.2" data-path="3-viz.html"><a href="3-viz.html#adjustbins"><i class="fa fa-check"></i><b>3.5.2</b> Adjusting the bins</a></li>
<li class="chapter" data-level="3.5.3" data-path="3-viz.html"><a href="3-viz.html#summary-2"><i class="fa fa-check"></i><b>3.5.3</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="3-viz.html"><a href="3-viz.html#facets"><i class="fa fa-check"></i><b>3.6</b> Facets</a></li>
<li class="chapter" data-level="3.7" data-path="3-viz.html"><a href="3-viz.html#boxplots"><i class="fa fa-check"></i><b>3.7</b> 5NG#4: Boxplots</a><ul>
<li class="chapter" data-level="3.7.1" data-path="3-viz.html"><a href="3-viz.html#geomboxplot"><i class="fa fa-check"></i><b>3.7.1</b> Boxplots via geom_boxplot</a></li>
<li class="chapter" data-level="3.7.2" data-path="3-viz.html"><a href="3-viz.html#summary-3"><i class="fa fa-check"></i><b>3.7.2</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="3-viz.html"><a href="3-viz.html#geombar"><i class="fa fa-check"></i><b>3.8</b> 5NG#5: Barplots</a><ul>
<li class="chapter" data-level="3.8.1" data-path="3-viz.html"><a href="3-viz.html#barplots-via-geom_bar-or-geom_col"><i class="fa fa-check"></i><b>3.8.1</b> Barplots via geom_bar or geom_col</a></li>
<li class="chapter" data-level="3.8.2" data-path="3-viz.html"><a href="3-viz.html#must-avoid-pie-charts"><i class="fa fa-check"></i><b>3.8.2</b> Must avoid pie charts!</a></li>
<li class="chapter" data-level="3.8.3" data-path="3-viz.html"><a href="3-viz.html#two-categ-barplot"><i class="fa fa-check"></i><b>3.8.3</b> Two categorical variables</a></li>
<li class="chapter" data-level="3.8.4" data-path="3-viz.html"><a href="3-viz.html#summary-4"><i class="fa fa-check"></i><b>3.8.4</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="3-viz.html"><a href="3-viz.html#conclusion-1"><i class="fa fa-check"></i><b>3.9</b> Conclusion</a><ul>
<li class="chapter" data-level="3.9.1" data-path="3-viz.html"><a href="3-viz.html#summary-table"><i class="fa fa-check"></i><b>3.9.1</b> Summary table</a></li>
<li class="chapter" data-level="3.9.2" data-path="3-viz.html"><a href="3-viz.html#argument-specification"><i class="fa fa-check"></i><b>3.9.2</b> Argument specification</a></li>
<li class="chapter" data-level="3.9.3" data-path="3-viz.html"><a href="3-viz.html#additional-resources-1"><i class="fa fa-check"></i><b>3.9.3</b> Additional resources</a></li>
<li class="chapter" data-level="3.9.4" data-path="3-viz.html"><a href="3-viz.html#whats-to-come-3"><i class="fa fa-check"></i><b>3.9.4</b> What’s to come</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="4-wrangling.html"><a href="4-wrangling.html"><i class="fa fa-check"></i><b>4</b> Data Wrangling</a><ul>
<li class="chapter" data-level="" data-path="4-wrangling.html"><a href="4-wrangling.html#needed-packages-1"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="4.1" data-path="4-wrangling.html"><a href="4-wrangling.html#piping"><i class="fa fa-check"></i><b>4.1</b> The pipe operator: <code>%&gt;%</code></a></li>
<li class="chapter" data-level="4.2" data-path="4-wrangling.html"><a href="4-wrangling.html#filter"><i class="fa fa-check"></i><b>4.2</b> <code>filter</code> rows</a></li>
<li class="chapter" data-level="4.3" data-path="4-wrangling.html"><a href="4-wrangling.html#summarize"><i class="fa fa-check"></i><b>4.3</b> <code>summarize</code> variables</a></li>
<li class="chapter" data-level="4.4" data-path="4-wrangling.html"><a href="4-wrangling.html#groupby"><i class="fa fa-check"></i><b>4.4</b> <code>group_by</code> rows</a><ul>
<li class="chapter" data-level="4.4.1" data-path="4-wrangling.html"><a href="4-wrangling.html#grouping-by-more-than-one-variable"><i class="fa fa-check"></i><b>4.4.1</b> Grouping by more than one variable</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="4-wrangling.html"><a href="4-wrangling.html#mutate"><i class="fa fa-check"></i><b>4.5</b> <code>mutate</code> existing variables</a></li>
<li class="chapter" data-level="4.6" data-path="4-wrangling.html"><a href="4-wrangling.html#arrange"><i class="fa fa-check"></i><b>4.6</b> <code>arrange</code> and sort rows</a></li>
<li class="chapter" data-level="4.7" data-path="4-wrangling.html"><a href="4-wrangling.html#joins"><i class="fa fa-check"></i><b>4.7</b> <code>join</code> data frames</a><ul>
<li class="chapter" data-level="4.7.1" data-path="4-wrangling.html"><a href="4-wrangling.html#matching-key-variable-names"><i class="fa fa-check"></i><b>4.7.1</b> Matching “key” variable names</a></li>
<li class="chapter" data-level="4.7.2" data-path="4-wrangling.html"><a href="4-wrangling.html#diff-key"><i class="fa fa-check"></i><b>4.7.2</b> Different “key” variable names</a></li>
<li class="chapter" data-level="4.7.3" data-path="4-wrangling.html"><a href="4-wrangling.html#multiple-key-variables"><i class="fa fa-check"></i><b>4.7.3</b> Multiple “key” variables</a></li>
<li class="chapter" data-level="4.7.4" data-path="4-wrangling.html"><a href="4-wrangling.html#normal-forms"><i class="fa fa-check"></i><b>4.7.4</b> Normal forms</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="4-wrangling.html"><a href="4-wrangling.html#other-verbs"><i class="fa fa-check"></i><b>4.8</b> Other verbs</a><ul>
<li class="chapter" data-level="4.8.1" data-path="4-wrangling.html"><a href="4-wrangling.html#select"><i class="fa fa-check"></i><b>4.8.1</b> <code>select</code> variables</a></li>
<li class="chapter" data-level="4.8.2" data-path="4-wrangling.html"><a href="4-wrangling.html#rename"><i class="fa fa-check"></i><b>4.8.2</b> <code>rename</code> variables</a></li>
<li class="chapter" data-level="4.8.3" data-path="4-wrangling.html"><a href="4-wrangling.html#top_n-values-of-a-variable"><i class="fa fa-check"></i><b>4.8.3</b> <code>top_n</code> values of a variable</a></li>
</ul></li>
<li class="chapter" data-level="4.9" data-path="4-wrangling.html"><a href="4-wrangling.html#conclusion-2"><i class="fa fa-check"></i><b>4.9</b> Conclusion</a><ul>
<li class="chapter" data-level="4.9.1" data-path="4-wrangling.html"><a href="4-wrangling.html#summary-table-1"><i class="fa fa-check"></i><b>4.9.1</b> Summary table</a></li>
<li class="chapter" data-level="4.9.2" data-path="4-wrangling.html"><a href="4-wrangling.html#additional-resources-2"><i class="fa fa-check"></i><b>4.9.2</b> Additional resources</a></li>
<li class="chapter" data-level="4.9.3" data-path="4-wrangling.html"><a href="4-wrangling.html#whats-to-come-1"><i class="fa fa-check"></i><b>4.9.3</b> What’s to come?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="5-tidy.html"><a href="5-tidy.html"><i class="fa fa-check"></i><b>5</b> Data Importing &amp; “Tidy” Data</a><ul>
<li class="chapter" data-level="" data-path="5-tidy.html"><a href="5-tidy.html#needed-packages-2"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="5.1" data-path="5-tidy.html"><a href="5-tidy.html#csv"><i class="fa fa-check"></i><b>5.1</b> Importing data</a><ul>
<li class="chapter" data-level="5.1.1" data-path="5-tidy.html"><a href="5-tidy.html#using-the-console"><i class="fa fa-check"></i><b>5.1.1</b> Using the console</a></li>
<li class="chapter" data-level="5.1.2" data-path="5-tidy.html"><a href="5-tidy.html#using-rstudios-interface"><i class="fa fa-check"></i><b>5.1.2</b> Using RStudio’s interface</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="5-tidy.html"><a href="5-tidy.html#tidy-data-ex"><i class="fa fa-check"></i><b>5.2</b> Tidy data</a><ul>
<li class="chapter" data-level="5.2.1" data-path="5-tidy.html"><a href="5-tidy.html#definition-of-tidy-data"><i class="fa fa-check"></i><b>5.2.1</b> Definition of “tidy” data</a></li>
<li class="chapter" data-level="5.2.2" data-path="5-tidy.html"><a href="5-tidy.html#converting-to-tidy-data"><i class="fa fa-check"></i><b>5.2.2</b> Converting to “tidy” data</a></li>
<li class="chapter" data-level="5.2.3" data-path="5-tidy.html"><a href="5-tidy.html#nycflights13-package-1"><i class="fa fa-check"></i><b>5.2.3</b> <code>nycflights13</code> package</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="5-tidy.html"><a href="5-tidy.html#case-study-tidy"><i class="fa fa-check"></i><b>5.3</b> Case study: Democracy in Guatemala</a></li>
<li class="chapter" data-level="5.4" data-path="5-tidy.html"><a href="5-tidy.html#conclusion-3"><i class="fa fa-check"></i><b>5.4</b> Conclusion</a><ul>
<li class="chapter" data-level="5.4.1" data-path="5-tidy.html"><a href="5-tidy.html#tidyverse-package"><i class="fa fa-check"></i><b>5.4.1</b> <code>tidyverse</code> package</a></li>
<li class="chapter" data-level="5.4.2" data-path="5-tidy.html"><a href="5-tidy.html#additional-resources-3"><i class="fa fa-check"></i><b>5.4.2</b> Additional resources</a></li>
<li class="chapter" data-level="5.4.3" data-path="5-tidy.html"><a href="5-tidy.html#whats-to-come-2"><i class="fa fa-check"></i><b>5.4.3</b> What’s to come?</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II Data Modeling via moderndive</b></span></li>
<li class="chapter" data-level="6" data-path="6-regression.html"><a href="6-regression.html"><i class="fa fa-check"></i><b>6</b> Basic Regression</a><ul>
<li class="chapter" data-level="" data-path="6-regression.html"><a href="6-regression.html#needed-packages-3"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="6.1" data-path="6-regression.html"><a href="6-regression.html#model1"><i class="fa fa-check"></i><b>6.1</b> One numerical explanatory variable</a><ul>
<li class="chapter" data-level="6.1.1" data-path="6-regression.html"><a href="6-regression.html#model1EDA"><i class="fa fa-check"></i><b>6.1.1</b> Exploratory data analysis</a></li>
<li class="chapter" data-level="6.1.2" data-path="6-regression.html"><a href="6-regression.html#model1table"><i class="fa fa-check"></i><b>6.1.2</b> Simple linear regression</a></li>
<li class="chapter" data-level="6.1.3" data-path="6-regression.html"><a href="6-regression.html#model1points"><i class="fa fa-check"></i><b>6.1.3</b> Observed/fitted values and residuals</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="6-regression.html"><a href="6-regression.html#model2"><i class="fa fa-check"></i><b>6.2</b> One categorical explanatory variable</a><ul>
<li class="chapter" data-level="6.2.1" data-path="6-regression.html"><a href="6-regression.html#model2EDA"><i class="fa fa-check"></i><b>6.2.1</b> Exploratory data analysis</a></li>
<li class="chapter" data-level="6.2.2" data-path="6-regression.html"><a href="6-regression.html#model2table"><i class="fa fa-check"></i><b>6.2.2</b> Linear regression</a></li>
<li class="chapter" data-level="6.2.3" data-path="6-regression.html"><a href="6-regression.html#model2points"><i class="fa fa-check"></i><b>6.2.3</b> Observed/fitted values and residuals</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="6-regression.html"><a href="6-regression.html#related-topics"><i class="fa fa-check"></i><b>6.3</b> Related topics</a><ul>
<li class="chapter" data-level="6.3.1" data-path="6-regression.html"><a href="6-regression.html#correlation-is-not-causation"><i class="fa fa-check"></i><b>6.3.1</b> Correlation is not necessarily causation</a></li>
<li class="chapter" data-level="6.3.2" data-path="6-regression.html"><a href="6-regression.html#leastsquares"><i class="fa fa-check"></i><b>6.3.2</b> Best fitting line</a></li>
<li class="chapter" data-level="6.3.3" data-path="6-regression.html"><a href="6-regression.html#underthehood"><i class="fa fa-check"></i><b>6.3.3</b> <code>get_regression_x()</code> functions</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="6-regression.html"><a href="6-regression.html#conclusion-4"><i class="fa fa-check"></i><b>6.4</b> Conclusion</a><ul>
<li class="chapter" data-level="6.4.1" data-path="6-regression.html"><a href="6-regression.html#additional-resources-basic-regression"><i class="fa fa-check"></i><b>6.4.1</b> Additional resources</a></li>
<li class="chapter" data-level="6.4.2" data-path="6-regression.html"><a href="6-regression.html#whats-to-come-4"><i class="fa fa-check"></i><b>6.4.2</b> What’s to come?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html"><i class="fa fa-check"></i><b>7</b> Multiple Regression</a><ul>
<li class="chapter" data-level="" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html#needed-packages-4"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="7.1" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html#model4"><i class="fa fa-check"></i><b>7.1</b> One numerical &amp; one categorical explanatory variable</a><ul>
<li class="chapter" data-level="7.1.1" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html#model4EDA"><i class="fa fa-check"></i><b>7.1.1</b> Exploratory data analysis</a></li>
<li class="chapter" data-level="7.1.2" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html#model4interactiontable"><i class="fa fa-check"></i><b>7.1.2</b> Interaction model</a></li>
<li class="chapter" data-level="7.1.3" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html#model4table"><i class="fa fa-check"></i><b>7.1.3</b> Parallel slopes model</a></li>
<li class="chapter" data-level="7.1.4" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html#model4points"><i class="fa fa-check"></i><b>7.1.4</b> Observed/fitted values and residuals</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html#model3"><i class="fa fa-check"></i><b>7.2</b> Two numerical explanatory variables</a><ul>
<li class="chapter" data-level="7.2.1" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html#model3EDA"><i class="fa fa-check"></i><b>7.2.1</b> Exploratory data analysis</a></li>
<li class="chapter" data-level="7.2.2" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html#model3table"><i class="fa fa-check"></i><b>7.2.2</b> Regression plane</a></li>
<li class="chapter" data-level="7.2.3" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html#model3points"><i class="fa fa-check"></i><b>7.2.3</b> Observed/fitted values and residuals</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html#related-topics-1"><i class="fa fa-check"></i><b>7.3</b> Related topics</a><ul>
<li class="chapter" data-level="7.3.1" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html#model-selection"><i class="fa fa-check"></i><b>7.3.1</b> Model selection</a></li>
<li class="chapter" data-level="7.3.2" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html#correlationcoefficient2"><i class="fa fa-check"></i><b>7.3.2</b> Correlation coefficient</a></li>
<li class="chapter" data-level="7.3.3" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html#simpsonsparadox"><i class="fa fa-check"></i><b>7.3.3</b> Simpson’s Paradox</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html#conclusion-5"><i class="fa fa-check"></i><b>7.4</b> Conclusion</a><ul>
<li class="chapter" data-level="7.4.1" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html#additional-resources-4"><i class="fa fa-check"></i><b>7.4.1</b> Additional resources</a></li>
<li class="chapter" data-level="7.4.2" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html#whats-to-come-5"><i class="fa fa-check"></i><b>7.4.2</b> What’s to come?</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III Statistical Inference via infer</b></span></li>
<li class="chapter" data-level="8" data-path="8-sampling.html"><a href="8-sampling.html"><i class="fa fa-check"></i><b>8</b> Sampling</a><ul>
<li class="chapter" data-level="" data-path="8-sampling.html"><a href="8-sampling.html#needed-packages-5"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="8.1" data-path="8-sampling.html"><a href="8-sampling.html#sampling-activity"><i class="fa fa-check"></i><b>8.1</b> Sampling bowl activity</a><ul>
<li class="chapter" data-level="8.1.1" data-path="8-sampling.html"><a href="8-sampling.html#what-proportion-of-this-bowls-balls-are-red"><i class="fa fa-check"></i><b>8.1.1</b> What proportion of this bowl’s balls are red?</a></li>
<li class="chapter" data-level="8.1.2" data-path="8-sampling.html"><a href="8-sampling.html#using-the-shovel-once"><i class="fa fa-check"></i><b>8.1.2</b> Using the shovel once</a></li>
<li class="chapter" data-level="8.1.3" data-path="8-sampling.html"><a href="8-sampling.html#student-shovels"><i class="fa fa-check"></i><b>8.1.3</b> Using the shovel 33 times</a></li>
<li class="chapter" data-level="8.1.4" data-path="8-sampling.html"><a href="8-sampling.html#what-did-we-just-do"><i class="fa fa-check"></i><b>8.1.4</b> What did we just do?</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="8-sampling.html"><a href="8-sampling.html#sampling-simulation"><i class="fa fa-check"></i><b>8.2</b> Computer simulation of sampling</a><ul>
<li class="chapter" data-level="8.2.1" data-path="8-sampling.html"><a href="8-sampling.html#using-the-virtual-shovel-once"><i class="fa fa-check"></i><b>8.2.1</b> Using the virtual shovel once</a></li>
<li class="chapter" data-level="8.2.2" data-path="8-sampling.html"><a href="8-sampling.html#using-the-virtual-shovel-33-times"><i class="fa fa-check"></i><b>8.2.2</b> Using the virtual shovel 33 times</a></li>
<li class="chapter" data-level="8.2.3" data-path="8-sampling.html"><a href="8-sampling.html#shovel-1000-times"><i class="fa fa-check"></i><b>8.2.3</b> Using the virtual shovel 1000 times</a></li>
<li class="chapter" data-level="8.2.4" data-path="8-sampling.html"><a href="8-sampling.html#different-shovels"><i class="fa fa-check"></i><b>8.2.4</b> Using different shovels</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="8-sampling.html"><a href="8-sampling.html#sampling-framework"><i class="fa fa-check"></i><b>8.3</b> Sampling framework</a><ul>
<li class="chapter" data-level="8.3.1" data-path="8-sampling.html"><a href="8-sampling.html#terminology-and-notation"><i class="fa fa-check"></i><b>8.3.1</b> Terminology &amp; notation</a></li>
<li class="chapter" data-level="8.3.2" data-path="8-sampling.html"><a href="8-sampling.html#sampling-definitions"><i class="fa fa-check"></i><b>8.3.2</b> Statistical definitions</a></li>
<li class="chapter" data-level="8.3.3" data-path="8-sampling.html"><a href="8-sampling.html#moral-of-the-story"><i class="fa fa-check"></i><b>8.3.3</b> The moral of the story</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="8-sampling.html"><a href="8-sampling.html#sampling-case-study"><i class="fa fa-check"></i><b>8.4</b> Case study: Polls</a></li>
<li class="chapter" data-level="8.5" data-path="8-sampling.html"><a href="8-sampling.html#sampling-conclusion"><i class="fa fa-check"></i><b>8.5</b> Conclusion</a><ul>
<li class="chapter" data-level="8.5.1" data-path="8-sampling.html"><a href="8-sampling.html#sampling-conclusion-table"><i class="fa fa-check"></i><b>8.5.1</b> Sampling scenarios</a></li>
<li class="chapter" data-level="8.5.2" data-path="8-sampling.html"><a href="8-sampling.html#sampling-conclusion-central-limit-theorem"><i class="fa fa-check"></i><b>8.5.2</b> Central Limit Theorem</a></li>
<li class="chapter" data-level="8.5.3" data-path="8-sampling.html"><a href="8-sampling.html#normal-distribution"><i class="fa fa-check"></i><b>8.5.3</b> Normal distributions</a></li>
<li class="chapter" data-level="8.5.4" data-path="8-sampling.html"><a href="8-sampling.html#additional-resources-5"><i class="fa fa-check"></i><b>8.5.4</b> Additional resources</a></li>
<li class="chapter" data-level="8.5.5" data-path="8-sampling.html"><a href="8-sampling.html#whats-to-come-6"><i class="fa fa-check"></i><b>8.5.5</b> What’s to come?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html"><i class="fa fa-check"></i><b>9</b> Bootstrapping and Confidence Intervals</a><ul>
<li class="chapter" data-level="" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#needed-packages-6"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="9.1" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#resampling-tactile"><i class="fa fa-check"></i><b>9.1</b> Pennies activity</a><ul>
<li class="chapter" data-level="9.1.1" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#what-is-the-average-year-on-us-pennies-in-2019"><i class="fa fa-check"></i><b>9.1.1</b> What is the average year on US pennies in 2019?</a></li>
<li class="chapter" data-level="9.1.2" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#resampling-once"><i class="fa fa-check"></i><b>9.1.2</b> Resampling once</a></li>
<li class="chapter" data-level="9.1.3" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#student-resamples"><i class="fa fa-check"></i><b>9.1.3</b> Resampling 35 times</a></li>
<li class="chapter" data-level="9.1.4" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#what-did-we-just-do-1"><i class="fa fa-check"></i><b>9.1.4</b> What did we just do?</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#resampling-simulation"><i class="fa fa-check"></i><b>9.2</b> Computer simulation of resampling</a><ul>
<li class="chapter" data-level="9.2.1" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#virtually-resampling-once"><i class="fa fa-check"></i><b>9.2.1</b> Virtually resampling once</a></li>
<li class="chapter" data-level="9.2.2" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#virtually-resampling-35-times"><i class="fa fa-check"></i><b>9.2.2</b> Virtually resampling 35 times</a></li>
<li class="chapter" data-level="9.2.3" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#bootstrap-1000-replicates"><i class="fa fa-check"></i><b>9.2.3</b> Virtually resampling 1000 times</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#ci-build-up"><i class="fa fa-check"></i><b>9.3</b> Understanding confidence intervals</a><ul>
<li class="chapter" data-level="9.3.1" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#percentile-method"><i class="fa fa-check"></i><b>9.3.1</b> Percentile method</a></li>
<li class="chapter" data-level="9.3.2" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#se-method"><i class="fa fa-check"></i><b>9.3.2</b> Standard error method</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#bootstrap-process"><i class="fa fa-check"></i><b>9.4</b> Constructing confidence intervals</a><ul>
<li class="chapter" data-level="9.4.1" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#original-workflow"><i class="fa fa-check"></i><b>9.4.1</b> Original workflow</a></li>
<li class="chapter" data-level="9.4.2" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#infer-workflow"><i class="fa fa-check"></i><b>9.4.2</b> infer package workflow</a></li>
<li class="chapter" data-level="9.4.3" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#percentile-method-infer"><i class="fa fa-check"></i><b>9.4.3</b> Percentile method with infer</a></li>
<li class="chapter" data-level="9.4.4" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#infer-se"><i class="fa fa-check"></i><b>9.4.4</b> Standard error method with infer</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#one-prop-ci"><i class="fa fa-check"></i><b>9.5</b> Interpreting confidence intervals</a><ul>
<li class="chapter" data-level="9.5.1" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#ilyas-yohan"><i class="fa fa-check"></i><b>9.5.1</b> Did the net capture the fish?</a></li>
<li class="chapter" data-level="9.5.2" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#shorthand"><i class="fa fa-check"></i><b>9.5.2</b> Precise &amp; shorthand interpretation</a></li>
<li class="chapter" data-level="9.5.3" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#ci-width"><i class="fa fa-check"></i><b>9.5.3</b> Width of confidence intervals</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#case-study-two-prop-ci"><i class="fa fa-check"></i><b>9.6</b> Case study: Is yawning contagious?</a><ul>
<li class="chapter" data-level="9.6.1" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#mythbusters-study-data"><i class="fa fa-check"></i><b>9.6.1</b> Mythbusters study data</a></li>
<li class="chapter" data-level="9.6.2" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#sampling-scenario"><i class="fa fa-check"></i><b>9.6.2</b> Sampling scenario</a></li>
<li class="chapter" data-level="9.6.3" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#ci-build"><i class="fa fa-check"></i><b>9.6.3</b> Constructing the confidence interval</a></li>
<li class="chapter" data-level="9.6.4" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#interpreting-the-confidence-interval"><i class="fa fa-check"></i><b>9.6.4</b> Interpreting the confidence interval</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#ci-conclusion"><i class="fa fa-check"></i><b>9.7</b> Conclusion</a><ul>
<li class="chapter" data-level="9.7.1" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#bootstrap-vs-sampling"><i class="fa fa-check"></i><b>9.7.1</b> Comparing bootstrap and sampling distributions</a></li>
<li class="chapter" data-level="9.7.2" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#theory-ci"><i class="fa fa-check"></i><b>9.7.2</b> Theory-based confidence intervals</a></li>
<li class="chapter" data-level="9.7.3" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#additional-resources-6"><i class="fa fa-check"></i><b>9.7.3</b> Additional resources</a></li>
<li class="chapter" data-level="9.7.4" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#whats-to-come-7"><i class="fa fa-check"></i><b>9.7.4</b> What’s to come?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html"><i class="fa fa-check"></i><b>10</b> Hypothesis Testing</a><ul>
<li class="chapter" data-level="" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#needed-packages-7"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="10.1" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#ht-activity"><i class="fa fa-check"></i><b>10.1</b> Promotions activity</a><ul>
<li class="chapter" data-level="10.1.1" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#does-gender-affect-promotions-at-bank"><i class="fa fa-check"></i><b>10.1.1</b> Does gender affect promotions at bank?</a></li>
<li class="chapter" data-level="10.1.2" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#shuffling-once"><i class="fa fa-check"></i><b>10.1.2</b> Shuffling once</a></li>
<li class="chapter" data-level="10.1.3" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#shuffling-16-times"><i class="fa fa-check"></i><b>10.1.3</b> Shuffling 16 times</a></li>
<li class="chapter" data-level="10.1.4" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#what-did-we-just-do-2"><i class="fa fa-check"></i><b>10.1.4</b> What did we just do?</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#understanding-ht"><i class="fa fa-check"></i><b>10.2</b> Understanding hypothesis tests</a></li>
<li class="chapter" data-level="10.3" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#ht-infer"><i class="fa fa-check"></i><b>10.3</b> Conducting hypothesis tests</a><ul>
<li class="chapter" data-level="10.3.1" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#infer-workflow-ht"><i class="fa fa-check"></i><b>10.3.1</b> infer package workflow</a></li>
<li class="chapter" data-level="10.3.2" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#comparison-with-confidence-intervals"><i class="fa fa-check"></i><b>10.3.2</b> Comparison with confidence intervals</a></li>
<li class="chapter" data-level="10.3.3" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#only-one-test"><i class="fa fa-check"></i><b>10.3.3</b> “There is only one test”</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#ht-interpretation"><i class="fa fa-check"></i><b>10.4</b> Interpreting hypothesis tests</a><ul>
<li class="chapter" data-level="10.4.1" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#trial"><i class="fa fa-check"></i><b>10.4.1</b> Two possible outcomes</a></li>
<li class="chapter" data-level="10.4.2" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#types-of-errors"><i class="fa fa-check"></i><b>10.4.2</b> Types of errors</a></li>
<li class="chapter" data-level="10.4.3" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#how-do-we-choose-alpha"><i class="fa fa-check"></i><b>10.4.3</b> How do we choose alpha?</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#ht-case-study"><i class="fa fa-check"></i><b>10.5</b> Case study: Are action or romance movies rated higher?</a><ul>
<li class="chapter" data-level="10.5.1" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#imdb-data"><i class="fa fa-check"></i><b>10.5.1</b> IMDb ratings data</a></li>
<li class="chapter" data-level="10.5.2" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#sampling-scenario-1"><i class="fa fa-check"></i><b>10.5.2</b> Sampling scenario</a></li>
<li class="chapter" data-level="10.5.3" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#conducting-the-hypothesis-test"><i class="fa fa-check"></i><b>10.5.3</b> Conducting the hypothesis test</a></li>
</ul></li>
<li class="chapter" data-level="10.6" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#conclusion-6"><i class="fa fa-check"></i><b>10.6</b> Conclusion</a><ul>
<li class="chapter" data-level="10.6.1" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#theory-hypo"><i class="fa fa-check"></i><b>10.6.1</b> Theory-based hypothesis tests</a></li>
<li class="chapter" data-level="10.6.2" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#when-inference-is-not-needed"><i class="fa fa-check"></i><b>10.6.2</b> When inference is not needed</a></li>
<li class="chapter" data-level="10.6.3" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#problems-with-p-values"><i class="fa fa-check"></i><b>10.6.3</b> Problems with p-values</a></li>
<li class="chapter" data-level="10.6.4" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#additional-resources-7"><i class="fa fa-check"></i><b>10.6.4</b> Additional resources</a></li>
<li class="chapter" data-level="10.6.5" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#whats-to-come-8"><i class="fa fa-check"></i><b>10.6.5</b> What’s to come</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html"><i class="fa fa-check"></i><b>11</b> Inference for Regression</a><ul>
<li class="chapter" data-level="" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#needed-packages-8"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="11.1" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#regression-refresher"><i class="fa fa-check"></i><b>11.1</b> Regression refresher</a><ul>
<li class="chapter" data-level="11.1.1" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#teaching-evals-analysis"><i class="fa fa-check"></i><b>11.1.1</b> Teaching evals analysis</a></li>
<li class="chapter" data-level="11.1.2" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#sampling-scenario-2"><i class="fa fa-check"></i><b>11.1.2</b> Sampling scenario</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#regression-interp"><i class="fa fa-check"></i><b>11.2</b> Interpreting regression tables</a><ul>
<li class="chapter" data-level="11.2.1" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#regression-se"><i class="fa fa-check"></i><b>11.2.1</b> Standard error</a></li>
<li class="chapter" data-level="11.2.2" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#regression-test-statistic"><i class="fa fa-check"></i><b>11.2.2</b> Test statistic</a></li>
<li class="chapter" data-level="11.2.3" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#p-value"><i class="fa fa-check"></i><b>11.2.3</b> p-value</a></li>
<li class="chapter" data-level="11.2.4" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#confidence-interval"><i class="fa fa-check"></i><b>11.2.4</b> Confidence interval</a></li>
<li class="chapter" data-level="11.2.5" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#regression-table-computation"><i class="fa fa-check"></i><b>11.2.5</b> How does R compute the table?</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#regression-conditions"><i class="fa fa-check"></i><b>11.3</b> Conditions for inference for regression</a><ul>
<li class="chapter" data-level="11.3.1" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#residuals-refresher"><i class="fa fa-check"></i><b>11.3.1</b> Residuals refresher</a></li>
<li class="chapter" data-level="11.3.2" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#linearity-of-relationship"><i class="fa fa-check"></i><b>11.3.2</b> Linearity of relationship</a></li>
<li class="chapter" data-level="11.3.3" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#independence-of-residuals"><i class="fa fa-check"></i><b>11.3.3</b> Independence of residuals</a></li>
<li class="chapter" data-level="11.3.4" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#normality-of-residuals"><i class="fa fa-check"></i><b>11.3.4</b> Normality of residuals</a></li>
<li class="chapter" data-level="11.3.5" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#equality-of-variance"><i class="fa fa-check"></i><b>11.3.5</b> Equality of variance</a></li>
<li class="chapter" data-level="11.3.6" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#what-is-the-conclusion"><i class="fa fa-check"></i><b>11.3.6</b> What’s the conclusion?</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#infer-regression"><i class="fa fa-check"></i><b>11.4</b> Simulation-based inference for regression</a><ul>
<li class="chapter" data-level="11.4.1" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#confidence-interval-for-slope"><i class="fa fa-check"></i><b>11.4.1</b> Confidence interval for slope</a></li>
<li class="chapter" data-level="11.4.2" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#hypothesis-test-for-slope"><i class="fa fa-check"></i><b>11.4.2</b> Hypothesis test for slope</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#conclusion-7"><i class="fa fa-check"></i><b>11.5</b> Conclusion</a><ul>
<li class="chapter" data-level="11.5.1" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#summary-5"><i class="fa fa-check"></i><b>11.5.1</b> Summary</a></li>
<li class="chapter" data-level="11.5.2" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#additional-resources-8"><i class="fa fa-check"></i><b>11.5.2</b> Additional resources</a></li>
<li class="chapter" data-level="11.5.3" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#whats-to-come-9"><i class="fa fa-check"></i><b>11.5.3</b> What’s to come</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>IV Conclusion</b></span></li>
<li class="chapter" data-level="12" data-path="12-thinking-with-data.html"><a href="12-thinking-with-data.html"><i class="fa fa-check"></i><b>12</b> Tell the Story with Data</a><ul>
<li class="chapter" data-level="" data-path="12-thinking-with-data.html"><a href="12-thinking-with-data.html#needed-packages-9"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="12.1" data-path="12-thinking-with-data.html"><a href="12-thinking-with-data.html#seattle-house-prices"><i class="fa fa-check"></i><b>12.1</b> Case study: Seattle house prices</a><ul>
<li class="chapter" data-level="12.1.1" data-path="12-thinking-with-data.html"><a href="12-thinking-with-data.html#house-prices-EDA-I"><i class="fa fa-check"></i><b>12.1.1</b> Exploratory data analysis (EDA)</a></li>
<li class="chapter" data-level="12.1.2" data-path="12-thinking-with-data.html"><a href="12-thinking-with-data.html#log10-transformations"><i class="fa fa-check"></i><b>12.1.2</b> log10 transformations</a></li>
<li class="chapter" data-level="12.1.3" data-path="12-thinking-with-data.html"><a href="12-thinking-with-data.html#eda-part-ii"><i class="fa fa-check"></i><b>12.1.3</b> EDA Part II</a></li>
<li class="chapter" data-level="12.1.4" data-path="12-thinking-with-data.html"><a href="12-thinking-with-data.html#house-prices-regression"><i class="fa fa-check"></i><b>12.1.4</b> Regression modeling</a></li>
<li class="chapter" data-level="12.1.5" data-path="12-thinking-with-data.html"><a href="12-thinking-with-data.html#house-prices-making-predictions"><i class="fa fa-check"></i><b>12.1.5</b> Making predictions</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="12-thinking-with-data.html"><a href="12-thinking-with-data.html#data-journalism"><i class="fa fa-check"></i><b>12.2</b> Case study: Effective data storytelling</a><ul>
<li class="chapter" data-level="12.2.1" data-path="12-thinking-with-data.html"><a href="12-thinking-with-data.html#bechdel-test-for-hollywood-gender-representation"><i class="fa fa-check"></i><b>12.2.1</b> Bechdel test for Hollywood gender representation</a></li>
<li class="chapter" data-level="12.2.2" data-path="12-thinking-with-data.html"><a href="12-thinking-with-data.html#us-births-in-1999"><i class="fa fa-check"></i><b>12.2.2</b> US Births in 1999</a></li>
<li class="chapter" data-level="12.2.3" data-path="12-thinking-with-data.html"><a href="12-thinking-with-data.html#script-of-r-code"><i class="fa fa-check"></i><b>12.2.3</b> Script of R code</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="12-thinking-with-data.html"><a href="12-thinking-with-data.html#concluding-remarks"><i class="fa fa-check"></i>Concluding remarks</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="A-appendixA.html"><a href="A-appendixA.html"><i class="fa fa-check"></i><b>A</b> Statistical Background</a><ul>
<li class="chapter" data-level="A.1" data-path="A-appendixA.html"><a href="A-appendixA.html#basic-statistical-terms"><i class="fa fa-check"></i><b>A.1</b> Basic statistical terms</a><ul>
<li class="chapter" data-level="A.1.1" data-path="A-appendixA.html"><a href="A-appendixA.html#mean"><i class="fa fa-check"></i><b>A.1.1</b> Mean</a></li>
<li class="chapter" data-level="A.1.2" data-path="A-appendixA.html"><a href="A-appendixA.html#median"><i class="fa fa-check"></i><b>A.1.2</b> Median</a></li>
<li class="chapter" data-level="A.1.3" data-path="A-appendixA.html"><a href="A-appendixA.html#standard-deviation"><i class="fa fa-check"></i><b>A.1.3</b> Standard deviation</a></li>
<li class="chapter" data-level="A.1.4" data-path="A-appendixA.html"><a href="A-appendixA.html#five-number-summary"><i class="fa fa-check"></i><b>A.1.4</b> Five-number summary</a></li>
<li class="chapter" data-level="A.1.5" data-path="A-appendixA.html"><a href="A-appendixA.html#distribution"><i class="fa fa-check"></i><b>A.1.5</b> Distribution</a></li>
<li class="chapter" data-level="A.1.6" data-path="A-appendixA.html"><a href="A-appendixA.html#outliers"><i class="fa fa-check"></i><b>A.1.6</b> Outliers</a></li>
</ul></li>
<li class="chapter" data-level="A.2" data-path="A-appendixA.html"><a href="A-appendixA.html#normal-curve"><i class="fa fa-check"></i><b>A.2</b> Normal distribution</a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="B-appendixB.html"><a href="B-appendixB.html"><i class="fa fa-check"></i><b>B</b> Inference Examples</a><ul>
<li class="chapter" data-level="" data-path="B-appendixB.html"><a href="B-appendixB.html#needed-packages-10"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="B.1" data-path="B-appendixB.html"><a href="B-appendixB.html#inference-mind-map"><i class="fa fa-check"></i><b>B.1</b> Inference mind map</a></li>
<li class="chapter" data-level="B.2" data-path="B-appendixB.html"><a href="B-appendixB.html#one-mean"><i class="fa fa-check"></i><b>B.2</b> One mean</a><ul>
<li class="chapter" data-level="B.2.1" data-path="B-appendixB.html"><a href="B-appendixB.html#problem-statement"><i class="fa fa-check"></i><b>B.2.1</b> Problem statement</a></li>
<li class="chapter" data-level="B.2.2" data-path="B-appendixB.html"><a href="B-appendixB.html#competing-hypotheses"><i class="fa fa-check"></i><b>B.2.2</b> Competing hypotheses</a></li>
<li class="chapter" data-level="B.2.3" data-path="B-appendixB.html"><a href="B-appendixB.html#exploring-the-sample-data"><i class="fa fa-check"></i><b>B.2.3</b> Exploring the sample data</a></li>
<li class="chapter" data-level="B.2.4" data-path="B-appendixB.html"><a href="B-appendixB.html#non-traditional-methods"><i class="fa fa-check"></i><b>B.2.4</b> Non-traditional methods</a></li>
<li class="chapter" data-level="B.2.5" data-path="B-appendixB.html"><a href="B-appendixB.html#traditional-methods"><i class="fa fa-check"></i><b>B.2.5</b> Traditional methods</a></li>
<li class="chapter" data-level="B.2.6" data-path="B-appendixB.html"><a href="B-appendixB.html#comparing-results"><i class="fa fa-check"></i><b>B.2.6</b> Comparing results</a></li>
</ul></li>
<li class="chapter" data-level="B.3" data-path="B-appendixB.html"><a href="B-appendixB.html#one-proportion"><i class="fa fa-check"></i><b>B.3</b> One proportion</a><ul>
<li class="chapter" data-level="B.3.1" data-path="B-appendixB.html"><a href="B-appendixB.html#problem-statement-1"><i class="fa fa-check"></i><b>B.3.1</b> Problem statement</a></li>
<li class="chapter" data-level="B.3.2" data-path="B-appendixB.html"><a href="B-appendixB.html#competing-hypotheses-1"><i class="fa fa-check"></i><b>B.3.2</b> Competing hypotheses</a></li>
<li class="chapter" data-level="B.3.3" data-path="B-appendixB.html"><a href="B-appendixB.html#exploring-the-sample-data-1"><i class="fa fa-check"></i><b>B.3.3</b> Exploring the sample data</a></li>
<li class="chapter" data-level="B.3.4" data-path="B-appendixB.html"><a href="B-appendixB.html#non-traditional-methods-1"><i class="fa fa-check"></i><b>B.3.4</b> Non-traditional methods</a></li>
<li class="chapter" data-level="B.3.5" data-path="B-appendixB.html"><a href="B-appendixB.html#traditional-methods-1"><i class="fa fa-check"></i><b>B.3.5</b> Traditional methods</a></li>
<li class="chapter" data-level="B.3.6" data-path="B-appendixB.html"><a href="B-appendixB.html#comparing-results-1"><i class="fa fa-check"></i><b>B.3.6</b> Comparing results</a></li>
</ul></li>
<li class="chapter" data-level="B.4" data-path="B-appendixB.html"><a href="B-appendixB.html#two-proportions"><i class="fa fa-check"></i><b>B.4</b> Two proportions</a><ul>
<li class="chapter" data-level="B.4.1" data-path="B-appendixB.html"><a href="B-appendixB.html#problem-statement-2"><i class="fa fa-check"></i><b>B.4.1</b> Problem statement</a></li>
<li class="chapter" data-level="B.4.2" data-path="B-appendixB.html"><a href="B-appendixB.html#competing-hypotheses-2"><i class="fa fa-check"></i><b>B.4.2</b> Competing hypotheses</a></li>
<li class="chapter" data-level="B.4.3" data-path="B-appendixB.html"><a href="B-appendixB.html#exploring-the-sample-data-2"><i class="fa fa-check"></i><b>B.4.3</b> Exploring the sample data</a></li>
<li class="chapter" data-level="B.4.4" data-path="B-appendixB.html"><a href="B-appendixB.html#non-traditional-methods-2"><i class="fa fa-check"></i><b>B.4.4</b> Non-traditional methods</a></li>
<li class="chapter" data-level="B.4.5" data-path="B-appendixB.html"><a href="B-appendixB.html#traditional-methods-2"><i class="fa fa-check"></i><b>B.4.5</b> Traditional methods</a></li>
<li class="chapter" data-level="B.4.6" data-path="B-appendixB.html"><a href="B-appendixB.html#check-conditions-2"><i class="fa fa-check"></i><b>B.4.6</b> Check conditions</a></li>
<li class="chapter" data-level="B.4.7" data-path="B-appendixB.html"><a href="B-appendixB.html#test-statistic-2"><i class="fa fa-check"></i><b>B.4.7</b> Test statistic</a></li>
<li class="chapter" data-level="B.4.8" data-path="B-appendixB.html"><a href="B-appendixB.html#state-conclusion-2"><i class="fa fa-check"></i><b>B.4.8</b> State conclusion</a></li>
<li class="chapter" data-level="B.4.9" data-path="B-appendixB.html"><a href="B-appendixB.html#comparing-results-2"><i class="fa fa-check"></i><b>B.4.9</b> Comparing results</a></li>
</ul></li>
<li class="chapter" data-level="B.5" data-path="B-appendixB.html"><a href="B-appendixB.html#two-means-independent-samples"><i class="fa fa-check"></i><b>B.5</b> Two means (independent samples)</a><ul>
<li class="chapter" data-level="B.5.1" data-path="B-appendixB.html"><a href="B-appendixB.html#problem-statement-3"><i class="fa fa-check"></i><b>B.5.1</b> Problem statement</a></li>
<li class="chapter" data-level="B.5.2" data-path="B-appendixB.html"><a href="B-appendixB.html#competing-hypotheses-3"><i class="fa fa-check"></i><b>B.5.2</b> Competing hypotheses</a></li>
<li class="chapter" data-level="B.5.3" data-path="B-appendixB.html"><a href="B-appendixB.html#exploring-the-sample-data-3"><i class="fa fa-check"></i><b>B.5.3</b> Exploring the sample data</a></li>
<li class="chapter" data-level="B.5.4" data-path="B-appendixB.html"><a href="B-appendixB.html#non-traditional-methods-3"><i class="fa fa-check"></i><b>B.5.4</b> Non-traditional methods</a></li>
<li class="chapter" data-level="B.5.5" data-path="B-appendixB.html"><a href="B-appendixB.html#traditional-methods-3"><i class="fa fa-check"></i><b>B.5.5</b> Traditional methods</a></li>
<li class="chapter" data-level="B.5.6" data-path="B-appendixB.html"><a href="B-appendixB.html#test-statistic-3"><i class="fa fa-check"></i><b>B.5.6</b> Test statistic</a></li>
<li class="chapter" data-level="B.5.7" data-path="B-appendixB.html"><a href="B-appendixB.html#compute-p-value-1"><i class="fa fa-check"></i><b>B.5.7</b> Compute <span class="math inline">\(p\)</span>-value</a></li>
<li class="chapter" data-level="B.5.8" data-path="B-appendixB.html"><a href="B-appendixB.html#state-conclusion-3"><i class="fa fa-check"></i><b>B.5.8</b> State conclusion</a></li>
<li class="chapter" data-level="B.5.9" data-path="B-appendixB.html"><a href="B-appendixB.html#comparing-results-3"><i class="fa fa-check"></i><b>B.5.9</b> Comparing results</a></li>
</ul></li>
<li class="chapter" data-level="B.6" data-path="B-appendixB.html"><a href="B-appendixB.html#two-means-paired-samples"><i class="fa fa-check"></i><b>B.6</b> Two means (paired samples)</a><ul>
<li class="chapter" data-level="B.6.1" data-path="B-appendixB.html"><a href="B-appendixB.html#competing-hypotheses-4"><i class="fa fa-check"></i><b>B.6.1</b> Competing hypotheses</a></li>
<li class="chapter" data-level="B.6.2" data-path="B-appendixB.html"><a href="B-appendixB.html#exploring-the-sample-data-4"><i class="fa fa-check"></i><b>B.6.2</b> Exploring the sample data</a></li>
<li class="chapter" data-level="B.6.3" data-path="B-appendixB.html"><a href="B-appendixB.html#non-traditional-methods-4"><i class="fa fa-check"></i><b>B.6.3</b> Non-traditional methods</a></li>
<li class="chapter" data-level="B.6.4" data-path="B-appendixB.html"><a href="B-appendixB.html#traditional-methods-4"><i class="fa fa-check"></i><b>B.6.4</b> Traditional methods</a></li>
<li class="chapter" data-level="B.6.5" data-path="B-appendixB.html"><a href="B-appendixB.html#comparing-results-4"><i class="fa fa-check"></i><b>B.6.5</b> Comparing results</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="C" data-path="C-appendixC.html"><a href="C-appendixC.html"><i class="fa fa-check"></i><b>C</b> Reach for the Stars</a><ul>
<li class="chapter" data-level="" data-path="C-appendixC.html"><a href="C-appendixC.html#needed-packages-11"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="C.1" data-path="C-appendixC.html"><a href="C-appendixC.html#sorted-barplots"><i class="fa fa-check"></i><b>C.1</b> Sorted barplots</a></li>
<li class="chapter" data-level="C.2" data-path="C-appendixC.html"><a href="C-appendixC.html#interactive-graphics"><i class="fa fa-check"></i><b>C.2</b> Interactive graphics</a><ul>
<li class="chapter" data-level="C.2.1" data-path="C-appendixC.html"><a href="C-appendixC.html#interactive-linegraphs"><i class="fa fa-check"></i><b>C.2.1</b> Interactive linegraphs</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="D" data-path="D-appendixD.html"><a href="D-appendixD.html"><i class="fa fa-check"></i><b>D</b> Learning Check Solutions</a><ul>
<li class="chapter" data-level="D.1" data-path="D-appendixD.html"><a href="D-appendixD.html#chapter-2-solutions"><i class="fa fa-check"></i><b>D.1</b> Chapter 2 Solutions</a></li>
<li class="chapter" data-level="D.2" data-path="D-appendixD.html"><a href="D-appendixD.html#chapter-3-solutions"><i class="fa fa-check"></i><b>D.2</b> Chapter 3 Solutions</a></li>
<li class="chapter" data-level="D.3" data-path="D-appendixD.html"><a href="D-appendixD.html#chapter-4-solutions"><i class="fa fa-check"></i><b>D.3</b> Chapter 4 Solutions</a></li>
<li class="chapter" data-level="D.4" data-path="D-appendixD.html"><a href="D-appendixD.html#chapter-5-solutions"><i class="fa fa-check"></i><b>D.4</b> Chapter 5 Solutions</a></li>
<li class="chapter" data-level="D.5" data-path="D-appendixD.html"><a href="D-appendixD.html#chapter-6-solutions"><i class="fa fa-check"></i><b>D.5</b> Chapter 6 Solutions</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Statistical Inference via Data Science</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<html>
<img src='https://moderndive.com/wide_format.png' alt="ModernDive">
</html>
<div id="confidence-intervals" class="section level1">
<h1><span class="header-section-number">Chapter 9</span> Bootstrapping and Confidence Intervals</h1>
<p>In Chapter <a href="8-sampling.html#sampling">8</a>, we studied sampling. We started with a “tactile” exercise where we wanted to know the proportion of balls in the sampling bowl in Figure <a href="8-sampling.html#fig:sampling-exercise-1">8.1</a> that are red. While we could have performed an exhaustive count, this would have been a tedious process. So instead we used a shovel to extract a sample of 50 balls and used the resulting proportion that were red as an estimate of the proportion of the bowl’s balls that are red. Furthermore, we made sure to mix the bowl’s contents before every use of the shovel. Because of the randomness induced by the mixing, different uses of the shovel yielded different proportions red and hence different estimates of the proportion of the bowl’s balls that are red.</p>
<p>We then mimicked this “tactile” exercise with an equivalent “virtual” exercise performed on the computer. Using our computers’ random number generator, we could very quickly mimic the above sampling procedure a large number of times. In Section <a href="8-sampling.html#different-shovels">8.2.4</a>, we quickly repeated the above sampling procedure 1000 times using three different “virtual” shovels with 25, 50, and 100 slots. We compared the variation of these three sets of 1000 estimates of the proportion of the bowl’s balls that are red in the three histograms in Figure <a href="8-sampling.html#fig:comparing-sampling-distributions-3">8.15</a>.</p>
<p>What we did there was construct <em>sampling distributions</em>. The motivation for taking 1000 repeated samples and visualizing the resulting estimates was to study how these estimates varied from one sample to another; in other words we wanted to study the effect of <em>sampling variation</em>. We quantified the variation of these estimates using their standard deviation which has a special name: the <em>standard error</em>. In particular, we saw that as the sample size increased from 25 to 50 to 100, the standard error decreased and thus the sampling distributions narrowed. In other words, larger sample sizes lead to more <em>precise</em> estimates.</p>
<p>We also described the above sampling exercises using the terminology and mathematical notation related to sampling we introduced in Section <a href="8-sampling.html#terminology-and-notation">8.3.1</a>. Our <em>study population</em> was the large bowl with <span class="math inline">\(N\)</span> = 2400 balls, while the <em>population parameter</em>, the unknown quantity of interest, here was the population proportion <span class="math inline">\(p\)</span> of the bowl’s balls that are red. Since performing a <em>census</em> would be very expensive in terms of time and energy, we instead extracted a <em>sample</em> of size <span class="math inline">\(n\)</span> = 50. The <em>point estimate</em>, also known as a <em>sample statistic</em>, used to estimate <span class="math inline">\(p\)</span> was the sample proportion <span class="math inline">\(\widehat{p}\)</span> of these 50 sampled balls that were red. Furthermore, since the sample was obtained at <em>random</em>, it can be considered as <em>unbiased</em> and <em>representative</em> of the population. Thus any results based on the sample could be <em>generalized</em> to the population. In other words, the sample proportion <span class="math inline">\(\widehat{p}\)</span> of the shovel’s <span class="math inline">\(n\)</span> = 50 balls that were red was a “good guess” of the true population proportion <span class="math inline">\(p\)</span> of the bowl’s <span class="math inline">\(N\)</span> = 2400 balls that are red. In other words, we used the sample to <em>infer</em> about the population.</p>
<p>However as described in Section <a href="8-sampling.html#sampling-simulation">8.2</a>, both the tactile and virtual sampling exercises are not what one would do in real life; they were merely <em>simulations</em> used to study the effects of sampling variation. In a real life situation, we would not take 1000 samples of size <span class="math inline">\(n\)</span>, but rather take a <em>single</em> representative sample of as large a size as possible. Additionally, we knew what the true value of the population parameter here was: the true population proportion of the bowl’s balls that are red. In a real life situation we will not know what this value is. Because if we did, then why would we take a sample to estimate it?</p>
<p>An example of a realistic sampling situation would be a poll, like the one described in the <a href="https://www.npr.org/sections/itsallpolitics/2013/12/04/248793753/poll-support-for-obama-among-young-americans-eroding">Obama poll</a> article you saw in Section <a href="8-sampling.html#sampling-case-study">8.4</a>. Pollsters did not know the true proportion of <strong>all</strong> young Americans who supported President Obama and thus took a single sample of size <span class="math inline">\(n\)</span> = 2089 young Americans to estimate the true unknown value.</p>
<p>So how does one study the effects of sampling variation when you only have a single sample to work with? There is no sample-to-sample variation is estimates when you only have one sample. One common method is known as <em>bootstrapping resampling</em>, which will be the focus of the earlier sections of this chapter.</p>
<p>Furthermore, what if we would like not only a single estimate of the unknown population parameter, we would like a <em>range of highly plausible</em> values? Going back to the Obama poll article, it stated that the pollsters’ estimate of the proportion of all young Americans who supported President Obama was 41%, but in addition it stated that the poll’s “margin of error was plus or minus 2.1 percentage points.” In other words this “plausible range” was [41% - 2.1%, 41% + 2.1%] = [37.9%, 43.1%]. This range of plausible values is known as a <em>confidence interval</em> and will be the focus of the later sections of this chapter.</p>
<div id="needed-packages-6" class="section level3 unnumbered">
<h3>Needed packages</h3>
<p>Let’s load all the packages needed for this chapter (this assumes you’ve already installed them). Recall from our discussion in Section <a href="5-tidy.html#tidyverse-package">5.4.1</a> that loading the <code>tidyverse</code> package by running <code>library(tidyverse)</code> loads the following commonly used data science packages all at once:</p>
<ul>
<li><code>ggplot2</code> for data visualization</li>
<li><code>dplyr</code> for data wrangling</li>
<li><code>tidyr</code> for converting data to “tidy” format</li>
<li><code>readr</code> for importing spreadsheet data into R</li>
<li>As well as the more advanced <code>purrr</code>, <code>tibble</code>, <code>stringr</code>, and <code>forcats</code> packages</li>
</ul>
<p>If needed, read Section <a href="2-getting-started.html#packages">2.3</a> for information on how to install and load R packages.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(tidyverse)
<span class="kw">library</span>(moderndive)
<span class="kw">library</span>(infer)</code></pre>
</div>
<div id="resampling-tactile" class="section level2">
<h2><span class="header-section-number">9.1</span> Pennies activity</h2>
<p>As we did in Chapter <a href="8-sampling.html#sampling">8</a>, we’ll begin with a hands-on tactile activity.</p>
<div id="what-is-the-average-year-on-us-pennies-in-2019" class="section level3">
<h3><span class="header-section-number">9.1.1</span> What is the average year on US pennies in 2019?</h3>
<p>Try to imagine all pennies being used in the United States in 2019. That’s a lot of pennies! Now say we’re are interested in the average year of minting of <em>all</em> these pennies. One way to compute this value would be to gather up all pennies being used in the US, record the year, and compute the average. This would be near impossible! So instead, let’s collect a sample of 50 pennies collected from a local bank in downtown Northampton, Massachusetts, the USA seen in Figure <a href="9-confidence-intervals.html#fig:resampling-exercise-a">9.1</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:resampling-exercise-a"></span>
<img src="images/sampling/pennies/bank.jpg" alt="Collecting a sample of 50 US pennies from a local bank." width="40%" /><img src="images/sampling/pennies/roll.jpg" alt="Collecting a sample of 50 US pennies from a local bank." width="40%" />
<p class="caption">
FIGURE 9.1: Collecting a sample of 50 US pennies from a local bank.
</p>
</div>
<p>An image of these 50 pennies can be seen in Figure <a href="9-confidence-intervals.html#fig:resampling-exercise-b">9.2</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:resampling-exercise-b"></span>
<img src="images/sampling/pennies/pennies_trim.jpg" alt="50 US pennies." width="100%" />
<p class="caption">
FIGURE 9.2: 50 US pennies.
</p>
</div>
<p>For each of the 50 pennies let’s assign an “ID” label and mark the year of minting, starting in the top left and ending in the bottom right progressing row by row, as seen in Figure <a href="9-confidence-intervals.html#fig:resampling-exercise-c">9.3</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:resampling-exercise-c"></span>
<img src="images/sampling/pennies/deliverable/3.jpg" alt="50 US pennies labelled." width="100%" />
<p class="caption">
FIGURE 9.3: 50 US pennies labelled.
</p>
</div>
<p>The <code>moderndive</code>  package contains this data on our 50 sampled pennies. Let’s explore this sample data first:</p>
<pre class="sourceCode r"><code class="sourceCode r">pennies_sample</code></pre>
<pre><code># A tibble: 50 x 2
      ID  year
   &lt;int&gt; &lt;dbl&gt;
 1     1  2002
 2     2  1986
 3     3  2017
 4     4  1988
 5     5  2008
 6     6  1983
 7     7  2008
 8     8  1996
 9     9  2004
10    10  2000
# … with 40 more rows</code></pre>
<p>The <code>pennies_sample</code> data frame has 50 rows corresponding to each penny with two variables. The first variable <code>ID</code> corresponds to the ID labels in Figure <a href="9-confidence-intervals.html#fig:resampling-exercise-c">9.3</a> whereas the second variable <code>year</code> corresponds to the year of minting saved as an integer.</p>
<p>Based on these 50 sampled pennies, what can we say about <em>all</em> US pennies in 2019? Let’s study some properties of our sample by performing an exploratory data analysis. Let’s first visualize the distribution of the year of these 50 pennies using our data visualization tools from Chapter <a href="3-viz.html#viz">3</a>. Since <code>year</code> is a numerical variable, we use a histogram in Figure <a href="9-confidence-intervals.html#fig:pennies-sample-histogram">9.4</a>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(pennies_sample, <span class="kw">aes</span>(<span class="dt">x =</span> year)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth =</span> <span class="dv">10</span>, <span class="dt">color =</span> <span class="st">&quot;white&quot;</span>)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:pennies-sample-histogram"></span>
<img src="moderndive_files/figure-html/pennies-sample-histogram-1.png" alt="Distribution of year on 50 US pennies." width="\textwidth" />
<p class="caption">
FIGURE 9.4: Distribution of year on 50 US pennies.
</p>
</div>
<p>We observe a slightly left-skewed  distribution since most values fall in between the 1980s through 2010s with only a few older than 1970. What is the average year for the 50 sampled pennies? Eyeballing the histogram it appears to be around 1990. Let’s now compute this value exactly using our data wrangling tools from Chapter <a href="4-wrangling.html#wrangling">4</a>.</p>
<pre class="sourceCode r"><code class="sourceCode r">pennies_sample <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">mean_year =</span> <span class="kw">mean</span>(year))</code></pre>
<pre><code># A tibble: 1 x 1
  mean_year
      &lt;dbl&gt;
1   1995.44</code></pre>
<p>Thus assuming <code>pennies_sample</code> is a representative sample from the population of all US pennies, a “good guess” of the average year of minting of all US pennies would be 1995.44, the average year of minting of our 50 sampled pennies. This should all start sounding similar to what we did previously in Chapter <a href="8-sampling.html#sampling">8</a>!</p>
<p>In Chapter <a href="8-sampling.html#sampling">8</a> our study population was the bowl of <span class="math inline">\(N\)</span> = 2400 balls. Our population parameter of interest was the population proportion of these balls that were red, denoted mathematically by <span class="math inline">\(p\)</span>. In order to estimate <span class="math inline">\(p\)</span>, we extracted a sample of 50 balls using the shovel and computed the relevant point estimate: the sample proportion of these 50 balls that were red, denoted mathematically by <span class="math inline">\(\widehat{p}\)</span>.</p>
<p>Here our study population is <span class="math inline">\(N\)</span> = whatever the number of pennies are being used in the US, a value which we don’t know and probably never will. The population parameter of interest is now the <em>population mean</em> year of all these pennies, a value denoted mathematically by the Greek letter <span class="math inline">\(\mu\)</span> pronounced “mu”. In order to estimate <span class="math inline">\(\mu\)</span>, we went to the bank and obtained a sample of 50 pennies and computed the relevant point estimate: the <em>sample mean</em> year of these 50 pennies, denoted mathematically by <span class="math inline">\(\overline{x}\)</span> pronounced “x-bar”. An alternative and more intuitive notation for the sample mean is <span class="math inline">\(\widehat{\mu}\)</span>. However this is unfortunately not as commonly used, so in this text, we’ll always denote the sample mean as <span class="math inline">\(\overline{x}\)</span>.</p>
<p>We summarize the correspondence between the sampling bowl exercise in Chapter <a href="8-sampling.html#sampling">8</a> and our pennies exercise in Table <a href="9-confidence-intervals.html#tab:table-ch8-b">9.1</a>, which are the first two rows of the previously seen Table <a href="8-sampling.html#tab:table-ch8">8.8</a> of the various sampling scenarios we’ll cover in this text.</p>
<table class="table" style="font-size: 16px; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:table-ch8-b">TABLE 9.1: </span>Scenarios of sampling for inference
</caption>
<thead>
<tr>
<th style="text-align:right;">
Scenario
</th>
<th style="text-align:left;">
Population parameter
</th>
<th style="text-align:left;">
Notation
</th>
<th style="text-align:left;">
Point estimate
</th>
<th style="text-align:left;">
Notation.
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;width: 0.5in; ">
1
</td>
<td style="text-align:left;width: 0.7in; ">
Population proportion
</td>
<td style="text-align:left;width: 1in; ">
<span class="math inline">\(p\)</span>
</td>
<td style="text-align:left;width: 1.1in; ">
Sample proportion
</td>
<td style="text-align:left;width: 1in; ">
<span class="math inline">\(\widehat{p}\)</span>
</td>
</tr>
<tr>
<td style="text-align:right;width: 0.5in; ">
2
</td>
<td style="text-align:left;width: 0.7in; ">
Population mean
</td>
<td style="text-align:left;width: 1in; ">
<span class="math inline">\(\mu\)</span>
</td>
<td style="text-align:left;width: 1.1in; ">
Sample mean
</td>
<td style="text-align:left;width: 1in; ">
<span class="math inline">\(\overline{x}\)</span> or <span class="math inline">\(\widehat{\mu}\)</span>
</td>
</tr>
</tbody>
</table>
<p>Going back to our 50 sampled pennies in Figure <a href="9-confidence-intervals.html#fig:resampling-exercise-c">9.3</a>, the point estimate of interest is the sample mean <span class="math inline">\(\overline{x}\)</span> of 1995.44. This quantity is an estimate of the population mean year of all US pennies <span class="math inline">\(\mu\)</span>.</p>
<p>Recall that we also saw in Chapter <a href="8-sampling.html#sampling">8</a> that such estimates are prone to sampling variation. For example, in this particular sample in Figure <a href="9-confidence-intervals.html#fig:resampling-exercise-c">9.3</a>, we observed three pennies with the year of 1999. If we obtained other samples of size 50 would we always observe exactly three pennies with the year of 1999? More than likely not. We might observe none, or one, or two, or maybe even all 50! The same can be said for the other 26 unique years that are represented in our sample of 50 pennies.</p>
<p>To study this sampling variation as we did in Chapter <a href="8-sampling.html#sampling">8</a>, we need more than one sample. In our case with pennies, how would we obtain another sample? We would go to the bank and get another roll of 50 pennies! However, in real-life sampling one doesn’t obtain many samples as we did in Chapter <a href="8-sampling.html#sampling">8</a>; those were merely simulations. So what how can we study sample-to-sample variation when we have only a single sample as in our case?</p>
<p>Just as different uses of the shovel in the bowl led to the different sample proportions red, different samples of 50 pennies will lead to different sample mean years. However, how can we study the effect of sampling variation using only our <em>single sample</em> seen in Figure <a href="9-confidence-intervals.html#fig:resampling-exercise-c">9.3</a>? We will do so using a technique known as “bootstrap resampling with replacement”, which we now illustrate.</p>
</div>
<div id="resampling-once" class="section level3">
<h3><span class="header-section-number">9.1.2</span> Resampling once</h3>
<p><strong>Step 1</strong>: Let’s print out identically-sized slips of paper representing the 50 pennies in Figure <a href="9-confidence-intervals.html#fig:resampling-exercise-c">9.3</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:tactile-resampling-1"></span>
<img src="images/sampling/pennies/tactile_simulation/1_paper_slips.png" alt="50 slips of paper representing 50 US pennies." width="50%" />
<p class="caption">
FIGURE 9.5: 50 slips of paper representing 50 US pennies.
</p>
</div>
<p><strong>Step 2</strong>: Put the 50 small pieces of paper into a hat or tuque.</p>
<div class="figure" style="text-align: center"><span id="fig:tactile-resampling-2"></span>
<img src="images/sampling/pennies/tactile_simulation/2_insert_in_hat.png" alt="Putting 50 slips of paper in a hat." width="50%" />
<p class="caption">
FIGURE 9.6: Putting 50 slips of paper in a hat.
</p>
</div>
<p><strong>Step 3</strong>: Mix the hat’s contents and draw one slip of paper at random. Record the year somewhere.</p>
<div class="figure" style="text-align: center"><span id="fig:tactile-resampling-3"></span>
<img src="images/sampling/pennies/tactile_simulation/3_draw_at_random.png" alt="Drawing one slip of paper." width="50%" />
<p class="caption">
FIGURE 9.7: Drawing one slip of paper.
</p>
</div>
<p><strong>Step 4</strong>: Put the slip of paper back in the hat! In other words, replace it!</p>
<div class="figure" style="text-align: center"><span id="fig:tactile-resampling-4"></span>
<img src="images/sampling/pennies/tactile_simulation/4_put_it_back.png" alt="Replacing slip of paper." width="50%" />
<p class="caption">
FIGURE 9.8: Replacing slip of paper.
</p>
</div>
<p><strong>Step 5</strong>: Repeat Steps 3 and 4 49 more times, resulting in 50 recorded years.</p>
<p>What we just performed was a <strong>resampling</strong>  of the original sample of 50 pennies. We are not sampling 50 pennies from the population of all US pennies as we did in our trip to the bank. Instead, we are mimicking this act by “re”-sampling 50 pennies from our originally sampled 50 pennies. However, why did we replace our resampled slip of paper back into the hat in Step 4? Because if we left the slip of paper out of the hat each time we performed Step 4, we would obtain the same 50 pennies, in the end, each time! In other words, replacing the slips of paper induces variation.</p>
<p>Being more precise with our terminology, we just performed a <strong>resampling with replacement</strong> of the original sample of 50 pennies. Had we left the slip of paper out of the hat each time we performed Step 4, this would be “resampling without replacement”.</p>
<p>Let’s study our 50 resampled pennies via an exploratory data analysis. First, let’s load the data into R by manually creating a data frame <code>pennies_resample</code> of our 50 resampled values. We’ll do this using the <code>tibble()</code> command from the <code>dplyr</code> package. Note that the 50 values you obtained will almost certainly not be the same as ours.</p>
<pre class="sourceCode r"><code class="sourceCode r">pennies_resample &lt;-<span class="st"> </span><span class="kw">tibble</span>(
  <span class="dt">year =</span> <span class="kw">c</span>(<span class="dv">1976</span>, <span class="dv">1962</span>, <span class="dv">1976</span>, <span class="dv">1983</span>, <span class="dv">2017</span>, <span class="dv">2015</span>, <span class="dv">2015</span>, <span class="dv">1962</span>, <span class="dv">2016</span>, <span class="dv">1976</span>, 
           <span class="dv">2006</span>, <span class="dv">1997</span>, <span class="dv">1988</span>, <span class="dv">2015</span>, <span class="dv">2015</span>, <span class="dv">1988</span>, <span class="dv">2016</span>, <span class="dv">1978</span>, <span class="dv">1979</span>, <span class="dv">1997</span>, 
           <span class="dv">1974</span>, <span class="dv">2013</span>, <span class="dv">1978</span>, <span class="dv">2015</span>, <span class="dv">2008</span>, <span class="dv">1982</span>, <span class="dv">1986</span>, <span class="dv">1979</span>, <span class="dv">1981</span>, <span class="dv">2004</span>, 
           <span class="dv">2000</span>, <span class="dv">1995</span>, <span class="dv">1999</span>, <span class="dv">2006</span>, <span class="dv">1979</span>, <span class="dv">2015</span>, <span class="dv">1979</span>, <span class="dv">1998</span>, <span class="dv">1981</span>, <span class="dv">2015</span>, 
           <span class="dv">2000</span>, <span class="dv">1999</span>, <span class="dv">1988</span>, <span class="dv">2017</span>, <span class="dv">1992</span>, <span class="dv">1997</span>, <span class="dv">1990</span>, <span class="dv">1988</span>, <span class="dv">2006</span>, <span class="dv">2000</span>)
)</code></pre>
<p>The 50 values of <code>year</code> in <code>pennies_resample</code> represent the resample of size 50 from the original sample of 50 pennies from the bank. We display the 50 resampled pennies in Figure <a href="9-confidence-intervals.html#fig:resampling-exercise-d">9.9</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:resampling-exercise-d"></span>
<img src="images/sampling/pennies/deliverable/4.jpg" alt="50 resampled US pennies labelled." width="100%" />
<p class="caption">
FIGURE 9.9: 50 resampled US pennies labelled.
</p>
</div>
<p>Let’s compare the distribution of the numerical variable <code>year</code> of our 50 resampled pennies with the distribution of the numerical variable <code>year</code> of our original sample of 50 pennies from the bank in Figure <a href="9-confidence-intervals.html#fig:origandresample">9.10</a>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(pennies_resample, <span class="kw">aes</span>(<span class="dt">x =</span> year)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth =</span> <span class="dv">10</span>, <span class="dt">color =</span> <span class="st">&quot;white&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Resample of 50 pennies&quot;</span>)
<span class="kw">ggplot</span>(pennies_sample, <span class="kw">aes</span>(<span class="dt">x =</span> year)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth =</span> <span class="dv">10</span>, <span class="dt">color =</span> <span class="st">&quot;white&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Original sample of 50 pennies&quot;</span>)</code></pre>

<pre><code>&lt;ScaleContinuousPosition&gt;
 Range:  
 Limits:    0 --   15</code></pre>
<pre><code>&lt;ScaleContinuousPosition&gt;
 Range:  
 Limits:    0 --   15</code></pre>
<div class="figure" style="text-align: center"><span id="fig:origandresample"></span>
<img src="moderndive_files/figure-html/origandresample-1.png" alt="Comparing year in the resample pennies_resample with the original sample pennies_sample." width="\textwidth" />
<p class="caption">
FIGURE 9.10: Comparing <code>year</code> in the resample <code>pennies_resample</code> with the original sample <code>pennies_sample</code>.
</p>
</div>
<p>Observe that while the general shape of the distribution of <code>year</code> is roughly similar, they are not identical. This is due to the variation induced by replacing the slips of paper each time we pull one out and recorded the year.</p>
<p>Recall from the previous section that the sample mean of the original sample of 50 pennies from the bank was 1995.44. What about for the <code>year</code> variable in <code>pennies_resample</code>? Any guesses? Let’s have <code>dplyr</code> help us out as before:</p>
<pre class="sourceCode r"><code class="sourceCode r">pennies_resample <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">mean_year =</span> <span class="kw">mean</span>(year))</code></pre>
<pre><code># A tibble: 1 x 1
  mean_year
      &lt;dbl&gt;
1   1994.82</code></pre>
<p>We obtained a different mean year of 1994.82. Again, this variation is induced by the “with replacement” from the “resampling with replacement” terminology we defined earlier.</p>
<p>What if we repeated several times this resampling exercise many times? Would we obtain the same sample mean <code>year</code> value each time? In other words, would our guess at the mean year of all pennies in the US in 2019 be exactly 1994.82 every time? Just as we did in Chapter <a href="8-sampling.html#sampling">8</a>, let’s perform this resampling activity with the help of 35 of our friends.</p>
</div>
<div id="student-resamples" class="section level3">
<h3><span class="header-section-number">9.1.3</span> Resampling 35 times</h3>
<p>Each of our 35 friends will repeat the same 5 steps above:</p>
<ol style="list-style-type: decimal">
<li>Start with 50 identically-sized slips of paper representing the 50 pennies.</li>
<li>Put the 50 small pieces of paper into a hat or tuque.</li>
<li>Mix the hat’s contents and draw one slip of paper at random. Record the year somewhere.</li>
<li>Replace the slip of paper back in the hat!</li>
<li>Repeat Steps 3 and 4 49 more times, resulting in 50 recorded years.</li>
</ol>
<p>Since we had 35 of our friends perform this task, we ended up with 35 <span class="math inline">\(\times\)</span> 50 = 1750 values. We recorded these values in a <a href="https://docs.google.com/spreadsheets/d/1y3kOsU_wDrDd5eiJbEtLeHT9L5SvpZb_TrzwFBsouk0/">shared spreadsheet</a> with 50 rows (plus a header row) and 35 columns; we display a snapshot of the first 10 rows and 5 columns in Figure <a href="9-confidence-intervals.html#fig:tactile-resampling-5">9.11</a></p>
<div class="figure" style="text-align: center"><span id="fig:tactile-resampling-5"></span>
<img src="images/sampling/pennies/tactile_simulation/5_shared_spreadsheet.png" alt="Snapshot of shared spreadsheet of resampled pennies." width="70%" />
<p class="caption">
FIGURE 9.11: Snapshot of shared spreadsheet of resampled pennies.
</p>
</div>
<p>For your convenience, we’ve taken these 35 <span class="math inline">\(\times\)</span> 50 = 1750 values and saved them in <code>virtual_resamples</code>, a “tidy” data frame included in the <code>moderndive</code> package:</p>
<pre class="sourceCode r"><code class="sourceCode r">pennies_resamples</code></pre>
<pre><code># A tibble: 1,750 x 3
   replicate name   year
       &lt;int&gt; &lt;chr&gt; &lt;dbl&gt;
 1         1 A      1988
 2         1 A      2002
 3         1 A      2015
 4         1 A      1998
 5         1 A      1979
 6         1 A      1971
 7         1 A      1971
 8         1 A      2015
 9         1 A      1988
10         1 A      1979
# … with 1,740 more rows</code></pre>
<p>What did each of our 35 friends obtain as the mean year? <code>dplyr</code> to the rescue once more! After grouping the rows by <code>name</code>, we summarize each group of rows with their mean <code>year</code>:</p>
<pre class="sourceCode r"><code class="sourceCode r">resampled_means &lt;-<span class="st"> </span>pennies_resamples <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(name) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">mean_year =</span> <span class="kw">mean</span>(year))
resampled_means</code></pre>
<pre><code># A tibble: 35 x 2
   name  mean_year
   &lt;chr&gt;     &lt;dbl&gt;
 1 A       1992.5 
 2 AA      1995.86
 3 B       1996.42
 4 BB      1992.4 
 5 C       1996.32
 6 CC      1995.88
 7 D       1996.9 
 8 DD      1997.46
 9 E       1991.22
10 EE      1998.44
# … with 25 more rows</code></pre>
<p>Observe that <code>resampled_means</code> has 35 rows corresponding to the 35 resample means based the 35 resamples performed by our friends. Furthermore, observe the variation in the 35 values in the variable <code>mean_year</code>. This variation exists because by “resampling with replacement”, our 35 friends obtained different resamples of 50 pennies, and thus obtained different resample mean year.</p>
<p>Since the variable <code>mean_year</code> is numerical, let’s visualize its distribution using a histogram in Figure <a href="9-confidence-intervals.html#fig:tactile-resampling-6">9.12</a>. Note that adding the argument <code>boundary = 1990</code> to <code>geom_histogram()</code> sets the binning structure of the histogram so that one of the boundaries between bins is at the year 1990 exactly.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(resampled_means, <span class="kw">aes</span>(<span class="dt">x =</span> mean_year)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth =</span> <span class="dv">1</span>, <span class="dt">color =</span> <span class="st">&quot;white&quot;</span>, <span class="dt">boundary =</span> <span class="dv">1990</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Resampled mean year&quot;</span>)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:tactile-resampling-6"></span>
<img src="moderndive_files/figure-html/tactile-resampling-6-1.png" alt="Distribution of 35 sample means from 35 resamples." width="\textwidth" />
<p class="caption">
FIGURE 9.12: Distribution of 35 sample means from 35 resamples.
</p>
</div>
<p>Observe the following about the histogram in Figure <a href="9-confidence-intervals.html#fig:tactile-resampling-6">9.12</a>:</p>
<ul>
<li>The distribution looks roughly normal.</li>
<li>We rarely observe sample mean years less than in 1992.</li>
<li>On the other side of the distribution, we rarely observe sample mean years greater than in 2000.</li>
<li>The most frequently occurring values occur between roughly 1992 and 1998.</li>
<li>The distribution of these 35 sample means based on 35 resamples is roughly centered at 1995, which is the sample mean of 1995.44 of the original sample of 50 pennies from the bank.</li>
</ul>
</div>
<div id="what-did-we-just-do-1" class="section level3">
<h3><span class="header-section-number">9.1.4</span> What did we just do?</h3>
<p>What we just demonstrated in this activity is the statistical procedure known as <em>bootstrap resampling with replacement</em> . We used <em>resampling</em> to mimic the sampling variation we observe from sample-to-sample as we did in Chapter <a href="8-sampling.html#sampling">8</a> on sampling, but this time using a <em>single</em> sample from the population.</p>
<p>In fact, the histogram of sample means from 35 resamples in Figure <a href="9-confidence-intervals.html#fig:tactile-resampling-6">9.12</a> is called the <em>bootstrap distribution</em>  of the sample mean and it is an approximation of the <em>sampling distribution</em> of the same mean, a concept we introduced in Chapter <a href="8-sampling.html#sampling">8</a>. In Section <a href="9-confidence-intervals.html#ci-conclusion">9.7</a> we’ll show you that the <em>bootstrap distribution</em> is an approximation to the <em>sampling distribution</em>. Using this bootstrap distribution, we can study the effect of sampling variation on our estimates, in particular study the typical “error” of our estimates, known as the <em>standard error</em> .</p>
<p>In Section <a href="9-confidence-intervals.html#resampling-simulation">9.2</a> we’ll mimic our tactile resampling activity virtually on the computer. We can use a computer to do the resampling many more times than our 35 friends could possibly do. This will allow us to better understand the bootstrap distribution. In Section <a href="9-confidence-intervals.html#ci-build-up">9.3</a> we’ll explicitly articulate our goals for this chapter: understanding resampling variation, defining the statistical concept of a <em>confidence interval</em> by building on our pennies example, and discussing the interpretation of confidence intervals.</p>
<p>Following this framework on confidence intervals, we’ll discuss the <code>dplyr</code> and <code>infer</code> package code needed to complete the process of <em>bootstrapping</em>, which is another name for this resampling approach that is most commonly found in developing confidence intervals. We’ve used one of the functions in the <code>infer</code> package already with <code>rep_sample_n()</code>, but there’s a lot more to this package than just that. We’ll introduce the tidy statistical inference framework that was the motivation for the <code>infer</code> package pipeline that will be the driving package throughout the rest of this book.</p>
<p>As we did in Chapter <a href="8-sampling.html#sampling">8</a>, we’ll tie all these ideas together with a real-life case study in Section <a href="9-confidence-intervals.html#case-study-two-prop-ci">9.6</a> involving data from an experiment about yawning from the US television show Mythbusters. The chapter concludes with a comparison of the sampling distribution and a bootstrap distribution using the balls data from Chapter <a href="8-sampling.html#sampling">8</a> on sampling.</p>
</div>
</div>
<div id="resampling-simulation" class="section level2">
<h2><span class="header-section-number">9.2</span> Computer simulation of resampling</h2>
<p>Let’s now mimic our tactile resampling activity virtually by using our computer.</p>
<div id="virtually-resampling-once" class="section level3">
<h3><span class="header-section-number">9.2.1</span> Virtually resampling once</h3>
<p>First, let’s perform the virtual analog of resampling once. Recall that the <code>pennies_sample</code> data frame included in the <code>moderndive</code> package contains the years of our original sample of 50 pennies from the bank. Furthermore, recall in Chapter <a href="8-sampling.html#sampling">8</a> on sampling that we used the <code>rep_sample_n()</code> function as a virtual shovel to sample balls from our virtual bowl of 2400 balls.</p>
<pre class="sourceCode r"><code class="sourceCode r">virtual_shovel &lt;-<span class="st"> </span>bowl <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">rep_sample_n</span>(<span class="dt">size =</span> <span class="dv">50</span>)</code></pre>
<p>Let’s combine these two elements to virtually mimic our resampling with replacement exercise involving the slips of paper representing our 50 pennies in Figure <a href="9-confidence-intervals.html#fig:resampling-exercise-c">9.3</a>:</p>
<pre class="sourceCode r"><code class="sourceCode r">virtual_resample &lt;-<span class="st"> </span>pennies_sample <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">rep_sample_n</span>(<span class="dt">size =</span> <span class="dv">50</span>, <span class="dt">replace =</span> <span class="ot">TRUE</span>)</code></pre>
<p>Observe how we explicitly set the <code>replace</code> argument to <code>TRUE</code> in order to tell <code>rep_sample_n()</code> that we would like to sample pennies  <em>with</em> replacement. Had we not set <code>replace = TRUE</code>, the function would’ve assumed the default value of <code>FALSE</code>. Additionally, since we didn’t specify the number of replicates via the <code>reps</code> argument, the function assumes the default of one replicate <code>reps = 1</code>. Note also that the <code>size</code> argument is set to match the original sample size of 50 pennies. So what does <code>virtual_resample</code> look like?</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">View</span>(virtual_resample)</code></pre>
<p>We’ll display only the first 10 out of 50 rows of <code>virtual_resample</code>’s contents in Table <a href="8-sampling.html#tab:virtual-shovel">8.2</a>.</p>
<table class="table" style="font-size: 16px; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:virtual-resample">TABLE 9.2: </span>First 10 resampled rows of 50 in virtual sample
</caption>
<thead>
<tr>
<th style="text-align:right;">
replicate
</th>
<th style="text-align:right;">
ID
</th>
<th style="text-align:right;">
year
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
37
</td>
<td style="text-align:right;">
1962
</td>
</tr>
<tr>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
2002
</td>
</tr>
<tr>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
45
</td>
<td style="text-align:right;">
1997
</td>
</tr>
<tr>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
28
</td>
<td style="text-align:right;">
2006
</td>
</tr>
<tr>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
50
</td>
<td style="text-align:right;">
2017
</td>
</tr>
<tr>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
10
</td>
<td style="text-align:right;">
2000
</td>
</tr>
<tr>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
16
</td>
<td style="text-align:right;">
2015
</td>
</tr>
<tr>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
47
</td>
<td style="text-align:right;">
1982
</td>
</tr>
<tr>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
23
</td>
<td style="text-align:right;">
1998
</td>
</tr>
<tr>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
44
</td>
<td style="text-align:right;">
2015
</td>
</tr>
</tbody>
</table>
<p>The <code>replicate</code> variable only takes on the value of 1 corresponding to us only having <code>reps = 1</code>, the <code>ID</code> variable indexes which of the 50 pennies from <code>pennies_sample</code> was resampled, and <code>year</code> denotes the year of minting.</p>
<p>Let’s compute the mean <code>year</code> in our virtual resample of size 50 using data wrangling functions included in the <code>dplyr</code> package:</p>
<pre class="sourceCode r"><code class="sourceCode r">virtual_resample <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">resample_mean =</span> <span class="kw">mean</span>(year))</code></pre>
<pre><code># A tibble: 1 x 2
  replicate resample_mean
      &lt;int&gt;         &lt;dbl&gt;
1         1          1996</code></pre>
<p>As when we did our tactile resampling, the resulting mean year is different than that mean year of our 50 originally sampled pennies of 1995.44.</p>
<!-- 
Chester: Not sure if needed, but those trying to follow along may be mystified if we don't include this. 

Note that tibbles will try to print as pretty as possible which may result in numbers being rounded. In this chapter, we have set the default number of values to be printed to six in tibbles with `options(pillar.sigfig = 6)`.

Albert: I'm not sure if it's worth trouble to explain that command and why tidyverse opts for 3 sigfigs.
-->
</div>
<div id="virtually-resampling-35-times" class="section level3">
<h3><span class="header-section-number">9.2.2</span> Virtually resampling 35 times</h3>
<p>Let’s now have 35 virtual friends perform our virtual resampling exercise. Using these results, we’ll be able to study the variability in the sample means from 35 resamples of size 50. Let’s first add a <code>reps = 35</code> argument to <code>rep_sample_n()</code>  to indicate we would like 35 replicates, or in other words, repeat the resampling with the replacement of 50 pennies 35 times.</p>
<pre class="sourceCode r"><code class="sourceCode r">virtual_resamples &lt;-<span class="st"> </span>pennies_sample <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">rep_sample_n</span>(<span class="dt">size =</span> <span class="dv">50</span>, <span class="dt">replace =</span> <span class="ot">TRUE</span>, <span class="dt">reps =</span> <span class="dv">35</span>)
virtual_resamples</code></pre>
<pre><code># A tibble: 1,750 x 3
# Groups:   replicate [35]
   replicate    ID  year
       &lt;int&gt; &lt;int&gt; &lt;dbl&gt;
 1         1    21  1981
 2         1    34  1985
 3         1     4  1988
 4         1    11  1994
 5         1    26  1979
 6         1     8  1996
 7         1    19  1983
 8         1    21  1981
 9         1    49  2006
10         1     2  1986
# … with 1,740 more rows</code></pre>
<p>The resulting <code>virtual_resamples</code> data frame has 35 <span class="math inline">\(\times\)</span> 50 = 1750 rows corresponding to 35 resamples of 50 pennies. What did each of our 35 virtual friends obtain as the mean year? We’ll use the same <code>dplyr</code> verbs as we did in the previous section, but computing the mean for each of our virtual friends separately by adding a <code>group_by(replicate)</code>:</p>
<pre class="sourceCode r"><code class="sourceCode r">virtual_resampled_means &lt;-<span class="st"> </span>virtual_resamples <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(replicate) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">mean_year =</span> <span class="kw">mean</span>(year))
virtual_resampled_means</code></pre>
<pre><code># A tibble: 35 x 2
   replicate mean_year
       &lt;int&gt;     &lt;dbl&gt;
 1         1   1995.58
 2         2   1999.74
 3         3   1993.7 
 4         4   1997.1 
 5         5   1999.42
 6         6   1995.12
 7         7   1994.94
 8         8   1997.78
 9         9   1991.26
10        10   1996.88
# … with 25 more rows</code></pre>
<p>Observe that <code>virtual_resampled_means</code> has 35 rows corresponding to the 35 resampled means and that the values of <code>mean_year</code> vary. Let’s visualize the distribution of the numerical variable <code>mean_year</code> using a histogram in Figure <a href="9-confidence-intervals.html#fig:tactile-resampling-7">9.13</a>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(virtual_resampled_means, <span class="kw">aes</span>(<span class="dt">x =</span> mean_year)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth =</span> <span class="dv">1</span>, <span class="dt">color =</span> <span class="st">&quot;white&quot;</span>, <span class="dt">boundary =</span> <span class="dv">1990</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Resampled mean year&quot;</span>)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:tactile-resampling-7"></span>
<img src="moderndive_files/figure-html/tactile-resampling-7-1.png" alt="Distribution of 35 sample means from 35 resamples." width="\textwidth" />
<p class="caption">
FIGURE 9.13: Distribution of 35 sample means from 35 resamples.
</p>
</div>
<p>To convince ourselves that our virtual resampling indeed mimics the resampling done by our 35 friends, let’s compare the bootstrap distribution we just virtually constructed with the bootstrap distribution our 35 friends constructed via tactile resampling in the previous section.</p>
<div class="figure" style="text-align: center"><span id="fig:orig-and-resample-means"></span>
<img src="moderndive_files/figure-html/orig-and-resample-means-1.png" alt="Comparing distributions of means from resamples." width="\textwidth" />
<p class="caption">
FIGURE 9.14: Comparing distributions of means from resamples.
</p>
</div>
<p>Recall that in the “resampling with replacement” scenario we are illustrating here both the above histograms have a special name: the <em>bootstrap distribution of the sample mean</em>. Furthermore, they are an approximation to the <em>sampling distribution</em> of the sample mean, a concept you saw in Chapter <a href="8-sampling.html#sampling">8</a> on sampling. These distributions allow us to study the effect of sampling variation on our estimates of the true population mean, in this case the true mean year for <em>all</em> US pennies. However, unlike in Chapter <a href="8-sampling.html#sampling">8</a> where we simulated the act of taking multiple samples, something one would never do in practice, bootstrap distributions are constructed from a <em>single</em> sample, in this case the 50 original pennies from the bank.</p>
<div class="learncheck">
<p>
<strong><em>Learning check</em></strong>
</p>
</div>
<!--
**(LC9.1)** Ask learners to compare the distributions since we did something similar in Chapter 8 and they should be well versed on this by now.
-->
<div class="learncheck">

</div>
</div>
<div id="bootstrap-1000-replicates" class="section level3">
<h3><span class="header-section-number">9.2.3</span> Virtually resampling 1000 times</h3>
<p>Remember that one of the goals of resampling with replacement is to construct the bootstrap distribution, which is an approximation of the sampling distribution of the point estimate of interest, here the sample mean year. However, the bootstrap distribution of in Figure <a href="9-confidence-intervals.html#fig:tactile-resampling-7">9.13</a> is based only on 35 resamples and hence looks a little coarse. Let’s increase the number of resamples to 1000 to better observe the shape and the variability from one resample to the next.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Repeat resampling 1000 times</span>
virtual_resamples &lt;-<span class="st"> </span>pennies_sample <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">rep_sample_n</span>(<span class="dt">size =</span> <span class="dv">50</span>, <span class="dt">replace =</span> <span class="ot">TRUE</span>, <span class="dt">reps =</span> <span class="dv">1000</span>)

<span class="co"># Compute 1000 sample means</span>
virtual_resampled_means &lt;-<span class="st"> </span>virtual_resamples <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(replicate) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">mean_year =</span> <span class="kw">mean</span>(year))</code></pre>
<p>However, in the interest of brevity, going forward let’s combine the above two operations into a single chain of <code>%&gt;%</code> pipe operators:</p>
<pre class="sourceCode r"><code class="sourceCode r">virtual_resampled_means &lt;-<span class="st"> </span>pennies_sample <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">rep_sample_n</span>(<span class="dt">size =</span> <span class="dv">50</span>, <span class="dt">replace =</span> <span class="ot">TRUE</span>, <span class="dt">reps =</span> <span class="dv">1000</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(replicate) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">mean_year =</span> <span class="kw">mean</span>(year))
virtual_resampled_means</code></pre>
<pre><code># A tibble: 1,000 x 2
   replicate mean_year
       &lt;int&gt;     &lt;dbl&gt;
 1         1   1992.6 
 2         2   1994.78
 3         3   1994.74
 4         4   1997.88
 5         5   1990   
 6         6   1999.48
 7         7   1990.26
 8         8   1993.2 
 9         9   1994.88
10        10   1996.3 
# … with 990 more rows</code></pre>
<p>Let’s visualize the bootstrap distribution of these 1000 sample means from 1000 virtual resamples looks like in Figure <a href="9-confidence-intervals.html#fig:one-thousand-sample-means">9.15</a>:</p>
<div class="figure" style="text-align: center"><span id="fig:one-thousand-sample-means"></span>
<img src="moderndive_files/figure-html/one-thousand-sample-means-1.png" alt="Bootstrap resampling distribution based on 1000 resamples." width="\textwidth" />
<p class="caption">
FIGURE 9.15: Bootstrap resampling distribution based on 1000 resamples.
</p>
</div>
<p>Note here the bell shape starting to become more apparent. We now have a general sense for the range of values that the sample mean may take on in these resamples from this histogram of the bootstrap distribution. Do you have a guess as to where this histogram is centered? With it being close to symmetric, either the mean or the median would serve as a good estimate for the center here. Let’s compute the mean:</p>
<pre class="sourceCode r"><code class="sourceCode r">virtual_resampled_means <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">mean_of_means =</span> <span class="kw">mean</span>(mean_year))</code></pre>
<pre><code># A tibble: 1 x 1
  mean_of_means
          &lt;dbl&gt;
1       1995.36</code></pre>
<p>The mean of the 1000 means from 1000 resamples is 1995.365. Note that this is quite close to the mean of our original sample of 50 pennies from the bank: 1995.44. This is the case since each of the 1000 resamples are based on the original sample of 50 pennies.</p>
<div class="learncheck">
<p>
<strong><em>Learning check</em></strong>
</p>
</div>
<p><strong>(LC9.2)</strong> What is the difference between a bootstrap distribution and a sampling distribution?</p>
<!--
**(LC9.3)** Ask learners to summarize important features of the plot as was done in Chapter 8.
-->
<div class="learncheck">

</div>
</div>
</div>
<div id="ci-build-up" class="section level2">
<h2><span class="header-section-number">9.3</span> Understanding confidence intervals</h2>
<p>Let’s start this section with an analogy involving fishing. Say you are trying to catch a fish. On the one hand, you could use a spear, while on the other you could use a net. Using the net will probably yield better results! Bringing things back to the pennies: you are trying to estimate the true population mean year <span class="math inline">\(\mu\)</span> of all US pennies.  Think of the value of <span class="math inline">\(\mu\)</span> as the fish.</p>
<p>On the one hand, we could use the appropriate point estimate/sample statistic to estimate <span class="math inline">\(\mu\)</span>, which we saw in Table <a href="9-confidence-intervals.html#tab:table-ch8-b">9.1</a> is the sample mean <span class="math inline">\(\overline{x}\)</span>. Based on our sample of 50 pennies from the bank, the sample mean was 1995.44. Think of this value as fishing with a spear.</p>
<p>On the other hand, let’s use our results from the previous section to construct a range of highly probable values for <span class="math inline">\(\mu\)</span>. Looking at the bootstrap distribution in Figure <a href="9-confidence-intervals.html#fig:one-thousand-sample-means">9.15</a>, between which two years would you say that “most” sample means lie? While this question is somewhat subjective, saying that most sample means lie in the interval 1992 to 2000 would not be unreasonable. Think of this interval as fishing with a net.</p>
<p>What we’ve just illustrated is the concept of a <em>confidence interval</em>, which we’ll abbreviate with “CI” throughout this book. So as opposed to a point estimate/sample statistic that estimates the value of an unknown population parameter with a single value, a <em>confidence interval</em>  gives a range of plausible values. Going back to our analogy, point estimates/sample statistics can be thought of as spears, whereas confidence intervals can be thought of as nets.</p>
<!--
Point estimate           |  Confidence interval
:-------------------------:|:-------------------------:
![](images/ss/149730074.png){ height=1.7in }  |  ![](images/ss/176684936.png){ height=1.7in }
-->
<div class="figure" style="text-align: center"><span id="fig:point-estimate-vs-conf-int"></span>
<img src="images/point_estimate_vs_conf_int.png" alt="Analogy of difference between point estimates and confidence intervals." width="100%" />
<p class="caption">
FIGURE 9.16: Analogy of difference between point estimates and confidence intervals.
</p>
</div>
<p>Our proposed interval of highly probably values for <span class="math inline">\(\mu\)</span> of 1992 to 2000 was constructed by eye and is thus somewhat subjective. We now introduce two methods for constructing such intervals in a more principled fashion: the percentile method and the standard error method.</p>
<p>Both methods for confidence interval construction share some commonalities. First, they are both constructed from the bootstrap distribution, an example of which you created using 1000 bootstrap resamples  with replacement in Subsection <a href="9-confidence-intervals.html#bootstrap-1000-replicates">9.2.3</a> and saved in the <code>virtual_resampled_means</code> data frame.</p>
<p>Second, they both require you to specify the  <em>confidence level</em>. All other things being equal, higher confidence levels correspond to wider confidence intervals and lower confidence levels corresponding to narrower confidence intervals. Commonly used confidence levels include 90%, 95%, and 99%; we’ll be mostly using 95% and hence constructing “95% confidence intervals for <span class="math inline">\(\mu\)</span>”.</p>
<div id="percentile-method" class="section level3">
<h3><span class="header-section-number">9.3.1</span> Percentile method</h3>
<p>Recall that the actual population mean year <span class="math inline">\(\mu\)</span> for all pennies in circulation in the US is unknown to us. The only way to know this value exactly would be to conduct a census of all pennies, a near impossible task. Instead, by constructing a confidence interval we’ll obtain a range of plausible values for this unknown <span class="math inline">\(\mu\)</span>.</p>
<p>One method to construct this range is to use the middle 95% of the 1000 sample means we computed using bootstrap resampling with replacement. We can do this by computing the 2.5<sup>th</sup> and 97.5<sup>th</sup> percentiles, which are 1991.059 and 1999.283 respectively. For now, let’s focus on the concepts behind a percentile method constructed confidence interval; we’ll show you the code to compute these values in the next section.</p>
<p>We can mark these percentiles on the bootstrap distribution with red vertical lines in Figure <a href="9-confidence-intervals.html#fig:percentile-method">9.17</a>. You can see that 95% of the values in the <code>mean_year</code> variable in <code>virtual_resampled_means</code> fall between the two endpoints, with 2.5% to the left of the left-most red line and 2.5% to the right of the right-most red line.</p>
<div class="figure" style="text-align: center"><span id="fig:percentile-method"></span>
<img src="moderndive_files/figure-html/percentile-method-1.png" alt="Percentile method 95 percent confidence interval." width="\textwidth" />
<p class="caption">
FIGURE 9.17: Percentile method 95 percent confidence interval.
</p>
</div>
</div>
<div id="se-method" class="section level3">
<h3><span class="header-section-number">9.3.2</span> Standard error method</h3>
<p>Recall in Subsection <a href="8-sampling.html#normal-distribution">8.5.3</a>, we saw that if a numerical variable follows a normal distribution, or in other words, the histogram of this variable is bell-shaped, then roughly 95% of values fall between <span class="math inline">\(\pm\)</span> 1.96 standard deviations of the mean. Given that our bootstrap distribution based on 1000 resamples with replacement in Figure <a href="9-confidence-intervals.html#fig:one-thousand-sample-means">9.15</a> is normally shaped, let’s use the above fact about normal distributions to construct a confidence interval in a different way.</p>
<p>First, the bootstrap distribution has a mean equal to <span class="math inline">\(\overline{x}\)</span>: the sample mean of our original 50 pennies of 1995.44. In other words, the bootstrap distribution is centered at 1995.44. Second, let’s compute the standard deviation of the bootstrap distribution</p>
<pre class="sourceCode r"><code class="sourceCode r">virtual_resampled_means <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">SE =</span> <span class="kw">sd</span>(mean_year))</code></pre>
<pre><code># A tibble: 1 x 1
       SE
    &lt;dbl&gt;
1 2.15466</code></pre>
<p>What is this value? Recall that the bootstrap distribution is an approximation to the sampling distribution and that the standard deviation of the sampling distribution has a special name: the <em>standard error</em>. So in other words, 2.15 is an approximation of the standard error of <span class="math inline">\(\overline{x}\)</span>.</p>
<p>Thus using our 95% rule of thumb about normal distributions from Subsection <a href="8-sampling.html#normal-distribution">8.5.3</a>, we can use the following formula to determine the lower and upper endpoints of the 95% confidence interval for <span class="math inline">\(\mu\)</span>:</p>
<p><span class="math display">\[
\begin{aligned}
\overline{x} \pm 1.96 \cdot SE &amp;= (\overline{x} - 1.96 \cdot SE, \overline{x} + 1.96 \cdot SE)\\
&amp;= (1995.44 - 1.96 \cdot 2.15, 1995.44 + 1.96 \cdot 2.15)\\
&amp;= (1991.15, 1999.73)
\end{aligned}
\]</span></p>
<p>Let’s add the SE method confidence interval (in blue) to our previously constructed percentile method confidence (in red) in Figure <a href="9-confidence-intervals.html#fig:percentile-and-se-method">9.18</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:percentile-and-se-method"></span>
<img src="moderndive_files/figure-html/percentile-and-se-method-1.png" alt="Comparing 95 percent confidence interval methods." width="\textwidth" />
<p class="caption">
FIGURE 9.18: Comparing 95 percent confidence interval methods.
</p>
</div>
<p>We see that both methods produce nearly identical confidence intervals with the percentile method yielding <span class="math inline">\((1991.06, 1999.28)\)</span> while the standard error method being <span class="math inline">\((1991.22, 1999.66)\)</span>. However, recall that we can only use the standard error rule when the bootstrap distribution is roughly normally-shaped.</p>
<p>Now that we’ve introduced the concept of confidence intervals and laid out the intuition behind two methods for constructing them, let’s explore the code that allows us to construct them.</p>
<!--
The variability of the sampling distribution may be approximated by the variability of the resampling distribution. Traditional theory-based methodologies for inference also have formulas for standard errors, assuming some conditions are met.

This is done by using the formula where $\bar{x}$ is our original sample mean and $SE$ stands for **standard error** and corresponds to the standard deviation of the resampling distribution.  The value of $multiplier$ here is the appropriate percentile of the standard normal distribution. We'll go into this further in Section \@ref(ci-conclusion).

These are automatically calculated when `level` is provided with `level = 0.95` being the default. (95% of the values in a standard normal distribution fall within 1.96 standard deviations of the mean, so $multiplier = 1.96$ for `level = 0.95`, for example.)  As mentioned, this formula assumes that the bootstrap distribution is symmetric and bell-shaped. This is often the case with bootstrap distributions, especially those in which the original distribution of the sample is not highly skewed.

This $\bar{x} \pm (multiplier * SE)$ formula is implemented in the `get_ci()` function as shown with our pennies problem using the bootstrap distribution's variability as an approximation for the sampling distribution's variability. We'll see more on this approximation shortly.

Note that the center of the confidence interval (the `point_estimate`) must be provided for the standard error confidence interval.


```r
standard_error_ci <- bootstrap_distribution %>% 
  get_ci(type = "se", point_estimate = x_bar)
standard_error_ci
```
-->
<div class="learncheck">
<p>
<strong><em>Learning check</em></strong>
</p>
</div>
<p><strong>(LC9.4)</strong> What condition about the bootstrap distribution must be met for us to be able to construct confidence intervals using the standard error method?</p>
<p><strong>(LC9.5)</strong> Say we wanted to construct a 68% confidence interval instead of a 95% confidence interval for <span class="math inline">\(\mu\)</span>?</p>
<div class="learncheck">

</div>
</div>
</div>
<div id="bootstrap-process" class="section level2">
<h2><span class="header-section-number">9.4</span> Constructing confidence intervals</h2>
<p>Recall that the process of resampling with a replacement we performed by hand in Section <a href="9-confidence-intervals.html#resampling-tactile">9.1</a> and virtually in Section <a href="9-confidence-intervals.html#resampling-simulation">9.2</a> is known as  <em>bootstrapping</em>. The term bootstrapping originates in the expression of “pulling oneself up by their bootstraps”: to <a href="https://en.wiktionary.org/wiki/pull_oneself_up_by_one%27s_bootstraps">“succeed only by one’s own efforts or abilities.”</a> From a statistical perspective, it alludes to succeeding in being able to study the effects of sampling variation on estimates from the “effort” of a single sample. Or more precisely,  constructing an approximation to the sampling distribution using only one sample.</p>
<p>To perform this resampling with replacement virtually in Section <a href="9-confidence-intervals.html#resampling-simulation">9.2</a>, we used the <code>rep_sample_n()</code> function, making sure that the size of the resamples matched the original sample size. In this section, we’ll build off these ideas to construct confidence intervals using a new package: the <code>infer</code> package for “tidy” and transparent statistical inference.</p>
<div id="original-workflow" class="section level3">
<h3><span class="header-section-number">9.4.1</span> Original workflow</h3>
<p>Recall that in Section <a href="9-confidence-intervals.html#resampling-simulation">9.2</a>, we virtually performed bootstrap resampling with replacement to build the bootstrap distribution, which in turn is an approximation to the sampling distribution we saw in Chapter <a href="8-sampling.html#sampling">8</a> but using only a single sample. Let’s revisit the flow using the <code>%&gt;%</code> pipe operator:</p>
<p>First, we used the <code>rep_sample_n()</code> function to sample <code>size = 50</code> pennies with replacement from the original sample of 50 pennies in <code>pennies_sample</code> by setting <code>replace = TRUE</code>. Furthermore, we repeated this resampling 1000 times by setting <code>reps = 1000</code>:</p>
<pre class="sourceCode r"><code class="sourceCode r">pennies_sample <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">rep_sample_n</span>(<span class="dt">size =</span> <span class="dv">50</span>, <span class="dt">replace =</span> <span class="ot">TRUE</span>, <span class="dt">reps =</span> <span class="dv">1000</span>)</code></pre>
<p>Second, since for each of our 1000 resamples of size 50, we want to compute a separate sample mean, we used the <code>dplyr</code> verb <code>group_by()</code> to group observations/rows together by the <code>replicate</code> variable…</p>
<pre class="sourceCode r"><code class="sourceCode r">pennies_sample <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">rep_sample_n</span>(<span class="dt">size =</span> <span class="dv">50</span>, <span class="dt">replace =</span> <span class="ot">TRUE</span>, <span class="dt">reps =</span> <span class="dv">1000</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(replicate) </code></pre>
<p>… followed by using <code>summarize()</code> to compute the sample <code>mean()</code> year from each <code>replicate</code> group:</p>
<pre class="sourceCode r"><code class="sourceCode r">pennies_sample <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">rep_sample_n</span>(<span class="dt">size =</span> <span class="dv">50</span>, <span class="dt">replace =</span> <span class="ot">TRUE</span>, <span class="dt">reps =</span> <span class="dv">1000</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(replicate) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">mean_year =</span> <span class="kw">mean</span>(year))</code></pre>
<p>For this simple case, we can get by with using the <code>rep_sample_n()</code> function and a couple of <code>dplyr</code> verbs to construct the bootstrap distribution. However, using only <code>dplyr</code> verbs only provides us with a limited set of tools. For more complicated situations, we need a little more firepower. Let’s repeat the above using the <code>infer</code> package.</p>
</div>
<div id="infer-workflow" class="section level3">
<h3><span class="header-section-number">9.4.2</span> infer package workflow</h3>
<!--
In future, consider:

1. Showing `dplyr` code to compute observed point estimate
1. Showing `infer` verbs to compute observed point estimate. i.e. no generate()
step.
1. Only after these two steps, showing `infer` verb pipeline to construct
bootstrap distribution of point estimate. i.e. with generate() and showing
diagram.
-->
<p>Just as <code>group_by() %&gt;% summarize()</code> produces a useful workflow in <code>dplyr</code>, we can also use <code>specify() %&gt;% calculate()</code> to compute summary measures on our original sample data. It’s often helpful both in confidence interval calculations, but also in hypothesis testing to identify what the corresponding statistic is in the original data. For our example on penny age, we computed above a value of <code>x_bar</code> using the <code>summarize()</code> verb in <code>dplyr</code>:</p>
<pre class="sourceCode r"><code class="sourceCode r">pennies_sample <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">stat =</span> <span class="kw">mean</span>(year))</code></pre>
<p>This can also be done by skipping the <code>generate()</code> step in the pipeline feeding <code>specify()</code> directly into <code>calculate()</code>: </p>
<pre class="sourceCode r"><code class="sourceCode r">pennies_sample <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">specify</span>(<span class="dt">response =</span> year) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">calculate</span>(<span class="dt">stat =</span> <span class="st">&quot;mean&quot;</span>)</code></pre>
<p>This shortcut will be particularly useful when the calculation of the observed statistic is tricky to do using <code>dplyr</code> alone. This is particularly the case when working with more than one explanatory variable as will be seen in Chapter <a href="10-hypothesis-testing.html#hypothesis-testing">10</a>.</p>
<p>The <code>infer</code> package makes efficient use of the <code>%&gt;%</code> pipe operator we saw in Chapter <a href="4-wrangling.html#wrangling">4</a> to spell out the sequence of steps necessary to perform statistical inference in a “tidy” and transparent fashion. Much in the same way that the functions in the <code>dplyr</code> have intuitive verb-based names, the <code>infer</code> package’s functions are also verbs that spell out the computational process of constructing confidence intervals, as well as hypothesis tests as we’ll see in Chapter <a href="10-hypothesis-testing.html#hypothesis-testing">10</a>.</p>
<p>Let’s illustrate the sequence of verbs to construct a confidence interval for <span class="math inline">\(\mu\)</span>, the population mean year of minting of all pennies in the US.</p>
<div id="specify-variables" class="section level4 unnumbered">
<h4>1. <code>specify</code> variables</h4>
<div class="figure" style="text-align: center"><span id="fig:infer-specify"></span>
<img src="images/flowcharts/infer/specify.png" alt="Diagram of specify() variables." width="20%" />
<p class="caption">
FIGURE 9.19: Diagram of specify() variables.
</p>
</div>
<p>The <code>specify()</code>  function is used to choose which variables in a data frame will be the focus of the statistical inference. We do this by specifying the <code>response</code> argument. For example, in our <code>pennies_sample</code> data frame of the 50 pennies sampled from the bank, the variable of interest is <code>year</code>:</p>
<pre class="sourceCode r"><code class="sourceCode r">pennies_sample <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">specify</span>(<span class="dt">response =</span> year)</code></pre>
<pre><code>Response: year (numeric)
# A tibble: 50 x 1
    year
   &lt;dbl&gt;
 1  2002
 2  1986
 3  2017
 4  1988
 5  2008
 6  1983
 7  2008
 8  1996
 9  2004
10  2000
# … with 40 more rows</code></pre>
<p>Notice how the data itself doesn’t change, but the <code>Response: year (numeric)</code> <em>meta-data</em> does. This is similar to how the <code>group_by()</code> verb from <code>dplyr</code> doesn’t change the data, but only adds “grouping” meta-data as we saw in Section <a href="4-wrangling.html#groupby">4.4</a>.</p>
<p>We can also specify which variables will be the focus of the statistical inference using a <code>formula = y ~ x</code> argument, where <code>y</code> is the response variable, <code>x</code> is the explanatory variable, with both separated by a “tilde” <code>~</code>. Recall that you used this same formula notation within the <code>lm()</code> function in Chapters <a href="6-regression.html#regression">6</a> and <a href="7-multiple-regression.html#multiple-regression">7</a> when fitting regression models. The following use of <code>specify()</code> with the <code>formula</code> argument yields the same result as above:</p>
<pre class="sourceCode r"><code class="sourceCode r">pennies_sample <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">specify</span>(<span class="dt">formula =</span> year <span class="op">~</span><span class="st"> </span><span class="ot">NULL</span>)</code></pre>
<p>Since in the case of pennies we only have a response variable and no explanatory variable of interest, we set the <code>x</code> on the right-hand side of the <code>~</code> to <code>NULL</code>.</p>
<p>While in the case of the pennies either specification works just fine, we’ll see examples later on where we have no choice but to use the <code>formula</code> specification, in particular in the upcoming Section <a href="9-confidence-intervals.html#case-study-two-prop-ci">9.6</a> on comparing two proportions and Chapter <a href="10-hypothesis-testing.html#hypothesis-testing">10</a> on hypothesis testing.</p>
</div>
<div id="generate-replicates" class="section level4 unnumbered">
<h4>2. <code>generate</code> replicates</h4>
<div class="figure" style="text-align: center"><span id="fig:infer-generate"></span>
<img src="images/flowcharts/infer/generate.png" alt="Diagram of generate() replicates." width="50%" />
<p class="caption">
FIGURE 9.20: Diagram of generate() replicates.
</p>
</div>
<p>After we <code>specify()</code> the variables of interest, we pipe the results into the <code>generate()</code> function to generate resampling replicates, or in other words, repeat the resampling process a large number of times. The <code>generate()</code>  function’s first argument is <code>reps</code>, which is used to give how many different repetitions one would like to perform. The second argument <code>type</code> determines the type of resampling we’d like to perform.</p>
<p>In our case, since we want to resample the 50 pennies in <code>pennies_sample</code> with replacement 1000 times, we set <code>reps = 1000</code> and <code>type = &quot;bootstrap&quot;</code> indicating that we want to perform bootstrap resampling.</p>
<pre class="sourceCode r"><code class="sourceCode r">pennies_sample <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">specify</span>(<span class="dt">response =</span> year) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">generate</span>(<span class="dt">reps =</span> <span class="dv">1000</span>, <span class="dt">type =</span> <span class="st">&quot;bootstrap&quot;</span>)</code></pre>
<pre><code>Response: year (numeric)
# A tibble: 50,000 x 2
# Groups:   replicate [1,000]
   replicate  year
       &lt;int&gt; &lt;dbl&gt;
 1         1  1996
 2         1  1988
 3         1  1979
 4         1  1978
 5         1  1983
 6         1  1981
 7         1  1993
 8         1  1996
 9         1  1992
10         1  1978
# … with 49,990 more rows</code></pre>
<p>Note the the resulting data frame has 50,000 rows. This is because we performed resampling of 50 pennies with replacement 1000 times and thus 50,000 = 1000 <span class="math inline">\(\times\)</span> 50. Accordingly, the variable <code>replicate</code>, indicating which resample each row belongs to, has the value <code>1</code> 50 times, the value <code>2</code> 50 times, all the way through to the value <code>1000</code> 50 times.</p>
<p>The default value of the <code>type</code> argument is <code>&quot;bootstrap&quot;</code>, so if the last line above were written as <code>generate(reps = 1000)</code>, we’d obtain the same results.</p>
<p><strong>Comparing with original workflow</strong>: Note that the steps up of the infer workflow so far produce the same results as the original workflow using the <code>rep_sample_n()</code> function we saw earlier. In other words, the following two code chunks produce similar results:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># infer workflow:               # Original workflow:</span>
pennies_sample <span class="op">%&gt;%</span><span class="st">              </span>pennies_sample <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">specify</span>(<span class="dt">response =</span> year) <span class="op">%&gt;%</span><span class="st">    </span><span class="kw">rep_sample_n</span>(<span class="dt">size =</span> <span class="dv">50</span>, <span class="dt">replace =</span> <span class="ot">TRUE</span>, 
  <span class="kw">generate</span>(<span class="dt">reps =</span> <span class="dv">1000</span>)                        <span class="dt">reps =</span> <span class="dv">1000</span>)              </code></pre>
</div>
<div id="calculate-summary-statistics" class="section level4 unnumbered">
<h4>3. <code>calculate</code> summary statistics</h4>
<div class="figure" style="text-align: center"><span id="fig:infer-calculate"></span>
<img src="images/flowcharts/infer/calculate.png" alt="Diagram of calculate() summary statistics." width="70%" />
<p class="caption">
FIGURE 9.21: Diagram of calculate() summary statistics.
</p>
</div>
<p>After we <code>generate()</code> many replicates of bootstrap resampling with replacement, we next want to condense each of 1000 resamples of size 50 to a single statistic value. As seen in the diagram, the <code>calculate()</code>  function does this.</p>
<p>In our case as we did earlier, we want to calculate the mean <code>year</code> for each bootstrap resample of size 50. To do so, we set the <code>stat</code> argument to <code>&quot;mean&quot;</code>. You can also set the <code>stat</code> argument to a variety of other common summary statistics, like <code>&quot;median&quot;</code>, <code>&quot;sum&quot;</code>, <code>&quot;sd&quot;</code> (standard deviation), and <code>&quot;prop&quot;</code> (proportion); we’ll see examples of their use throughout the remaining chapters. Let’s save the result in a data frame called <code>bootstrap_distribution</code>:</p>
<pre class="sourceCode r"><code class="sourceCode r">bootstrap_distribution &lt;-<span class="st"> </span>pennies_sample <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">specify</span>(<span class="dt">response =</span> year) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">generate</span>(<span class="dt">reps =</span> <span class="dv">1000</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">calculate</span>(<span class="dt">stat =</span> <span class="st">&quot;mean&quot;</span>)
bootstrap_distribution</code></pre>
<pre><code># A tibble: 1,000 x 2
   replicate    stat
       &lt;int&gt;   &lt;dbl&gt;
 1         1 1993.48
 2         2 1993.8 
 3         3 1996.88
 4         4 1995.34
 5         5 1996.98
 6         6 1995.72
 7         7 1995.36
 8         8 1992.6 
 9         9 1994.24
10        10 1993.16
# … with 990 more rows</code></pre>
<p>We see that the resulting data frame has 1000 rows and 2 columns corresponding to the 1000 replicates and the mean <code>year</code> for each bootstrap resample saved in the variable <code>stat</code>.</p>
<p><strong>Comparing with original workflow</strong>: You may have recognized at this point that the <code>calculate()</code> step in the <code>infer</code> workflow produces the same output as the <code>group_by() %&gt;% summarize()</code> steps in the original workflow:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># infer workflow:                 # Original workflow:</span>
pennies_sample <span class="op">%&gt;%</span><span class="st">                </span>pennies_sample <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">specify</span>(<span class="dt">response =</span> year) <span class="op">%&gt;%</span><span class="st">      </span><span class="kw">rep_sample_n</span>(<span class="dt">size =</span> <span class="dv">50</span>, <span class="dt">replace =</span> <span class="ot">TRUE</span>, 
  <span class="kw">generate</span>(<span class="dt">reps =</span> <span class="dv">1000</span>) <span class="op">%&gt;%</span><span class="st">                      </span><span class="dt">reps =</span> <span class="dv">1000</span>) <span class="op">%&gt;%</span><span class="st">              </span>
<span class="st">  </span><span class="kw">calculate</span>(<span class="dt">stat =</span> <span class="st">&quot;mean&quot;</span>)          <span class="kw">group_by</span>(replicate) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">                                    </span><span class="kw">summarize</span>(<span class="dt">mean_year =</span> <span class="kw">mean</span>(year))</code></pre>
</div>
<div id="visualize-the-results" class="section level4 unnumbered">
<h4>4. <code>visualize</code> the results</h4>
<div class="figure" style="text-align: center"><span id="fig:infer-visualize"></span>
<img src="images/flowcharts/infer/visualize.png" alt="Diagram of visualize() results." width="100%" />
<p class="caption">
FIGURE 9.22: Diagram of visualize() results.
</p>
</div>
<p>The <code>visualize()</code>  verb provides a quick way to visualize the bootstrap distribution as a histogram of the numerical <code>stat</code> variable’s values.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">visualize</span>(bootstrap_distribution)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:boostrap-distribution-infer"></span>
<img src="moderndive_files/figure-html/boostrap-distribution-infer-1.png" alt="Bootstrap distribution." width="\textwidth" />
<p class="caption">
FIGURE 9.23: Bootstrap distribution.
</p>
</div>
<p><strong>Comparing with original workflow</strong>: In fact, <code>visualize()</code> is a <em>wrapper function</em> for the <code>ggplot()</code> function that uses a <code>geom_histogram()</code> layer. Recall that we illustrated the concept of a wrapper function in Figure <a href="6-regression.html#fig:moderndive-figure-wrapper">6.5</a> in Section <a href="6-regression.html#model1table">6.1.2</a>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># infer workflow:                    # Original workflow:</span>
<span class="kw">visualize</span>(bootstrap_distribution)    <span class="kw">ggplot</span>(bootstrap_distribution, 
                                            <span class="kw">aes</span>(<span class="dt">x =</span> stat)) <span class="op">+</span>
<span class="st">                                       </span><span class="kw">geom_histogram</span>()</code></pre>
<p>The <code>visualize()</code> function can take many other arguments which we’ll see momentarily to customize the plot further. It also works with helper functions to do the shading of the histogram values corresponding to the confidence interval values.</p>
<p>Let’s recap the steps of the <code>infer</code> workflow for creating a visualization of the bootstrap distribution.</p>
<div class="figure" style="text-align: center"><span id="fig:infer-workflow-ci"></span>
<img src="images/flowcharts/infer/ci_diagram.png" alt="infer package workflow for confidence intervals." width="100%" />
<p class="caption">
FIGURE 9.24: infer package workflow for confidence intervals.
</p>
</div>
<p>Recall how we introduced two different methods for constructing 95% confidence intervals for an unknown population parameter in Section <a href="9-confidence-intervals.html#confidence-intervals">9</a>. Let’s now check out the <code>infer</code> package code to explicitly construct these. There are also some additional neat functions to visualize the resulting confidence intervals built-in!</p>
</div>
</div>
<div id="percentile-method-infer" class="section level3">
<h3><span class="header-section-number">9.4.3</span> Percentile method with infer</h3>
<p>Recall the percentile method for constructing 95% confidence intervals we introduced in Section <a href="9-confidence-intervals.html#percentile-method">9.3.1</a>. This method sets the lower endpoint at the 2.5<sup>th</sup> percentile of the bootstrap distribution and similarly sets the upper-endpoint at the 97.5<sup>th</sup> percentile. The resulting interval captures the middle 95% of the values of the sample mean in the bootstrap distribution.</p>
<p>We can compute the 95% confidence interval by piping the <code>bootstrap_distribution</code> data frame we created above into the <code>get_confidence_interval()</code>  function from the <code>infer</code> package, with the confidence <code>level</code> set to 0.95 and the confidence interval <code>type</code> to be percentile. Let’s save the results in <code>percentile_ci</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r">percentile_ci &lt;-<span class="st"> </span>bootstrap_distribution <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">get_confidence_interval</span>(<span class="dt">level =</span> <span class="fl">0.95</span>, <span class="dt">type =</span> <span class="st">&quot;percentile&quot;</span>)
percentile_ci</code></pre>
<pre><code># A tibble: 1 x 2
   `2.5%` `97.5%`
    &lt;dbl&gt;   &lt;dbl&gt;
1 1991.16 1999.58</code></pre>
<p>If we would like to visualize the interval (1991.16, 1999.58), we can pipe the <code>bootstrap_distribution</code> data frame into the <code>visualize()</code> function and add a <code>shade_confidence_interval()</code>  layer to our plot with the <code>endpoints</code> argument to be <code>percentile_ci</code>:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">visualize</span>(bootstrap_distribution) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">shade_confidence_interval</span>(<span class="dt">endpoints =</span> <span class="kw">c</span>(<span class="fl">1991.28</span>, <span class="fl">1999.76</span>))</code></pre>
<div class="figure" style="text-align: center"><span id="fig:percentile-ci-viz"></span>
<img src="moderndive_files/figure-html/percentile-ci-viz-1.png" alt="Percentile method 95 percent confidence interval." width="\textwidth" />
<p class="caption">
FIGURE 9.25: Percentile method 95 percent confidence interval.
</p>
</div>
<p>Observe that 95% of the sample means stored in the <code>stat</code> variable in <code>bootstrap_distribution</code> falls between the two endpoints marked with the darker lines, with 2.5% of the sample means to the left of the shaded area and 2.5% of the sample means to the right. You also have the option to change the colors of the shading using the <code>color</code> and <code>fill</code> arguments. There’s also the alias <code>shade_ci()</code> for folks that don’t want to type out all of <code>confidence_interval</code> and prefer <code>ci</code> instead.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">visualize</span>(bootstrap_distribution) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">shade_ci</span>(<span class="dt">endpoints =</span> percentile_ci, <span class="dt">color =</span> <span class="st">&quot;hotpink&quot;</span>, <span class="dt">fill =</span> <span class="st">&quot;khaki&quot;</span>)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:percentile-ci-viz-2"></span>
<img src="moderndive_files/figure-html/percentile-ci-viz-2-1.png" alt="Alternate display of percentile method 95 percent confidence interval." width="\textwidth" />
<p class="caption">
FIGURE 9.26: Alternate display of percentile method 95 percent confidence interval.
</p>
</div>
</div>
<div id="infer-se" class="section level3">
<h3><span class="header-section-number">9.4.4</span> Standard error method with infer</h3>
<p>Recall the standard error method for constructing 95% confidence intervals we introduced in Section <a href="9-confidence-intervals.html#se-method">9.3.2</a>. For any distribution that is normally shaped, roughly 95% of values lie within two standard deviations of the mean. In the case of the bootstrap distribution, the standard deviation has a special name: the standard error. So using our rule of thumb about normally shaped distributions, a 95% confidence interval is <span class="math inline">\(\overline{x} \pm 1.96 \cdot SE\)</span> = <span class="math inline">\((\overline{x} - 1.96 \cdot SE, \overline{x} + 1.96 \cdot SE)\)</span>.</p>
<p>We can compute the 95% confidence interval by piping the <code>bootstrap_distribution</code> data frame we created above into the <code>get_confidence_interval()</code> function. First, we set the <code>type</code> argument set to be <code>&quot;se&quot;</code>. Second, we must specify the <code>point_estimate</code> argument in order to set the center of the confidence interval: we set this to be sample mean of the original sample of 50 pennies of 1995.44.</p>
<pre class="sourceCode r"><code class="sourceCode r">standard_error_ci &lt;-<span class="st"> </span>bootstrap_distribution <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">get_confidence_interval</span>(<span class="dt">type =</span> <span class="st">&quot;se&quot;</span>, <span class="dt">point_estimate =</span> <span class="fl">1995.44</span>)
standard_error_ci</code></pre>
<pre><code># A tibble: 1 x 2
    lower   upper
    &lt;dbl&gt;   &lt;dbl&gt;
1 1991.16 1999.72</code></pre>
<p>If we would like to visualize the interval (1991.16, 1999.72), we can pipe the <code>bootstrap_distribution</code> data frame into the <code>visualize()</code> function and add a <code>shade_confidence_interval()</code> layer to our plot with the <code>endpoints</code> argument to be <code>standard_error_ci</code>:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">visualize</span>(bootstrap_distribution) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">shade_confidence_interval</span>(<span class="dt">endpoints =</span> standard_error_ci)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:se-ci-viz"></span>
<img src="moderndive_files/figure-html/se-ci-viz-1.png" alt="Standard error method 95 percent confidence interval." width="\textwidth" />
<p class="caption">
FIGURE 9.27: Standard error method 95 percent confidence interval.
</p>
</div>
<p>As noted in Section <a href="9-confidence-intervals.html#ci-build-up">9.3</a>, both methods produce similar confidence intervals:</p>
<ul>
<li>Percentile method: (1991.16, 1999.58)</li>
<li>Standard error method: (1991.16, 1999.72)</li>
</ul>
</div>
</div>
<div id="one-prop-ci" class="section level2">
<h2><span class="header-section-number">9.5</span> Interpreting confidence intervals</h2>
<p>Now that we’ve shown you how to construct confidence intervals using a sample drawn from the population, let’s now focus on how to interpret them. In order to interpret a confidence interval thoroughly however, we need to know the true value of the population parameter in question.</p>
<p>In the case of our pennies example, we don’t know the value of the population parameter of interest: the population mean year of minting <span class="math inline">\(\mu\)</span> of all pennies in the US. Furthermore, we probably never will know this value given the near impossibility of performing a census.</p>
<p>In the case of our sampling bowl from Chapter <a href="8-sampling.html#sampling">8</a> however, we can compute the value of the population parameter of interest: the population proportion <span class="math inline">\(p\)</span> of the <span class="math inline">\(N\)</span> = 2400 balls that are red. Recall the <code>bowl</code> data frame in the <code>moderndive</code> package contains our population of interest. We can calculate the proportion of red balls in this population to get the value of <span class="math inline">\(p\)</span>:</p>
<pre class="sourceCode r"><code class="sourceCode r">bowl <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">p_red =</span> <span class="kw">mean</span>(color <span class="op">==</span><span class="st"> &quot;red&quot;</span>))</code></pre>
<pre><code># A tibble: 1 x 1
  p_red
  &lt;dbl&gt;
1 0.375</code></pre>
<p>At this point you might be asking yourself: If we already know that <span class="math inline">\(p\)</span> = 0.375 = 37.5% of the bowl’s balls are red, then why are we sampling to estimate this value, to begin with? Your skepticism is merited! Recall from Section <a href="8-sampling.html#sampling-simulation">8.2</a>, that this was virtual “simulation” used to study sampling. In any real-world setting, however, we would not know the value of the population proportion <span class="math inline">\(p\)</span> and hence we have no choice but use sampling to estimate it.</p>
<p>Bringing the discussion back to confidence intervals constructed based on samples from the bowl, we have to ask ourselves: Does the interval include <span class="math inline">\(p\)</span> = 0.375 = 37.5% or not? Alternatively, going back to our “fishing with a spear” versus “fishing with a net” analogy from Section <a href="9-confidence-intervals.html#ci-build-up">9.3</a>, we have to ask ourselves: Did our net capture the fish or not?</p>
<div id="ilyas-yohan" class="section level3">
<h3><span class="header-section-number">9.5.1</span> Did the net capture the fish?</h3>
<p>Recall from in Table <a href="8-sampling.html#tab:tactile-red1">8.1</a> that we had 33 groups of friends repeat this sampling simulation, each taking samples of size 50 from the bowl and compute the sample proportion of red <span class="math inline">\(\widehat{p}\)</span>, resulting in 33 such estimates of <span class="math inline">\(p\)</span>. Let’s focus on Ilyas and Yohan’s sample in Table <a href="8-sampling.html#tab:tactile-red1">8.1</a> where they observed 21 red balls out of the 50 in their shovel, in other words, their sample proportion <span class="math inline">\(\widehat{p}\)</span> = 21/50 = 0.42 = 42%. This data is stored in the <code>bowl_sample_1</code> data frame in the <code>moderndive</code> package:</p>
<!--
At this point you might be asking yourself: why did we take 33 samples of size 50 to estimate the population proportion $p$ of the balls that are red? Wouldn't it have made more sense to take a single sample that's as big as possible? Again this was virtual "simulation" used to study sampling variation. In order to study sample-to-sample variation, we need more than one sample! In any real-world setting however, we would not take repeated samples, rather a single sample that's as representative and as large as possible!
-->
<pre class="sourceCode r"><code class="sourceCode r">bowl_sample_<span class="dv">1</span></code></pre>
<pre><code># A tibble: 50 x 1
   color
   &lt;chr&gt;
 1 white
 2 white
 3 red  
 4 red  
 5 white
 6 white
 7 red  
 8 white
 9 white
10 white
# … with 40 more rows</code></pre>
<p>Let’s follow the <code>infer</code> package workflow from Section <a href="9-confidence-intervals.html#infer-workflow">9.4.2</a> to create a percentile method 95% confidence interval for <span class="math inline">\(p\)</span> using sample data in <code>bowl_sample_1</code>.</p>
<div id="specify-variables-1" class="section level4 unnumbered">
<h4>1. <code>specify</code> variables</h4>
<p>First, we <code>specify()</code> the <code>response</code> variable of interest <code>color</code>:</p>
<pre class="sourceCode r"><code class="sourceCode r">bowl_sample_<span class="dv">1</span> <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">specify</span>(<span class="dt">response =</span> color)</code></pre>
<pre><code>Error: A level of the response variable `color` needs to be specified for the `success`
argument in `specify()`.</code></pre>
<p>Whoops! We need to define which event is of interest! <code>red</code> or <code>white</code> balls? Since we are interested in proportions red, let’s set <code>success</code> to be <code>&quot;red&quot;</code>:</p>
<pre class="sourceCode r"><code class="sourceCode r">bowl_sample_<span class="dv">1</span> <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">specify</span>(<span class="dt">response =</span> color, <span class="dt">success =</span> <span class="st">&quot;red&quot;</span>)</code></pre>
<pre><code>Response: color (factor)
# A tibble: 50 x 1
   color
   &lt;fct&gt;
 1 white
 2 white
 3 red  
 4 red  
 5 white
 6 white
 7 red  
 8 white
 9 white
10 white
# … with 40 more rows</code></pre>
</div>
<div id="generate-replicates-1" class="section level4 unnumbered">
<h4>2. <code>generate</code> replicates</h4>
<p>Second, we <code>generate()</code> 1000 replicates via bootstrap with replacement of our original sample of 50 balls in <code>bowl_sample_1</code> by setting <code>reps = 1000</code> and <code>type = &quot;bootstrap&quot;</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r">bowl_sample_<span class="dv">1</span> <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">specify</span>(<span class="dt">response =</span> color, <span class="dt">success =</span> <span class="st">&quot;red&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">generate</span>(<span class="dt">reps =</span> <span class="dv">1000</span>, <span class="dt">type =</span> <span class="st">&quot;bootstrap&quot;</span>)</code></pre>
<p>Note the resulting data frame has 50,000 rows. This is because we performed resampling of 50 balls with replacement 1000 times and thus 50,000 = 1000 <span class="math inline">\(\times\)</span> 50. Accordingly, the variable <code>replicate</code>, indicating which resample each row belongs to, has the value <code>1</code> 50 times, the value <code>2</code> 50 times, all the way through to the value <code>1000</code> 50 times. Recall generating 1000 replicates means we are repeating the resampling 1000 times so that we can study the sampling variation from resampling to resample!</p>
</div>
<div id="calculate-summary-statistics-1" class="section level4 unnumbered">
<h4>3. <code>calculate</code> summary statistics</h4>
<p>Third, we summarize each of 1000 resamples of size 50 with their <code>prop</code>ortion of “successes”, in other words, the proportion of the balls that are <code>&quot;red&quot;</code>. Let’s save the result in a data frame called <code>sample_1_bootstrap</code>:</p>
<pre class="sourceCode r"><code class="sourceCode r">sample_<span class="dv">1</span>_bootstrap &lt;-<span class="st"> </span>bowl_sample_<span class="dv">1</span> <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">specify</span>(<span class="dt">response =</span> color, <span class="dt">success =</span> <span class="st">&quot;red&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">generate</span>(<span class="dt">reps =</span> <span class="dv">1000</span>, <span class="dt">type =</span> <span class="st">&quot;bootstrap&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">calculate</span>(<span class="dt">stat =</span> <span class="st">&quot;prop&quot;</span>)
sample_<span class="dv">1</span>_bootstrap</code></pre>
<pre><code># A tibble: 1,000 x 2
   replicate  stat
       &lt;int&gt; &lt;dbl&gt;
 1         1  0.36
 2         2  0.42
 3         3  0.52
 4         4  0.38
 5         5  0.38
 6         6  0.38
 7         7  0.46
 8         8  0.3 
 9         9  0.5 
10        10  0.46
# … with 990 more rows</code></pre>
</div>
<div id="visualize-the-results-1" class="section level4 unnumbered">
<h4>4. <code>visualize</code> the results</h4>
<p>Fourth and lastly, let’s compute the resulting 95% confidence interval.</p>
<pre class="sourceCode r"><code class="sourceCode r">percentile_ci_<span class="dv">1</span> &lt;-<span class="st"> </span>sample_<span class="dv">1</span>_bootstrap <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">get_confidence_interval</span>(<span class="dt">level =</span> <span class="fl">0.95</span>, <span class="dt">type =</span> <span class="st">&quot;percentile&quot;</span>)
percentile_ci_<span class="dv">1</span></code></pre>
<pre><code># A tibble: 1 x 2
  `2.5%`  `97.5%`
   &lt;dbl&gt;    &lt;dbl&gt;
1   0.28 0.540500</code></pre>
<p>Furthermore, let’s visualize the bootstrap distribution where we’ve adjusted the number of bins to better see the resulting shape. Furthermore, we add a vertical red line at <span class="math inline">\(\widehat{p}\)</span> = 21/50 = 0.42 = 42% using <code>geom_vline()</code> by setting the <code>xintercept</code> argument.</p>
<pre class="sourceCode r"><code class="sourceCode r">sample_<span class="dv">1</span>_bootstrap <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">visualize</span>(<span class="dt">bins =</span> <span class="dv">15</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">shade_confidence_interval</span>(<span class="dt">endpoints =</span> <span class="kw">c</span>(<span class="fl">0.28</span>, <span class="fl">0.56</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> <span class="fl">0.375</span>, <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:shovel-bootstrap-1-infer"></span>
<img src="moderndive_files/figure-html/shovel-bootstrap-1-infer-1.png" alt="Bootstrap distribution." width="\textwidth" />
<p class="caption">
FIGURE 9.28: Bootstrap distribution.
</p>
</div>
<p>Did Ilyas and Yohan’s net capture the fish? In other words, did the 95% confidence interval for <span class="math inline">\(p\)</span> based on the 50 balls they sampled contain the true value of <span class="math inline">\(p\)</span>, the population proportion of the bowl’s balls that are red? Yes! 0.375 is between the endpoints of our confidence interval (0.28, 0.54).</p>
<p>However, will <em>every</em> 95% confidence interval for <span class="math inline">\(p\)</span> capture this value? In other words, if we had a different sample of size 50 and constructed a confidence interval using the same method, would we be guaranteed that it contained the population proportion <span class="math inline">\(p\)</span> as well? Let’s study the effect of sampling variation by randomly sampling <em>another</em> 50 balls from our virtual <code>bowl</code> using our virtual shovel:</p>
<pre class="sourceCode r"><code class="sourceCode r">bowl_sample_<span class="dv">2</span> &lt;-<span class="st"> </span>bowl <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">rep_sample_n</span>(<span class="dt">size =</span> <span class="dv">50</span>)
bowl_sample_<span class="dv">2</span></code></pre>
<pre><code># A tibble: 50 x 3
# Groups:   replicate [1]
   replicate ball_ID color
       &lt;int&gt;   &lt;int&gt; &lt;chr&gt;
 1         1    1665 red  
 2         1    1312 red  
 3         1    2105 red  
 4         1     810 white
 5         1     189 white
 6         1    1429 white
 7         1    2294 red  
 8         1    1233 white
 9         1    1951 white
10         1    2061 white
# … with 40 more rows</code></pre>
<p>Let’s perform the same steps of the <code>infer</code> pipeline we did on <code>bowl_sample_1</code> to generate <em>another</em> 95% confidence interval for <span class="math inline">\(p\)</span> based on the new sample of 50 balls in <code>bowl_sample_2</code>. First we create the bootstrap distribution of the sample proportion <span class="math inline">\(\widehat{p}\)</span> and save the results in <code>sample_2_bootstrap</code>:</p>
<pre class="sourceCode r"><code class="sourceCode r">sample_<span class="dv">2</span>_bootstrap &lt;-<span class="st"> </span>bowl_sample_<span class="dv">2</span> <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">specify</span>(<span class="dt">response =</span> color, <span class="dt">success =</span> <span class="st">&quot;red&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">generate</span>(<span class="dt">reps =</span> <span class="dv">1000</span>, <span class="dt">type =</span> <span class="st">&quot;bootstrap&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">calculate</span>(<span class="dt">stat =</span> <span class="st">&quot;prop&quot;</span>)
sample_<span class="dv">2</span>_bootstrap</code></pre>
<pre><code># A tibble: 1,000 x 2
   replicate  stat
       &lt;int&gt; &lt;dbl&gt;
 1         1  0.36
 2         2  0.38
 3         3  0.42
 4         4  0.26
 5         5  0.5 
 6         6  0.32
 7         7  0.4 
 8         8  0.32
 9         9  0.5 
10        10  0.44
# … with 990 more rows</code></pre>
<p>We once again compute the percentile-based confidence interval.</p>
<pre class="sourceCode r"><code class="sourceCode r">percentile_ci_<span class="dv">2</span> &lt;-<span class="st"> </span>sample_<span class="dv">2</span>_bootstrap <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">get_confidence_interval</span>(<span class="dt">level =</span> <span class="fl">0.95</span>, <span class="dt">type =</span> <span class="st">&quot;percentile&quot;</span>)
percentile_ci_<span class="dv">2</span></code></pre>
<pre><code># A tibble: 1 x 2
  `2.5%` `97.5%`
   &lt;dbl&gt;   &lt;dbl&gt;
1   0.22     0.5</code></pre>
<p>Does this new net capture the fish? In other words, did the 95% confidence interval for <span class="math inline">\(p\)</span> based on the 50 newly sampled balls contain the true value of <span class="math inline">\(p\)</span>, the population proportion of the bowl’s balls that are red? Yes! 0.375 is between the endpoints of our confidence interval (0.22, 0.5).</p>
<p>Let’s now repeat this process 100 more times, leaving us with 100 different 95% confidence intervals <span class="math inline">\(p\)</span> derived from 100 different samples of size 50 balls from the population <code>bowl</code>. Let’s visualize the results in Figure <a href="9-confidence-intervals.html#fig:reliable-percentile">9.29</a> where:</p>
<ol style="list-style-type: decimal">
<li>We mark the true population proportion red <span class="math inline">\(p\)</span> = 0.375 = 0.375% with a vertical red line.</li>
<li>We mark each of the 100 95% confidence intervals for <span class="math inline">\(p\)</span> with horizontal lines. These are the “nets.”</li>
<li>The horizontal the line if colored orange of the confidence interval “captures” the true value of <span class="math inline">\(p\)</span> in red and the line is blue otherwise.</li>
<li>We also mark each line with a dot indicated the value of the point estimate: the sample proportion <span class="math inline">\(\widehat{p}\)</span>. These are the “spears.”</li>
</ol>
<div class="figure" style="text-align: center"><span id="fig:reliable-percentile"></span>
<img src="moderndive_files/figure-html/reliable-percentile-1.png" alt="100 SE-based 95 percent confidence intervals for $p$." width="\textwidth" />
<p class="caption">
FIGURE 9.29: 100 SE-based 95 percent confidence intervals for <span class="math inline">\(p\)</span>.
</p>
</div>
<p>Of the 100 confidence intervals based on 100 samples of size <span class="math inline">\(n\)</span> = 50, 96 of them captured the population mean <span class="math inline">\(p\)</span> = 0.375, whereas 4 of them didn’t. In other words, 96 of our nets caught the fish whereas 4 of our nets didn’t.</p>
<p>This is where the 95% confidence level we defined in Section <a href="9-confidence-intervals.html#ci-build-up">9.3</a> comes into play: for every 100 confidence intervals based on 100 different random examples, we <em>expect</em> that 95 of them will capture <span class="math inline">\(p\)</span> and 5 won’t. Note that “expect” is a probabilistic statement that averages over the sampling variation. In other words, for every 100 confidence intervals, we will observe about 5 confidence intervals that fail to capture <span class="math inline">\(p\)</span>. In Figure <a href="9-confidence-intervals.html#fig:reliable-percentile">9.29</a> for example, 4 of the confidence intervals failed to capture <span class="math inline">\(p\)</span>.</p>
<p>To further accentuate this point, let’s perform a similar procedure using 85% standard-error based confidence intervals instead. Let’s visualize the results in Figure <a href="9-confidence-intervals.html#fig:reliable-se">9.30</a>. Observe how the widths of the 80% confidence intervals are narrower than the 95% confidence intervals; we’ll explore other determinants of the widths of confidence intervals in the next section.</p>
<div class="figure" style="text-align: center"><span id="fig:reliable-se"></span>
<img src="moderndive_files/figure-html/reliable-se-1.png" alt="100 SE-based 85 percent confidence intervals for $p$" width="\textwidth" />
<p class="caption">
FIGURE 9.30: 100 SE-based 85 percent confidence intervals for <span class="math inline">\(p\)</span>
</p>
</div>
<p>Of the 100 confidence intervals based on 100 samples of size <span class="math inline">\(n = 50\)</span>, 86 of them captured the population proportion <span class="math inline">\(p = 0.375\)</span>, whereas 14 of them did not. Note that since we lowered the confidence level from 95% to 80%, we now have a much larger number of confidence intervals that failed to “catch the fish.”</p>
</div>
</div>
<div id="shorthand" class="section level3">
<h3><span class="header-section-number">9.5.2</span> Precise &amp; shorthand interpretation</h3>
<p></p>
<p>Let’s return our attention to our 95% confidence intervals. The precise and mathematically correct interpretation of a 95% confidence interval is a little long-winded:</p>
<blockquote>
<p>Precise interpretation: If we repeated our sampling procedure a large number of times, we expect about 95% of the resulting confidence intervals to capture the value of the population parameter.</p>
</blockquote>
<p>This is what we observed in Figure <a href="9-confidence-intervals.html#fig:reliable-percentile">9.29</a>: that our confidence interval construction procedure is 95% “reliable”. In other words, we can expect our confidence intervals to include the true population parameter 95% of the time.</p>
<p>A common but incorrect interpretation is: “There is a 95% probability that the confidence interval contains <span class="math inline">\(p\)</span>.” Because looking at Figure <a href="9-confidence-intervals.html#fig:reliable-percentile">9.29</a>, each of the confidence intervals either does or doesn’t contain <span class="math inline">\(p\)</span>, in other words, the probability is either 1 or 0.</p>
<p>So if the 95% confidence level only relates to the reliability of the confidence interval construction procedure, what insight can be derived from one particular confidence interval? For example, going back to the pennies example, we found that the percentile method 95% confidence interval for <span class="math inline">\(\mu\)</span> was (1991.16, 1999.58) whereas the standard error method 95% confidence interval was (1991.16, 1999.72).</p>
<p>Loosely speaking, we can think of these intervals as our “best guess” of a plausible range of values for the mean year of minting of all US pennies. Furthermore, for the rest of this text, we’ll use the following shorthand to summarize the precise interpretation.</p>
<blockquote>
<p>Short-hand interpretation: We are 95% “confident” that a 95% confidence interval captures the value of the population parameter.</p>
</blockquote>
<p>We use quotation marks around “confident” to emphasize that while 95% relates to the reliability of our confidence interval construction procedure, ultimately the resulting interval is our best guess of a range of values that contain the population parameter.</p>
<p>So returning to our pennies example and focusing on the percentile-method, we are 95% “confident” that the true mean year of pennies in circulation in 2019 is somewhere between 1991.16 and 1999.58.</p>
</div>
<div id="ci-width" class="section level3">
<h3><span class="header-section-number">9.5.3</span> Width of confidence intervals</h3>
<p>Now that we know how to interpret confidence intervals, let’s go over some factors that determine their width.</p>
<div id="impact-of-confidence-level" class="section level4 unnumbered">
<h4>Impact of confidence level</h4>
<p>One factor that determines the confidence interval width is the pre-specified confidence level. For example in Figures <a href="9-confidence-intervals.html#fig:reliable-percentile">9.29</a> and <a href="9-confidence-intervals.html#fig:reliable-se">9.30</a>, we compared the widths of 95% and 80% confidence intervals. Recall that the 95% confidence intervals were wider. The quantification of the confidence level should match what you expect of the word “confident.” In order to be more confident in our best guess of a range of values, we need to widen the range of values.</p>
<p>To elaborate on this, imagine we want to guess the forecasted high temperature in Seoul, South Korea on August 15th. Given Seoul’s temperate climate with 4 distinct seasons, we could say somewhat confidently that the high temperature would be between 50°F - 95°F (10°C - 35°C). However, if we wanted a temperature range we were <em>absolutely</em> confident about, would we need to widen or narrow this range? We’d need to widen it! We need this wider range since it is possible to have a freak cold spell or heat wave. So a range of temperatures we could be near certain about would be between 32°F - 110°F (0°C - 43°C). On the other hand, if we wanted a range we could tolerate being a little less confident, we could narrow this range to between 70°F - 85°F (21°C - 30°C).</p>
<p>Going back to our sampling bowl, let’s compare confidence intervals for <span class="math inline">\(p\)</span> based on three different confidence levels: 80%, 95%, and 99%. Specifically, we’ll first take 30 different random samples of <span class="math inline">\(n\)</span> = 50 balls from the bowl. We’ll then construct 10 percentile-based confidence intervals based on each of the three different confidence levels and compare the widths of these intervals. We visualize the resulting 30 confidence intervals in Figure <a href="9-confidence-intervals.html#fig:reliable-percentile-80-95-99">9.31</a> along with a vertical red line marking the true value of <span class="math inline">\(p\)</span> = 0.375 = 0.375%, the population proportion of the bowl’s balls that are red.</p>
<!-- 
Chester says: Should we load the perc_cis_by_level and percentile_cis_by_n data
frames into the moderndive package too so that readers can explore them a bit?

Albert says: I totally agree. However making the code to replicate this process
student-friendly is going to take a lot of work and this chapter is getting
rather large as is, so let's punt until next edition. For now, let's just show
the resulting faceted plots comparing:

-For n=50, 80% + 95% + 99% confidence intervals
-For 95% confidence level, based on n = 25, 50, 100
-->
<!--
See above note: punted for now

Let's take a look into what the `perc_cis_by_level` data frame looks like and how a sample of 10 different confidence intervals each from the 80%, 95%, and 99% levels compare visually in terms of length. Then, we'll start computing some widths of the confidence intervals. Then we'll head into calculating the mean and median widths across the three different levels.



We see that the sample proportion of reds varies in the `point_estimate` column with varying `lower` and `upper` bounds as well depending on the variability of the bootstrap distribution. The width of the confidence intervals appears to increase from left to right going from 80% confidence levels to 95% and then to 99%. Let's now compute the confidence interval (CI) width for each of these intervals and then get the median and mean length.
-->
<div class="figure" style="text-align: center"><span id="fig:reliable-percentile-80-95-99"></span>
<img src="moderndive_files/figure-html/reliable-percentile-80-95-99-1.png" alt="Ten 80, 95, and 99 percent confidence intervals for $p$ based on $n = 50$." width="\textwidth" />
<p class="caption">
FIGURE 9.31: Ten 80, 95, and 99 percent confidence intervals for <span class="math inline">\(p\)</span> based on <span class="math inline">\(n = 50\)</span>.
</p>
</div>
<p>Observe that as the confidence level increase from 80% to 95% to 99%, in general, the confidence intervals get wider. Let’s compare the average widths in Table <a href="9-confidence-intervals.html#tab:perc-cis-average-width">9.3</a>.</p>
<table class="table" style="font-size: 16px; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:perc-cis-average-width">TABLE 9.3: </span>Mean width of 80, 95, and 99 percent confidence intervals.
</caption>
<thead>
<tr>
<th style="text-align:left;">
Confidence level
</th>
<th style="text-align:right;">
Mean width
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
80%
</td>
<td style="text-align:right;">
0.166
</td>
</tr>
<tr>
<td style="text-align:left;">
95%
</td>
<td style="text-align:right;">
0.264
</td>
</tr>
<tr>
<td style="text-align:left;">
99%
</td>
<td style="text-align:right;">
0.338
</td>
</tr>
</tbody>
</table>
<p>So in order to have a higher confidence interval, our “plausible range of values” must be wider. Ideally we would have both high confidence level and narrower confidence intervals; however, we cannot have it both ways. If we want to “be more confident”, we need to allow for wider intervals. Conversely, if we would like a narrow and tight interval, we must sacrifice confidence level.</p>
<p>The moral of the story is:  <strong>Higher confidence levels tend to produce wider confidence intervals.</strong> However, it is important to keep in mind in our example that we kept the sample size fixed at <span class="math inline">\(n\)</span> = 50. In other words, all 30 random samples from <code>bowl</code> used to construct the 30 confidence intervals had the same sample size. What happens if, instead, we take samples of different sizes? Recall that we did this in Section <a href="8-sampling.html#different-shovels">8.2.4</a> where did this using virtual shovels with 25, 50, and 100 slots. We delve into this next.</p>
</div>
<div id="impact-of-sample-size" class="section level4 unnumbered">
<h4>Impact of sample size</h4>
<p>This time, let’s fix the confidence level at 95%, but consider three different sample sizes: <span class="math inline">\(n\)</span> equals 25, 50, and 100. Specifically, we’ll first take 10 different random samples of size 25, 10 different random samples of size 50, and 10 different random samples of size 100. We’ll then construct 95% percentile-based confidence intervals. We visualize the resulting 30 confidence intervals in Figure <a href="9-confidence-intervals.html#fig:reliable-percentile-n-25-50-100">9.32</a> along with a vertical red line marking the true value of <span class="math inline">\(p\)</span> = 0.375 = 0.375%, the population proportion of the bowl’s balls that are red.</p>
<div class="figure" style="text-align: center"><span id="fig:reliable-percentile-n-25-50-100"></span>
<img src="moderndive_files/figure-html/reliable-percentile-n-25-50-100-1.png" alt="Ten 95 percent confidence intervals for $p$ based on n = 25, 50, and 100." width="\textwidth" />
<p class="caption">
FIGURE 9.32: Ten 95 percent confidence intervals for <span class="math inline">\(p\)</span> based on n = 25, 50, and 100.
</p>
</div>
<p>Observe that as our confidence intervals are based on larger and larger sample sizes, in general, the confidence intervals get narrower. Let’s compare the average widths in Table <a href="9-confidence-intervals.html#tab:perc-cis-average-width-2">9.4</a>.</p>
<table class="table" style="font-size: 16px; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:perc-cis-average-width-2">TABLE 9.4: </span>Mean width of 95 percent confidence intervals based on n = 25, 50, and 100.
</caption>
<thead>
<tr>
<th style="text-align:left;">
Sample size
</th>
<th style="text-align:right;">
Mean width
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
n = 25
</td>
<td style="text-align:right;">
0.380
</td>
</tr>
<tr>
<td style="text-align:left;">
n = 50
</td>
<td style="text-align:right;">
0.270
</td>
</tr>
<tr>
<td style="text-align:left;">
n = 100
</td>
<td style="text-align:right;">
0.183
</td>
</tr>
</tbody>
</table>
<p>The moral of the story is:  <strong>Larger sample sizes tend to produce narrow confidence intervals.</strong> Recall that this was a key message in Section <a href="8-sampling.html#moral-of-the-story">8.3.3</a>. As we used the larger and larger shovels to draw our samples, our sample proportions red <span class="math inline">\(\widehat{p}\)</span> tended to vary less. In other words, our estimates got more and more precise.</p>
<p>We visualized these results in Figure <a href="8-sampling.html#fig:comparing-sampling-distributions-3">8.15</a> where we compared the <em>sampling distributions</em> for <span class="math inline">\(\widehat{p}\)</span> based on samples of size <span class="math inline">\(n\)</span> equal 25, 50, 100. Furthermore, we could quantify the spread of these sampling distributions using their standard deviation, which as a special name: the <em>standard error</em>. As the sample size increases, the standard error decreases.</p>
<p>In fact, the standard error is a related factor in confidence interval width, which we explore in Subsection <a href="9-confidence-intervals.html#theory-ci">9.7.2</a> when we discuss theoretically constructed confidence intervals using mathematical formulas.</p>
<!-- 
A good learning check might be to have the readers calculate confidence intervals when n = 1000, 2000, 2400. To their astonishment (maybe), they'll see that the size of the confidence interval is 0 when they get to 2400. 
-->
</div>
</div>
</div>
<div id="case-study-two-prop-ci" class="section level2">
<h2><span class="header-section-number">9.6</span> Case study: Is yawning contagious?</h2>
<p>Let’s apply our knowledge of confidence intervals to answer the question: “Is yawning contagious?” If you see someone else yawn, are you more likely to yawn? In an <a href="http://www.discovery.com/tv-shows/mythbusters/mythbusters-database/yawning-contagious/">episode</a> of the US show <em>Mythbusters</em>, the hosts conducted an experiment to answer this question. The episode is available to view in the United States on the Discovery Network website <a href="https://www.discovery.com/tv-shows/mythbusters/videos/is-yawning-contagious">here</a> and more information about the episode is also available on <a href="https://www.imdb.com/title/tt0768479/">IMDb</a>.</p>
<div id="mythbusters-study-data" class="section level3">
<h3><span class="header-section-number">9.6.1</span> Mythbusters study data</h3>
<p>Fifty adult participants who thought they were being considered for an appearance on the show were interviewed by a show recruiter who either yawned or did not. Participants then sat by themselves in a large van and were asked to wait. While in the van, the Mythbusters watched via hidden camera to see if the participants yawned. The data frame containing the results is available in the <code>mythbusters_yawn</code> data frame included in the <code>moderndive</code> package: </p>
<pre class="sourceCode r"><code class="sourceCode r">mythbusters_yawn</code></pre>
<pre><code># A tibble: 50 x 3
    subj group   yawn 
   &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;
 1     1 seed    yes  
 2     2 control yes  
 3     3 seed    no   
 4     4 seed    yes  
 5     5 seed    no   
 6     6 control no   
 7     7 seed    yes  
 8     8 control no   
 9     9 control no   
10    10 seed    no   
# … with 40 more rows</code></pre>
<p>The variables are:</p>
<ul>
<li><code>subj</code>: The participant ID with values 1 through 50.</li>
<li><code>group</code>: A binary categorical variable of whether the participant was exposed to yawning, where <code>&quot;seed&quot;</code> indicates the participant was exposed to yawning and <code>&quot;control&quot;</code> indicates the participant was not.</li>
<li><code>yawn</code>: A <code>&quot;yes&quot;</code> vs <code>&quot;no&quot;</code> binary categorical variable indicating whether the participant responded by yawning.</li>
</ul>
<p>Let’s use some data wrangling to obtain counts of the four possible outcomes:</p>
<pre class="sourceCode r"><code class="sourceCode r">mythbusters_yawn <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(group, yawn) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">count =</span> <span class="kw">n</span>())</code></pre>
<pre><code># A tibble: 4 x 3
# Groups:   group [2]
  group   yawn  count
  &lt;chr&gt;   &lt;chr&gt; &lt;int&gt;
1 control no       12
2 control yes       4
3 seed    no       24
4 seed    yes      10</code></pre>
<p>So 12 participants who were not exposed to yawning did not yawn, while 4 participants who were not exposed to yawning did yawn. So out of the 16 people who were not exposed to yawning, 4/16 = 0.25 = 25% did yawn. On the other hand, 24 participants who were exposed to yawning did not yawn, while 10 participants who were exposed to yawning did yawn. So out of the 34 people who were exposed to yawning, 10/34 = 0.294 = 29.4% did yawn.</p>
<p>Putting these two values together, the participants who were exposed to yawning yawned 29.4% - 25% = 4.4% more often than those who were not exposed to yawning.</p>
</div>
<div id="sampling-scenario" class="section level3">
<h3><span class="header-section-number">9.6.2</span> Sampling scenario</h3>
<p>In Chapter <a href="8-sampling.html#sampling">8</a> our study population was the bowl of <span class="math inline">\(N\)</span> = 2400 balls. Our population parameter of interest was the population proportion of these balls that were red, denoted mathematically by <span class="math inline">\(p\)</span>. In order to estimate <span class="math inline">\(p\)</span>, we extracted a sample of 50 balls using the shovel and computed the relevant point estimate: the sample proportion of these 50 balls that were red, denoted mathematically by <span class="math inline">\(\widehat{p}\)</span>.</p>
<p>Who is the study population here? All humans? All the people who watch the show Mythbusters? It’s hard to say! This question can only be answered if we know how the show’s hosts recruited participants! We alas don’t have this information. Only for the purposes of this case study, however, we’ll assume that the 50 participants are a representative sample of all Americans, and thus any results of this experiment will generalize to all <span class="math inline">\(N\)</span> = 327 million Americans (2018 population).</p>
<p>Just like with our sampling bowl, the population parameter of interest will involve proportions, but this time it will be the difference in population proportions <span class="math inline">\(p_{seed} - p_{control}\)</span>, where <span class="math inline">\(p_{seed}\)</span> is the population proportion of people exposed to yawning who yawn and <span class="math inline">\(p_{control}\)</span> is the population proportion of people not exposed to yawning who yawn. Correspondingly, the point estimate/sample statistic based on sampled data will be the difference in sample proportions <span class="math inline">\(\widehat{p}_{seed} - \widehat{p}_{control}\)</span>. Let’s extend Table <a href="8-sampling.html#tab:table-ch8">8.8</a> of scenarios of sampling for inference to include our latest scenario.</p>
<table class="table" style="font-size: 16px; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:table-ch8-c">TABLE 9.5: </span>Scenarios of sampling for inference
</caption>
<thead>
<tr>
<th style="text-align:right;">
Scenario
</th>
<th style="text-align:left;">
Population parameter
</th>
<th style="text-align:left;">
Notation
</th>
<th style="text-align:left;">
Point estimate
</th>
<th style="text-align:left;">
Notation.
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;width: 0.5in; ">
1
</td>
<td style="text-align:left;width: 0.7in; ">
Population proportion
</td>
<td style="text-align:left;width: 1in; ">
<span class="math inline">\(p\)</span>
</td>
<td style="text-align:left;width: 1.1in; ">
Sample proportion
</td>
<td style="text-align:left;width: 1in; ">
<span class="math inline">\(\widehat{p}\)</span>
</td>
</tr>
<tr>
<td style="text-align:right;width: 0.5in; ">
2
</td>
<td style="text-align:left;width: 0.7in; ">
Population mean
</td>
<td style="text-align:left;width: 1in; ">
<span class="math inline">\(\mu\)</span>
</td>
<td style="text-align:left;width: 1.1in; ">
Sample mean
</td>
<td style="text-align:left;width: 1in; ">
<span class="math inline">\(\overline{x}\)</span> or <span class="math inline">\(\widehat{\mu}\)</span>
</td>
</tr>
<tr>
<td style="text-align:right;width: 0.5in; ">
3
</td>
<td style="text-align:left;width: 0.7in; ">
Difference in population proportions
</td>
<td style="text-align:left;width: 1in; ">
<span class="math inline">\(p_1 - p_2\)</span>
</td>
<td style="text-align:left;width: 1.1in; ">
Difference in sample proportions
</td>
<td style="text-align:left;width: 1in; ">
<span class="math inline">\(\widehat{p}_1 - \widehat{p}_2\)</span>
</td>
</tr>
</tbody>
</table>
<p>This is known as a situation of <em>two-sample</em> inference since we have two separate samples, in this case, those who were exposed to yawning and those who were not. So in our case, based on two separate samples of size <span class="math inline">\(n_{seed}\)</span> = 34 and <span class="math inline">\(n_{control}\)</span> = 16,</p>
<p><span class="math display">\[
\widehat{p}_{seed} - \widehat{p}_{control} = \frac{24}{34} - \frac{12}{16} = 0.04411765 \approx 4.4\%
\]</span></p>
<p>However, say we had sampled 50 different people, 34 to be exposed to yawning and 16 not, and repeated this experiment. Would we obtain the exact same estimated difference of 4.4%? Probably not, because of sampling variation. How does this sampling variation affect our estimate of 4.4%? In other words, what would be a plausible range of values for this difference that accounts for this sampling variation? We can answer this question with confidence intervals! Furthermore, since we only have one single sample of 50 participants, we can construct the 95% confidence interval for <span class="math inline">\(p_{seed} - p_{control}\)</span> using bootstrap resampling with replacement.</p>
</div>
<div id="ci-build" class="section level3">
<h3><span class="header-section-number">9.6.3</span> Constructing the confidence interval</h3>
<p>As we did in Section <a href="9-confidence-intervals.html#infer-workflow">9.4.2</a>, let’s spell out the steps of the <code>infer</code> workflow to construct the 95% confidence interval for <span class="math inline">\(p_{seed} - p_{control}\)</span>. However, since the difference in proportions is a new scenario for inference, we’ll need to identify some new arguments to include in the <code>infer</code> functions along the way.</p>
<div id="specify-variables-2" class="section level4 unnumbered">
<h4>1. <code>specify</code> variables</h4>
<p>We take our <code>mythbusters_yawn</code> data frame with the data and <code>specify()</code> which variables are of interest using the formula interface where</p>
<ul>
<li>Our response variable is <code>yawn</code>: whether or not a participant yawned.</li>
<li>The explanatory variable is <code>group</code>: whether or not a participant was exposed to yawning.</li>
</ul>
<pre class="sourceCode r"><code class="sourceCode r">mythbusters_yawn <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">specify</span>(<span class="dt">formula =</span> yawn <span class="op">~</span><span class="st"> </span>group)</code></pre>
<pre><code>Error: A level of the response variable `yawn` needs to be 
specified for the `success` argument in `specify()`.</code></pre>
<p>Alas, we got an error message. <code>infer</code> is telling us that one of the levels of the categorical variable <code>yawn</code> needs to be defined as the <code>success</code>, or the event of interest we are trying to count and compute proportions. Are we interested in those participants who <code>&quot;yes&quot;</code> yawned or are we interested in those participants who <code>&quot;no&quot;</code> didn’t yawn? This isn’t clear. So we set the <code>success</code> argument to <code>&quot;yes&quot;</code> as follows:</p>
<pre class="sourceCode r"><code class="sourceCode r">mythbusters_yawn <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">specify</span>(<span class="dt">formula =</span> yawn <span class="op">~</span><span class="st"> </span>group, <span class="dt">success =</span> <span class="st">&quot;yes&quot;</span>)</code></pre>
<pre><code>Response: yawn (factor)
Explanatory: group (factor)
# A tibble: 50 x 2
   yawn  group  
   &lt;fct&gt; &lt;fct&gt;  
 1 yes   seed   
 2 yes   control
 3 no    seed   
 4 yes   seed   
 5 no    seed   
 6 no    control
 7 yes   seed   
 8 no    control
 9 no    control
10 no    seed   
# … with 40 more rows</code></pre>
</div>
<div id="generate-replicates-2" class="section level4 unnumbered">
<h4>2. <code>generate</code> replicates</h4>
<p>Our next step in building a confidence interval is to create a bootstrap distribution of statistics (differences in proportions of successes). We saw how it works with both a single variable in computing bootstrap means in Subsection <a href="9-confidence-intervals.html#bootstrap-process">9.4</a> and in computing bootstrap proportions in Section <a href="9-confidence-intervals.html#one-prop-ci">9.5</a>, but we haven’t yet worked with bootstrapping involving multiple variables though.</p>
<p>In the <code>infer</code> package, bootstrapping with multiple variables means that each <strong>row</strong> is potentially resampled. Let’s investigate this by looking at the first few rows of <code>mythbusters_yawn</code>:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(mythbusters_yawn)</code></pre>
<pre><code># A tibble: 6 x 3
   subj group   yawn 
  &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;
1     1 seed    yes  
2     2 control yes  
3     3 seed    no   
4     4 seed    yes  
5     5 seed    no   
6     6 control no   </code></pre>
<p>When we bootstrap this data, we are potentially pulling the subject’s readings multiple times. Thus, we could see the entries of <code>&quot;seed&quot;</code> for <code>group</code> and <code>&quot;no&quot;</code> for <code>yawn</code> together in a new row in a bootstrap sample. This is further seen by exploring the <code>sample_n()</code> function in <code>dplyr</code> on this smaller 6-row data frame comprised of <code>head(mythbusters_yawn)</code>. The <code>sample_n()</code> function can perform this bootstrapping procedure and is similar to the <code>rep_sample_n()</code> function in <code>infer</code>, except that it is not <code>rep</code>eated but rather only performs one sample with or without replacement.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(mythbusters_yawn) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">sample_n</span>(<span class="dt">size =</span> <span class="dv">6</span>, <span class="dt">replace =</span> <span class="ot">TRUE</span>)</code></pre>
<pre><code># A tibble: 6 x 3
   subj group   yawn 
  &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;
1     1 seed    yes  
2     6 control no   
3     1 seed    yes  
4     5 seed    no   
5     4 seed    yes  
6     4 seed    yes  </code></pre>
<p>We can see that in this bootstrap sample generated from the first six rows of <code>mythbusters_yawn</code>, we have some rows repeated. The same is true when we perform the <code>generate()</code> step in <code>infer</code> as done below. Next, we <code>generate</code> 1000 replicates, or in other words, we bootstrap resample the 50 participants with replacement 1000 times. This is what will inject sampling variation into our results.</p>
<pre class="sourceCode r"><code class="sourceCode r">mythbusters_yawn <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">specify</span>(<span class="dt">formula =</span> yawn <span class="op">~</span><span class="st"> </span>group, <span class="dt">success =</span> <span class="st">&quot;yes&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">generate</span>(<span class="dt">reps =</span> <span class="dv">1000</span>, <span class="dt">type =</span> <span class="st">&quot;bootstrap&quot;</span>)</code></pre>
<pre><code>Response: yawn (factor)
Explanatory: group (factor)
# A tibble: 50,000 x 3
# Groups:   replicate [1,000]
   replicate yawn  group  
       &lt;int&gt; &lt;fct&gt; &lt;fct&gt;  
 1         1 no    seed   
 2         1 no    seed   
 3         1 yes   control
 4         1 yes   seed   
 5         1 no    control
 6         1 yes   seed   
 7         1 no    control
 8         1 no    seed   
 9         1 no    seed   
10         1 no    seed   
# … with 49,990 more rows</code></pre>
<p>Note the resulting data frame has 50,000 rows. This is because we performed resampling of 50 participants with replacement 1000 times and thus 50,000 = 1000 <span class="math inline">\(\times\)</span> 50. Accordingly, the variable <code>replicate</code>, indicating which resample each row belongs to, has the value <code>1</code> 50 times, the value <code>2</code> 50 times, all the way through to the value <code>1000</code> 50 times.</p>
</div>
<div id="calculate-summary-statistics-2" class="section level4 unnumbered">
<h4>3. <code>calculate</code> summary statistics</h4>
<p>After we <code>generate()</code> many replicates of bootstrap resampling with replacement, we next want to summarize of the bootstrap resamples of size 50 with a single summary statistic, the difference in proportions. I do this by setting the <code>stat</code> argument to <code>&quot;diff in props&quot;</code>:</p>
<!-- 
A challenging learning check for those {dplyr} diehards is to get these values 
without using {infer}. It takes a double group_by() and some trickery, but could 
be a good exercise for those that don't quite see the power of {infer}.
-->
<pre class="sourceCode r"><code class="sourceCode r">mythbusters_yawn <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">specify</span>(<span class="dt">formula =</span> yawn <span class="op">~</span><span class="st"> </span>group, <span class="dt">success =</span> <span class="st">&quot;yes&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">generate</span>(<span class="dt">reps =</span> <span class="dv">1000</span>, <span class="dt">type =</span> <span class="st">&quot;bootstrap&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">calculate</span>(<span class="dt">stat =</span> <span class="st">&quot;diff in props&quot;</span>)</code></pre>
<pre><code>Error: Statistic is based on a difference; specify the `order` in which to
subtract the levels of the explanatory variable.</code></pre>
<p>We see another error here. We need to specify the order of the subtraction. Is it <span class="math inline">\(\widehat{p}_{seed} - \widehat{p}_{control}\)</span> or <span class="math inline">\(\widehat{p}_{control} - \widehat{p}_{seed}\)</span>. We specify it to be <span class="math inline">\(\widehat{p}_{seed} - \widehat{p}_{control}\)</span> by setting <code>order = c(&quot;seed&quot;, &quot;control&quot;)</code>. You can also set <code>order = c(&quot;control&quot;, &quot;seed&quot;)</code>; it makes no difference in the analysis. However, whatever order you choose, it is important to stay consistent throughout your analysis.</p>
<p>Let’s save the output in a data frame <code>bootstrap_distribution_yawning</code>:</p>
<pre class="sourceCode r"><code class="sourceCode r">bootstrap_distribution_yawning &lt;-<span class="st"> </span>mythbusters_yawn <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">specify</span>(<span class="dt">formula =</span> yawn <span class="op">~</span><span class="st"> </span>group, <span class="dt">success =</span> <span class="st">&quot;yes&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">generate</span>(<span class="dt">reps =</span> <span class="dv">1000</span>, <span class="dt">type =</span> <span class="st">&quot;bootstrap&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">calculate</span>(<span class="dt">stat =</span> <span class="st">&quot;diff in props&quot;</span>, <span class="dt">order =</span> <span class="kw">c</span>(<span class="st">&quot;seed&quot;</span>, <span class="st">&quot;control&quot;</span>))
bootstrap_distribution_yawning</code></pre>
<pre><code># A tibble: 1,000 x 2
   replicate       stat
       &lt;int&gt;      &lt;dbl&gt;
 1         1 -0.0213904
 2         2  0.0459770
 3         3  0        
 4         4 -0.0129870
 5         5  0.326765 
 6         6  0.122807 
 7         7  0.293718 
 8         8  0.0761905
 9         9  0.0679117
10        10 -0.0231729
# … with 990 more rows</code></pre>
<p>We see that the resulting data frame has 1000 rows and 2 columns corresponding to the 1000 replicates and the difference in proportions for each bootstrap resample saved in the variable <code>stat</code>.</p>
</div>
<div id="visualize-the-results-2" class="section level4 unnumbered">
<h4>4. <code>visualize</code> the results</h4>
<p>In Figure <a href="9-confidence-intervals.html#fig:bootstrap-distribution-mythbusters">9.33</a> we <code>visualize()</code> the resulting bootstrap resampling distribution.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">visualize</span>(bootstrap_distribution_yawning)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:bootstrap-distribution-mythbusters"></span>
<img src="moderndive_files/figure-html/bootstrap-distribution-mythbusters-1.png" alt="Bootstrap distribution." width="\textwidth" />
<p class="caption">
FIGURE 9.33: Bootstrap distribution.
</p>
</div>
<p>First, let’s compute the 95% confidence interval for <span class="math inline">\(p_{seed} - p_{control}\)</span> using the percentile method, in other words by identifying the 2.5<sup>th</sup> and 97.5<sup>th</sup> percentiles which include the middle 95% of values. Recall that this method does not require the bootstrap distribution to be normally shaped.</p>
<pre class="sourceCode r"><code class="sourceCode r">bootstrap_distribution_yawning <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">get_confidence_interval</span>(<span class="dt">type =</span> <span class="st">&quot;percentile&quot;</span>, <span class="dt">level =</span> <span class="fl">0.95</span>)</code></pre>
<pre><code># A tibble: 1 x 2
     `2.5%`  `97.5%`
      &lt;dbl&gt;    &lt;dbl&gt;
1 -0.218313 0.304763</code></pre>
<p>Second, since the bootstrap distribution is roughly bell-shaped, it is reasonable to assume that it is normally shaped, and thus we can construct a confidence interval using the standard error method. Recall to construct a standard error method, we need to specify the center of the interval using the <code>point_estimate</code> argument. We set it to be the observed difference in sample proportions of 4.4% we computed earlier.</p>
<p>However, we can also use the <code>infer</code> workflow to let R compute this value by excluding the <code>generate()</code> 1000 bootstrap replicates step. In other words, do not compute the difference in proportions for 1000 bootstrap samples with replacement, rather focus only on the observed sample data. We can achieve this by commenting out the <code>generate()</code> line, telling R to ignore it:</p>
<pre class="sourceCode r"><code class="sourceCode r">mythbusters_yawn <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">specify</span>(<span class="dt">formula =</span> yawn <span class="op">~</span><span class="st"> </span>group, <span class="dt">success =</span> <span class="st">&quot;yes&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="co"># generate(reps = 1000, type = &quot;bootstrap&quot;) %&gt;% </span>
<span class="st">  </span><span class="kw">calculate</span>(<span class="dt">stat =</span> <span class="st">&quot;diff in props&quot;</span>, <span class="dt">order =</span> <span class="kw">c</span>(<span class="st">&quot;seed&quot;</span>, <span class="st">&quot;control&quot;</span>))</code></pre>
<pre><code># A tibble: 1 x 1
       stat
      &lt;dbl&gt;
1 0.0441176</code></pre>
<p>We thus plug this value as the <code>point_estimate</code> argument.</p>
<pre class="sourceCode r"><code class="sourceCode r">bootstrap_distribution_yawning <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">get_confidence_interval</span>(<span class="dt">type =</span> <span class="st">&quot;se&quot;</span>, <span class="dt">point_estimate =</span> <span class="fl">0.0441176</span>)</code></pre>
<pre><code># A tibble: 1 x 2
      lower    upper
      &lt;dbl&gt;    &lt;dbl&gt;
1 -0.213435 0.301670</code></pre>
<p>Let’s visualize both confidence intervals in Figure <a href="9-confidence-intervals.html#fig:bootstrap-distribution-mythbusters-CI">9.34</a>, with the percentile method interval in red and the standard error method interval in blue. Observe that they are both similar.</p>
<div class="figure" style="text-align: center"><span id="fig:bootstrap-distribution-mythbusters-CI"></span>
<img src="moderndive_files/figure-html/bootstrap-distribution-mythbusters-CI-1.png" alt="Two 95 percent confidence intervals: percentile method in red, standard error method in blue." width="\textwidth" />
<p class="caption">
FIGURE 9.34: Two 95 percent confidence intervals: percentile method in red, standard error method in blue.
</p>
</div>
</div>
</div>
<div id="interpreting-the-confidence-interval" class="section level3">
<h3><span class="header-section-number">9.6.4</span> Interpreting the confidence interval</h3>
<p>Given that both confidence intervals are quite similar, let’s focus our interpretation to only the percentile method confidence interval of (-0.22, 0.3). Recall that the correct statistical interpretation of a 95% confidence interval is: if repeated this procedure 100 times, then we’d expect 95 of the confidence intervals to capture the true population difference in proportions <span class="math inline">\(p_{seed} - p_{control}\)</span>. In other words, if we gathered 100 samples of <span class="math inline">\(n\)</span> = 50 participants from a similar pool of people and constructed 100 confidence intervals, about 95 of them will contain the true value of <span class="math inline">\(p_{seed} - p_{control}\)</span> while about 5 won’t. Given that this is a little long winded, we use the shorthand: we’re 95% “confident” that the true difference in proportions <span class="math inline">\(p_{seed} - p_{control}\)</span> is between (-0.22, 0.3).</p>
<p>There is one value of particular interest that this interval contains: zero. If <span class="math inline">\(p_{seed} - p_{control} = 0\)</span>, then there would be no difference in proportion yawning, suggesting that there is no associated effect of being exposed to yawning. Since the 95% confidence interval includes 0, we cannot conclusively say if either proportion is larger. Of our 1000 bootstrap resamples with replacement, sometimes <span class="math inline">\(\widehat{p}_{seed}\)</span> was higher and thus those exposed to yawning yawned themselves more often, and other times the reverse. Say on the other hand the 95% confidence interval was entirely above zero. This would be suggestive that <span class="math inline">\(p_{seed} - p_{control} &gt; 0\)</span> and thus those exposed to yawning yawned more often.</p>
<p>Furthermore, if the 50 participants were randomly allocated to the <code>&quot;seed&quot;</code> and <code>&quot;control&quot;</code> groups, then this would be suggestive that being exposed to yawning doesn’t not <em>cause</em> yawning. In other words, yawning is not contagious. However, no information on how participants were assigned to be exposed to yawning or not could be found, so we cannot make such a causal statement.</p>
</div>
</div>
<div id="ci-conclusion" class="section level2">
<h2><span class="header-section-number">9.7</span> Conclusion</h2>
<div id="bootstrap-vs-sampling" class="section level3">
<h3><span class="header-section-number">9.7.1</span> Comparing bootstrap and sampling distributions</h3>
<p>In Section <a href="8-sampling.html#shovel-1000-times">8.2.3</a>, we took 1000 virtual samples from the <code>bowl</code> using a virtual shovel, then computed 1000 values of the sample proportion red <span class="math inline">\(\widehat{p}\)</span>, an visualized their distribution in a histogram. Recall that this distribution is called the <em>sampling distribution of</em> <span class="math inline">\(\widehat{p}\)</span> and furthermore the standard deviation of this sampling distribution has a special name: the <em>standard error</em>.</p>
<p>However, this exercise was not what one would typically do in real-life, rather is was a simulation to study the effects of sampling variation on the value of <span class="math inline">\(\widehat{p}\)</span>. In real-life, one would take only one sample that’s as large as possible. But how can we get a sense of the effect of sample-to-sample variation if we only have one sample? Don’t we need many samples?</p>
<p>The solution to this was to perform bootstrap resampling with replacement from the original sample. We did this in the resampling activity in Section <a href="9-confidence-intervals.html#resampling-tactile">9.1</a> where in this case, we were focused on the mean year of minting of pennies rather than the proportion of the bowl’s balls that were red. We used pieces of paper representing the original sample of 50 pennies from the bank and resampled them with replacement from the hat. We had 35 of our friends perform this activity and visualized their resulting sample means <span class="math inline">\(\overline{x}\)</span>.</p>
<p>This distribution was called the <em>bootstrap distribution</em> of <span class="math inline">\(\overline{x}\)</span> and it is an <em>approximation</em> to the sampling distribution of <span class="math inline">\(\overline{x}\)</span>.  Thus the variation of the bootstrap distribution of <span class="math inline">\(\overline{x}\)</span> could be used as an approximation to the variation of the sampling distribution of <span class="math inline">\(\overline{x}\)</span>.</p>
<p>Let’s now compare the sampling distribution of <span class="math inline">\(\widehat{p}\)</span> with the bootstrap distribution of <span class="math inline">\(\widehat{p}\)</span> and see how well they line up. Recall that we computed the sampling distribution of <span class="math inline">\(\widehat{p}\)</span> in Section <a href="8-sampling.html#shovel-1000-times">8.2.3</a> based on 1000 virtual samples of size <span class="math inline">\(n\)</span> = 50 from the <code>bowl</code>. We’ll compare this to the bootstrap distribution of <span class="math inline">\(\widehat{p}\)</span> from Section <a href="9-confidence-intervals.html#ilyas-yohan">9.5.1</a> based on 1000 resamples with replacement from Ilyas and Yohan’s sample of 50 balls saved in <code>bowl_sample_1</code>.</p>
<div id="sampling-distribution" class="section level4 unnumbered">
<h4>Sampling distribution</h4>
<p>Here is the code you previously saw in Section <a href="8-sampling.html#shovel-1000-times">8.2.3</a> to construct the sampling distribution of <span class="math inline">\(\widehat{p}\)</span>, with some small changes to incorporate the statistical terminology relating to sampling you learned in Section <a href="8-sampling.html#terminology-and-notation">8.3.1</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:sampling-distribution-part-deux"></span>
<img src="moderndive_files/figure-html/sampling-distribution-part-deux-1.png" alt="Previously seen sampling distribution of sample proportion red for $n = 1000$." width="\textwidth" />
<p class="caption">
FIGURE 9.35: Previously seen sampling distribution of sample proportion red for <span class="math inline">\(n = 1000\)</span>.
</p>
</div>
<p>An important thing to keep in mind is the default value for <code>replace</code> is <code>FALSE</code> when using <code>rep_sample_n()</code>. This is because when sampling 50 balls with a shovel, we are extracting 50 balls one-by-one <em>without</em> replacing them. This is in contrast to bootstrap resampling <em>with</em> replacement, where we resample a ball and put it back, and repeat this process 50 times.</p>
<p>We can also examine the variability in this sampling distribution by calculating the standard deviation of the <code>propr_red</code> variable representing 1000 values of the sample proportion <span class="math inline">\(\widehat{p}\)</span>. Remember that the standard deviation of the sampling distribution is the <strong>standard error</strong>, frequently denoted as <code>se</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r">sampling_distribution <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">se =</span> <span class="kw">sd</span>(prop_red))</code></pre>
<pre><code># A tibble: 1 x 1
         se
      &lt;dbl&gt;
1 0.0673987</code></pre>
</div>
<div id="bootstrap-distribution" class="section level4 unnumbered">
<h4>Bootstrap distribution</h4>
<p>Here is the code you previously saw in Section <a href="9-confidence-intervals.html#ilyas-yohan">9.5.1</a> to construct the bootstrap distribution of <span class="math inline">\(\widehat{p}\)</span> based on Ilyas and Yohan’s original sample of 50 balls saved in <code>bowl_sample_1</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Compute the bootstrap distribution using infer workflow:</span>
bootstrap_distribution &lt;-<span class="st"> </span>bowl_sample_<span class="dv">1</span> <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">specify</span>(<span class="dt">response =</span> color, <span class="dt">success =</span> <span class="st">&quot;red&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">generate</span>(<span class="dt">reps =</span> <span class="dv">1000</span>, <span class="dt">type =</span> <span class="st">&quot;bootstrap&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">calculate</span>(<span class="dt">stat =</span> <span class="st">&quot;prop&quot;</span>)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:bootstrap-distribution-part-deux"></span>
<img src="moderndive_files/figure-html/bootstrap-distribution-part-deux-1.png" alt="Bootstrap distribution of sample proportion red for $n = 1000$." width="\textwidth" />
<p class="caption">
FIGURE 9.36: Bootstrap distribution of sample proportion red for <span class="math inline">\(n = 1000\)</span>.
</p>
</div>
<pre class="sourceCode r"><code class="sourceCode r">bootstrap_distribution <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">se =</span> <span class="kw">sd</span>(stat))</code></pre>
<pre><code># A tibble: 1 x 1
         se
      &lt;dbl&gt;
1 0.0693340</code></pre>
</div>
<div id="comparison" class="section level4 unnumbered">
<h4>Comparison</h4>
<p>Now that we have computed both the sampling distribution and the bootstrap distributions, let’s visualize them side-by-side in Figure <a href="9-confidence-intervals.html#fig:side-by-side">9.37</a>. We’ll make both histograms have the same scale on the x and y-axes to make them more comparable and add vertical red lines that denote the proportion of the bowl’s balls that are red <span class="math inline">\(p\)</span> = 0.375. Furthermore, we’ll add a vertical dashed line at Ilyas and Yohan’s value of the sample proportion <span class="math inline">\(\widehat{p}\)</span> = 21/50 = 0.42 = 42%.</p>
<div class="figure" style="text-align: center"><span id="fig:side-by-side"></span>
<img src="moderndive_files/figure-html/side-by-side-1.png" alt="Comparing the sampling and bootstrap distributions of $\widehat{p}$" width="\textwidth" />
<p class="caption">
FIGURE 9.37: Comparing the sampling and bootstrap distributions of <span class="math inline">\(\widehat{p}\)</span>
</p>
</div>
<p>There is a lot going on in this comparison, so let’s pick them apart slowly. First, notice how the sampling distribution in salmon is centered at <span class="math inline">\(p\)</span> = 0.375. This is because the sample is done at random in an unbiased fashion, so the estimates <span class="math inline">\(\widehat{p}\)</span> are centered at the true value of <span class="math inline">\(p\)</span>. This is actually an artifact of the Central Limit Theorem introduced in Chapter <a href="8-sampling.html#sampling">8</a>. The center of the sampling distribution is expected to be the value of the population parameter, in this case <span class="math inline">\(p\)</span>.</p>
<p>However, this is not the case with the bootstrap distribution in blue. The bootstrap distribution is centered at 0.42, which is the proportion red of Ilyas and Yohan’s 50 sampled balls. This is because we are resampling from the sample and not from the population. Since the bootstrap distribution is centered at the original sample proportion, it doesn’t necessarily provide a good estimate of the overall population proportion <span class="math inline">\(p\)</span>, which we calculated to be 0.375. This leads us to our first lesson about bootstrapping:</p>
<blockquote>
<p>The bootstrap distribution will likely not have the same center as the sampling distribution. In other words, bootstrapping cannot improve the quality of an estimate resulting from a single sample.</p>
</blockquote>
<p>However, let’s now visually compare the spread of the two distributions; they are somewhat similar. In fact, we computed the standard deviations of both distributions earlier. Let’s compare them in Table <a href="9-confidence-intervals.html#tab:comparing-se">9.6</a></p>
<table class="table" style="font-size: 16px; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:comparing-se">TABLE 9.6: </span>Comparing standard errors
</caption>
<thead>
<tr>
<th style="text-align:left;">
Distribution type
</th>
<th style="text-align:right;">
Standard error
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Sampling distribution
</td>
<td style="text-align:right;">
0.067
</td>
</tr>
<tr>
<td style="text-align:left;">
Bootstrap distribution
</td>
<td style="text-align:right;">
0.069
</td>
</tr>
</tbody>
</table>
<p>Notice that the bootstrap distribution’s standard error is a good approximation to the sampling distribution’s standard error. This leads us to our second lesson about bootstrapping:</p>
<blockquote>
<p>Even if the bootstrap distribution might not have the same center as the sampling distribution, it will likely have a very similar spread. In other words, bootstrapping will give you a good estimate of the standard error using only a single sample.</p>
</blockquote>
<p>Using the fact that the bootstrap distribution and sampling distributions have similar spreads, we can build confidence intervals using bootstrapping as we’ve done all throughout this chapter!</p>
</div>
</div>
<div id="theory-ci" class="section level3">
<h3><span class="header-section-number">9.7.2</span> Theory-based confidence intervals</h3>
<p>So far in this chapter, we’ve constructed confidence intervals using two methods: the percentile method and the standard error method. Recall from Section <a href="9-confidence-intervals.html#se-method">9.3.2</a> however that we can only use the standard-error method of the bootstrap distribution is bell-shaped i.e. normally distributed. If this is the case, however, there is another method for constructing confidence intervals that do not involve using your computer to do resampling with replacement. There actually is a theory-based method involving a mathematical formula!</p>
<p>The formula uses the rule of thumb we saw in Subsection <a href="8-sampling.html#normal-distribution">8.5.3</a> that 95% of values in a normal distribution are within <span class="math inline">\(\pm 1.96\)</span> standard deviations of the mean. In the case of sampling and bootstrap distributions, recall that the standard deviation has a special name: the <em>standard error</em>. Furthermore, there is in many cases a formula that approximates the standard error! In the case of our <code>bowl</code> where we used the sample proportion red <span class="math inline">\(\widehat{p}\)</span> to estimate the proportion of the bowl’s balls that are red, the formula that approximates the standard error is:</p>
<p><span class="math display">\[\text{SE}_{\widehat{p}} \approx \sqrt{\frac{\widehat{p}(1-\widehat{p})}{n}}\]</span></p>
<p>For example, recall from Table <a href="8-sampling.html#tab:tactile-red1">8.1</a> that Yohan and Ilyas sampled <span class="math inline">\(n\)</span> = 50 balls and observed a sample proportion <span class="math inline">\(\widehat{p}\)</span> of 21/50 = 0.42 = 42%. So using the approximation of the standard error is</p>
<p><span class="math display">\[\text{SE}_{\widehat{p}} \approx \sqrt{\frac{0.42(1-0.42)}{50}} = \sqrt{0.004872} = 0.0698\]</span></p>
<p>The key observation to make here is that there is an <span class="math inline">\(n\)</span> in the denominator. In other words, as the sample size <span class="math inline">\(n\)</span> increases, the standard error decreases. We’ve demonstrated this fact this using virtual simulation in Section <a href="8-sampling.html#moral-of-the-story">8.3.3</a>. If you don’t recall this demonstration, we highly recommend you go back and read that section.</p>
<p>So going back to Yohan and Ilyas’ sample proportion of <span class="math inline">\(\widehat{p}\)</span> of 21/50 = 0.42 = 42%, say this were based on a sample of size <span class="math inline">\(n\)</span>=100 instead of 50. Then the standard error would be:</p>
<p><span class="math display">\[\text{SE}_{\widehat{p}} \approx \sqrt{\frac{0.42(1-0.42)}{100}} = \sqrt{0.002436} = 0.0494\]</span></p>
<p>Observe that the standard error has gone done from 0.0698 to 0.0494. In other words, this particular estimate is more <em>precise</em>. Recall that we illustrated the difference between accuracy and precision of estimates in Figure <a href="8-sampling.html#fig:accuracy-vs-precision">8.16</a>.</p>
<p>Why is this formula true? Unfortunately, we don’t have the tools at this point to prove this; you’ll need to take a more advanced course in probability and statistics.</p>
<div id="theory-based-method-for-constructing-confidence-intervals" class="section level4 unnumbered">
<h4>Theory-based method for constructing confidence intervals</h4>
<p>We now present a third method for constructing a 95% confidence interval for <span class="math inline">\(p\)</span> that does not involve bootstrap resampling with replacement, but rather mathematical formulas. It is critical to remember that this method holds only if the sampling distribution is normally shaped.</p>
<ol style="list-style-type: decimal">
<li>Collect a single representative sample of size <span class="math inline">\(n\)</span> that’s as large as possible.</li>
<li>Compute the point estimate: the sample proportion <span class="math inline">\(\widehat{p}\)</span>. Think of this as the center of your net.</li>
<li>Compute the approximation to the standard error</li>
</ol>
<p><span class="math display">\[\text{SE}_{\widehat{p}} \approx \sqrt{\frac{\widehat{p}(1-\widehat{p})}{n}}\]</span></p>
<ol style="list-style-type: decimal">
<li>Compute a quantity known as the <em>margin of error</em> (more later):</li>
</ol>
<p><span class="math display">\[\text{MoE}_{\widehat{p}} = 1.96 \cdot \text{SE}_{\widehat{p}} =  1.96 \cdot \sqrt{\frac{\widehat{p}(1-\widehat{p})}{n}}\]</span></p>
<ol style="list-style-type: decimal">
<li>Compute both endpoints of the confidence interval.
<ul>
<li><p>The lower end-point <code>lower_ci</code>. Think of this as the left end-point of the net:
<span class="math display">\[\widehat{p} - \text{MoE}_{\widehat{p}} = \widehat{p} - 1.96 \cdot \text{SE}_{\widehat{p}} = \widehat{p} - 1.96 \cdot \sqrt{\frac{\widehat{p}(1-\widehat{p})}{n}}\]</span></p></li>
<li><p>The upper endpoint <code>upper_ci</code>. Think of this as the right end-point of the net:
<span class="math display">\[\widehat{p} + \text{MoE}_{\widehat{p}} = \widehat{p} + 1.96 \cdot \text{SE}_{\widehat{p}} = \widehat{p} + 1.96 \cdot \sqrt{\frac{\widehat{p}(1-\widehat{p})}{n}}\]</span></p></li>
<li><p>Alternatively, you can succinctly summarize a 95% confidence interval for <span class="math inline">\(p\)</span> using the <span class="math inline">\(\pm\)</span> symbol:</p></li>
</ul>
<span class="math display">\[\widehat{p} \pm \text{MoE}_{\widehat{p}} = \widehat{p} \pm 1.96 \cdot \text{SE}_{\widehat{p}} = \widehat{p} \pm 1.96 \cdot \sqrt{\frac{\widehat{p}(1-\widehat{p})}{n}}\]</span></li>
</ol>
<p>So going back to Yohan and Ilyas’ sample of <span class="math inline">\(n=50\)</span> balls that had 21 red balls, the 95% confidence interval for <span class="math inline">\(p\)</span> is 0.42 <span class="math inline">\(\pm\)</span> 1.96 <span class="math inline">\(\cdot\)</span> 0.0698 = 0.42 <span class="math inline">\(\pm\)</span> 0.137 = (0.42 - 0.137, 0.42 + 0.137) = (0.283, 0.557). In other words, Yohan and Ilyas are 95% “confident” that the true proportion red of the bowl’s balls is between 28.3% and 55.7%. Given that the true population proportion <span class="math inline">\(p\)</span> was 37.5%, they successfully captured the fish.</p>
<p>In Step 4 above, we defined the  <em>margin of error</em>. You can think of this quantity as how much the net extends to the left and to the right of the center of our net. The 1.96 multiplier roots in the 95% rule of thumb we introduced earlier and the fact that we want the confidence level to be 95%. The value of the margin error entirely determines the width of the confidence interval. Recall from Section <a href="9-confidence-intervals.html#ci-width">9.5.3</a> that confidence interval widths are determined by an interplay of the confidence level, the sample size <span class="math inline">\(n\)</span>, and the standard error.</p>
<p>Let’s study a real-life example by revisiting the poll of President Obama’s approval rating among young Americans aged 18-29 in the 2013 National Public Radio article <a href="https://www.npr.org/sections/itsallpolitics/2013/12/04/248793753/poll-support-for-obama-among-young-americans-eroding">Poll: Support For Obama Among Young Americans Eroding</a>. Pollsters found that based on a representative sample of <span class="math inline">\(n\)</span> = 2089 young Americans, <span class="math inline">\(\widehat{p}\)</span> = 0.41 = 41% supported President Obama.</p>
<p>If you look towards the end of the article, it states: “The poll’s margin of error was plus or minus 2.1 percentage points.” This is precisely the <span class="math inline">\(\text{MoE}\)</span> from above:</p>
<p><span class="math display">\[
\begin{aligned}
\text{MoE} &amp;= 1.96 \cdot \text{SE} =  1.96 \cdot \sqrt{\frac{\widehat{p}(1-\widehat{p})}{n}} = 1.96 \cdot \sqrt{\frac{0.41(1-0.41)}{2089}} \\
&amp;= 1.96 \cdot 0.0108 = 0.021
\end{aligned}
\]</span></p>
<p>Thus their poll results are based on a confidence level of 95% and the resulting 95% confidence interval for the proportion of all young Americans who support Obama is: <span class="math inline">\(\widehat{p} \pm \text{MoE}\)</span> = 0.42 <span class="math inline">\(\pm\)</span> 0.021 = (0.339, 0.441) = (33.9%, 44.1%)</p>
</div>
<div id="confidence-intervals-based-on-33-tactile-samples" class="section level4 unnumbered">
<h4>Confidence intervals based on 33 tactile samples</h4>
<p>Let’s revisit our 33 friend’s samples from the <code>bowl</code> from Section <a href="8-sampling.html#student-shovels">8.1.3</a>. Recall this data was saved in the <code>tactile_prop_red</code> data frame included in the <code>moderndive</code> package. We’ll then apply the theory-based procedure for constructing confidence intervals for <span class="math inline">\(p\)</span> using some of the <code>dplyr</code> data wrangling tools seen in Chapter <a href="4-wrangling.html#wrangling">4</a>:</p>
<ol style="list-style-type: decimal">
<li>Rename <code>prop_red</code> to <code>p_hat</code>, the statistical name of the sample proportion <span class="math inline">\(\widehat{p}\)</span>.</li>
<li>Make explicit the sample size <code>n</code> of <span class="math inline">\(n\)</span> = 50</li>
<li>Compute the:
<ul>
<li>Standard error <code>SE</code> for <span class="math inline">\(\widehat{p}\)</span> using the formula above.</li>
<li>Margin of error <code>MoE</code> by multiplying the <code>SE</code> by 1.96</li>
<li>Left endpoint of the confidence interval <code>lower_ci</code></li>
<li>Right endpoint of the confidence interval <code>upper_ci</code></li>
</ul></li>
</ol>
<pre class="sourceCode r"><code class="sourceCode r">conf_ints &lt;-<span class="st"> </span>tactile_prop_red <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">rename</span>(<span class="dt">p_hat =</span> prop_red) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(
    <span class="dt">n =</span> <span class="dv">50</span>,
    <span class="dt">SE =</span> <span class="kw">sqrt</span>(p_hat <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>p_hat) <span class="op">/</span><span class="st"> </span>n),
    <span class="dt">MoE =</span> <span class="fl">1.96</span> <span class="op">*</span><span class="st"> </span>SE,
    <span class="dt">lower_ci =</span> p_hat <span class="op">-</span><span class="st"> </span>MoE,
    <span class="dt">upper_ci =</span> p_hat <span class="op">+</span><span class="st"> </span>MoE
  )
conf_ints</code></pre>
<pre><code># A tibble: 33 x 9
   group    replicate red_balls p_hat     n        SE      MoE lower_ci upper_ci
   &lt;chr&gt;        &lt;int&gt;     &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;
 1 Ilyas, …         1        21  0.42    50 0.0697997 0.136807 0.283193 0.556807
 2 Morgan,…         2        17  0.34    50 0.0669925 0.131305 0.208695 0.471305
 3 Martin,…         3        21  0.42    50 0.0697997 0.136807 0.283193 0.556807
 4 Clark, …         4        21  0.42    50 0.0697997 0.136807 0.283193 0.556807
 5 Riddhi,…         5        18  0.36    50 0.0678823 0.133049 0.226951 0.493049
 6 Andrew,…         6        19  0.38    50 0.0686440 0.134542 0.245458 0.514542
 7 Julia            7        19  0.38    50 0.0686440 0.134542 0.245458 0.514542
 8 Rachel,…         8        11  0.22    50 0.0585833 0.114823 0.105177 0.334823
 9 Daniel,…         9        15  0.3     50 0.0648074 0.127023 0.172977 0.427023
10 Josh, M…        10        17  0.34    50 0.0669925 0.131305 0.208695 0.471305
# … with 23 more rows</code></pre>
<p>Let’s plot now plot the 33 confidence intervals for <span class="math inline">\(p\)</span> saved in <code>conf_ints</code> along with a vertical red line at <span class="math inline">\(p\)</span> = 0.375 = 37.5% indicating the true proportion of the <code>bowl</code>’s balls that are red in Figure <a href="9-confidence-intervals.html#fig:tactile-conf-int">9.38</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:tactile-conf-int"></span>
<img src="moderndive_files/figure-html/tactile-conf-int-1.png" alt="33 95 percent confidence intervals based on 33 tactile samples of size n = 50." width="\textwidth" />
<p class="caption">
FIGURE 9.38: 33 95 percent confidence intervals based on 33 tactile samples of size n = 50.
</p>
</div>
<p>Observe that 31 of the 33 confidence intervals “captured” the true value of <span class="math inline">\(p\)</span>, for a success rate of 31 / 33 = 93.94%. While this is not quite 95%, recall that we <em>expect</em> about 95% of such confidence intervals to capture <span class="math inline">\(p\)</span>, the actual observed success rate will vary.</p>
<p>Theoretical-based methods like this have largely been used in the past because we didn’t have the computing power to perform simulation-based methods such as bootstrapping. They are still commonly used though and if the sampling and bootstrap distributions are normality distributed, they can provide a nice option for constructing confidence intervals as well as performing hypothesis tests as we will see in Chapter <a href="10-hypothesis-testing.html#hypothesis-testing">10</a>.</p>
<!--
Albert: This section is getting hella long, so will comment this out for now. Let's consider adding 
it back if we have room in book.

#### Confidence intervals based on 100 virtual samples {-}

Let's say however, we repeated the above 100 times, not tactilely, but virtually. Let's do this only 100 times instead of 1000 like we did before so that the results can fit on the screen. Again, the steps for compute a 95% confidence interval for $p$ are:

1. Collect a sample of size $n = 50$ as we did in Chapter \@ref(sampling)
1. Compute $\widehat{p}$: the sample proportion red of these $n$ = 50 balls
1. Compute the standard error $\text{SE} = \sqrt{\frac{\widehat{p}(1-\widehat{p})}{n}}$
1. Compute the margin of error $\text{MoE} = 1.96 \cdot \text{SE} =  1.96 \cdot \sqrt{\frac{\widehat{p}(1-\widehat{p})}{n}}$
1. Compute both end points of the confidence interval:
    + `lower_ci`: $\widehat{p} - \text{MoE} = \widehat{p} - 1.96 \cdot \text{SE} = \widehat{p} - 1.96 \cdot \sqrt{\frac{\widehat{p}(1-\widehat{p})}{n}}$
    + `upper_ci`: $\widehat{p} + \text{MoE} = \widehat{p} + 1.96 \cdot \text{SE} = \widehat{p} +1.96 \cdot \sqrt{\frac{\widehat{p}(1-\widehat{p})}{n}}$

Run the following three steps, being sure to `View()` the resulting data frame after each step so you can convince yourself of what's going on:


```r
# First: Take 100 virtual samples of n=50 balls
virtual_samples <- bowl %>% 
  rep_sample_n(size = 50, reps = 100)

# Second: For each virtual sample compute the proportion red
virtual_prop_red <- virtual_samples %>% 
  group_by(replicate) %>% 
  summarize(red = sum(color == "red")) %>% 
  mutate(prop_red = red / 50)

# Third: Compute the 95% confidence interval as above
virtual_prop_red <- virtual_prop_red %>% 
  rename(p_hat = prop_red) %>% 
  mutate(
    n = 50,
    SE = sqrt(p_hat*(1-p_hat)/n),
    MoE = 1.96 * SE,
    lower_ci = p_hat - MoE,
    upper_ci = p_hat + MoE
  )
```

Here are the results:



We see that of our 100 confidence intervals based on samples of size $n$ = 50, `sum(virtual_prop_red[["captured"]])` of them captured the true $p = 900/2400$, whereas `100 - sum(virtual_prop_red[["captured"]])` of them missed. As we create more and more confidence intervals based on more and more samples, about 95% of these intervals will capture. In other words our procedure is "95% reliable." 
-->
</div>
</div>
<div id="additional-resources-6" class="section level3">
<h3><span class="header-section-number">9.7.3</span> Additional resources</h3>
<p>An R script file of all R code used in this chapter is available <a href="scripts/09-confidence-intervals.R">here</a>.</p>
<p>If you want to more examples of the <code>infer</code> workflow to construct confidence intervals, we suggest you check out the <code>infer</code> package homepage, in particular, a series of example analyses available at <a href="https://infer.netlify.com/articles/" class="uri">https://infer.netlify.com/articles/</a>.</p>
</div>
<div id="whats-to-come-7" class="section level3">
<h3><span class="header-section-number">9.7.4</span> What’s to come?</h3>
<p>Now that we’ve equipped ourselves with confidence intervals, in Chapter <a href="10-hypothesis-testing.html#hypothesis-testing">10</a> we’ll cover the other common tool for statistical inference: hypothesis testing.</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="8-sampling.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="10-hypothesis-testing.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/moderndive/moderndive_book/edit/master/09-confidence-intervals.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
