<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 10 Hypothesis Testing | Statistical Inference via Data Science</title>
  <meta name="description" content="An open-source and fully-reproducible electronic textbook for teaching statistical inference using tidyverse data science tools." />
  <meta name="generator" content="bookdown 0.11 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 10 Hypothesis Testing | Statistical Inference via Data Science" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://moderndive.com/" />
  <meta property="og:image" content="https://moderndive.com/images/logos/book_cover.png" />
  <meta property="og:description" content="An open-source and fully-reproducible electronic textbook for teaching statistical inference using tidyverse data science tools." />
  <meta name="github-repo" content="moderndive/moderndive_book" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 10 Hypothesis Testing | Statistical Inference via Data Science" />
  
  <meta name="twitter:description" content="An open-source and fully-reproducible electronic textbook for teaching statistical inference using tidyverse data science tools." />
  <meta name="twitter:image" content="https://moderndive.com/images/logos/book_cover.png" />

<meta name="author" content="Chester Ismay and Albert Y. Kim" />


<meta name="date" content="2019-08-07" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  <link rel="apple-touch-icon-precomposed" sizes="152x152" href="images/logos/favicons/apple-touch-icon.png" />
  <link rel="shortcut icon" href="images/logos/favicons/favicon.ico" type="image/x-icon" />
<link rel="prev" href="9-confidence-intervals.html">
<link rel="next" href="11-inference-for-regression.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<script src="libs/htmlwidgets-1.3/htmlwidgets.js"></script>
<link href="libs/dygraphs-1.1.1/dygraph.css" rel="stylesheet" />
<script src="libs/dygraphs-1.1.1/dygraph-combined.js"></script>
<script src="libs/dygraphs-1.1.1/shapes.js"></script>
<script src="libs/moment-2.8.4/moment.js"></script>
<script src="libs/moment-timezone-0.2.5/moment-timezone-with-data.js"></script>
<script src="libs/moment-fquarter-1.0.0/moment-fquarter.min.js"></script>
<script src="libs/dygraphs-binding-1.1.1.6/dygraphs.js"></script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-89938436-1', 'auto');
  ga('send', 'pageview');

</script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#sec:intro-for-students"><i class="fa fa-check"></i><b>1.1</b> Introduction for students</a><ul>
<li class="chapter" data-level="1.1.1" data-path="index.html"><a href="index.html#subsec:learning-goals"><i class="fa fa-check"></i><b>1.1.1</b> What you will learn from this book</a></li>
<li class="chapter" data-level="1.1.2" data-path="index.html"><a href="index.html#subsec:pipeline"><i class="fa fa-check"></i><b>1.1.2</b> Data/science pipeline</a></li>
<li class="chapter" data-level="1.1.3" data-path="index.html"><a href="index.html#subsec:reproducible"><i class="fa fa-check"></i><b>1.1.3</b> Reproducible research</a></li>
<li class="chapter" data-level="1.1.4" data-path="index.html"><a href="index.html#final-note-for-students"><i class="fa fa-check"></i><b>1.1.4</b> Final note for students</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#sec:intro-instructors"><i class="fa fa-check"></i><b>1.2</b> Introduction for instructors</a><ul>
<li class="chapter" data-level="1.2.1" data-path="index.html"><a href="index.html#who-is-this-book-for"><i class="fa fa-check"></i><b>1.2.1</b> Who is this book for?</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#sec:connect-contribute"><i class="fa fa-check"></i><b>1.3</b> Connect and contribute</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#sec:about-book"><i class="fa fa-check"></i><b>1.4</b> About this book</a></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#sec:about-authors"><i class="fa fa-check"></i><b>1.5</b> About the authors</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="2-getting-started.html"><a href="2-getting-started.html"><i class="fa fa-check"></i><b>2</b> Getting Started with Data in R</a><ul>
<li class="chapter" data-level="2.1" data-path="2-getting-started.html"><a href="2-getting-started.html#r-rstudio"><i class="fa fa-check"></i><b>2.1</b> What are R and RStudio?</a><ul>
<li class="chapter" data-level="2.1.1" data-path="2-getting-started.html"><a href="2-getting-started.html#installing-r-and-rstudio"><i class="fa fa-check"></i><b>2.1.1</b> Installing R and RStudio</a></li>
<li class="chapter" data-level="2.1.2" data-path="2-getting-started.html"><a href="2-getting-started.html#using-r-via-rstudio"><i class="fa fa-check"></i><b>2.1.2</b> Using R via RStudio</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="2-getting-started.html"><a href="2-getting-started.html#code"><i class="fa fa-check"></i><b>2.2</b> How do I code in R?</a><ul>
<li class="chapter" data-level="2.2.1" data-path="2-getting-started.html"><a href="2-getting-started.html#programming-concepts"><i class="fa fa-check"></i><b>2.2.1</b> Basic programming concepts and terminology</a></li>
<li class="chapter" data-level="2.2.2" data-path="2-getting-started.html"><a href="2-getting-started.html#errors-warnings-and-messages"><i class="fa fa-check"></i><b>2.2.2</b> Errors, warnings, and messages</a></li>
<li class="chapter" data-level="2.2.3" data-path="2-getting-started.html"><a href="2-getting-started.html#tips-on-learning-to-code"><i class="fa fa-check"></i><b>2.2.3</b> Tips on learning to code</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="2-getting-started.html"><a href="2-getting-started.html#packages"><i class="fa fa-check"></i><b>2.3</b> What are R packages?</a><ul>
<li class="chapter" data-level="2.3.1" data-path="2-getting-started.html"><a href="2-getting-started.html#package-installation"><i class="fa fa-check"></i><b>2.3.1</b> Package installation</a></li>
<li class="chapter" data-level="2.3.2" data-path="2-getting-started.html"><a href="2-getting-started.html#package-loading"><i class="fa fa-check"></i><b>2.3.2</b> Package loading</a></li>
<li class="chapter" data-level="2.3.3" data-path="2-getting-started.html"><a href="2-getting-started.html#package-use"><i class="fa fa-check"></i><b>2.3.3</b> Package use</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="2-getting-started.html"><a href="2-getting-started.html#nycflights13"><i class="fa fa-check"></i><b>2.4</b> Explore your first datasets</a><ul>
<li class="chapter" data-level="2.4.1" data-path="2-getting-started.html"><a href="2-getting-started.html#nycflights13-package"><i class="fa fa-check"></i><b>2.4.1</b> <code>nycflights13</code> package</a></li>
<li class="chapter" data-level="2.4.2" data-path="2-getting-started.html"><a href="2-getting-started.html#flights-data-frame"><i class="fa fa-check"></i><b>2.4.2</b> <code>flights</code> data frame</a></li>
<li class="chapter" data-level="2.4.3" data-path="2-getting-started.html"><a href="2-getting-started.html#exploredataframes"><i class="fa fa-check"></i><b>2.4.3</b> Exploring data frames</a></li>
<li class="chapter" data-level="2.4.4" data-path="2-getting-started.html"><a href="2-getting-started.html#identification-vs-measurement-variables"><i class="fa fa-check"></i><b>2.4.4</b> Identification &amp; measurement variables</a></li>
<li class="chapter" data-level="2.4.5" data-path="2-getting-started.html"><a href="2-getting-started.html#help-files"><i class="fa fa-check"></i><b>2.4.5</b> Help files</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="2-getting-started.html"><a href="2-getting-started.html#conclusion"><i class="fa fa-check"></i><b>2.5</b> Conclusion</a><ul>
<li class="chapter" data-level="2.5.1" data-path="2-getting-started.html"><a href="2-getting-started.html#additional-resources"><i class="fa fa-check"></i><b>2.5.1</b> Additional resources</a></li>
<li class="chapter" data-level="2.5.2" data-path="2-getting-started.html"><a href="2-getting-started.html#whats-to-come"><i class="fa fa-check"></i><b>2.5.2</b> What’s to come?</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>I Data Science via the tidyverse</b></span></li>
<li class="chapter" data-level="3" data-path="3-viz.html"><a href="3-viz.html"><i class="fa fa-check"></i><b>3</b> Data Visualization</a><ul>
<li class="chapter" data-level="" data-path="3-viz.html"><a href="3-viz.html#needed-packages"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="3.1" data-path="3-viz.html"><a href="3-viz.html#grammarofgraphics"><i class="fa fa-check"></i><b>3.1</b> The Grammar of Graphics</a><ul>
<li class="chapter" data-level="3.1.1" data-path="3-viz.html"><a href="3-viz.html#components-of-the-grammar"><i class="fa fa-check"></i><b>3.1.1</b> Components of the Grammar</a></li>
<li class="chapter" data-level="3.1.2" data-path="3-viz.html"><a href="3-viz.html#gapminder"><i class="fa fa-check"></i><b>3.1.2</b> Gapminder data</a></li>
<li class="chapter" data-level="3.1.3" data-path="3-viz.html"><a href="3-viz.html#other-components"><i class="fa fa-check"></i><b>3.1.3</b> Other components</a></li>
<li class="chapter" data-level="3.1.4" data-path="3-viz.html"><a href="3-viz.html#ggplot2-package"><i class="fa fa-check"></i><b>3.1.4</b> ggplot2 package</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="3-viz.html"><a href="3-viz.html#FiveNG"><i class="fa fa-check"></i><b>3.2</b> Five Named Graphs - The 5NG</a></li>
<li class="chapter" data-level="3.3" data-path="3-viz.html"><a href="3-viz.html#scatterplots"><i class="fa fa-check"></i><b>3.3</b> 5NG#1: Scatterplots</a><ul>
<li class="chapter" data-level="3.3.1" data-path="3-viz.html"><a href="3-viz.html#geompoint"><i class="fa fa-check"></i><b>3.3.1</b> Scatterplots via geom_point</a></li>
<li class="chapter" data-level="3.3.2" data-path="3-viz.html"><a href="3-viz.html#overplotting"><i class="fa fa-check"></i><b>3.3.2</b> Over-plotting</a></li>
<li class="chapter" data-level="3.3.3" data-path="3-viz.html"><a href="3-viz.html#summary"><i class="fa fa-check"></i><b>3.3.3</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="3-viz.html"><a href="3-viz.html#linegraphs"><i class="fa fa-check"></i><b>3.4</b> 5NG#2: Linegraphs</a><ul>
<li class="chapter" data-level="3.4.1" data-path="3-viz.html"><a href="3-viz.html#geomline"><i class="fa fa-check"></i><b>3.4.1</b> Linegraphs via geom_line</a></li>
<li class="chapter" data-level="3.4.2" data-path="3-viz.html"><a href="3-viz.html#summary-1"><i class="fa fa-check"></i><b>3.4.2</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="3-viz.html"><a href="3-viz.html#histograms"><i class="fa fa-check"></i><b>3.5</b> 5NG#3: Histograms</a><ul>
<li class="chapter" data-level="3.5.1" data-path="3-viz.html"><a href="3-viz.html#geomhistogram"><i class="fa fa-check"></i><b>3.5.1</b> Histograms via geom_histogram</a></li>
<li class="chapter" data-level="3.5.2" data-path="3-viz.html"><a href="3-viz.html#adjustbins"><i class="fa fa-check"></i><b>3.5.2</b> Adjusting the bins</a></li>
<li class="chapter" data-level="3.5.3" data-path="3-viz.html"><a href="3-viz.html#summary-2"><i class="fa fa-check"></i><b>3.5.3</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="3-viz.html"><a href="3-viz.html#facets"><i class="fa fa-check"></i><b>3.6</b> Facets</a></li>
<li class="chapter" data-level="3.7" data-path="3-viz.html"><a href="3-viz.html#boxplots"><i class="fa fa-check"></i><b>3.7</b> 5NG#4: Boxplots</a><ul>
<li class="chapter" data-level="3.7.1" data-path="3-viz.html"><a href="3-viz.html#geomboxplot"><i class="fa fa-check"></i><b>3.7.1</b> Boxplots via geom_boxplot</a></li>
<li class="chapter" data-level="3.7.2" data-path="3-viz.html"><a href="3-viz.html#summary-3"><i class="fa fa-check"></i><b>3.7.2</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="3-viz.html"><a href="3-viz.html#geombar"><i class="fa fa-check"></i><b>3.8</b> 5NG#5: Barplots</a><ul>
<li class="chapter" data-level="3.8.1" data-path="3-viz.html"><a href="3-viz.html#barplots-via-geom_bar-or-geom_col"><i class="fa fa-check"></i><b>3.8.1</b> Barplots via geom_bar or geom_col</a></li>
<li class="chapter" data-level="3.8.2" data-path="3-viz.html"><a href="3-viz.html#must-avoid-pie-charts"><i class="fa fa-check"></i><b>3.8.2</b> Must avoid pie charts!</a></li>
<li class="chapter" data-level="3.8.3" data-path="3-viz.html"><a href="3-viz.html#two-categ-barplot"><i class="fa fa-check"></i><b>3.8.3</b> Two categorical variables</a></li>
<li class="chapter" data-level="3.8.4" data-path="3-viz.html"><a href="3-viz.html#summary-4"><i class="fa fa-check"></i><b>3.8.4</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="3-viz.html"><a href="3-viz.html#conclusion-1"><i class="fa fa-check"></i><b>3.9</b> Conclusion</a><ul>
<li class="chapter" data-level="3.9.1" data-path="3-viz.html"><a href="3-viz.html#summary-table"><i class="fa fa-check"></i><b>3.9.1</b> Summary table</a></li>
<li class="chapter" data-level="3.9.2" data-path="3-viz.html"><a href="3-viz.html#argument-specification"><i class="fa fa-check"></i><b>3.9.2</b> Argument specification</a></li>
<li class="chapter" data-level="3.9.3" data-path="3-viz.html"><a href="3-viz.html#additional-resources-1"><i class="fa fa-check"></i><b>3.9.3</b> Additional resources</a></li>
<li class="chapter" data-level="3.9.4" data-path="3-viz.html"><a href="3-viz.html#whats-to-come-3"><i class="fa fa-check"></i><b>3.9.4</b> What’s to come</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="4-wrangling.html"><a href="4-wrangling.html"><i class="fa fa-check"></i><b>4</b> Data Wrangling</a><ul>
<li class="chapter" data-level="" data-path="4-wrangling.html"><a href="4-wrangling.html#needed-packages-1"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="4.1" data-path="4-wrangling.html"><a href="4-wrangling.html#piping"><i class="fa fa-check"></i><b>4.1</b> The pipe operator: <code>%&gt;%</code></a></li>
<li class="chapter" data-level="4.2" data-path="4-wrangling.html"><a href="4-wrangling.html#filter"><i class="fa fa-check"></i><b>4.2</b> <code>filter</code> rows</a></li>
<li class="chapter" data-level="4.3" data-path="4-wrangling.html"><a href="4-wrangling.html#summarize"><i class="fa fa-check"></i><b>4.3</b> <code>summarize</code> variables</a></li>
<li class="chapter" data-level="4.4" data-path="4-wrangling.html"><a href="4-wrangling.html#groupby"><i class="fa fa-check"></i><b>4.4</b> <code>group_by</code> rows</a><ul>
<li class="chapter" data-level="4.4.1" data-path="4-wrangling.html"><a href="4-wrangling.html#grouping-by-more-than-one-variable"><i class="fa fa-check"></i><b>4.4.1</b> Grouping by more than one variable</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="4-wrangling.html"><a href="4-wrangling.html#mutate"><i class="fa fa-check"></i><b>4.5</b> <code>mutate</code> existing variables</a></li>
<li class="chapter" data-level="4.6" data-path="4-wrangling.html"><a href="4-wrangling.html#arrange"><i class="fa fa-check"></i><b>4.6</b> <code>arrange</code> and sort rows</a></li>
<li class="chapter" data-level="4.7" data-path="4-wrangling.html"><a href="4-wrangling.html#joins"><i class="fa fa-check"></i><b>4.7</b> <code>join</code> data frames</a><ul>
<li class="chapter" data-level="4.7.1" data-path="4-wrangling.html"><a href="4-wrangling.html#matching-key-variable-names"><i class="fa fa-check"></i><b>4.7.1</b> Matching “key” variable names</a></li>
<li class="chapter" data-level="4.7.2" data-path="4-wrangling.html"><a href="4-wrangling.html#diff-key"><i class="fa fa-check"></i><b>4.7.2</b> Different “key” variable names</a></li>
<li class="chapter" data-level="4.7.3" data-path="4-wrangling.html"><a href="4-wrangling.html#multiple-key-variables"><i class="fa fa-check"></i><b>4.7.3</b> Multiple “key” variables</a></li>
<li class="chapter" data-level="4.7.4" data-path="4-wrangling.html"><a href="4-wrangling.html#normal-forms"><i class="fa fa-check"></i><b>4.7.4</b> Normal forms</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="4-wrangling.html"><a href="4-wrangling.html#other-verbs"><i class="fa fa-check"></i><b>4.8</b> Other verbs</a><ul>
<li class="chapter" data-level="4.8.1" data-path="4-wrangling.html"><a href="4-wrangling.html#select"><i class="fa fa-check"></i><b>4.8.1</b> <code>select</code> variables</a></li>
<li class="chapter" data-level="4.8.2" data-path="4-wrangling.html"><a href="4-wrangling.html#rename"><i class="fa fa-check"></i><b>4.8.2</b> <code>rename</code> variables</a></li>
<li class="chapter" data-level="4.8.3" data-path="4-wrangling.html"><a href="4-wrangling.html#top_n-values-of-a-variable"><i class="fa fa-check"></i><b>4.8.3</b> <code>top_n</code> values of a variable</a></li>
</ul></li>
<li class="chapter" data-level="4.9" data-path="4-wrangling.html"><a href="4-wrangling.html#conclusion-2"><i class="fa fa-check"></i><b>4.9</b> Conclusion</a><ul>
<li class="chapter" data-level="4.9.1" data-path="4-wrangling.html"><a href="4-wrangling.html#summary-table-1"><i class="fa fa-check"></i><b>4.9.1</b> Summary table</a></li>
<li class="chapter" data-level="4.9.2" data-path="4-wrangling.html"><a href="4-wrangling.html#additional-resources-2"><i class="fa fa-check"></i><b>4.9.2</b> Additional resources</a></li>
<li class="chapter" data-level="4.9.3" data-path="4-wrangling.html"><a href="4-wrangling.html#whats-to-come-1"><i class="fa fa-check"></i><b>4.9.3</b> What’s to come?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="5-tidy.html"><a href="5-tidy.html"><i class="fa fa-check"></i><b>5</b> Data Importing &amp; “Tidy” Data</a><ul>
<li class="chapter" data-level="" data-path="5-tidy.html"><a href="5-tidy.html#needed-packages-2"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="5.1" data-path="5-tidy.html"><a href="5-tidy.html#csv"><i class="fa fa-check"></i><b>5.1</b> Importing data</a><ul>
<li class="chapter" data-level="5.1.1" data-path="5-tidy.html"><a href="5-tidy.html#using-the-console"><i class="fa fa-check"></i><b>5.1.1</b> Using the console</a></li>
<li class="chapter" data-level="5.1.2" data-path="5-tidy.html"><a href="5-tidy.html#using-rstudios-interface"><i class="fa fa-check"></i><b>5.1.2</b> Using RStudio’s interface</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="5-tidy.html"><a href="5-tidy.html#tidy-data-ex"><i class="fa fa-check"></i><b>5.2</b> Tidy data</a><ul>
<li class="chapter" data-level="5.2.1" data-path="5-tidy.html"><a href="5-tidy.html#definition-of-tidy-data"><i class="fa fa-check"></i><b>5.2.1</b> Definition of “tidy” data</a></li>
<li class="chapter" data-level="5.2.2" data-path="5-tidy.html"><a href="5-tidy.html#converting-to-tidy-data"><i class="fa fa-check"></i><b>5.2.2</b> Converting to “tidy” data</a></li>
<li class="chapter" data-level="5.2.3" data-path="5-tidy.html"><a href="5-tidy.html#nycflights13-package-1"><i class="fa fa-check"></i><b>5.2.3</b> <code>nycflights13</code> package</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="5-tidy.html"><a href="5-tidy.html#case-study-tidy"><i class="fa fa-check"></i><b>5.3</b> Case study: Democracy in Guatemala</a></li>
<li class="chapter" data-level="5.4" data-path="5-tidy.html"><a href="5-tidy.html#conclusion-3"><i class="fa fa-check"></i><b>5.4</b> Conclusion</a><ul>
<li class="chapter" data-level="5.4.1" data-path="5-tidy.html"><a href="5-tidy.html#tidyverse-package"><i class="fa fa-check"></i><b>5.4.1</b> <code>tidyverse</code> package</a></li>
<li class="chapter" data-level="5.4.2" data-path="5-tidy.html"><a href="5-tidy.html#additional-resources-3"><i class="fa fa-check"></i><b>5.4.2</b> Additional resources</a></li>
<li class="chapter" data-level="5.4.3" data-path="5-tidy.html"><a href="5-tidy.html#whats-to-come-2"><i class="fa fa-check"></i><b>5.4.3</b> What’s to come?</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II Data Modeling via moderndive</b></span></li>
<li class="chapter" data-level="6" data-path="6-regression.html"><a href="6-regression.html"><i class="fa fa-check"></i><b>6</b> Basic Regression</a><ul>
<li class="chapter" data-level="" data-path="6-regression.html"><a href="6-regression.html#needed-packages-3"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="6.1" data-path="6-regression.html"><a href="6-regression.html#model1"><i class="fa fa-check"></i><b>6.1</b> One numerical explanatory variable</a><ul>
<li class="chapter" data-level="6.1.1" data-path="6-regression.html"><a href="6-regression.html#model1EDA"><i class="fa fa-check"></i><b>6.1.1</b> Exploratory data analysis</a></li>
<li class="chapter" data-level="6.1.2" data-path="6-regression.html"><a href="6-regression.html#model1table"><i class="fa fa-check"></i><b>6.1.2</b> Simple linear regression</a></li>
<li class="chapter" data-level="6.1.3" data-path="6-regression.html"><a href="6-regression.html#model1points"><i class="fa fa-check"></i><b>6.1.3</b> Observed/fitted values and residuals</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="6-regression.html"><a href="6-regression.html#model2"><i class="fa fa-check"></i><b>6.2</b> One categorical explanatory variable</a><ul>
<li class="chapter" data-level="6.2.1" data-path="6-regression.html"><a href="6-regression.html#model2EDA"><i class="fa fa-check"></i><b>6.2.1</b> Exploratory data analysis</a></li>
<li class="chapter" data-level="6.2.2" data-path="6-regression.html"><a href="6-regression.html#model2table"><i class="fa fa-check"></i><b>6.2.2</b> Linear regression</a></li>
<li class="chapter" data-level="6.2.3" data-path="6-regression.html"><a href="6-regression.html#model2points"><i class="fa fa-check"></i><b>6.2.3</b> Observed/fitted values and residuals</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="6-regression.html"><a href="6-regression.html#related-topics"><i class="fa fa-check"></i><b>6.3</b> Related topics</a><ul>
<li class="chapter" data-level="6.3.1" data-path="6-regression.html"><a href="6-regression.html#correlation-is-not-causation"><i class="fa fa-check"></i><b>6.3.1</b> Correlation is not necessarily causation</a></li>
<li class="chapter" data-level="6.3.2" data-path="6-regression.html"><a href="6-regression.html#leastsquares"><i class="fa fa-check"></i><b>6.3.2</b> Best fitting line</a></li>
<li class="chapter" data-level="6.3.3" data-path="6-regression.html"><a href="6-regression.html#underthehood"><i class="fa fa-check"></i><b>6.3.3</b> <code>get_regression_x()</code> functions</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="6-regression.html"><a href="6-regression.html#conclusion-4"><i class="fa fa-check"></i><b>6.4</b> Conclusion</a><ul>
<li class="chapter" data-level="6.4.1" data-path="6-regression.html"><a href="6-regression.html#additional-resources-basic-regression"><i class="fa fa-check"></i><b>6.4.1</b> Additional resources</a></li>
<li class="chapter" data-level="6.4.2" data-path="6-regression.html"><a href="6-regression.html#whats-to-come-4"><i class="fa fa-check"></i><b>6.4.2</b> What’s to come?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html"><i class="fa fa-check"></i><b>7</b> Multiple Regression</a><ul>
<li class="chapter" data-level="" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html#needed-packages-4"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="7.1" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html#model4"><i class="fa fa-check"></i><b>7.1</b> One numerical &amp; one categorical explanatory variable</a><ul>
<li class="chapter" data-level="7.1.1" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html#model4EDA"><i class="fa fa-check"></i><b>7.1.1</b> Exploratory data analysis</a></li>
<li class="chapter" data-level="7.1.2" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html#model4interactiontable"><i class="fa fa-check"></i><b>7.1.2</b> Interaction model</a></li>
<li class="chapter" data-level="7.1.3" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html#model4table"><i class="fa fa-check"></i><b>7.1.3</b> Parallel slopes model</a></li>
<li class="chapter" data-level="7.1.4" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html#model4points"><i class="fa fa-check"></i><b>7.1.4</b> Observed/fitted values and residuals</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html#model3"><i class="fa fa-check"></i><b>7.2</b> Two numerical explanatory variables</a><ul>
<li class="chapter" data-level="7.2.1" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html#model3EDA"><i class="fa fa-check"></i><b>7.2.1</b> Exploratory data analysis</a></li>
<li class="chapter" data-level="7.2.2" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html#model3table"><i class="fa fa-check"></i><b>7.2.2</b> Regression plane</a></li>
<li class="chapter" data-level="7.2.3" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html#model3points"><i class="fa fa-check"></i><b>7.2.3</b> Observed/fitted values and residuals</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html#related-topics-1"><i class="fa fa-check"></i><b>7.3</b> Related topics</a><ul>
<li class="chapter" data-level="7.3.1" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html#model-selection"><i class="fa fa-check"></i><b>7.3.1</b> Model selection</a></li>
<li class="chapter" data-level="7.3.2" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html#correlationcoefficient2"><i class="fa fa-check"></i><b>7.3.2</b> Correlation coefficient</a></li>
<li class="chapter" data-level="7.3.3" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html#simpsonsparadox"><i class="fa fa-check"></i><b>7.3.3</b> Simpson’s Paradox</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html#conclusion-5"><i class="fa fa-check"></i><b>7.4</b> Conclusion</a><ul>
<li class="chapter" data-level="7.4.1" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html#additional-resources-4"><i class="fa fa-check"></i><b>7.4.1</b> Additional resources</a></li>
<li class="chapter" data-level="7.4.2" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html#whats-to-come-5"><i class="fa fa-check"></i><b>7.4.2</b> What’s to come?</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III Statistical Inference via infer</b></span></li>
<li class="chapter" data-level="8" data-path="8-sampling.html"><a href="8-sampling.html"><i class="fa fa-check"></i><b>8</b> Sampling</a><ul>
<li class="chapter" data-level="" data-path="8-sampling.html"><a href="8-sampling.html#needed-packages-5"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="8.1" data-path="8-sampling.html"><a href="8-sampling.html#sampling-activity"><i class="fa fa-check"></i><b>8.1</b> Sampling bowl activity</a><ul>
<li class="chapter" data-level="8.1.1" data-path="8-sampling.html"><a href="8-sampling.html#what-proportion-of-this-bowls-balls-are-red"><i class="fa fa-check"></i><b>8.1.1</b> What proportion of this bowl’s balls are red?</a></li>
<li class="chapter" data-level="8.1.2" data-path="8-sampling.html"><a href="8-sampling.html#using-the-shovel-once"><i class="fa fa-check"></i><b>8.1.2</b> Using the shovel once</a></li>
<li class="chapter" data-level="8.1.3" data-path="8-sampling.html"><a href="8-sampling.html#student-shovels"><i class="fa fa-check"></i><b>8.1.3</b> Using the shovel 33 times</a></li>
<li class="chapter" data-level="8.1.4" data-path="8-sampling.html"><a href="8-sampling.html#what-did-we-just-do"><i class="fa fa-check"></i><b>8.1.4</b> What did we just do?</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="8-sampling.html"><a href="8-sampling.html#sampling-simulation"><i class="fa fa-check"></i><b>8.2</b> Computer simulation of sampling</a><ul>
<li class="chapter" data-level="8.2.1" data-path="8-sampling.html"><a href="8-sampling.html#using-the-virtual-shovel-once"><i class="fa fa-check"></i><b>8.2.1</b> Using the virtual shovel once</a></li>
<li class="chapter" data-level="8.2.2" data-path="8-sampling.html"><a href="8-sampling.html#using-the-virtual-shovel-33-times"><i class="fa fa-check"></i><b>8.2.2</b> Using the virtual shovel 33 times</a></li>
<li class="chapter" data-level="8.2.3" data-path="8-sampling.html"><a href="8-sampling.html#shovel-1000-times"><i class="fa fa-check"></i><b>8.2.3</b> Using the virtual shovel 1000 times</a></li>
<li class="chapter" data-level="8.2.4" data-path="8-sampling.html"><a href="8-sampling.html#different-shovels"><i class="fa fa-check"></i><b>8.2.4</b> Using different shovels</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="8-sampling.html"><a href="8-sampling.html#sampling-framework"><i class="fa fa-check"></i><b>8.3</b> Sampling framework</a><ul>
<li class="chapter" data-level="8.3.1" data-path="8-sampling.html"><a href="8-sampling.html#terminology-and-notation"><i class="fa fa-check"></i><b>8.3.1</b> Terminology &amp; notation</a></li>
<li class="chapter" data-level="8.3.2" data-path="8-sampling.html"><a href="8-sampling.html#sampling-definitions"><i class="fa fa-check"></i><b>8.3.2</b> Statistical definitions</a></li>
<li class="chapter" data-level="8.3.3" data-path="8-sampling.html"><a href="8-sampling.html#moral-of-the-story"><i class="fa fa-check"></i><b>8.3.3</b> The moral of the story</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="8-sampling.html"><a href="8-sampling.html#sampling-case-study"><i class="fa fa-check"></i><b>8.4</b> Case study: Polls</a></li>
<li class="chapter" data-level="8.5" data-path="8-sampling.html"><a href="8-sampling.html#sampling-conclusion"><i class="fa fa-check"></i><b>8.5</b> Conclusion</a><ul>
<li class="chapter" data-level="8.5.1" data-path="8-sampling.html"><a href="8-sampling.html#sampling-conclusion-table"><i class="fa fa-check"></i><b>8.5.1</b> Sampling scenarios</a></li>
<li class="chapter" data-level="8.5.2" data-path="8-sampling.html"><a href="8-sampling.html#sampling-conclusion-central-limit-theorem"><i class="fa fa-check"></i><b>8.5.2</b> Central Limit Theorem</a></li>
<li class="chapter" data-level="8.5.3" data-path="8-sampling.html"><a href="8-sampling.html#normal-distribution"><i class="fa fa-check"></i><b>8.5.3</b> Normal distributions</a></li>
<li class="chapter" data-level="8.5.4" data-path="8-sampling.html"><a href="8-sampling.html#additional-resources-5"><i class="fa fa-check"></i><b>8.5.4</b> Additional resources</a></li>
<li class="chapter" data-level="8.5.5" data-path="8-sampling.html"><a href="8-sampling.html#whats-to-come-6"><i class="fa fa-check"></i><b>8.5.5</b> What’s to come?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html"><i class="fa fa-check"></i><b>9</b> Bootstrapping and Confidence Intervals</a><ul>
<li class="chapter" data-level="" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#needed-packages-6"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="9.1" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#resampling-tactile"><i class="fa fa-check"></i><b>9.1</b> Pennies activity</a><ul>
<li class="chapter" data-level="9.1.1" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#what-is-the-average-year-on-us-pennies-in-2019"><i class="fa fa-check"></i><b>9.1.1</b> What is the average year on US pennies in 2019?</a></li>
<li class="chapter" data-level="9.1.2" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#resampling-once"><i class="fa fa-check"></i><b>9.1.2</b> Resampling once</a></li>
<li class="chapter" data-level="9.1.3" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#student-resamples"><i class="fa fa-check"></i><b>9.1.3</b> Resampling 35 times</a></li>
<li class="chapter" data-level="9.1.4" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#what-did-we-just-do-1"><i class="fa fa-check"></i><b>9.1.4</b> What did we just do?</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#resampling-simulation"><i class="fa fa-check"></i><b>9.2</b> Computer simulation of resampling</a><ul>
<li class="chapter" data-level="9.2.1" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#virtually-resampling-once"><i class="fa fa-check"></i><b>9.2.1</b> Virtually resampling once</a></li>
<li class="chapter" data-level="9.2.2" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#virtually-resampling-35-times"><i class="fa fa-check"></i><b>9.2.2</b> Virtually resampling 35 times</a></li>
<li class="chapter" data-level="9.2.3" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#bootstrap-1000-replicates"><i class="fa fa-check"></i><b>9.2.3</b> Virtually resampling 1000 times</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#ci-build-up"><i class="fa fa-check"></i><b>9.3</b> Understanding confidence intervals</a><ul>
<li class="chapter" data-level="9.3.1" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#percentile-method"><i class="fa fa-check"></i><b>9.3.1</b> Percentile method</a></li>
<li class="chapter" data-level="9.3.2" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#se-method"><i class="fa fa-check"></i><b>9.3.2</b> Standard error method</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#bootstrap-process"><i class="fa fa-check"></i><b>9.4</b> Constructing confidence intervals</a><ul>
<li class="chapter" data-level="9.4.1" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#original-workflow"><i class="fa fa-check"></i><b>9.4.1</b> Original workflow</a></li>
<li class="chapter" data-level="9.4.2" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#infer-workflow"><i class="fa fa-check"></i><b>9.4.2</b> infer package workflow</a></li>
<li class="chapter" data-level="9.4.3" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#percentile-method-infer"><i class="fa fa-check"></i><b>9.4.3</b> Percentile method with infer</a></li>
<li class="chapter" data-level="9.4.4" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#infer-se"><i class="fa fa-check"></i><b>9.4.4</b> Standard error method with infer</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#one-prop-ci"><i class="fa fa-check"></i><b>9.5</b> Interpreting confidence intervals</a><ul>
<li class="chapter" data-level="9.5.1" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#ilyas-yohan"><i class="fa fa-check"></i><b>9.5.1</b> Did the net capture the fish?</a></li>
<li class="chapter" data-level="9.5.2" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#shorthand"><i class="fa fa-check"></i><b>9.5.2</b> Precise &amp; shorthand interpretation</a></li>
<li class="chapter" data-level="9.5.3" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#ci-width"><i class="fa fa-check"></i><b>9.5.3</b> Width of confidence intervals</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#case-study-two-prop-ci"><i class="fa fa-check"></i><b>9.6</b> Case study: Is yawning contagious?</a><ul>
<li class="chapter" data-level="9.6.1" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#mythbusters-study-data"><i class="fa fa-check"></i><b>9.6.1</b> Mythbusters study data</a></li>
<li class="chapter" data-level="9.6.2" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#sampling-scenario"><i class="fa fa-check"></i><b>9.6.2</b> Sampling scenario</a></li>
<li class="chapter" data-level="9.6.3" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#ci-build"><i class="fa fa-check"></i><b>9.6.3</b> Constructing the confidence interval</a></li>
<li class="chapter" data-level="9.6.4" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#interpreting-the-confidence-interval"><i class="fa fa-check"></i><b>9.6.4</b> Interpreting the confidence interval</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#ci-conclusion"><i class="fa fa-check"></i><b>9.7</b> Conclusion</a><ul>
<li class="chapter" data-level="9.7.1" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#bootstrap-vs-sampling"><i class="fa fa-check"></i><b>9.7.1</b> Comparing bootstrap and sampling distributions</a></li>
<li class="chapter" data-level="9.7.2" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#theory-ci"><i class="fa fa-check"></i><b>9.7.2</b> Theory-based confidence intervals</a></li>
<li class="chapter" data-level="9.7.3" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#additional-resources-6"><i class="fa fa-check"></i><b>9.7.3</b> Additional resources</a></li>
<li class="chapter" data-level="9.7.4" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#whats-to-come-7"><i class="fa fa-check"></i><b>9.7.4</b> What’s to come?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html"><i class="fa fa-check"></i><b>10</b> Hypothesis Testing</a><ul>
<li class="chapter" data-level="" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#needed-packages-7"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="10.1" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#ht-activity"><i class="fa fa-check"></i><b>10.1</b> Promotions activity</a><ul>
<li class="chapter" data-level="10.1.1" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#does-gender-affect-promotions-at-bank"><i class="fa fa-check"></i><b>10.1.1</b> Does gender affect promotions at bank?</a></li>
<li class="chapter" data-level="10.1.2" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#shuffling-once"><i class="fa fa-check"></i><b>10.1.2</b> Shuffling once</a></li>
<li class="chapter" data-level="10.1.3" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#shuffling-16-times"><i class="fa fa-check"></i><b>10.1.3</b> Shuffling 16 times</a></li>
<li class="chapter" data-level="10.1.4" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#what-did-we-just-do-2"><i class="fa fa-check"></i><b>10.1.4</b> What did we just do?</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#understanding-ht"><i class="fa fa-check"></i><b>10.2</b> Understanding hypothesis tests</a></li>
<li class="chapter" data-level="10.3" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#ht-infer"><i class="fa fa-check"></i><b>10.3</b> Conducting hypothesis tests</a><ul>
<li class="chapter" data-level="10.3.1" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#infer-workflow-ht"><i class="fa fa-check"></i><b>10.3.1</b> infer package workflow</a></li>
<li class="chapter" data-level="10.3.2" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#comparison-with-confidence-intervals"><i class="fa fa-check"></i><b>10.3.2</b> Comparison with confidence intervals</a></li>
<li class="chapter" data-level="10.3.3" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#only-one-test"><i class="fa fa-check"></i><b>10.3.3</b> “There is only one test”</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#ht-interpretation"><i class="fa fa-check"></i><b>10.4</b> Interpreting hypothesis tests</a><ul>
<li class="chapter" data-level="10.4.1" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#trial"><i class="fa fa-check"></i><b>10.4.1</b> Two possible outcomes</a></li>
<li class="chapter" data-level="10.4.2" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#types-of-errors"><i class="fa fa-check"></i><b>10.4.2</b> Types of errors</a></li>
<li class="chapter" data-level="10.4.3" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#how-do-we-choose-alpha"><i class="fa fa-check"></i><b>10.4.3</b> How do we choose alpha?</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#ht-case-study"><i class="fa fa-check"></i><b>10.5</b> Case study: Are action or romance movies rated higher?</a><ul>
<li class="chapter" data-level="10.5.1" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#imdb-data"><i class="fa fa-check"></i><b>10.5.1</b> IMDb ratings data</a></li>
<li class="chapter" data-level="10.5.2" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#sampling-scenario-1"><i class="fa fa-check"></i><b>10.5.2</b> Sampling scenario</a></li>
<li class="chapter" data-level="10.5.3" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#conducting-the-hypothesis-test"><i class="fa fa-check"></i><b>10.5.3</b> Conducting the hypothesis test</a></li>
</ul></li>
<li class="chapter" data-level="10.6" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#conclusion-6"><i class="fa fa-check"></i><b>10.6</b> Conclusion</a><ul>
<li class="chapter" data-level="10.6.1" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#theory-hypo"><i class="fa fa-check"></i><b>10.6.1</b> Theory-based hypothesis tests</a></li>
<li class="chapter" data-level="10.6.2" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#when-inference-is-not-needed"><i class="fa fa-check"></i><b>10.6.2</b> When inference is not needed</a></li>
<li class="chapter" data-level="10.6.3" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#problems-with-p-values"><i class="fa fa-check"></i><b>10.6.3</b> Problems with p-values</a></li>
<li class="chapter" data-level="10.6.4" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#additional-resources-7"><i class="fa fa-check"></i><b>10.6.4</b> Additional resources</a></li>
<li class="chapter" data-level="10.6.5" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#whats-to-come-8"><i class="fa fa-check"></i><b>10.6.5</b> What’s to come</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html"><i class="fa fa-check"></i><b>11</b> Inference for Regression</a><ul>
<li class="chapter" data-level="" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#needed-packages-8"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="11.1" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#regression-refresher"><i class="fa fa-check"></i><b>11.1</b> Regression refresher</a><ul>
<li class="chapter" data-level="11.1.1" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#teaching-evals-analysis"><i class="fa fa-check"></i><b>11.1.1</b> Teaching evals analysis</a></li>
<li class="chapter" data-level="11.1.2" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#sampling-scenario-2"><i class="fa fa-check"></i><b>11.1.2</b> Sampling scenario</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#regression-interp"><i class="fa fa-check"></i><b>11.2</b> Interpreting regression tables</a><ul>
<li class="chapter" data-level="11.2.1" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#regression-se"><i class="fa fa-check"></i><b>11.2.1</b> Standard error</a></li>
<li class="chapter" data-level="11.2.2" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#regression-test-statistic"><i class="fa fa-check"></i><b>11.2.2</b> Test statistic</a></li>
<li class="chapter" data-level="11.2.3" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#p-value"><i class="fa fa-check"></i><b>11.2.3</b> p-value</a></li>
<li class="chapter" data-level="11.2.4" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#confidence-interval"><i class="fa fa-check"></i><b>11.2.4</b> Confidence interval</a></li>
<li class="chapter" data-level="11.2.5" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#regression-table-computation"><i class="fa fa-check"></i><b>11.2.5</b> How does R compute the table?</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#regression-conditions"><i class="fa fa-check"></i><b>11.3</b> Conditions for inference for regression</a><ul>
<li class="chapter" data-level="11.3.1" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#residuals-refresher"><i class="fa fa-check"></i><b>11.3.1</b> Residuals refresher</a></li>
<li class="chapter" data-level="11.3.2" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#linearity-of-relationship"><i class="fa fa-check"></i><b>11.3.2</b> Linearity of relationship</a></li>
<li class="chapter" data-level="11.3.3" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#independence-of-residuals"><i class="fa fa-check"></i><b>11.3.3</b> Independence of residuals</a></li>
<li class="chapter" data-level="11.3.4" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#normality-of-residuals"><i class="fa fa-check"></i><b>11.3.4</b> Normality of residuals</a></li>
<li class="chapter" data-level="11.3.5" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#equality-of-variance"><i class="fa fa-check"></i><b>11.3.5</b> Equality of variance</a></li>
<li class="chapter" data-level="11.3.6" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#what-is-the-conclusion"><i class="fa fa-check"></i><b>11.3.6</b> What’s the conclusion?</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#infer-regression"><i class="fa fa-check"></i><b>11.4</b> Simulation-based inference for regression</a><ul>
<li class="chapter" data-level="11.4.1" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#confidence-interval-for-slope"><i class="fa fa-check"></i><b>11.4.1</b> Confidence interval for slope</a></li>
<li class="chapter" data-level="11.4.2" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#hypothesis-test-for-slope"><i class="fa fa-check"></i><b>11.4.2</b> Hypothesis test for slope</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#conclusion-7"><i class="fa fa-check"></i><b>11.5</b> Conclusion</a><ul>
<li class="chapter" data-level="11.5.1" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#summary-5"><i class="fa fa-check"></i><b>11.5.1</b> Summary</a></li>
<li class="chapter" data-level="11.5.2" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#additional-resources-8"><i class="fa fa-check"></i><b>11.5.2</b> Additional resources</a></li>
<li class="chapter" data-level="11.5.3" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#whats-to-come-9"><i class="fa fa-check"></i><b>11.5.3</b> What’s to come</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>IV Conclusion</b></span></li>
<li class="chapter" data-level="12" data-path="12-thinking-with-data.html"><a href="12-thinking-with-data.html"><i class="fa fa-check"></i><b>12</b> Tell the Story with Data</a><ul>
<li class="chapter" data-level="" data-path="12-thinking-with-data.html"><a href="12-thinking-with-data.html#needed-packages-9"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="12.1" data-path="12-thinking-with-data.html"><a href="12-thinking-with-data.html#seattle-house-prices"><i class="fa fa-check"></i><b>12.1</b> Case study: Seattle house prices</a><ul>
<li class="chapter" data-level="12.1.1" data-path="12-thinking-with-data.html"><a href="12-thinking-with-data.html#house-prices-EDA-I"><i class="fa fa-check"></i><b>12.1.1</b> Exploratory data analysis (EDA)</a></li>
<li class="chapter" data-level="12.1.2" data-path="12-thinking-with-data.html"><a href="12-thinking-with-data.html#log10-transformations"><i class="fa fa-check"></i><b>12.1.2</b> log10 transformations</a></li>
<li class="chapter" data-level="12.1.3" data-path="12-thinking-with-data.html"><a href="12-thinking-with-data.html#eda-part-ii"><i class="fa fa-check"></i><b>12.1.3</b> EDA Part II</a></li>
<li class="chapter" data-level="12.1.4" data-path="12-thinking-with-data.html"><a href="12-thinking-with-data.html#house-prices-regression"><i class="fa fa-check"></i><b>12.1.4</b> Regression modeling</a></li>
<li class="chapter" data-level="12.1.5" data-path="12-thinking-with-data.html"><a href="12-thinking-with-data.html#house-prices-making-predictions"><i class="fa fa-check"></i><b>12.1.5</b> Making predictions</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="12-thinking-with-data.html"><a href="12-thinking-with-data.html#data-journalism"><i class="fa fa-check"></i><b>12.2</b> Case study: Effective data storytelling</a><ul>
<li class="chapter" data-level="12.2.1" data-path="12-thinking-with-data.html"><a href="12-thinking-with-data.html#bechdel-test-for-hollywood-gender-representation"><i class="fa fa-check"></i><b>12.2.1</b> Bechdel test for Hollywood gender representation</a></li>
<li class="chapter" data-level="12.2.2" data-path="12-thinking-with-data.html"><a href="12-thinking-with-data.html#us-births-in-1999"><i class="fa fa-check"></i><b>12.2.2</b> US Births in 1999</a></li>
<li class="chapter" data-level="12.2.3" data-path="12-thinking-with-data.html"><a href="12-thinking-with-data.html#script-of-r-code"><i class="fa fa-check"></i><b>12.2.3</b> Script of R code</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="12-thinking-with-data.html"><a href="12-thinking-with-data.html#concluding-remarks"><i class="fa fa-check"></i>Concluding remarks</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="A-appendixA.html"><a href="A-appendixA.html"><i class="fa fa-check"></i><b>A</b> Statistical Background</a><ul>
<li class="chapter" data-level="A.1" data-path="A-appendixA.html"><a href="A-appendixA.html#basic-statistical-terms"><i class="fa fa-check"></i><b>A.1</b> Basic statistical terms</a><ul>
<li class="chapter" data-level="A.1.1" data-path="A-appendixA.html"><a href="A-appendixA.html#mean"><i class="fa fa-check"></i><b>A.1.1</b> Mean</a></li>
<li class="chapter" data-level="A.1.2" data-path="A-appendixA.html"><a href="A-appendixA.html#median"><i class="fa fa-check"></i><b>A.1.2</b> Median</a></li>
<li class="chapter" data-level="A.1.3" data-path="A-appendixA.html"><a href="A-appendixA.html#standard-deviation"><i class="fa fa-check"></i><b>A.1.3</b> Standard deviation</a></li>
<li class="chapter" data-level="A.1.4" data-path="A-appendixA.html"><a href="A-appendixA.html#five-number-summary"><i class="fa fa-check"></i><b>A.1.4</b> Five-number summary</a></li>
<li class="chapter" data-level="A.1.5" data-path="A-appendixA.html"><a href="A-appendixA.html#distribution"><i class="fa fa-check"></i><b>A.1.5</b> Distribution</a></li>
<li class="chapter" data-level="A.1.6" data-path="A-appendixA.html"><a href="A-appendixA.html#outliers"><i class="fa fa-check"></i><b>A.1.6</b> Outliers</a></li>
</ul></li>
<li class="chapter" data-level="A.2" data-path="A-appendixA.html"><a href="A-appendixA.html#normal-curve"><i class="fa fa-check"></i><b>A.2</b> Normal distribution</a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="B-appendixB.html"><a href="B-appendixB.html"><i class="fa fa-check"></i><b>B</b> Inference Examples</a><ul>
<li class="chapter" data-level="" data-path="B-appendixB.html"><a href="B-appendixB.html#needed-packages-10"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="B.1" data-path="B-appendixB.html"><a href="B-appendixB.html#inference-mind-map"><i class="fa fa-check"></i><b>B.1</b> Inference mind map</a></li>
<li class="chapter" data-level="B.2" data-path="B-appendixB.html"><a href="B-appendixB.html#one-mean"><i class="fa fa-check"></i><b>B.2</b> One mean</a><ul>
<li class="chapter" data-level="B.2.1" data-path="B-appendixB.html"><a href="B-appendixB.html#problem-statement"><i class="fa fa-check"></i><b>B.2.1</b> Problem statement</a></li>
<li class="chapter" data-level="B.2.2" data-path="B-appendixB.html"><a href="B-appendixB.html#competing-hypotheses"><i class="fa fa-check"></i><b>B.2.2</b> Competing hypotheses</a></li>
<li class="chapter" data-level="B.2.3" data-path="B-appendixB.html"><a href="B-appendixB.html#exploring-the-sample-data"><i class="fa fa-check"></i><b>B.2.3</b> Exploring the sample data</a></li>
<li class="chapter" data-level="B.2.4" data-path="B-appendixB.html"><a href="B-appendixB.html#non-traditional-methods"><i class="fa fa-check"></i><b>B.2.4</b> Non-traditional methods</a></li>
<li class="chapter" data-level="B.2.5" data-path="B-appendixB.html"><a href="B-appendixB.html#traditional-methods"><i class="fa fa-check"></i><b>B.2.5</b> Traditional methods</a></li>
<li class="chapter" data-level="B.2.6" data-path="B-appendixB.html"><a href="B-appendixB.html#comparing-results"><i class="fa fa-check"></i><b>B.2.6</b> Comparing results</a></li>
</ul></li>
<li class="chapter" data-level="B.3" data-path="B-appendixB.html"><a href="B-appendixB.html#one-proportion"><i class="fa fa-check"></i><b>B.3</b> One proportion</a><ul>
<li class="chapter" data-level="B.3.1" data-path="B-appendixB.html"><a href="B-appendixB.html#problem-statement-1"><i class="fa fa-check"></i><b>B.3.1</b> Problem statement</a></li>
<li class="chapter" data-level="B.3.2" data-path="B-appendixB.html"><a href="B-appendixB.html#competing-hypotheses-1"><i class="fa fa-check"></i><b>B.3.2</b> Competing hypotheses</a></li>
<li class="chapter" data-level="B.3.3" data-path="B-appendixB.html"><a href="B-appendixB.html#exploring-the-sample-data-1"><i class="fa fa-check"></i><b>B.3.3</b> Exploring the sample data</a></li>
<li class="chapter" data-level="B.3.4" data-path="B-appendixB.html"><a href="B-appendixB.html#non-traditional-methods-1"><i class="fa fa-check"></i><b>B.3.4</b> Non-traditional methods</a></li>
<li class="chapter" data-level="B.3.5" data-path="B-appendixB.html"><a href="B-appendixB.html#traditional-methods-1"><i class="fa fa-check"></i><b>B.3.5</b> Traditional methods</a></li>
<li class="chapter" data-level="B.3.6" data-path="B-appendixB.html"><a href="B-appendixB.html#comparing-results-1"><i class="fa fa-check"></i><b>B.3.6</b> Comparing results</a></li>
</ul></li>
<li class="chapter" data-level="B.4" data-path="B-appendixB.html"><a href="B-appendixB.html#two-proportions"><i class="fa fa-check"></i><b>B.4</b> Two proportions</a><ul>
<li class="chapter" data-level="B.4.1" data-path="B-appendixB.html"><a href="B-appendixB.html#problem-statement-2"><i class="fa fa-check"></i><b>B.4.1</b> Problem statement</a></li>
<li class="chapter" data-level="B.4.2" data-path="B-appendixB.html"><a href="B-appendixB.html#competing-hypotheses-2"><i class="fa fa-check"></i><b>B.4.2</b> Competing hypotheses</a></li>
<li class="chapter" data-level="B.4.3" data-path="B-appendixB.html"><a href="B-appendixB.html#exploring-the-sample-data-2"><i class="fa fa-check"></i><b>B.4.3</b> Exploring the sample data</a></li>
<li class="chapter" data-level="B.4.4" data-path="B-appendixB.html"><a href="B-appendixB.html#non-traditional-methods-2"><i class="fa fa-check"></i><b>B.4.4</b> Non-traditional methods</a></li>
<li class="chapter" data-level="B.4.5" data-path="B-appendixB.html"><a href="B-appendixB.html#traditional-methods-2"><i class="fa fa-check"></i><b>B.4.5</b> Traditional methods</a></li>
<li class="chapter" data-level="B.4.6" data-path="B-appendixB.html"><a href="B-appendixB.html#check-conditions-2"><i class="fa fa-check"></i><b>B.4.6</b> Check conditions</a></li>
<li class="chapter" data-level="B.4.7" data-path="B-appendixB.html"><a href="B-appendixB.html#test-statistic-2"><i class="fa fa-check"></i><b>B.4.7</b> Test statistic</a></li>
<li class="chapter" data-level="B.4.8" data-path="B-appendixB.html"><a href="B-appendixB.html#state-conclusion-2"><i class="fa fa-check"></i><b>B.4.8</b> State conclusion</a></li>
<li class="chapter" data-level="B.4.9" data-path="B-appendixB.html"><a href="B-appendixB.html#comparing-results-2"><i class="fa fa-check"></i><b>B.4.9</b> Comparing results</a></li>
</ul></li>
<li class="chapter" data-level="B.5" data-path="B-appendixB.html"><a href="B-appendixB.html#two-means-independent-samples"><i class="fa fa-check"></i><b>B.5</b> Two means (independent samples)</a><ul>
<li class="chapter" data-level="B.5.1" data-path="B-appendixB.html"><a href="B-appendixB.html#problem-statement-3"><i class="fa fa-check"></i><b>B.5.1</b> Problem statement</a></li>
<li class="chapter" data-level="B.5.2" data-path="B-appendixB.html"><a href="B-appendixB.html#competing-hypotheses-3"><i class="fa fa-check"></i><b>B.5.2</b> Competing hypotheses</a></li>
<li class="chapter" data-level="B.5.3" data-path="B-appendixB.html"><a href="B-appendixB.html#exploring-the-sample-data-3"><i class="fa fa-check"></i><b>B.5.3</b> Exploring the sample data</a></li>
<li class="chapter" data-level="B.5.4" data-path="B-appendixB.html"><a href="B-appendixB.html#non-traditional-methods-3"><i class="fa fa-check"></i><b>B.5.4</b> Non-traditional methods</a></li>
<li class="chapter" data-level="B.5.5" data-path="B-appendixB.html"><a href="B-appendixB.html#traditional-methods-3"><i class="fa fa-check"></i><b>B.5.5</b> Traditional methods</a></li>
<li class="chapter" data-level="B.5.6" data-path="B-appendixB.html"><a href="B-appendixB.html#test-statistic-3"><i class="fa fa-check"></i><b>B.5.6</b> Test statistic</a></li>
<li class="chapter" data-level="B.5.7" data-path="B-appendixB.html"><a href="B-appendixB.html#compute-p-value-1"><i class="fa fa-check"></i><b>B.5.7</b> Compute <span class="math inline">\(p\)</span>-value</a></li>
<li class="chapter" data-level="B.5.8" data-path="B-appendixB.html"><a href="B-appendixB.html#state-conclusion-3"><i class="fa fa-check"></i><b>B.5.8</b> State conclusion</a></li>
<li class="chapter" data-level="B.5.9" data-path="B-appendixB.html"><a href="B-appendixB.html#comparing-results-3"><i class="fa fa-check"></i><b>B.5.9</b> Comparing results</a></li>
</ul></li>
<li class="chapter" data-level="B.6" data-path="B-appendixB.html"><a href="B-appendixB.html#two-means-paired-samples"><i class="fa fa-check"></i><b>B.6</b> Two means (paired samples)</a><ul>
<li class="chapter" data-level="B.6.1" data-path="B-appendixB.html"><a href="B-appendixB.html#competing-hypotheses-4"><i class="fa fa-check"></i><b>B.6.1</b> Competing hypotheses</a></li>
<li class="chapter" data-level="B.6.2" data-path="B-appendixB.html"><a href="B-appendixB.html#exploring-the-sample-data-4"><i class="fa fa-check"></i><b>B.6.2</b> Exploring the sample data</a></li>
<li class="chapter" data-level="B.6.3" data-path="B-appendixB.html"><a href="B-appendixB.html#non-traditional-methods-4"><i class="fa fa-check"></i><b>B.6.3</b> Non-traditional methods</a></li>
<li class="chapter" data-level="B.6.4" data-path="B-appendixB.html"><a href="B-appendixB.html#traditional-methods-4"><i class="fa fa-check"></i><b>B.6.4</b> Traditional methods</a></li>
<li class="chapter" data-level="B.6.5" data-path="B-appendixB.html"><a href="B-appendixB.html#comparing-results-4"><i class="fa fa-check"></i><b>B.6.5</b> Comparing results</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="C" data-path="C-appendixC.html"><a href="C-appendixC.html"><i class="fa fa-check"></i><b>C</b> Reach for the Stars</a><ul>
<li class="chapter" data-level="" data-path="C-appendixC.html"><a href="C-appendixC.html#needed-packages-11"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="C.1" data-path="C-appendixC.html"><a href="C-appendixC.html#sorted-barplots"><i class="fa fa-check"></i><b>C.1</b> Sorted barplots</a></li>
<li class="chapter" data-level="C.2" data-path="C-appendixC.html"><a href="C-appendixC.html#interactive-graphics"><i class="fa fa-check"></i><b>C.2</b> Interactive graphics</a><ul>
<li class="chapter" data-level="C.2.1" data-path="C-appendixC.html"><a href="C-appendixC.html#interactive-linegraphs"><i class="fa fa-check"></i><b>C.2.1</b> Interactive linegraphs</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="D" data-path="D-appendixD.html"><a href="D-appendixD.html"><i class="fa fa-check"></i><b>D</b> Learning Check Solutions</a><ul>
<li class="chapter" data-level="D.1" data-path="D-appendixD.html"><a href="D-appendixD.html#chapter-2-solutions"><i class="fa fa-check"></i><b>D.1</b> Chapter 2 Solutions</a></li>
<li class="chapter" data-level="D.2" data-path="D-appendixD.html"><a href="D-appendixD.html#chapter-3-solutions"><i class="fa fa-check"></i><b>D.2</b> Chapter 3 Solutions</a></li>
<li class="chapter" data-level="D.3" data-path="D-appendixD.html"><a href="D-appendixD.html#chapter-4-solutions"><i class="fa fa-check"></i><b>D.3</b> Chapter 4 Solutions</a></li>
<li class="chapter" data-level="D.4" data-path="D-appendixD.html"><a href="D-appendixD.html#chapter-5-solutions"><i class="fa fa-check"></i><b>D.4</b> Chapter 5 Solutions</a></li>
<li class="chapter" data-level="D.5" data-path="D-appendixD.html"><a href="D-appendixD.html#chapter-6-solutions"><i class="fa fa-check"></i><b>D.5</b> Chapter 6 Solutions</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Statistical Inference via Data Science</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<html>
<img src='https://moderndive.com/wide_format.png' alt="ModernDive">
</html>
<div id="hypothesis-testing" class="section level1">
<h1><span class="header-section-number">Chapter 10</span> Hypothesis Testing</h1>
<p>Now that we’ve studied one commonly used method for statistical inference, confidence intervals in the previous Section <a href="9-confidence-intervals.html#confidence-intervals">9</a>, we’ll now study the other commonly used method, hypothesis testing. Hypothesis tests allow us to take a sample of data from a population and infer about the plausibility of competing hypotheses. For example, in the upcoming “promotions” activity in Section <a href="10-hypothesis-testing.html#ht-activity">10.1</a>, you’ll study the data collected from a psychology study in the 1970’s to infer as to whether there exists gender-based discrimination in the banking industry as a whole.</p>
<p>The good news is we’ve already covered many of the necessary concepts to understand hypothesis testing in Chapters <a href="8-sampling.html#sampling">8</a> and <a href="9-confidence-intervals.html#confidence-intervals">9</a>. We will expand further on these ideas here and also provide a general framework for understanding hypothesis tests. By understanding this general framework, you’ll be able to adapt it to many different scenarios.</p>
<p>The same can be said for confidence intervals. There was one general framework that applies to all confidence intervals and we elaborated on this using the <code>infer</code> package pipeline in Chapter <a href="9-confidence-intervals.html#confidence-intervals">9</a>. The specifics may change slightly for each variation, but the important idea is to understand the general framework so that you can apply it to more specific problems. We believe that this approach is much better in the long-term than teaching you specific tests and confidence intervals rigorously.</p>
<p>If you’d like more practice or to see how this framework applies to different scenarios, you can find fully-worked out examples for many common hypothesis tests and their corresponding confidence intervals in Appendix B. We recommend that you carefully review these examples as they also cover how the general frameworks apply to traditional normal-based methodologies like the <span class="math inline">\(t\)</span>-test and normal-theory confidence intervals. You’ll see there that these traditional methods are just approximations for the general computational frameworks, but require conditions to be met for their results to be valid. The general frameworks using randomization, simulation, and bootstrapping do not hold the same sorts of restrictions and further advance computational thinking, which is one big reason for their emphasis throughout this textbook.</p>
<div id="needed-packages-7" class="section level3 unnumbered">
<h3>Needed packages</h3>
<p>Let’s load all the packages needed for this chapter (this assumes you’ve already installed them). Recall from our discussion in Section <a href="5-tidy.html#tidyverse-package">5.4.1</a> that loading the <code>tidyverse</code> package by running <code>library(tidyverse)</code> loads the following commonly used data science packages all at once:</p>
<ul>
<li><code>ggplot2</code> for data visualization</li>
<li><code>dplyr</code> for data wrangling</li>
<li><code>tidyr</code> for converting data to “tidy” format</li>
<li><code>readr</code> for importing spreadsheet data into R</li>
<li>As well as the more advanced <code>purrr</code>, <code>tibble</code>, <code>stringr</code>, and <code>forcats</code> packages</li>
</ul>
<p>If needed, read Section <a href="2-getting-started.html#packages">2.3</a> for information on how to install and load R packages.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(tidyverse)
<span class="kw">library</span>(infer)
<span class="kw">library</span>(moderndive)
<span class="kw">library</span>(nycflights13)
<span class="kw">library</span>(ggplot2movies)</code></pre>
</div>
<div id="ht-activity" class="section level2">
<h2><span class="header-section-number">10.1</span> Promotions activity</h2>
<p>Let’s start with an activity studying the effect of gender on promotions at a bank.</p>
<div id="does-gender-affect-promotions-at-bank" class="section level3">
<h3><span class="header-section-number">10.1.1</span> Does gender affect promotions at bank?</h3>
<p>Say you are working at a bank in the 1970’s and you are submitting your resume to apply for a promotion. Will your gender affect your chances of getting promoted? To answer this question, we’ll focus on a study published in the “Journal of Applied Psychology” in 1974 and previously used in the <a href="https://www.openintro.org/">OpenIntro</a> series of statistics textbooks.</p>
<p>To begin the study, 48 bank supervisors were asked to assume the role of a hypothetical personnel director of a bank with multiple branches. Every one of the bank supervisors was given a resume and asked whether or not the candidate on the resume was fit to be promoted to a new position in one of their branches.</p>
<p>However, each of these 48 resumes were identical in all respects except one: the name of the applicant at the top of the resume. 24 of the supervisors were randomly given resumes with stereotypically “male” names while 24 of the supervisors were randomly given resumes with stereotypically “female” names. Since only (binary) gender varied from resume to resume, researchers could isolate the effect of this variable in promotion rates.</p>
<p><strong>Note:</strong> While many people today (including the authors) disagree with such a binary view of gender, it is important to remember that this study was conducted at a time where more nuanced views of gender were not as prevalent. Despite this imperfection, we decided to still use this example as we feel it still demonstrates relevant insight about the nature of the workplace.</p>
<p>The <code>moderndive</code> package contains the data on the 48 applicants in the <code>promotions</code> data frame. Let’s explore this data first:</p>
<pre class="sourceCode r"><code class="sourceCode r">promotions</code></pre>
<pre><code># A tibble: 48 x 3
      id decision gender
   &lt;int&gt; &lt;fct&gt;    &lt;fct&gt; 
 1     1 promoted male  
 2     2 promoted male  
 3     3 promoted male  
 4     4 promoted male  
 5     5 promoted male  
 6     6 promoted male  
 7     7 promoted male  
 8     8 promoted male  
 9     9 promoted male  
10    10 promoted male  
# … with 38 more rows</code></pre>
<p>The variable <code>id</code> acts as an identification variable for all 48 rows, the <code>decision</code> variable indicates whether the applicant was selected for promotion or not, while the <code>gender</code> variable indicates the gender of the name used on the resume. Recall that this data does not pertain to 24 actual men and 24 actual women, but rather 48 identical resumes of which 24 were assigned stereotypically “male” names and 24 were assigned stereotypical “female” names.</p>
<p>Let’s perform an exploratory data analysis in Figure <a href="10-hypothesis-testing.html#fig:promotions-barplot">10.1</a> of the relationship between the two categorical variables <code>decision</code> and <code>gender</code>. Recall that we saw in Section <a href="3-viz.html#two-categ-barplot">3.8.3</a> that one way we can visualize such a relationship is using a stacked barplot.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(promotions, <span class="kw">aes</span>(<span class="dt">x =</span> gender, <span class="dt">fill =</span> decision)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_bar</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Gender of name on resume&quot;</span>)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:promotions-barplot"></span>
<img src="moderndive_files/figure-html/promotions-barplot-1.png" alt="Barplot of relationship between gender and promotion decision." width="\textwidth" />
<p class="caption">
FIGURE 10.1: Barplot of relationship between gender and promotion decision.
</p>
</div>
<p>It appears that resumes with female names were much less likely to be accepted for promotion. Let’s quantify these promotions rates by computing the proportion of resumes accepted for promotion for each group using the <code>dplyr</code> package for data wrangling:</p>
<pre class="sourceCode r"><code class="sourceCode r">promotions <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(gender, decision) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">n =</span> <span class="kw">n</span>())</code></pre>
<pre><code># A tibble: 4 x 3
# Groups:   gender [2]
  gender decision     n
  &lt;fct&gt;  &lt;fct&gt;    &lt;int&gt;
1 male   not          3
2 male   promoted    21
3 female not         10
4 female promoted    14</code></pre>
<p>So of the 24 resumes with male names 21 were selected for promotion, for a proportion of 21/24 = 0.875 = 87.5%. On the other hand, of the 24 resumes with female names 14 were selected for promotion, for a proportion of 14/24 = 0.583 = 58.3%. Comparing these two rates of promotion, it appears that resumes with male names were selected for promotion at a rate 0.875 - 0.583 = 0.292 = 29.2% higher than resumes with female names. A clear edge for the “male” applicants.</p>
<p>The question is however, does this provide conclusive evidence that there is some discrimination in terms of gender in promotions at banks? Could a difference in promotion rates of 29.2% still occur by chance, even in a world of no gender-based discrimination? In other words, what is the role of sampling variation in these results? To answer this question, we’ll again rely on simulation to generate results as we did with our sampling bowl in Chapter <a href="8-sampling.html#sampling">8</a> and our pennies in Chapter <a href="9-confidence-intervals.html#confidence-intervals">9</a>.</p>
</div>
<div id="shuffling-once" class="section level3">
<h3><span class="header-section-number">10.1.2</span> Shuffling once</h3>
<p>First, imagine a hypothetical universe with no gender discrimination in promotions, with a big emphasis on the “hypothetical.” In such a hypothetical universe, the gender of an applicant would have no bearing on their chances of promotions. Bringing things back to our <code>promotions</code> data frame, the <code>gender</code> variable would thus be an irrelevant label. If the <code>gender</code> label is irrelevant, then we can randomly “shuffle” this label to no consequence!</p>
<p>To illustrate this idea, let’s narrow our focus to six arbitrarily chosen resumes of the 48 in Table <a href="10-hypothesis-testing.html#tab:compare-six">10.1</a>: three resumes not resulting in a promotion and three resumes resulting in a promotion. The left-hand side of the table displays the original relationship between <code>decision</code> and <code>gender</code> that was actually observed by researchers.</p>
<p>However, in our hypothesized universe of no gender discrimination, gender is irrelevant and thus it is of no consequence to randomly shuffle the values of <code>gender</code>. The right-hand side of the table displays one such possible random shuffling. Observe how the number of male and female remains the same at three each, but they are listed in a different order.</p>
<table class="kable_wrapper table" style="font-size: 16px; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:compare-six">TABLE 10.1: </span>Relationship of decision and gender for 6 resumes: original (left) and shuffled (right).
</caption>
<tbody>
<tr>
<td>
<table>
<thead>
<tr>
<th style="text-align:right;">
id
</th>
<th style="text-align:left;">
decision
</th>
<th style="text-align:left;">
gender
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
1
</td>
<td style="text-align:left;">
promoted
</td>
<td style="text-align:left;">
male
</td>
</tr>
<tr>
<td style="text-align:right;">
5
</td>
<td style="text-align:left;">
promoted
</td>
<td style="text-align:left;">
male
</td>
</tr>
<tr>
<td style="text-align:right;">
6
</td>
<td style="text-align:left;">
promoted
</td>
<td style="text-align:left;">
male
</td>
</tr>
<tr>
<td style="text-align:right;">
20
</td>
<td style="text-align:left;">
promoted
</td>
<td style="text-align:left;">
male
</td>
</tr>
<tr>
<td style="text-align:right;">
21
</td>
<td style="text-align:left;">
promoted
</td>
<td style="text-align:left;">
male
</td>
</tr>
<tr>
<td style="text-align:right;">
47
</td>
<td style="text-align:left;">
not
</td>
<td style="text-align:left;">
female
</td>
</tr>
</tbody>
</table>
</td>
<td>
<table>
<thead>
<tr>
<th style="text-align:right;">
id
</th>
<th style="text-align:left;">
decision
</th>
<th style="text-align:left;">
gender
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
1
</td>
<td style="text-align:left;">
promoted
</td>
<td style="text-align:left;">
male
</td>
</tr>
<tr>
<td style="text-align:right;">
5
</td>
<td style="text-align:left;">
promoted
</td>
<td style="text-align:left;">
male
</td>
</tr>
<tr>
<td style="text-align:right;">
6
</td>
<td style="text-align:left;">
promoted
</td>
<td style="text-align:left;">
male
</td>
</tr>
<tr>
<td style="text-align:right;">
20
</td>
<td style="text-align:left;">
promoted
</td>
<td style="text-align:left;">
female
</td>
</tr>
<tr>
<td style="text-align:right;">
21
</td>
<td style="text-align:left;">
promoted
</td>
<td style="text-align:left;">
male
</td>
</tr>
<tr>
<td style="text-align:right;">
47
</td>
<td style="text-align:left;">
not
</td>
<td style="text-align:left;">
male
</td>
</tr>
</tbody>
</table>
</td>
</tr>
</tbody>
</table>
<p>Again, such random shuffling of gender only makes sense in the hypothesized universe of no gender discrimination. How could we extend this shuffling of the gender variable to all 48 resumes by hand? One way would be by using standard deck of 52 playing cards, which we display in Figure <a href="10-hypothesis-testing.html#fig:deck-of-cards">10.2</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:deck-of-cards"></span>
<img src="images/ss/670789453.png" alt="Standard deck of 52 playing cards." width="90%" />
<p class="caption">
FIGURE 10.2: Standard deck of 52 playing cards.
</p>
</div>
<p>Since half the cards are red and the other half are black, by removing 2 red cards and 2 black cards, we would end up with 24 red cards and 24 black cards. After shuffling these 48 cards as seen in Figure <a href="10-hypothesis-testing.html#fig:shuffling">10.3</a>, we can flip the cards over one-by-one, assigning “male” for each red card and “female” for each black card.</p>
<div class="figure" style="text-align: center"><span id="fig:shuffling"></span>
<img src="images/ss/128283971.png" alt="Shuffling deck cards." width="90%" />
<p class="caption">
FIGURE 10.3: Shuffling deck cards.
</p>
</div>
<!--
Going back to our index cards, pick up each of the 24 cards corresponding to males and females that you placed on top of the manager cards. The next step is to put the two stacks of index cards together, creating a new set of 48 cards.  If we assume that the two population means are equal, we are saying that there is no association between promotion and gender (male vs female). If there really is no association between these two variables than for each of the 48 managers, it wouldn't matter whether they saw the name of a male or female candidate on the resume they were given. They'd each be equally likely of granting a promotion for each of the two binary genders. So how do we do this with the cards?

Now that we have the our 48 cards corresponding to gender in a single pile, shuffle them. Feel free to do this a couple times. Now take each of the cards off the top of the pile and assign them to the 48 different supervisors. Keep the supervisor cards in the same place they were before. We are, thus, randomly assigning the different values of the **explanatory** variable to each of the entries of the **response** variable. To reiterate, we hold the response variable of `promotion` fixed by not shuffling those cards but we shuffle the values of `gender` as the explanatory variable. Let's check out what the first few rows of this permutation of the gender cards onto the supervisors might look like as data.
-->
<p>We’ve saved one such shuffling/permutation in the <code>promotions_shuffled</code> data frame of the <code>moderndive</code> package. If you view both the original <code>promotions</code> and the shuffled <code>promotions_shuffled</code> data frames and compare them, you’ll see that while the <code>decision</code> variables are identical, the <code>gender</code> variables are indeed different.</p>
<pre class="sourceCode r"><code class="sourceCode r">promotions_shuffled</code></pre>
<pre><code># A tibble: 48 x 3
      id decision gender
   &lt;int&gt; &lt;fct&gt;    &lt;fct&gt; 
 1     1 promoted female
 2     2 promoted female
 3     3 promoted male  
 4     4 promoted female
 5     5 promoted male  
 6     6 promoted male  
 7     7 promoted male  
 8     8 promoted female
 9     9 promoted male  
10    10 promoted female
# … with 38 more rows</code></pre>
<p>Let’s repeat the same exploratory data analysis we did for the original <code>promotions</code> data on our shuffled <code>promotions_shuffled</code> data frame. Let’s create a barplot visualizing the relationship between <code>decision</code> and shuffled <code>gender</code> and compare this to the original unshuffled version in Figure <a href="10-hypothesis-testing.html#fig:promotions-barplot-permuted">10.4</a>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(promotions_shuffled, <span class="kw">aes</span>(<span class="dt">x =</span> gender, <span class="dt">fill =</span> decision)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_bar</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Gender of resume name&quot;</span>)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:promotions-barplot-permuted"></span>
<img src="moderndive_files/figure-html/promotions-barplot-permuted-1.png" alt="Barplot of relationship between shuffled gender and promotion decision." width="\textwidth" />
<p class="caption">
FIGURE 10.4: Barplot of relationship between shuffled gender and promotion decision.
</p>
</div>
<p>Compared to the barplot in Figure <a href="10-hypothesis-testing.html#fig:promotions-barplot">10.1</a>, it appears the different in “male” vs “female” promotions rates is now different. Let’s also compute the proportion of resumes accepted for promotion for each group:</p>
<pre class="sourceCode r"><code class="sourceCode r">promotions_shuffled <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(gender, decision) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">n =</span> <span class="kw">n</span>())</code></pre>
<pre><code># A tibble: 4 x 3
# Groups:   gender [2]
  gender decision     n
  &lt;fct&gt;  &lt;fct&gt;    &lt;int&gt;
1 male   not          6
2 male   promoted    18
3 female not          7
4 female promoted    17</code></pre>
<p>So in this hypothetical universe of no discrimination, 18/24 = 0.75 = 75% of “male” resumes were selected for promotion. On the other hand, 17/24 = 0.708 = 70.8% of “female” resumes were selected for promotion. Comparing these two values, it appears that resumes with male names were selected for promotion at a different rate of 0.75 - 0.708 = 0.042 = 4.2%.</p>
<p>Observe how this difference in rates is different than the difference in rates of 0.292 = 29.2% we originally observed. This is once again due to sampling variation. How can we better understand the effect of this sampling variation? By doing this several times!</p>
</div>
<div id="shuffling-16-times" class="section level3">
<h3><span class="header-section-number">10.1.3</span> Shuffling 16 times</h3>
<p>We recruited 16 groups of our friends to repeat the above shuffling/permuting exercise. We recorded these values in a <a href="https://docs.google.com/spreadsheets/d/1Q-ENy3o5IrpJshJ7gn3hJ5A0TOWV2AZrKNHMsshQtiE/edit?usp=sharing">shared spreadsheet</a>; we display a snapshot of the first 10 rows and 5 columns in Figure <a href="10-hypothesis-testing.html#fig:tactile-shuffling">10.5</a></p>
<div class="figure" style="text-align: center"><span id="fig:tactile-shuffling"></span>
<img src="images/sampling/promotions/shared_spreadsheet.png" alt="Snapshot of shared spreadsheet of shuffled resumes." width="100%" />
<p class="caption">
FIGURE 10.5: Snapshot of shared spreadsheet of shuffled resumes.
</p>
</div>
<p>In Figure <a href="10-hypothesis-testing.html#fig:null-distribution-1">10.6</a>, we show the distribution of the 16 “shuffled” differences in promotion rates using a histogram. Remember that the histogram represents the differences in promotion rates in our <em>hypothesized universe</em> of no gender discrimination. We also mark the observed difference in promotion rate that happened in real-life of 0.292 = 29.2% with a red line.</p>
<div class="figure" style="text-align: center"><span id="fig:null-distribution-1"></span>
<img src="moderndive_files/figure-html/null-distribution-1-1.png" alt="Distribution of &quot;shuffled&quot; differences in promotions." width="\textwidth" />
<p class="caption">
FIGURE 10.6: Distribution of “shuffled” differences in promotions.
</p>
</div>
<p>Observe first that the histogram is both roughly centered at 0. Saying that the difference in promotion rates is 0 is equivalent to saying that both genders had the same promotion rate. In other words, these 16 values are consistent with what we would expect in our hypothesized universe of no gender discrimination. However, while the values are centered at 0, there is variation about 0. This is because even in a hypothesized universe of no gender discrimination, you still still observe small differences in promotion rates because of <em>sampling variation</em>. Looking at the histogram, it could even be as extreme as -0.292 or 0.208.</p>
<p>Turning our attention to what we observed in real-life: the difference of 0.292 = 29.2% is marked with a red line. Ask yourself: in a hypothesized world of no gender discrimination, how likely would it be that we observe this difference? In our opinion, not often! Now ask yourself: what does this say about our hypothesized universe of no gender discrimination.</p>
<!-- 
Now each of our 33 friends does the following:

1. Takes the two decks of cards.
2. Shuffles the cards corresponding to gender.
3. Assigns the shuffled cards to the original deck of supervisors' decisions.
4. Count how many cards fall into each of the four categories:
  - Promoted males
  - Non-promoted males
  - Promoted females
  - Non-promoted females
5. Determines the proportion of promoted males out of 24.
6. Determines the proportion of promoted females out of 24.
7. Subtracts those two differences to get a new value of the test statistic, assuming the null hypothesis is true.

Let's see what this leads to for our friends in terms of results and label where the observed test statistic falls in relation to our friends' statistics:


```r
obs_diff_prop <- promotions %>% 
  specify(decision ~ gender, success = "promoted") %>% 
  calculate(stat = "diff in props", order = c("male", "female"))
obs_diff_prop
```



We see that of the 33 samples we selected only one is close to as extreme as what we observed. Thus, we might guess that we are starting to see some data suggesting that gender discrimination might be at play. Many the statistics calculated appear close to 0 with the vast remainder appearing around values of a difference of -0.1 and 0.1. So what further evidence would we need to make this suggestion a little clearer? More simulations! As we've done before in Chapters \@ref(sampling) and \@ref(confidence-intervals), we'll use the computer to simulate these permutations and calculations many times. Let's do just that with the `infer` package in the next section.
-->
</div>
<div id="what-did-we-just-do-2" class="section level3">
<h3><span class="header-section-number">10.1.4</span> What did we just do?</h3>
<p>What we just demonstrated in this activity is the statistical procedure known as <em>hypothesis testing</em>, specifically via a <em>permutation test</em>. Such procedures allow us to test the validity of hypotheses using sampled data. The term “permutation”  is the mathematical term for “shuffling”: take a series of values and reorder them randomly, as you did with the playing cards.</p>
<p>In fact, permutations are another form of resampling. While the bootstrap method involves resampling with replacement, permutation methods involve resampling without replacement. Think of our exercise involving the slips of paper representing pennies and the hat in Section <a href="9-confidence-intervals.html#resampling-tactile">9.1</a>: after sampling a penny, you put it back in the hat. Now think of our deck of cards, after drawing a card, you laid it out in front of you without putting it back in the hat.</p>
<p>In our above example, we tested the validity of the hypothesized universe of no gender discrimination. Since the evidence contained in our observed sample of 48 resumes in the <code>promotions</code> data frame was somewhat inconsistent with our hypothesized universe, we would be inclined to <em>reject</em> this hypothesized universe and declare that the evidence suggests there is gender discrimination.</p>
<p>Much like with our case study on whether yawning is contagious from Section <a href="9-confidence-intervals.html#case-study-two-prop-ci">9.6</a>, the above example involves inference about an unknown difference of population proportions: <span class="math inline">\(p_{m} - p_{f}\)</span>, where <span class="math inline">\(p_{m}\)</span> is the population proportion of “male” resumes being recommended for promotion and <span class="math inline">\(p_{f}\)</span> is the population proportion of “male” resumes being recommended for promotion.</p>
<p>So based on our sample of <span class="math inline">\(n_m\)</span> = 24 “male” applicants and <span class="math inline">\(n_w\)</span> = 24 “female” applicants, the point estimate for <span class="math inline">\(p_{m} - p_{f}\)</span> is the difference of sample proportions <span class="math inline">\(\widehat{p}_{m} -\widehat{p}_{f}\)</span> = 0.875 - 0.583 = 0.292 = 29.2%. This difference in favor of “male” resumes of 0.292 is greater than 0, suggesting discrimination in favor of men.</p>
<p>However the question we asked ourselves was “is this difference meaningfully different than 0?” In other words, is that difference indicative of true discrimination, or can we just attribute it to sampling variation? Hypothesis testing allows us to make such distinctions.</p>
</div>
</div>
<div id="understanding-ht" class="section level2">
<h2><span class="header-section-number">10.2</span> Understanding hypothesis tests</h2>
<p>Much like the terminology, notation, and definitions relating to sampling you saw in Section <a href="8-sampling.html#sampling-framework">8.3</a>, there is a lot of terminology, notation, and definitions related to hypothesis testing that one must know before being able to conduct hypothesis tests effectively. Learning these may seem like a very daunting task at first. However with practice, practice, and practice, anyone can master them.</p>
<p>First, a <strong>hypothesis</strong>  is a statement about the value of an unknown population parameter. In our resume activity, our population parameter is the difference in population proportions <span class="math inline">\(p_{m} - p_{f}\)</span>. Hypothesis tests can involve any of the population parameters in Table <a href="8-sampling.html#tab:table-ch8">8.8</a> of the 6 inference scenarios we’ll cover in this book and more.</p>
<p>Second, a <strong>hypothesis test</strong>  consists of a test between two competing hypotheses: 1) a <strong>null hypothesis</strong> <span class="math inline">\(H_0\)</span> (pronounced “H-naught”) versus 2) an <strong>alternative hypothesis</strong> <span class="math inline">\(H_A\)</span> (also denoted <span class="math inline">\(H_1\)</span>).</p>
<p>Generally the null hypothesis  is a claim that there really is “no effect” or “no difference.” In many cases, the null hypothesis represents the status quo or that nothing interesting is happening. Furthermore, generally the alternative hypothesis  is the claim the experimenter or researcher wants to establish or find evidence for and is viewed as a “challenger” hypothesis to the null hypothesis <span class="math inline">\(H_0\)</span>. In our resume activity, an appropriate hypothesis test would be:</p>
<p><span class="math display">\[
\begin{aligned}
H_0 &amp;: \text{men and women are promoted at the same rate}\\
\text{vs } H_A &amp;: \text{men are promoted at a higher rate than women}
\end{aligned}
\]</span></p>
<p>Note some of the choices we have made. First, we set the null hypothesis <span class="math inline">\(H_0\)</span> to be that there is no difference in promotion rate and the “challenger” alternative hypothesis <span class="math inline">\(H_A\)</span> to be that there is a difference. While it would not be wrong in principle to reverse the two, it is a convention in statistical inference that the null hypothesis is set to reflect a “null” situation where “nothing is going on,” in this case that there is no difference in promotion rates. Furthermore we set <span class="math inline">\(H_A\)</span> to be that men are promoted at a <em>higher</em> rate, a subjective choice reflecting a prior suspicion we have that this is the case. We call such alternative hypotheses  <em>one-sided alternatives</em>. If someone else however does not share such suspicions and only wants to investigate that there is a difference in rate, whether higher or lower, they we set what is known as a  <em>two-sided alternative</em>.</p>
<p>We can re-express the formulation of our hypothesis test in terms of the notation for our population parameter of interest:</p>
<p><span class="math display">\[
\begin{aligned}
H_0 &amp;: p_{m} - p_{f} = 0\\
\text{vs } H_A&amp;: p_{m} - p_{f} &gt; 0
\end{aligned}
\]</span></p>
<p>Observe how the alternative hypothesis <span class="math inline">\(H_A\)</span> is one-sided <span class="math inline">\(p_{m} - p_{f} &gt; 0\)</span>. Had we opted for a two-sided alternative, we would have set <span class="math inline">\(p_{m} - p_{f} \neq 0\)</span>. For the purposes of the illustration of the terminology, notation, and definitions related to hypothesis testing however, we’ll stick with the simpler one-sided alternative. We’ll present an example of a two-sided alternative in Section <a href="10-hypothesis-testing.html#ht-case-study">10.5</a>.</p>
<p>Third, a <strong>test statistic</strong>  is a point estimate/sample statistic formula used for hypothesis testing, where a sample statistic is merely a summary statistic based on a sample of observations. Recall we saw in Section <a href="4-wrangling.html#summarize">4.3</a> that a summary statistic takes in many values and returns only one. Here, a sample would consist of <span class="math inline">\(n_m\)</span> = 24 “male” resumes and <span class="math inline">\(n_f\)</span> =24 “female” resumes. The point estimate of interest is the resulting difference in sample proportions <span class="math inline">\(\widehat{p}_{m} - \widehat{p}_{f}\)</span>. This quantity estimates of the unknown population parameter of interest: the difference in population proportions <span class="math inline">\(p_{m} - p_{f}\)</span>.</p>
<p>Fourth, the <strong>observed test statistic</strong>  is the value of the test statistic that we observed in real-life. In our case we computed this value using the data saved in the <code>promotions</code> data frame: it was the observed difference of <span class="math inline">\(\widehat{p}_{m} -\widehat{p}_{f}\)</span> = 0.875 - 0.583 = 0.292 = 29.2%.</p>
<p>Fifth, the <strong>null distribution</strong>  is the sampling distribution of the test statistic <em>assuming the null hypothesis <span class="math inline">\(H_0\)</span> is true</em>. Ooof! That’s a long one! Let’s unpack it slowly. The key to understanding the null distribution is that the null hypothesis <span class="math inline">\(H_0\)</span> <em>assumed</em> to be true. We’re not saying that it is true at this point, merely assuming it. In our case, this corresponds to our hypothesized universe of no gender discrimination in promotion rates. Assuming the null hypothesis <span class="math inline">\(H_0\)</span>, also stated as “Under <span class="math inline">\(H_0\)</span>”, how does the test statistic vary due to sampling variation? In our case, how will the difference in sample proportions <span class="math inline">\(\widehat{p}_{m} - \widehat{p}_{f}\)</span> vary due to sampling? Recall from Section <a href="8-sampling.html#sampling-definitions">8.3.2</a> that distributions that display how point estimates vary due to sampling variation are called <em>sampling distributions</em>. The only additional thing to keep in mind for null distributions is that they are sampling distributions <em>assuming the null hypothesis <span class="math inline">\(H_0\)</span> is true</em>.</p>
<p>In our case, we previously visualized the null distribution in Figure <a href="10-hypothesis-testing.html#fig:null-distribution-1">10.6</a>, which we re-display below in Figure <a href="10-hypothesis-testing.html#fig:null-distribution-2">10.7</a> using our new notation and terminology. It is the distribution of the 16 different difference in sample proportions our friends computed <em>assuming</em> a hypothetical universe of no gender discrimination.</p>
<div class="figure" style="text-align: center"><span id="fig:null-distribution-2"></span>
<img src="moderndive_files/figure-html/null-distribution-2-1.png" alt="Null distribution and observed test statistic." width="\textwidth" />
<p class="caption">
FIGURE 10.7: Null distribution and observed test statistic.
</p>
</div>
<p>Sixth, the <strong>p-value</strong>  is the probability of obtaining a test statistic just as extreme or more extreme than the observed test statistic <em>assuming the null hypothesis <span class="math inline">\(H_0\)</span> is true</em>. Double ooof! Let’s unpack this slowly as well. You can think of the p-value as a quantification of “surprise”: assuming <span class="math inline">\(H_0\)</span> is true how surprised are we at observing the test statistic we did? Or in our case, in our hypothesized universe of no gender discrimination how surprised are we that we observed a difference in promotion rates of 0.292 = 29.2%? Very surprised? Somewhat surprised?</p>
<p>The p-value quantifies this probability, or in the case of Figure <a href="10-hypothesis-testing.html#fig:null-distribution-2">10.7</a>, of our 16 difference in sample proportions, what proportion had a more “extreme” result? Here, extreme is defined in terms of the alternative hypothesis <span class="math inline">\(H_A\)</span> that “male” applicants are promoted at a higher rate than “female” applicants. In other words, how often was the discrimination in favor of men even more pronounced than 0.875 - 0.583 = 0.292 = 29.2%?</p>
<p>In this case, only 0 time out of 16 did we obtain a difference in proportion greater than or equal to the observed difference of 0.292 = 29.2%. A very rare outcome of only 1 time in 16! Given the rarity of such a pronounced in difference in promotion rates in our hypothesized universe of no gender discrimination, we’re inclined to <em>reject</em>  this hypothesis in favor of the one saying there is discrimination in favor of the “male” applicants. We’ll see later on however, the p-value isn’t quite 1/16, but rather (0 + 1)/(16 + 1) = 1/17 = 0.059 as we need to include the the observed test statistic in our calculation.</p>
<p>Seventh and lastly, in many hypothesis testing procedures, it is common to and recommended to set the <strong>significance level</strong>  of the test beforehand. It is denoted by the Greek letter <span class="math inline">\(\alpha\)</span>. This value acts as a cutoff on the p-values, where if the p-value falls below <span class="math inline">\(\alpha\)</span>, we would reject the null hypothesis <span class="math inline">\(H_0\)</span>. Alternatively, if the p-value does not fall below <span class="math inline">\(\alpha\)</span>, we would fail to reject <span class="math inline">\(H_0\)</span>. Note this statement is not quite the same as saying we “accept” <span class="math inline">\(H_0\)</span>. This distinction is rather subtle and not immediately obvious, so we’ll revisit it later in Section <a href="10-hypothesis-testing.html#ht-interpretation">10.4</a>.</p>
<p>While different fields tend to use different values of <span class="math inline">\(\alpha\)</span>, some commonly used values for <span class="math inline">\(\alpha\)</span> are 0.1, 0.01, and 0.05, with 0.05 being the choice people often make when people don’t put much thought into it. We’ll talk more about <span class="math inline">\(\alpha\)</span> significance levels in Section <a href="10-hypothesis-testing.html#ht-interpretation">10.4</a>, but first let’s fully conduct the hypothesis test corresponding to our promotions activity in the next section.</p>
</div>
<div id="ht-infer" class="section level2">
<h2><span class="header-section-number">10.3</span> Conducting hypothesis tests</h2>
<p>In Section <a href="9-confidence-intervals.html#bootstrap-process">9.4</a>, we showed you how to construct confidence intervals. We first illustrated how to do this using raw <code>dplyr</code> data wrangling verbs and the <code>rep_sample_n()</code> function which we introduced in Section <a href="8-sampling.html#shovel-1000-times">8.2.3</a> when illustrating the use of the virtual shovel. In particular, we constructed confidence intervals by resampling with replacement by setting the <code>replace = TRUE</code> argument to the <code>rep_sample_n()</code> function.</p>
<p>We then showed you how to perform the same task using the <code>infer</code> package workflow. While the end result of both workflows are the same, a bootstrap distribution from which we can construct a confidence interval, the <code>infer</code> package workflow emphasizes each of the steps in the overall process in Figure <a href="10-hypothesis-testing.html#fig:infer-ci">10.8</a> using function names that are intuitively named:</p>
<ol style="list-style-type: decimal">
<li><code>specify()</code> the variables of interest in your data frame</li>
<li><code>generate()</code> replicates of bootstrap resamples with replacement</li>
<li><code>calculate()</code> the summary statistic of interest</li>
<li><code>visualize()</code> the resulting bootstrap distribution and the confidence interval.</li>
</ol>
<div class="figure" style="text-align: center"><span id="fig:infer-ci"></span>
<img src="images/flowcharts/infer/visualize.png" alt="Confidence intervals via the infer package." width="80%" />
<p class="caption">
FIGURE 10.8: Confidence intervals via the infer package.
</p>
</div>
<p>In this section, we now show you how to extend and modify the previously seen <code>infer</code> pipeline to conduct hypothesis tests. You’ll notice that the basic outline of the workflow is almost identical, except for an additional <code>hypothesize()</code> step between <code>specify()</code> and <code>generate()</code>, as can be seen in Figure <a href="10-hypothesis-testing.html#fig:inferht">10.9</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:inferht"></span>
<img src="images/flowcharts/infer/ht.png" alt="Hypothesis testing via the infer package." width="80%" />
<p class="caption">
FIGURE 10.9: Hypothesis testing via the infer package.
</p>
</div>
<p>Furthermore, we’ll use a pre-specified significance level <span class="math inline">\(\alpha\)</span> = 0.001 for this hypothesis test. Let’s leave the justification of this choice of <span class="math inline">\(\alpha\)</span> until later on in Section <a href="10-hypothesis-testing.html#ht-interpretation">10.4</a>.</p>
<div id="infer-workflow-ht" class="section level3">
<h3><span class="header-section-number">10.3.1</span> infer package workflow</h3>
<!--
you were introduced to the framework for inference including the following verbs: `specify()`, `generate()`, and `calculate()`. This was useful when calculating bootstrap distributions in order to develop confidence intervals in both the one-sample and two-sample cases. One of the great powers of the `infer` package is in extending confidence intervals to hypothesis testing by including one more verb: `hypothesize()`. 

Remember that our goal here is to generate many different samples, assuming the null hypothesis is true. In doing so we will create a **null distribution**. This null distribution is similar to what we have seen so far with the *sampling distribution* in Chapter \@ref(sampling) and the *bootstrap distribution* in Chapter \@ref(confidence-intervals). Here though we have one more condition to apply in that we assume the null hypothesis is true, thus where the name of the *null* distribution comes from. The null distribution is still used to look at the variability from one sample to the next, but now we are interested in seeing where what we actually saw would fall on the "chance distribution." In doing so, we'll have a good sense for whether random chance is a good explanation for seeing the results in our observed sample or if there is something else going on which better aligns with $H_a$, the alternative hypothesis.

Let's explore the `infer` pipeline one more time here on the gender discrimination study from Section \@ref(ht-activity).
-->
<div id="specify-variables-3" class="section level4 unnumbered">
<h4>1. <code>specify</code> variables</h4>
<p>Recall that we use the <code>specify()</code>  verb to denote the response and, if needed, explanatory variables for our study. In this case, since we are interested in any potential effects of gender on promotion decisions, we set <code>decision</code> as the response variable and <code>gender</code> as the explanatory variable using the <code>formula</code> argument using the notation <code>&lt;response&gt; ~ &lt;explanatory&gt;</code> where <code>&lt;response</code>&gt; is the name of the response variable in the data frame and <code>&lt;explanatory&gt;</code> is the name of the explanatory variable. So in our case it is <code>decision ~ gender</code>. Lastly, since we are interested in the proportions of resumes <code>&quot;promoted&quot;</code> and not proportions of resumes <code>not</code> promoted, we set the argument <code>success = &quot;promoted&quot;</code></p>
<pre class="sourceCode r"><code class="sourceCode r">promotions <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">specify</span>(<span class="dt">formula =</span> decision <span class="op">~</span><span class="st"> </span>gender, <span class="dt">success =</span> <span class="st">&quot;promoted&quot;</span>)</code></pre>
<pre><code>Response: decision (factor)
Explanatory: gender (factor)
# A tibble: 48 x 2
   decision gender
   &lt;fct&gt;    &lt;fct&gt; 
 1 promoted male  
 2 promoted male  
 3 promoted male  
 4 promoted male  
 5 promoted male  
 6 promoted male  
 7 promoted male  
 8 promoted male  
 9 promoted male  
10 promoted male  
# … with 38 more rows</code></pre>
<p>Again, notice how the <code>promotions</code> data itself doesn’t change, but the <code>Response: decision (factor)</code> and <code>Explanatory: gender (factor)</code> <em>meta-data</em> do. This is similar to how the <code>group_by()</code> verb from <code>dplyr</code> doesn’t change the data, but only adds “grouping” meta-data as we saw in Section <a href="4-wrangling.html#groupby">4.4</a>.</p>
</div>
<div id="hypothesize-the-null" class="section level4 unnumbered">
<h4>2. <code>hypothesize</code> the null</h4>
<p>In order to conduct hypothesis tests using the <code>infer</code> workflow, we need a new step:  <code>hypothesize()</code>. Recall from Section <a href="10-hypothesis-testing.html#understanding-ht">10.2</a> that our hypothesis test was</p>
<p><span class="math display">\[
\begin{aligned}
H_0 &amp;: p_{m} - p_{f} = 0\\
\text{vs } H_A&amp;: p_{m} - p_{f} &gt; 0
\end{aligned}
\]</span></p>
<p>In other words, the null hypothesis <span class="math inline">\(H_0\)</span> corresponding to our “hypothesized universe” stated that there was no difference in gender-based discrimination rates. We set this null hypothesis <span class="math inline">\(H_0\)</span> in our <code>infer</code> workflow by setting the <code>null</code> argument of the <code>hypothesize()</code> function to either:</p>
<ul>
<li><code>&quot;point&quot;</code> for hypotheses involving a single sample or</li>
<li><code>&quot;independence&quot;</code> for hypotheses involving two samples</li>
</ul>
<p>In our case, since we have two samples (the “male” and “female” applicants), we set <code>null = &quot;independence&quot;</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r">promotions <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">specify</span>(<span class="dt">formula =</span> decision <span class="op">~</span><span class="st"> </span>gender, <span class="dt">success =</span> <span class="st">&quot;promoted&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">hypothesize</span>(<span class="dt">null =</span> <span class="st">&quot;independence&quot;</span>)</code></pre>
<pre><code># A tibble: 48 x 2
   decision gender
   &lt;fct&gt;    &lt;fct&gt; 
 1 promoted male  
 2 promoted male  
 3 promoted male  
 4 promoted male  
 5 promoted male  
 6 promoted male  
 7 promoted male  
 8 promoted male  
 9 promoted male  
10 promoted male  
# … with 38 more rows</code></pre>
<p>Again, the data has not changed yet. This will occur at the upcoming <code>generate()</code> step; we’re merely setting meta-data for now.</p>
<p>Where do the terms “point” and “independence” come from? These are two technical statistics terms. The term “point” relates from the fact that for a single group of observations, you will test the value of the point. Going back to the pennies example from Chapter <a href="9-confidence-intervals.html#confidence-intervals">9</a>, say we wanted to test if the mean year of all US pennies was equal to 1993 or not, we would be testing the “point” value <span class="math inline">\(\mu\)</span> as follows</p>
<p><span class="math display">\[
\begin{aligned}
H_0 &amp;: \mu = 1993\\
\text{vs } H_A&amp;: \mu \neq 1993
\end{aligned}
\]</span></p>
<p>The term “independence” relates to the fact that for two groups of observations, you are testing whether or not the response variable is independent of the explanatory variable that assigns the group. In our case, we are testing whether the <code>decision</code> response variable is “independent” of the explanatory variable <code>gender</code> that assigns each resume to either one of the two groups.</p>
</div>
<div id="generate-replicates-3" class="section level4 unnumbered">
<h4>3. <code>generate</code> replicates</h4>
<p>After we have set the null hypothesis, we simulate observations assuming the null hypothesis is true by repeating the shuffling exercise you performed in Section <a href="10-hypothesis-testing.html#ht-activity">10.1</a> several times. Instead of merely doing it 16 times as our groups of friends did, let’s use the computer to repeat this 1000 times by setting <code>reps = 1000</code> in the <code>generate()</code>  function. However, unlike with confidence intervals where we generated replicates using <code>type = &quot;bootstrap&quot;</code> resampling with replacement, we’ll now perform shuffles/permutations by setting <code>type = &quot;permute&quot;</code>. Recall that shuffles/permutations are a form of resampling without replacement.</p>
<pre class="sourceCode r"><code class="sourceCode r">promotions <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">specify</span>(<span class="dt">formula =</span> decision <span class="op">~</span><span class="st"> </span>gender, <span class="dt">success =</span> <span class="st">&quot;promoted&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">hypothesize</span>(<span class="dt">null =</span> <span class="st">&quot;independence&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">generate</span>(<span class="dt">reps =</span> <span class="dv">1000</span>, <span class="dt">type =</span> <span class="st">&quot;permute&quot;</span>)</code></pre>
<pre><code>Response: decision (factor)
Explanatory: gender (factor)
Null Hypothesis: independence
# A tibble: 48,000 x 3
# Groups:   replicate [1,000]
   decision gender replicate
   &lt;fct&gt;    &lt;fct&gt;      &lt;int&gt;
 1 promoted male           1
 2 not      male           1
 3 promoted male           1
 4 promoted female         1
 5 promoted female         1
 6 promoted female         1
 7 promoted female         1
 8 promoted female         1
 9 promoted female         1
10 not      female         1
# … with 47,990 more rows</code></pre>
<p>Note the the resulting data frame has 48,000 rows. This is because we performed shuffles/permutations of the 48 values of <code>gender</code> 1000 times and thus 48,000 = 1000 <span class="math inline">\(\times\)</span> 48. Accordingly the variable <code>replicate</code>, indicating which resample each row belongs to, has the value <code>1</code> 48 times, the value <code>2</code> 48 times, all the way through to the value <code>1000</code> 48 times.</p>
</div>
<div id="calculate-summary-statistics-3" class="section level4 unnumbered">
<h4>4. <code>calculate</code> summary statistics</h4>
<p>Now that we have 1000 replicated “shuffles” assuming the null hypothesis that both “male” and “female” applicants were promoted at the same rate, let’s <code>calculate()</code>  the appropriate summary statistic for each of our 1000 shuffles. Recall from Section <a href="10-hypothesis-testing.html#understanding-ht">10.2</a> that point estimates/summary statistics relating to hypothesis testing have a specific name: <em>test statistics</em>. Since the unknown population parameter of interest is the difference in population proportions <span class="math inline">\(p_{m} - p_{f}\)</span>, the test statistic of interest here is the difference in sample proportions <span class="math inline">\(\widehat{p}_{m} - \widehat{p}_{f}\)</span>.</p>
<p>For each of our 1000 shuffles, we can calculate this test statistic by setting <code>stat = &quot;diff in props&quot;</code>. Furthermore, since we are interested in <span class="math inline">\(\widehat{p}_{m} - \widehat{p}_{f}\)</span> and not the reverse-ordered <span class="math inline">\(\widehat{p}_{f} - \widehat{p}_{m}\)</span>, we set <code>order = c(&quot;male&quot;, &quot;female&quot;)</code>. Let’s save the result in a data frame called <code>null_distribution</code>:</p>
<pre class="sourceCode r"><code class="sourceCode r">null_distribution &lt;-<span class="st"> </span>promotions <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">specify</span>(<span class="dt">formula =</span> decision <span class="op">~</span><span class="st"> </span>gender, <span class="dt">success =</span> <span class="st">&quot;promoted&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">hypothesize</span>(<span class="dt">null =</span> <span class="st">&quot;independence&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">generate</span>(<span class="dt">reps =</span> <span class="dv">1000</span>, <span class="dt">type =</span> <span class="st">&quot;permute&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">calculate</span>(<span class="dt">stat =</span> <span class="st">&quot;diff in props&quot;</span>, <span class="dt">order =</span> <span class="kw">c</span>(<span class="st">&quot;male&quot;</span>, <span class="st">&quot;female&quot;</span>))
null_distribution</code></pre>
<pre><code># A tibble: 1,000 x 2
   replicate       stat
       &lt;int&gt;      &lt;dbl&gt;
 1         1 -0.208333 
 2         2  0.291667 
 3         3  0.125    
 4         4 -0.208333 
 5         5 -0.125    
 6         6  0.0416667
 7         7 -0.0416667
 8         8  0.291667 
 9         9  0.0416667
10        10  0.125    
# … with 990 more rows</code></pre>
<p>Observe that we have 1000 values of <code>stat</code>, each representing one “shuffled” instance of <span class="math inline">\(\widehat{p}_{m} - \widehat{p}_{f}\)</span> in a hypothesized world of no gender discrimination. Note as well we chose the name of this data frame carefully: <code>null_distribution</code>. Recall once again from Section <a href="10-hypothesis-testing.html#understanding-ht">10.2</a> that such sampling distributions when the null hypothesis <span class="math inline">\(H_0\)</span> is assumed to be true have a special name: the <em>null distribution</em>.</p>
<p>But wait! What happened in real-life? What was the observed difference in promotions rates? In other words, what was the <em>observed test statistic</em> <span class="math inline">\(\widehat{p}_{m} - \widehat{p}_{f}\)</span>? Recall from Section <a href="10-hypothesis-testing.html#ht-activity">10.1</a> that we computed this observed difference by hand to be 0.875 - 0.583 = 0.292 = 29.2%. We can also achieve this using the code above but with the <code>hypothesize()</code> and <code>generate()</code> steps removed. Let’s save this in <code>obs_diff_prop</code></p>
<pre class="sourceCode r"><code class="sourceCode r">obs_diff_prop &lt;-<span class="st"> </span>promotions <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">specify</span>(decision <span class="op">~</span><span class="st"> </span>gender, <span class="dt">success =</span> <span class="st">&quot;promoted&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">calculate</span>(<span class="dt">stat =</span> <span class="st">&quot;diff in props&quot;</span>, <span class="dt">order =</span> <span class="kw">c</span>(<span class="st">&quot;male&quot;</span>, <span class="st">&quot;female&quot;</span>))
obs_diff_prop</code></pre>
<pre><code># A tibble: 1 x 1
      stat
     &lt;dbl&gt;
1 0.291667</code></pre>
</div>
<div id="visualize-the-p-value" class="section level4 unnumbered">
<h4>5. <code>visualize</code> the p-value</h4>
<p>The final step is to measure how surprised would we be by a promotion difference of 29.2% in a hypothesized universe of no gender discrimination. If very surprised, then we would be inclined to reject the validity of our hypothesized universe.</p>
<p>We start by visualizing the <em>null distribution</em> of our 1000 values of <span class="math inline">\(\widehat{p}_{m} - \widehat{p}_{f}\)</span> using <code>visualize()</code>  in Figure <a href="10-hypothesis-testing.html#fig:null-distribution-infer">10.10</a>. Recall that these are values of the difference in promotion rate assuming <span class="math inline">\(H_0\)</span> is true, in other words in our hypothesized universe of no gender discrimination.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">visualize</span>(null_distribution, <span class="dt">binwidth =</span> <span class="fl">0.1</span>)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:null-distribution-infer"></span>
<img src="moderndive_files/figure-html/null-distribution-infer-1.png" alt="Bootstrap distribution" width="\textwidth" />
<p class="caption">
FIGURE 10.10: Bootstrap distribution
</p>
</div>
<p>Let’s now add what happened in real-life to Figure <a href="10-hypothesis-testing.html#fig:null-distribution-infer">10.10</a>, the observed difference in promotions rates of 0.875 - 0.583 = 0.292 = 29.2%. However, instead of merely adding a vertical line using <code>geom_vline()</code>, let’s use the  <code>shade_p_value()</code> function with <code>obs_stat</code> set to the observed test statistic value we saved in <code>obs_diff_prop</code> and <code>direction = &quot;right&quot;</code>:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">visualize</span>(null_distribution, <span class="dt">bins =</span> <span class="dv">10</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">shade_p_value</span>(<span class="dt">obs_stat =</span> obs_diff_prop, <span class="dt">direction =</span> <span class="st">&quot;right&quot;</span>)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:null-distribution-infer-2"></span>
<img src="moderndive_files/figure-html/null-distribution-infer-2-1.png" alt="Shaded histogram to show p-value." width="\textwidth" />
<p class="caption">
FIGURE 10.11: Shaded histogram to show p-value.
</p>
</div>
<p>In the resulting Figure <a href="10-hypothesis-testing.html#fig:null-distribution-infer-2">10.11</a>, the solid red line marks 0.292 = 29.2%. However, what does the shaded-region correspond to? This is the p-value. Recall the definition of the p-value from Section <a href="10-hypothesis-testing.html#understanding-ht">10.2</a>:</p>
<blockquote>
<p>A p-value is the probability of obtaining a test statistic just as or more extreme than the observed test statistic <em>assuming the null hypothesis <span class="math inline">\(H_0\)</span> is true</em>.</p>
</blockquote>
<p>Recall our alternative hypothesis <span class="math inline">\(H_A\)</span> is that <span class="math inline">\(p_{m} - p_{f} &gt; 0\)</span> i.e. there is a difference in promotion rates in favor of men. So “more extreme” corresponds to differences that are “bigger” or “more positive” or “more to the right.” Hence we set the <code>direction</code> argument of <code>shade_p_value()</code> to be <code>&quot;right&quot;</code>. Had our alternative hypothesis <span class="math inline">\(H_A\)</span> been the other possible one-sided alternative <span class="math inline">\(p_{m} - p_{f} &lt; 0\)</span> suggesting discrimination in favor of “female” applicants, we would’ve set <code>direction = &quot;left&quot;</code>. Had our alternative hypothesis <span class="math inline">\(H_A\)</span> been two-sided <span class="math inline">\(p_{m} - p_{f} \neq 0\)</span> suggesting discrimination in either direction, we would’ve set <code>direction = &quot;both&quot;</code>.</p>
<p>So judging by the shaded region in Figure <a href="10-hypothesis-testing.html#fig:null-distribution-infer-2">10.11</a>, it seems we would somewhat rarely observe differences in promotion rates of 0.292 = 29.2% or more in a hypothesized universe of no gender discrimination. In other words, the p-value is somewhat small. Hence, we would be inclined to reject this hypothesized universe, or in statistical language: reject <span class="math inline">\(H_0\)</span>.</p>
<p>What fraction of the null distribution is shaded? In other words, what is the exact p-value? We can compute its numerical value using the <code>get_p_value()</code>  function using the exact same arguments as with the <code>visualize()</code> code above:</p>
<pre class="sourceCode r"><code class="sourceCode r">null_distribution <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">get_p_value</span>(<span class="dt">obs_stat =</span> obs_diff_prop, <span class="dt">direction =</span> <span class="st">&quot;right&quot;</span>)</code></pre>
<pre><code># A tibble: 1 x 1
  p_value
    &lt;dbl&gt;
1   0.027</code></pre>
<p>In other words, the probability of observing a difference in promotion rates as large as 0.292 = 29.2% due to sampling variation alone is only 0.027 = 2.7%. Since this p-value is greater than our pre-specified significance level <span class="math inline">\(\alpha\)</span> = 0.001, we fail to reject the null hypothesis <span class="math inline">\(H_0: p_{m} - p_{f} = 0\)</span>. In other words, this p-value wasn’t sufficiently small to reject our hypothesized universe of no gender discrimination.</p>
</div>
</div>
<div id="comparison-with-confidence-intervals" class="section level3">
<h3><span class="header-section-number">10.3.2</span> Comparison with confidence intervals</h3>
<p>One of the great things about the <code>infer</code> pipeline is that we can jump between hypothesis tests and confidence intervals with minimal changes! Recall from the previous section that to create the null distribution needed to compute the p-value, we ran the following code:</p>
<pre class="sourceCode r"><code class="sourceCode r">null_distribution &lt;-<span class="st"> </span>promotions <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">specify</span>(<span class="dt">formula =</span> decision <span class="op">~</span><span class="st"> </span>gender, <span class="dt">success =</span> <span class="st">&quot;promoted&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">hypothesize</span>(<span class="dt">null =</span> <span class="st">&quot;independence&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">generate</span>(<span class="dt">reps =</span> <span class="dv">1000</span>, <span class="dt">type =</span> <span class="st">&quot;permute&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">calculate</span>(<span class="dt">stat =</span> <span class="st">&quot;diff in props&quot;</span>, <span class="dt">order =</span> <span class="kw">c</span>(<span class="st">&quot;male&quot;</span>, <span class="st">&quot;female&quot;</span>))</code></pre>
<p>To create the corresponding bootstrap distribution needed to construct a 95% confidence interval for <span class="math inline">\(p_{m} - p_{f}\)</span>, we only need to make two changes.  First, we remove the <code>hypothesize()</code> step since we are no longer assuming a null hypothesis <span class="math inline">\(H_0\)</span> is true when we bootstrap. We do this by commenting out the <code>hypothesize()</code> line of code. Second, we switch the <code>type</code> of resampling in the <code>generate()</code> step to be <code>&quot;bootstrap&quot;</code> instead of <code>&quot;permute&quot;</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r">bootstrap_distribution &lt;-<span class="st"> </span>promotions <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">specify</span>(<span class="dt">formula =</span> decision <span class="op">~</span><span class="st"> </span>gender, <span class="dt">success =</span> <span class="st">&quot;promoted&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="co"># Change 1 - Remove hypothesize():</span>
<span class="st">  </span><span class="co"># hypothesize(null = &quot;independence&quot;) %&gt;% </span>
<span class="st">  </span><span class="co"># Change 2 - Switch type from &quot;permute&quot; to &quot;bootstrap&quot;:</span>
<span class="st">  </span><span class="kw">generate</span>(<span class="dt">reps =</span> <span class="dv">1000</span>, <span class="dt">type =</span> <span class="st">&quot;bootstrap&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">calculate</span>(<span class="dt">stat =</span> <span class="st">&quot;diff in props&quot;</span>, <span class="dt">order =</span> <span class="kw">c</span>(<span class="st">&quot;male&quot;</span>, <span class="st">&quot;female&quot;</span>))</code></pre>
<p>Using <code>bootstrap_distribution</code>, we first compute the percentile-based confidence intervals:</p>
<pre class="sourceCode r"><code class="sourceCode r">percentile_ci &lt;-<span class="st"> </span>bootstrap_distribution <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">get_confidence_interval</span>(<span class="dt">level =</span> <span class="fl">0.95</span>, <span class="dt">type =</span> <span class="st">&quot;percentile&quot;</span>)
percentile_ci</code></pre>
<pre><code># A tibble: 1 x 2
     `2.5%`  `97.5%`
      &lt;dbl&gt;    &lt;dbl&gt;
1 0.0414187 0.522222</code></pre>
<p>Using our shorthand interpretation for 95% confidence intervals from Section <a href="9-confidence-intervals.html#shorthand">9.5.2</a>, we are 95% “confident” that the true difference in population proportions <span class="math inline">\(p_{m} - p_{f}\)</span> is between (0.041, 0.522). Let’s visualize <code>bootstrap_distribution</code> and this percentile-based 95% confidence interval for <span class="math inline">\(p_{m} - p_{f}\)</span> in Figure <a href="10-hypothesis-testing.html#fig:bootstrap-distribution-two-prop-percentile">10.12</a>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">visualize</span>(bootstrap_distribution) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">shade_confidence_interval</span>(<span class="dt">endpoints =</span> percentile_ci)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:bootstrap-distribution-two-prop-percentile"></span>
<img src="moderndive_files/figure-html/bootstrap-distribution-two-prop-percentile-1.png" alt="Percentile-based 95 percent confidence interval." width="\textwidth" />
<p class="caption">
FIGURE 10.12: Percentile-based 95 percent confidence interval.
</p>
</div>
<p>Notice a key value that is not included in the 95% confidence interval for <span class="math inline">\(p_{m} - p_{f}\)</span>: 0. In other words, a difference of 0 is not included in our net, suggesting that <span class="math inline">\(p_{m}\)</span> and <span class="math inline">\(p_{f}\)</span> are different!</p>
<p>Since the bootstrap distribution appears to be roughly normally shaped, we can also used the standard error based confidence intervals, being sure to specify <code>point_estimate</code> as the observed difference in promotion rates 0.292 = 29.2% saved in <code>obs_diff_prop</code>:</p>
<pre class="sourceCode r"><code class="sourceCode r">se_ci &lt;-<span class="st"> </span>bootstrap_distribution <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">get_confidence_interval</span>(<span class="dt">level =</span> <span class="fl">0.95</span>, <span class="dt">type =</span> <span class="st">&quot;se&quot;</span>, 
                          <span class="dt">point_estimate =</span> obs_diff_prop)
se_ci</code></pre>
<pre><code># A tibble: 1 x 2
      lower    upper
      &lt;dbl&gt;    &lt;dbl&gt;
1 0.0490607 0.534273</code></pre>
<p>Let’s visualize <code>bootstrap_distribution</code> again and now the standard error based 95% confidence interval for <span class="math inline">\(p_{m} - p_{f}\)</span> in Figure <a href="10-hypothesis-testing.html#fig:bootstrap-distribution-two-prop-se">10.13</a>. Again, notice how the value 0 is not included in our confidence interval, again suggesting that <span class="math inline">\(p_{m}\)</span> and <span class="math inline">\(p_{f}\)</span> are different!</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">visualize</span>(bootstrap_distribution) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">shade_confidence_interval</span>(<span class="dt">endpoints =</span> se_ci)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:bootstrap-distribution-two-prop-se"></span>
<img src="moderndive_files/figure-html/bootstrap-distribution-two-prop-se-1.png" alt="Standard error-based 95 percent confidence interval." width="\textwidth" />
<p class="caption">
FIGURE 10.13: Standard error-based 95 percent confidence interval.
</p>
</div>
<div class="learncheck">
<p>
<strong><em>Learning check</em></strong>
</p>
</div>
<p><strong>(LC10.1)</strong> Conduct the same analysis comparing male and female promotion rates using the median rating instead of the mean rating? What was different and what was the same?</p>
<p><strong>(LC10.2)</strong> Describe in a paragraph how we used Allen Downey’s diagram to conclude if a statistical difference existed between the promotion rate of males and females using this study.</p>
<p><strong>(LC10.3)</strong> Why are we relatively confident that the distributions of the sample proportions will be good approximations of the population distributions of promotion proportions for the two genders?</p>
<p><strong>(LC10.4)</strong> Using the definition of “<span class="math inline">\(p\)</span>-value”, write in words what the <span class="math inline">\(p\)</span>-value represents for the hypothesis test above comparing the promotion rates for males and females.</p>
<p><strong>(LC10.5)</strong> What is the value of the <span class="math inline">\(p\)</span>-value for the hypothesis test comparing the mean rating of romance to action movies? How can it be interpreted in the context of the problem?</p>
<div class="learncheck">

</div>
</div>
<div id="only-one-test" class="section level3">
<h3><span class="header-section-number">10.3.3</span> “There is only one test”</h3>
<p>Let’s recap the steps necessary to conduct a hypothesis test using the terminology, notation, and definitions related to sampling you saw in Section <a href="10-hypothesis-testing.html#understanding-ht">10.2</a> and the <code>infer</code> workflow from Section #ref(infer-workflow-ht):</p>
<ol style="list-style-type: decimal">
<li><code>specify()</code> the variables of interest in your observed data.</li>
<li><code>hypothesize()</code> the null hypothesis <span class="math inline">\(H_0\)</span>. In other words, set a “model” for the universe assuming <span class="math inline">\(H_0\)</span> is true.</li>
<li><code>generate()</code> shuffles assuming <span class="math inline">\(H_0\)</span> is true. In other words, <em>simulate</em> data assuming <span class="math inline">\(H_0\)</span> in true.</li>
<li><code>calculate()</code> the <em>test statistic</em> of interest, both for the observed data and your simulated data.</li>
<li><code>visualize()</code> the resulting <em>null distribution</em> and compute the <em>p-value</em> by comparing the null distribution to the observed test statistic.</li>
</ol>
<p>While this is a lot to digest, especially the first time you encounter hypothesis testing, the nice is thing is once you understand this framework, then you can understand any hypothesis test. In a famous blog post, computer scientist Allen Downey called this the <a href="http://allendowney.blogspot.com/2016/06/there-is-still-only-one-test.html">“There is only one test”</a> framework, which he displayed in Figure <a href="10-hypothesis-testing.html#fig:htdowney">10.14</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:htdowney"></span>
<img src="images/ht.png" alt="Hypothesis Testing Framework." width="90%" />
<p class="caption">
FIGURE 10.14: Hypothesis Testing Framework.
</p>
</div>
<p>Notice a similarity with the “hypothesis testing via <code>infer</code>” diagram you saw in Figure <a href="10-hypothesis-testing.html#fig:inferht">10.9</a>? That’s because the <code>infer</code> package was explicitly designed to match the “There is only one test” framework. So if you can understand the framework, you can easily generalize these ideals for all hypothesis testing scenarios, whether for population proportions <span class="math inline">\(p\)</span>, population means <span class="math inline">\(\mu\)</span>, differences in population proportions <span class="math inline">\(p_1 - p_2\)</span>, differences in population means <span class="math inline">\(\mu_1 - \mu_2\)</span>, and as you’ll see in Chapter <a href="11-inference-for-regression.html#inference-for-regression">11</a> on inference for regression, population regression intercepts <span class="math inline">\(\beta_0\)</span> and population regression slopes <span class="math inline">\(\beta_1\)</span> as well.</p>
</div>
</div>
<div id="ht-interpretation" class="section level2">
<h2><span class="header-section-number">10.4</span> Interpreting hypothesis tests</h2>
<p>Hypothesis tests are often challenging to understand at first. In this section, we’ll focus on ways to help with deciphering the process and address some common misconceptions.</p>
<div id="trial" class="section level3">
<h3><span class="header-section-number">10.4.1</span> Two possible outcomes</h3>
<p>In Section <a href="10-hypothesis-testing.html#understanding-ht">10.2</a>, we mentioned that given a pre-specified significance level <span class="math inline">\(\alpha\)</span> there are two possible outcomes of a hypothesis test:</p>
<ul>
<li>If the p-value is less than <span class="math inline">\(\alpha\)</span>, we <em>reject</em> the null hypothesis <span class="math inline">\(H_0\)</span> in favor of <span class="math inline">\(H_A\)</span>.</li>
<li>If the p-value is greater than or equal to <span class="math inline">\(\alpha\)</span>, we <em>fail to reject</em> the null hypothesis <span class="math inline">\(H_0\)</span>.</li>
</ul>
<p>Unfortunately, the latter result is often misinterpreted as “accepting” the null hypothesis <span class="math inline">\(H_0\)</span>. While at first glance it may seem to be saying the same thing, there is a subtle difference. Saying that we “accept the null hypothesis <span class="math inline">\(H_0\)</span>” is equivalent to stating “we think the null hypothesis <span class="math inline">\(H_0\)</span> is true.” However, saying that we “fail to reject the null hypothesis <span class="math inline">\(H_0\)</span>” is saying something else: “<span class="math inline">\(H_0\)</span> may still be false, we don’t have any evidence to say so.” In other words, there is an absence of proof. However absence of proof is not proof of absence.</p>
<p>As an analogy to this distinction,  let’s use the United States criminal justice system as an analogy. A criminal trial in the United States is a similar situation in which a choice between two contradictory claims must be made about a defendant who is on trial.</p>
<ol style="list-style-type: decimal">
<li>The defendant is truly either “innocent” or “guilty.”</li>
<li>The defendant is presumed “innocent until proven guilty.”</li>
<li>The defendant is found guilty only if there is <em>strong evidence</em> that the defendant is guilty. The phrase “beyond a reasonable doubt” is often used to set the cutoff value for when enough evidence exists to find the defendant guilty.</li>
<li>The defendant is found to be either “not guilty” or “guilty” in the ultimate verdict.</li>
</ol>
<p>In other words, “not guilty” verdicts are not suggesting the defendant is “innocent”, but instead that “while the defendant may still actually be guilty, there wasn’t enough evidence to prove this fact.” Now let’s make the connections with hypothesis tests.</p>
<ol style="list-style-type: decimal">
<li>Either the null hypothesis <span class="math inline">\(H_0\)</span> or the alternative hypothesis <span class="math inline">\(H_A\)</span> is true.</li>
<li>Hypothesis tests are always conducted assuming the null hypothesis <span class="math inline">\(H_0\)</span> is true.</li>
<li>We reject the null hypothesis <span class="math inline">\(H_0\)</span> in favor of <span class="math inline">\(H_A\)</span> only if the evidence found in the sample suggests that <span class="math inline">\(H_A\)</span> is true. The significance level <span class="math inline">\(\alpha\)</span> is used to set the threshold on how strong evidence we require.</li>
<li>We ultimately decide to either “fail to reject <span class="math inline">\(H_0\)</span>” or “reject <span class="math inline">\(H_0\)</span>.”</li>
</ol>
<p>So while gut instinct may suggest “fail to reject <span class="math inline">\(H_0\)</span>” and “accept <span class="math inline">\(H_0\)</span>” are equivalent statements, they are not. “Accepting <span class="math inline">\(H_0\)</span>” is equivalent to finding a defendant innocent. We cannot show that a person is innocent; we can only say that there was not enough substantial evidence to find the person guilty.</p>
<p>So going back to our <code>promotions</code> activity, recall in Section <a href="10-hypothesis-testing.html#ht-infer">10.3</a> that our hypothesis test was <span class="math inline">\(H_0: p_{m} - p_{f} = 0\)</span> versus <span class="math inline">\(H_A: p_{m} - p_{f} &gt; 0\)</span>, we used a pre-specified significance level of <span class="math inline">\(\alpha\)</span> = 0.001, and we found a p-value of 0.027. Since the p-value was greater than <span class="math inline">\(\alpha\)</span> = 0.001, we fail to reject <span class="math inline">\(H_0\)</span>. In other words, while <span class="math inline">\(H_0\)</span> may actually be false, we didn’t find any evidence in this particular sample of 48 to suggest so. We also state this conclusion using non-statistical language: we found no evidence in the data to suggest that there was no gender discrimination.</p>
</div>
<div id="types-of-errors" class="section level3">
<h3><span class="header-section-number">10.4.2</span> Types of errors</h3>
<p>Unfortunately, there is some chance a jury or a judge can make an incorrect decision in a criminal trial by reaching the wrong verdict. This often stems from the fact that prosecutors don’t have all the relevant evidence, but are limited to what evidence the police can find. The same holds for hypothesis testing. We can make incorrect decisions about a population parameter because we only have a sample of data from the population and thus sampling variation can lead us to incorrect conclusions.</p>
<p>There are two possible erroneous conclusions in a criminal trial: either 1) a truly innocent person is found guilty or 2) a truly guilty person is found not guilty. Similarly, there are two possible errors in a hypothesis test: either 1) rejecting <span class="math inline">\(H_0\)</span> when in fact <span class="math inline">\(H_0\)</span> is true called a <strong>Type I error</strong>  or 2) failing to reject <span class="math inline">\(H_0\)</span> when in fact <span class="math inline">\(H_0\)</span> is false called a  <strong>Type II error</strong>. Another term used for “Type I error” is “false positive” while another term for “Type II error” include “false negative.”</p>
<p>This risk of error is the price researchers pay for basing inference about a population on a sample. The only way we could be absolutely certain about our conclusion is to perform a full census of the population, but as we’ve seen in our numerous examples and activities so far, this is often very expensive and other impossible. This in any hypothesis test based on a sample, we tolerate the chance that a Type I error will be made and some chance that a Type II error will occur.</p>
<p>To help understand the concepts of Type I error and Type II errors, we apply these terms in our criminal justice analogy in Figure <a href="10-hypothesis-testing.html#fig:trial-errors-table">10.15</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:trial-errors-table"></span>
<img src="images/gt_error_table.png" alt="Type I and Type II errors in criminal trials." width="\textwidth" />
<p class="caption">
FIGURE 10.15: Type I and Type II errors in criminal trials.
</p>
</div>
<p>Thus a Type I error corresponds to incorrectly putting a truly innocent person in jail whereas a Type II error corresponds to letting a truly guilty person go free. Let’s show the corresponding table for hypothesis tests</p>
<div class="figure" style="text-align: center"><span id="fig:trial-errors-table-ht"></span>
<img src="images/gt_error_table_ht.png" alt="Type I and Type II errors in hypothesis tests." width="\textwidth" />
<p class="caption">
FIGURE 10.16: Type I and Type II errors in hypothesis tests.
</p>
</div>
</div>
<div id="how-do-we-choose-alpha" class="section level3">
<h3><span class="header-section-number">10.4.3</span> How do we choose alpha?</h3>
<p>We stated earlier if we are using sample data to make inferences about a population, we run the risk of making mistakes. For confidence intervals, this would be obtaining a constructed confidence interval that doesn’t contain the true value of the population parameter. For hypothesis tests, this would be making either a Type I or Type II error. Obviously, we want to minimize the probability of either error; we want a small probability of drawing an incorrect conclusion:</p>
<ul>
<li>The probability of a Type I Error occurring is denoted by <span class="math inline">\(\alpha\)</span> and is the <strong>significance level</strong> of the hypothesis test we defined in Section <a href="10-hypothesis-testing.html#understanding-ht">10.2</a></li>
<li>The probability of a Type II Error is denoted by <span class="math inline">\(\beta\)</span>. <span class="math inline">\(1-\beta\)</span> is known as the <strong>power</strong> of the hypothesis test.</li>
</ul>
<p>In other words,</p>
<ul>
<li><span class="math inline">\(\alpha\)</span> corresponds to the probability of incorrectly rejecting <span class="math inline">\(H_0\)</span> when in fact <span class="math inline">\(H_0\)</span> is true.</li>
<li><span class="math inline">\(\beta\)</span> corresponds to the probability of incorrectly failing to reject <span class="math inline">\(H_0\)</span> when in fact <span class="math inline">\(H_0\)</span> is false.</li>
</ul>
<p>Ideally, we want <span class="math inline">\(\alpha = 0\)</span> and <span class="math inline">\(\beta = 0\)</span>, meaning that the chance of making either error is 0. However, this can never be the case in any situation where we are sampling for inference. We will always have the possibility of at least one error existing when we use sample data. Furthermore, these two error probabilities are inversely related. As the probability of a Type I error goes down, the probability of a Type II error goes up.</p>
<p>What is typically done is we fix the probability of a Type I error by pre-specifying <span class="math inline">\(\alpha\)</span> and try to minimize <span class="math inline">\(\beta\)</span>. In other words, we will tolerate a certain fraction of incorrect rejections of the null hypothesis <span class="math inline">\(H_0\)</span>. This is analogous to setting the confidence level of a confidence interval. So for example if we used <span class="math inline">\(\alpha\)</span> = 0.01, we would be are using a hypothesis testing procedure that in the long run would incorrectly reject the null hypothesis <span class="math inline">\(H_0\)</span> one percent of the time.</p>
<p>So what value should you use for <span class="math inline">\(\alpha\)</span>?  Different fields have different conventions, but some commonly used values include 0.10, 0.05, 0.01, and 0.001. However, it is important to keep in mind that if you use a relatively small value of <span class="math inline">\(\alpha\)</span>, then all things being equal p-values will have a harder time being less than <span class="math inline">\(\alpha\)</span>, and thus we would reject the null hypothesis less often. In other words, we would reject the null hypothesis <span class="math inline">\(H_0\)</span> only if we have <em>very strong</em> evidence to do so. This is known as a “conservative” test. On the other hand, if we used a relatively large value of <span class="math inline">\(\alpha\)</span>, then all things being equal p-values will have an easier time being less than <span class="math inline">\(\alpha\)</span>, and thus we would reject the null hypothesis more often. In other words, we would reject the null hypothesis <span class="math inline">\(H_0\)</span> even if we only have <em>mild</em> evidence to do so. This is known as a “liberal” test.</p>
<div class="learncheck">
<p>
<strong><em>Learning check</em></strong>
</p>
</div>
<p><strong>(LC10.6)</strong> What is wrong about saying “The defendant is innocent.” based on the US system of criminal trials?</p>
<p><strong>(LC10.7)</strong> What is the purpose of hypothesis testing?</p>
<p><strong>(LC10.8)</strong> What are some flaws with hypothesis testing? How could we alleviate them?</p>
<div class="learncheck">

</div>
</div>
</div>
<div id="ht-case-study" class="section level2">
<h2><span class="header-section-number">10.5</span> Case study: Are action or romance movies rated higher?</h2>
<p>Let’s apply our knowledge of hypothesis testing to answer the question: “Are action or romance movies rated higher on IMDb?” <a href="https://www.imdb.com/">IMDb</a> is an internet movie database providing information on movie and television show casts, plot summaries, trivia, and ratings. We’ll investigate if on average action or romance movies get a higher rating on IMDb.</p>
<div id="imdb-data" class="section level3">
<h3><span class="header-section-number">10.5.1</span> IMDb ratings data</h3>
<!--
**Important note:** Remember that we hardly ever have access to the population values as we do here.  This example was used to show how well hypothesis testing procedures using methods like permutation can do at testing hypotheses about population parameters. In nearly all circumstances, we'll be needing to use only a sample of the population to try to infer conclusions about the unknown population parameter values.  This example does show a nice relationship between statistics (where data is usually small and more focused on experimental settings) and data science (where data is frequently large and collected without experimental conditions). 
-->
<p>The <code>movies</code> dataset in the <code>ggplot2movies</code> package contains information on 58,788 movies that have been rated by users of IMDB.com.</p>
<pre class="sourceCode r"><code class="sourceCode r">movies</code></pre>
<pre><code># A tibble: 58,788 x 24
   title  year length budget rating votes    r1    r2    r3    r4    r5    r6
   &lt;chr&gt; &lt;int&gt;  &lt;int&gt;  &lt;int&gt;  &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
 1 $      1971    121     NA  6.4     348   4.5   4.5   4.5   4.5  14.5  24.5
 2 $100…  1939     71     NA  6        20   0    14.5   4.5  24.5  14.5  14.5
 3 $21 …  1941      7     NA  8.200     5   0     0     0     0     0    24.5
 4 $40,…  1996     70     NA  8.200     6  14.5   0     0     0     0     0  
 5 $50,…  1975     71     NA  3.4      17  24.5   4.5   0    14.5  14.5   4.5
 6 $pent  2000     91     NA  4.3      45   4.5   4.5   4.5  14.5  14.5  14.5
 7 $win…  2002     93     NA  5.3     200   4.5   0     4.5   4.5  24.5  24.5
 8 &#39;15&#39;   2002     25     NA  6.7      24   4.5   4.5   4.5   4.5   4.5  14.5
 9 &#39;38    1987     97     NA  6.6      18   4.5   4.5   4.5   0     0     0  
10 &#39;49-…  1917     61     NA  6        51   4.5   0     4.5   4.5   4.5  44.5
# … with 58,778 more rows, and 12 more variables: r7 &lt;dbl&gt;, r8 &lt;dbl&gt;, r9 &lt;dbl&gt;,
#   r10 &lt;dbl&gt;, mpaa &lt;chr&gt;, Action &lt;int&gt;, Animation &lt;int&gt;, Comedy &lt;int&gt;,
#   Drama &lt;int&gt;, Documentary &lt;int&gt;, Romance &lt;int&gt;, Short &lt;int&gt;</code></pre>
<p>We’ll focus on a random sample of 68 movies that are classified as either “action” or “romance” movies but not both. We disregard movies that are classified as both so that we can assign all 68 movies into either category. Furthermore, since the original <code>movies</code> dataset was a little messy, we provided a pre-wrangled version of our data in the <code>movies_sample</code> data frame included in the <code>moderndive</code> package (you can look at the code to do this data wrangling <a href="https://github.com/moderndive/moderndive/blob/master/data-raw/process_data_sets.R#L14">here</a>):</p>
<pre class="sourceCode r"><code class="sourceCode r">movies_sample</code></pre>
<pre><code># A tibble: 68 x 4
   title                     year rating genre  
   &lt;chr&gt;                    &lt;int&gt;  &lt;dbl&gt; &lt;chr&gt;  
 1 Underworld                1985    3.1 Action 
 2 Love Affair               1932    6.3 Romance
 3 Junglee                   1961    6.8 Romance
 4 Eversmile, New Jersey     1989    5   Romance
 5 Search and Destroy        1979    4   Action 
 6 Secreto de Romelia, El    1988    4.9 Romance
 7 Amants du Pont-Neuf, Les  1991    7.4 Romance
 8 Illicit Dreams            1995    3.5 Action 
 9 Kabhi Kabhie              1976    7.7 Romance
10 Electric Horseman, The    1979    5.8 Romance
# … with 58 more rows</code></pre>
<p>The variables include the <code>title</code> and <code>year</code> the movie was filmed. Furthermore, we have a numerical variable <code>rating</code>, which is the IMDb rating out of 10 stars, and a binary categorical variable <code>genre</code> indicating if the movie was an <code>Action</code> or <code>Romance</code> movie. We are interested in whether <code>Action</code> or <code>Romance</code> movies got on average a higher <code>rating</code>.</p>
<p>Let’s perform an exploratory data analysis of this data. Recall from Section <a href="3-viz.html#geomboxplot">3.7.1</a> that a boxplot one visualization we can use to show the relationship between a numerical and a categorical variable. Another option you saw in Section <a href="3-viz.html#facets">3.6</a> would be to use a faceted histogram. However, in the interest of brevity let’s visualize just the boxplot in Figure <a href="10-hypothesis-testing.html#fig:action-romance-boxplot">10.17</a>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(<span class="dt">data =</span> movies_sample, <span class="kw">aes</span>(<span class="dt">x =</span> genre, <span class="dt">y =</span> rating)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_boxplot</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">y =</span> <span class="st">&quot;IMDb rating&quot;</span>)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:action-romance-boxplot"></span>
<img src="moderndive_files/figure-html/action-romance-boxplot-1.png" alt="Boxplot of IMDb rating vs genre." width="\textwidth" />
<p class="caption">
FIGURE 10.17: Boxplot of IMDb rating vs genre.
</p>
</div>
<p>Eyeballing Figure <a href="10-hypothesis-testing.html#fig:action-romance-boxplot">10.17</a>, it appears that romance movies have a higher median rating. Do we have reason to believe however, that there is a <em>significant</em> difference between the mean <code>rating</code> for action movies compared to romance movies? It’s hard to say just based on the plots. The boxplot does show that the median sample rating is higher for romance movies. Let’s now calculate the number of movies, the mean rating, and the standard deviation split by the binary variable <code>genre</code>. We’ll do this using <code>dplyr</code> data wrangling verbs, in particular the count of each type of movies using the <code>n()</code> summary statistic function.</p>
<pre class="sourceCode r"><code class="sourceCode r">movies_sample <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(genre) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">n =</span> <span class="kw">n</span>(), <span class="dt">mean_rating =</span> <span class="kw">mean</span>(rating), <span class="dt">std_dev =</span> <span class="kw">sd</span>(rating))</code></pre>
<pre><code># A tibble: 2 x 4
  genre       n mean_rating std_dev
  &lt;chr&gt;   &lt;int&gt;       &lt;dbl&gt;   &lt;dbl&gt;
1 Action     32     5.275   1.36121
2 Romance    36     6.32222 1.60963</code></pre>
<p>So we have 36 movies with an average rating of 6.32 stars out of 10 and <code>n_action</code> movies with a sample mean rating of 5.28 stars out of 10. The difference in these average ratings is thus 6.32 - 5.28 = 1.05. So there appears to be an edge of 1.05 stars in romance movie ratings. The question is however, are these results indicative of a true difference for all romance and action movies? Or could this difference be attributable to chance an sampling variation?</p>
</div>
<div id="sampling-scenario-1" class="section level3">
<h3><span class="header-section-number">10.5.2</span> Sampling scenario</h3>
<p>Let’s tie things in back with our sampling idea in Chapter <a href="8-sampling.html#sampling">8</a>. Recall our sampling bowl with <span class="math inline">\(N\)</span> = 2400 balls. Our population parameter of interest was the population proportion of these balls that were red, denoted mathematically by <span class="math inline">\(p\)</span>. In order to estimate <span class="math inline">\(p\)</span>, we extracted a sample of 50 balls using the shovel and computed the relevant point estimate: the sample proportion of these 50 balls that were red, denoted mathematically by <span class="math inline">\(\widehat{p}\)</span>.</p>
<p>What is the study population here? It is all movies in the IMDb database that are either action or romance (but not both). In other words, of all 58,788 in the <code>movies</code> data frame included in the <code>ggplot2movies</code> package, our study population are those movie who are either <code>Action</code> or <code>Romance</code>. What is the sample here? It is the 68 movies included in the <code>movies_sample</code> dataset. Since this sample was randomly taken from the population <code>movies</code>, it is representative of all romance and action movies, and thus any analysis and results based on <code>movies_sample</code> can generalize to the entire population. Recall you studied these ideas in Section <a href="8-sampling.html#terminology-and-notation">8.3.1</a>.</p>
<p>What are the relevant population parameter and point estimates? We introduce the fourth sampling scenario in Table <a href="10-hypothesis-testing.html#tab:summarytable-ch10">10.2</a>.</p>
<table class="table" style="font-size: 16px; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:summarytable-ch10">TABLE 10.2: </span>Scenarios of sampling for inference
</caption>
<thead>
<tr>
<th style="text-align:right;">
Scenario
</th>
<th style="text-align:left;">
Population parameter
</th>
<th style="text-align:left;">
Notation
</th>
<th style="text-align:left;">
Point estimate
</th>
<th style="text-align:left;">
Notation.
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;width: 0.5in; ">
1
</td>
<td style="text-align:left;width: 0.7in; ">
Population proportion
</td>
<td style="text-align:left;width: 1in; ">
<span class="math inline">\(p\)</span>
</td>
<td style="text-align:left;width: 1.1in; ">
Sample proportion
</td>
<td style="text-align:left;width: 1in; ">
<span class="math inline">\(\widehat{p}\)</span>
</td>
</tr>
<tr>
<td style="text-align:right;width: 0.5in; ">
2
</td>
<td style="text-align:left;width: 0.7in; ">
Population mean
</td>
<td style="text-align:left;width: 1in; ">
<span class="math inline">\(\mu\)</span>
</td>
<td style="text-align:left;width: 1.1in; ">
Sample mean
</td>
<td style="text-align:left;width: 1in; ">
<span class="math inline">\(\overline{x}\)</span> or <span class="math inline">\(\widehat{\mu}\)</span>
</td>
</tr>
<tr>
<td style="text-align:right;width: 0.5in; ">
3
</td>
<td style="text-align:left;width: 0.7in; ">
Difference in population proportions
</td>
<td style="text-align:left;width: 1in; ">
<span class="math inline">\(p_1 - p_2\)</span>
</td>
<td style="text-align:left;width: 1.1in; ">
Difference in sample proportions
</td>
<td style="text-align:left;width: 1in; ">
<span class="math inline">\(\widehat{p}_1 - \widehat{p}_2\)</span>
</td>
</tr>
<tr>
<td style="text-align:right;width: 0.5in; ">
4
</td>
<td style="text-align:left;width: 0.7in; ">
Difference in population means
</td>
<td style="text-align:left;width: 1in; ">
<span class="math inline">\(\mu_1 - \mu_2\)</span>
</td>
<td style="text-align:left;width: 1.1in; ">
Difference in sample means
</td>
<td style="text-align:left;width: 1in; ">
<span class="math inline">\(\overline{x}_1 - \overline{x}_2\)</span>
</td>
</tr>
</tbody>
</table>
<p>So whereas the sampling bowl exercise in Section <a href="8-sampling.html#sampling-activity">8.1</a> concerned proportions, the pennies exercise in Section <a href="9-confidence-intervals.html#resampling-tactile">9.1</a> concerned means, the case study on whether yawning is contagious in Section <a href="9-confidence-intervals.html#case-study-two-prop-ci">9.6</a> and the promotions activity in Section <a href="10-hypothesis-testing.html#ht-activity">10.1</a> concerned differences in proportions, we are now concerned with differences in means.</p>
<p>In other words, the population parameter of interest is the difference in population mean ratings <span class="math inline">\(\mu_a - \mu_r\)</span>, where <span class="math inline">\(\mu_a\)</span> is the mean rating of all action movies on IMDb and similarly <span class="math inline">\(\mu_r\)</span> is the mean rating of all romance movies. Thus, the point estimate/sample statistic of interest is the difference in sample means <span class="math inline">\(\overline{x}_a - \overline{x}_r\)</span>, where <span class="math inline">\(\overline{x}_a\)</span> is the mean rating of the <span class="math inline">\(n_a\)</span> = <code>n_action</code> movies in our sample and <span class="math inline">\(\overline{x}_r\)</span> is the mean rating of the <span class="math inline">\(n_r\)</span> = <code>n_romance</code> in our sample. Based on our earlier exploratory data analysis, our estimate <span class="math inline">\(\overline{x}_a - \overline{x}_r\)</span> is 5.28 - 6.32 = -1.05.</p>
<p>So there appears to be a slight difference of -1.05 in favor of romance movies. The question is however, could this difference of -1.05 be merely due to chance and sampling variation? Or are these results indicative of a true difference in mean ratings for all romance and action movies? To answer this question, we’ll use hypothesis testing.</p>
</div>
<div id="conducting-the-hypothesis-test" class="section level3">
<h3><span class="header-section-number">10.5.3</span> Conducting the hypothesis test</h3>
<p>We’ll be testing</p>
<p><span class="math display">\[
\begin{aligned}
H_0 &amp;: \mu_a - \mu_r = 0\\
\text{vs } H_A&amp;: \mu_a - \mu_r \neq 0
\end{aligned}
\]</span></p>
<p>In other words, the null hypothesis <span class="math inline">\(H_0\)</span> suggests that both romance and action movies have the same mean rating. This is the “hypothesized universe” we’ll <em>assume</em> is true. The alternative hypothesis <span class="math inline">\(H_A\)</span> suggests on the other hand that there is a difference. Note that unlike the one-sided alternative we used in the promotions exercise <span class="math inline">\(H_a: p_m - p_f &gt; 0\)</span>, we are now considering a two-sided alternative of <span class="math inline">\(H_A: \mu_a - \mu_r \neq 0\)</span>.</p>
<p>Furthermore, we’ll pre-specify a relatively high significance level <span class="math inline">\(\alpha\)</span> = 0.2. By setting this value high, all things being equal there is a higher chance that the p-value will be less than this value, and thus there is a higher chance that we’ll reject the null hypothesis <span class="math inline">\(H_0\)</span> in favor of the alternative hypothesis <span class="math inline">\(H_A\)</span>. In other words, we’ll reject the hypothesis that there is no difference in mean ratings for all action and romance movies even if we only have mild evidence.</p>
<div id="specify-variables-4" class="section level4 unnumbered">
<h4>1. <code>specify</code> variables</h4>
<p>We first <code>specify()</code> the variables of interest in the <code>movies_sample</code> data frame using the <code>rating ~ genre</code>. This tells <code>infer</code> that the numerical variable <code>rating</code> is the outcome variable while the binary categorical variable <code>genre</code> is the explanatory variable. Note here however, than unlike when we are interested in proportions, since we are interested in the mean of a numerical variable, we do not need to set the <code>success</code> argument.</p>
<pre class="sourceCode r"><code class="sourceCode r">movies_sample <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">specify</span>(<span class="dt">formula =</span> rating <span class="op">~</span><span class="st"> </span>genre)</code></pre>
<pre><code>Response: rating (numeric)
Explanatory: genre (factor)
# A tibble: 68 x 2
   rating genre  
    &lt;dbl&gt; &lt;fct&gt;  
 1    3.1 Action 
 2    6.3 Romance
 3    6.8 Romance
 4    5   Romance
 5    4   Action 
 6    4.9 Romance
 7    7.4 Romance
 8    3.5 Action 
 9    7.7 Romance
10    5.8 Romance
# … with 58 more rows</code></pre>
</div>
<div id="hypothesize-the-null-1" class="section level4 unnumbered">
<h4>2. <code>hypothesize</code> the null</h4>
<p>We set the null hypothesis <span class="math inline">\(H_0: \mu_a - \mu_r = 0\)</span> by using the <code>hypothesize()</code> function. Since we have two samples, the action and romance movies, we set <code>null = &quot;independence&quot;</code> as we described in Section <a href="10-hypothesis-testing.html#ht-infer">10.3</a>.</p>
<pre class="sourceCode r"><code class="sourceCode r">movies_sample <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">specify</span>(<span class="dt">formula =</span> rating <span class="op">~</span><span class="st"> </span>genre) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">hypothesize</span>(<span class="dt">null =</span> <span class="st">&quot;independence&quot;</span>)</code></pre>
<pre><code># A tibble: 68 x 2
   rating genre  
    &lt;dbl&gt; &lt;fct&gt;  
 1    3.1 Action 
 2    6.3 Romance
 3    6.8 Romance
 4    5   Romance
 5    4   Action 
 6    4.9 Romance
 7    7.4 Romance
 8    3.5 Action 
 9    7.7 Romance
10    5.8 Romance
# … with 58 more rows</code></pre>
</div>
<div id="generate-replicates-4" class="section level4 unnumbered">
<h4>3. <code>generate</code> replicates</h4>
<p>After we have set the null hypothesis, we simulate observations assuming the null hypothesis is true by repeating the shuffling/permutation exercise you performed in Section <a href="10-hypothesis-testing.html#ht-activity">10.1</a>. We’ll repeat this resampling of <code>type = &quot;permute&quot;</code> a total of <code>reps = 1000</code> times .</p>
<pre class="sourceCode r"><code class="sourceCode r">movies_sample <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">specify</span>(<span class="dt">formula =</span> rating <span class="op">~</span><span class="st"> </span>genre) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">hypothesize</span>(<span class="dt">null =</span> <span class="st">&quot;independence&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">generate</span>(<span class="dt">reps =</span> <span class="dv">1000</span>, <span class="dt">type =</span> <span class="st">&quot;permute&quot;</span>)</code></pre>
<pre><code>Response: rating (numeric)
Explanatory: genre (factor)
Null Hypothesis: independence
# A tibble: 68,000 x 3
# Groups:   replicate [1,000]
   rating genre   replicate
    &lt;dbl&gt; &lt;fct&gt;       &lt;int&gt;
 1  4.4   Action          1
 2  5.2   Romance         1
 3  7.3   Romance         1
 4  4.9   Romance         1
 5  4.100 Action          1
 6  7.4   Romance         1
 7  5     Romance         1
 8  5.100 Action          1
 9  4.4   Romance         1
10  8     Romance         1
# … with 67,990 more rows</code></pre>
<p>Observe that it is at this point our output differs from the original <code>movies_sample</code> data frame. The resulting data frame has 68,000 rows. This is because we performed shuffles/permutations of the 68 values of <code>genre</code> 1000 times and thus 68,000 = 1000 <span class="math inline">\(\times\)</span> 68.</p>
</div>
<div id="calculate-summary-statistics-4" class="section level4 unnumbered">
<h4>4. <code>calculate</code> summary statistics</h4>
<p>Now that we have 1000 replicated “shuffles” assuming the null hypothesis that both <code>Action</code> and <code>Romance</code> movies on average have the same ratings on IMDb, let’s <code>calculate()</code> the appropriate summary statistic for each of our 1000 shuffles. Recall from Section <a href="10-hypothesis-testing.html#understanding-ht">10.2</a> that point estimates/summary statistics relating to hypothesis testing have a specific name: <em>test statistics</em>. Since the unknown population parameter of interest is the difference in population means <span class="math inline">\(\mu_{a} - \mu_{r}\)</span>, the test statistic of interest here is the difference in sample means <span class="math inline">\(\overline{x}_{a} - \overline{x}_{r}\)</span>.</p>
<p>For each of our 1000 shuffles, we can calculate this test statistic by setting <code>stat = &quot;diff in means&quot;</code>. Furthermore, since we are interested in <span class="math inline">\(\overline{x}_{a} - \overline{x}_{r}\)</span> and not the reverse-ordered <span class="math inline">\(\overline{x}_{r} - \overline{x}_{a}\)</span>, we set <code>order = c(&quot;Action&quot;, &quot;Romance&quot;)</code>. Let’s save the result in a data frame called <code>null_distribution_movies</code>:</p>
<pre class="sourceCode r"><code class="sourceCode r">null_distribution_movies &lt;-<span class="st"> </span>movies_sample <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">specify</span>(<span class="dt">formula =</span> rating <span class="op">~</span><span class="st"> </span>genre) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">hypothesize</span>(<span class="dt">null =</span> <span class="st">&quot;independence&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">generate</span>(<span class="dt">reps =</span> <span class="dv">1000</span>, <span class="dt">type =</span> <span class="st">&quot;permute&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">calculate</span>(<span class="dt">stat =</span> <span class="st">&quot;diff in means&quot;</span>, <span class="dt">order =</span> <span class="kw">c</span>(<span class="st">&quot;Action&quot;</span>, <span class="st">&quot;Romance&quot;</span>))
null_distribution_movies</code></pre>
<pre><code># A tibble: 1,000 x 2
   replicate      stat
       &lt;int&gt;     &lt;dbl&gt;
 1         1 -0.923264
 2         2  0.363542
 3         3  0.404861
 4         4  0.463889
 5         5 -0.610417
 6         6 -0.279861
 7         7 -0.262153
 8         8 -0.291667
 9         9 -0.114583
10        10  0.398958
# … with 990 more rows</code></pre>
<p>Observe that we have 1000 values of <code>stat</code>, each representing one “shuffled” instance of <span class="math inline">\(\overline{x}_{a} - \overline{x}_{r}\)</span> in a hypothesized world of no difference in movie ratings between romance and action movies.</p>
<p>But wait! What happened in real-life? What was the observed difference in promotions rates? In other words, what was the <em>observed test statistic</em> <span class="math inline">\(\overline{x}_{a} - \overline{x}_{r}\)</span>? Recall our earlier data wrangling from earlier, this observed difference in means was 5.28 - 6.32 = -1.05. We can also achieve this using the code above but with the <code>hypothesize()</code> and <code>generate()</code> steps removed. Let’s save this in <code>obs_diff_means</code></p>
<pre class="sourceCode r"><code class="sourceCode r">obs_diff_means &lt;-<span class="st"> </span>movies_sample <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">specify</span>(<span class="dt">formula =</span> rating <span class="op">~</span><span class="st"> </span>genre) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">calculate</span>(<span class="dt">stat =</span> <span class="st">&quot;diff in means&quot;</span>, <span class="dt">order =</span> <span class="kw">c</span>(<span class="st">&quot;Action&quot;</span>, <span class="st">&quot;Romance&quot;</span>))
obs_diff_means</code></pre>
<pre><code># A tibble: 1 x 1
      stat
     &lt;dbl&gt;
1 -1.04722</code></pre>
</div>
<div id="visualize-the-p-value-1" class="section level4 unnumbered">
<h4>5. <code>visualize</code> the p-value</h4>
<p>Lastly to compute the p-value, we have to assess how “extreme” the observed difference in means -1.05 is by comparing it to our null distribution constructed in a hypothesized universe of no difference in movie ratings. Let’s visualize the p-value in Figure <a href="10-hypothesis-testing.html#fig:null-distribution-movies-2">10.18</a>. Unlike our example in Section <a href="10-hypothesis-testing.html#infer-workflow-ht">10.3.1</a> involving promotions, since we have a two-sided alternative hypothesis <span class="math inline">\(H_A: \mu_a - \mu_r \neq 0\)</span>, we have to allow for both possibilities for “more extreme”, so we set <code>direction = &quot;both&quot;</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">visualize</span>(null_distribution_movies, <span class="dt">bins =</span> <span class="dv">10</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">shade_p_value</span>(<span class="dt">obs_stat =</span> obs_diff_means, <span class="dt">direction =</span> <span class="st">&quot;both&quot;</span>)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:null-distribution-movies-2"></span>
<img src="moderndive_files/figure-html/null-distribution-movies-2-1.png" alt="Null distribution, observed test statistic, and p-value." width="\textwidth" />
<p class="caption">
FIGURE 10.18: Null distribution, observed test statistic, and p-value.
</p>
</div>
<p>Recall the tree elements of this plot. First, the histogram is the null distribution, which is the technical term for the sampling distribution of the “shuffled” difference in sample means <span class="math inline">\(\overline{x}_{a} - \overline{x}_{r}\)</span> assuming <span class="math inline">\(H_0\)</span> is true. Second, the solid line is the observed test statistic, or the difference in sample means we observed in real-life of 5.28 - 6.32 = -1.05. Notice where this solid line is located in the null distribution: it very plausible to observe such a value. Third, the shaded area is the p-value, or the probability of obtaining a test statistic just as or more extreme than the observed test statistic <em>assuming the null hypothesis <span class="math inline">\(H_0\)</span> is true</em>.</p>
<p>What proportion of the null distribution is shaded? In other words, what is the numerical value of the p-value? We use the <code>get_p_value()</code> function to compute this value:</p>
<pre class="sourceCode r"><code class="sourceCode r">null_distribution_movies <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">get_p_value</span>(<span class="dt">obs_stat =</span> obs_diff_means, <span class="dt">direction =</span> <span class="st">&quot;both&quot;</span>)</code></pre>
<pre><code># A tibble: 1 x 1
  p_value
    &lt;dbl&gt;
1   0.016</code></pre>
<p>This p-value of 0.016 is very small. In other words, there is a small chance that we’d observe a sample with a difference of 5.28 - 6.32 = -1.05 in a universe where there was truly no difference in ratings. This p-value is in fact much small that our pre-specified <span class="math inline">\(\alpha\)</span> significance level of 0.2, and thus we are very inclined to reject the null hypothesis <span class="math inline">\(H_0: \mu_a - \mu_r = 0\)</span> in favor of the alternative hypothesis <span class="math inline">\(H_A: \mu_a - \mu_r \neq 0\)</span>. In non-statistical language, the conclusion is: the evidence in this sample of data suggests we should reject the hypothesis that there is no difference in mean IMDb ratings between romance and action movies in favor of the hypothesis that there is a difference.</p>
<div class="learncheck">
<p>
<strong><em>Learning check</em></strong>
</p>
</div>
<p><strong>(LC10.9)</strong> Conduct the same analysis comparing action movies versus romantic movies using the median rating instead of the mean rating. What was different and what was the same?</p>
<p><strong>(LC10.10)</strong> What conclusions can you make from viewing the faceted histogram looking at <code>rating</code> versus <code>genre</code> that you couldn’t see when looking at the boxplot?</p>
<p><strong>(LC10.11)</strong> Describe in a paragraph how we used Allen Downey’s diagram to conclude if a statistical difference existed between mean movie ratings for action and romance movies.</p>
<p><strong>(LC10.12)</strong> Why are we relatively confident that the distributions of the sample ratings will be good approximations of the population distributions of ratings for the two genres?</p>
<p><strong>(LC10.13)</strong> Using the definition of “<span class="math inline">\(p\)</span>-value”, write in words what the <span class="math inline">\(p\)</span>-value represents for the hypothesis test above comparing the mean rating of romance to action movies.</p>
<p><strong>(LC10.14)</strong> What is the value of the <span class="math inline">\(p\)</span>-value for the hypothesis test comparing the mean rating of romance to action movies?</p>
<p><strong>(LC10.15)</strong> Do the results of the hypothesis test match up with the original plots we made looking at the population of movies? Why or why not?</p>
<div class="learncheck">

</div>
</div>
</div>
</div>
<div id="conclusion-6" class="section level2">
<h2><span class="header-section-number">10.6</span> Conclusion</h2>
<div id="theory-hypo" class="section level3">
<h3><span class="header-section-number">10.6.1</span> Theory-based hypothesis tests</h3>
<p>Much as we did in Section <a href="9-confidence-intervals.html#theory-ci">9.7.2</a> when we showed you a theory-based method for constructing confidence intervals that involved mathematical formulas, we now present an example of a traditional theory-based method to conduct the hypothesis test to determining if there is a statistically significant difference in the mean rating of Action versus Romance movies. This method rely on probability models, probability distributions, and a few assumptions to construct the null distribution. This is contrast to the approach we used in Section <a href="10-hypothesis-testing.html#ht-infer">10.3</a> where we relied on simulations to construct the null distribution.</p>
<p>These traditional theory-based methods have been used for decades mostly because researchers didn’t have access to computers that could run thousands of simulations quickly and efficiently. Now that computing power is much cheaper and much more accessible, simulation-based methods are much more feasible, however many fields and researchers continue to use theory-based methods. Hence we make it a point to include discussion about them here.</p>
<p>As we’ll show in this section, any theory-based method is ultimately an approximation to the simulation-based method. The theory-based method we’ll focus on is known as the <em>two-sample <span class="math inline">\(t\)</span>-test</em> for testing differences in sample means where the test statistic of interest isn’t the difference in sample means <span class="math inline">\(\overline{x}_1 - \overline{x}_2\)</span>, but the related two-sample <span class="math inline">\(t\)</span>-statistic. The data we’ll use will once again be the <code>movies_sample</code> data of action and romance movies where the outcome variable of interest are movies’ IMDb ratings.</p>
<div id="two-sample-t-statistic" class="section level4 unnumbered">
<h4>Two-sample t-statistic</h4>
<p>A common task in statistics is the process of “standardizing a variable.” By standardizing different variables, we can make them more comparable. For example, say you are interested in studying the distribution of temperature recordings from Portland, Oregon, USA with temperature recordings in Montreal, Quebec, Canada. Given that the US temperatures are generally recorded in degrees Fahrenheit and Canadian temperatures are generally recorded in degrees Celsius, how can we make them comparable? On the one hand, we could convert the degrees Fahrenheit into Celsius, or vice versa. On the other, we could convert them both to a common “standardized” scale.</p>
<p>One common method for standardization from probability theory is computing the  <span class="math inline">\(z\)</span>-score:</p>
<p><span class="math display">\[Z = \frac{x - \mu}{\sigma}\]</span></p>
<p>where <span class="math inline">\(x\)</span> represent the value of a variable, <span class="math inline">\(\mu\)</span> represents the mean of the variable, and <span class="math inline">\(\sigma\)</span> represents the standard deviation of the variable. You first subtract the mean <span class="math inline">\(\mu\)</span> from each value of <span class="math inline">\(x\)</span> and then divide <span class="math inline">\(x - \mu\)</span> by the standard deviation <span class="math inline">\(\sigma\)</span>. These operations will have the effect of “re-centering” your variable around 0 and “re-scaling” your variable <span class="math inline">\(x\)</span> to have what are known as “standard units.”</p>
<p>Thus, if your variable has 10 elements, each one has a corresponding <span class="math inline">\(z\)</span>-score that gives how many standard deviations away that value is from its mean. <span class="math inline">\(z\)</span>-scores are normally distributed with mean 0 and standard deviation 1. Such a curve is called a “<span class="math inline">\(z\)</span>-distribution” as well a “standard normal” curve and they have the common, bell-shaped pattern from Figure <a href="10-hypothesis-testing.html#fig:zcurve">10.19</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:zcurve"></span>
<img src="moderndive_files/figure-html/zcurve-1.png" alt="Standard normal z curve." width="60%" />
<p class="caption">
FIGURE 10.19: Standard normal z curve.
</p>
</div>
<p>Bringing these back to the difference of sample mean ratings <span class="math inline">\(\overline{x}_a - \overline{x}_r\)</span> of action versus romance movies, how would we standardize this variable? By once again subtracting it’s mean and standard deviation. Building on ideas from Section <a href="8-sampling.html#moral-of-the-story">8.3.3</a> that: 1) If the sampling was done in representative fashion, then the sampling distribution of <span class="math inline">\(\overline{x}_a - \overline{x}_r\)</span> would be centered at the true population parameter: the difference in population means <span class="math inline">\(\mu_a - \mu_r\)</span>. 2) The standard deviation of point estimates like <span class="math inline">\(\overline{x}_a - \overline{x}_r\)</span> have a special name: the standard error</p>
<p>Applying these ideas, we present the two-sample  <span class="math inline">\(t\)</span>-statistic:</p>
<p><span class="math display">\[t = \dfrac{ (\bar{x}_a - \bar{x}_r) - (\mu_a - \mu_r)}{ \text{SE}_{\bar{x}_a - \bar{x}_r} } = \dfrac{ (\bar{x}_a - \bar{x}_r) - (\mu_a - \mu_r)}{ \sqrt{\dfrac{{s_a}^2}{n_a} + \dfrac{{s_r}^2}{n_r}}  }\]</span></p>
<p>Oofda! There is a lot to try to unpack here! Let’s go slowly. In the numerator <span class="math inline">\(\bar{x}_a-\bar{x}_r\)</span> is the difference in sample means while <span class="math inline">\(\mu_a - \mu_r\)</span> is the difference in population means. In the denominator <span class="math inline">\(s_a\)</span> and <span class="math inline">\(s_r\)</span> are the <em>sample standard deviations</em> of the action and romance movies in our sample <code>movies_sample</code> while <span class="math inline">\(n_a\)</span> and <span class="math inline">\(n_r\)</span> is the sample sizes of the action and romance movies. Putting the above together gives us the standard error <span class="math inline">\(\text{SE}_{\bar{x}_a - \bar{x}_r}\)</span>.</p>
<p>Look closely at the formula for <span class="math inline">\(\text{SE}_{\bar{x}_a - \bar{x}_r}\)</span> in the denominator: the sample sizes <span class="math inline">\(n_a\)</span> and <span class="math inline">\(n_r\)</span> are there. So as the sample sizes increase, the standard error goes down. We’ve seen this concept numerous times now, in particular in our simulations using the three shovels with <span class="math inline">\(n\)</span> = 25, 50, and 100 slots in Figure <a href="8-sampling.html#fig:comparing-sampling-distributions-3">8.15</a> and in Section <a href="9-confidence-intervals.html#ci-width">9.5.3</a> where we studied the effect of using larger sample sizes on the widths of confidence intervals.</p>
<p>So how can we use the two-sample <span class="math inline">\(t\)</span>-statistic as a test statistic in our hypothesis test? First, assuming the null hypothesis <span class="math inline">\(H_0: \mu_a - \mu_r = 0\)</span> is true, the right-hand side of the numerator becomes 0. Second, similarly to how the Central Limit Theorem from Section <a href="8-sampling.html#sampling-conclusion-central-limit-theorem">8.5.2</a> states that sample means follow a normal distribution, it can be mathematically proven that <span class="math inline">\(T\)</span> follows a <span class="math inline">\(t\)</span> distribution with <em>degrees of freedom “roughly equal” to <span class="math inline">\(df = n_a + n_r - 2\)</span></em>. We display three examples of <span class="math inline">\(t\)</span>-distributions in Figure <a href="10-hypothesis-testing.html#fig:t-distributions">10.20</a> along with the standard normal <span class="math inline">\(z\)</span> curve.</p>
<!--
Regenerate this via ggplot!
-->
<div class="figure" style="text-align: center"><span id="fig:t-distributions"></span>
<img src="images/t-distributions.png" alt="Examples of t-distributions and the z curve." width="60%" />
<p class="caption">
FIGURE 10.20: Examples of t-distributions and the z curve.
</p>
</div>
<p>Begin by looking at the center of the plot at 0 on the horizontal axis. Note that the bottom curve corresponds to 1 degrees of freedom, the curve above it is for 3 degrees of freedom, the curve above that is for 10 degrees of freedom, and lastly the dashed curve is the standard normal <span class="math inline">\(z\)</span> curve.</p>
<p>Observe that all four curves have a bell shape, are centered at 0, and that as the degrees of freedom increase, the <span class="math inline">\(t\)</span>-distribution resembles the standard normal <span class="math inline">\(z\)</span> curve. The “degrees of freedom”  can be thought of measuring how different the <span class="math inline">\(t\)</span> distribution will be compared to a normal distribution. The “roughly equal” above indicates that the equation <span class="math inline">\(df = n_a + n_r - 2\)</span> is a “good enough” approximation to the true degrees of freedom. The <a href="https://en.wikipedia.org/wiki/Student%27s_t-test#Equal_or_unequal_sample_sizes,_unequal_variances">true formula</a> is a bit more complicated than this simple expression, but we’ve found the formula to be beyond the scope of this book since it does little to build the intuition of the <span class="math inline">\(t\)</span>-test. The message to remain however is that small sample sizes lead to small degrees of freedom and thus lead to <span class="math inline">\(t\)</span> distributions that are slightly different than the <span class="math inline">\(z\)</span> curve: they have more values in the tails of their distributions. On the other hand, large sample sizes lead to large degrees of freedom and thus lead to <span class="math inline">\(t\)</span> distributions that closely align with the standard normal <span class="math inline">\(z\)</span>-curve.</p>
<p>So, assuming the null hypothesis <span class="math inline">\(H_0\)</span> is true, our formula for the test statistic simplifies a bit:</p>
<p><span class="math display">\[t = \dfrac{ (\bar{x}_a - \bar{x}_r) - 0}{ \sqrt{\dfrac{{s_a}^2}{n_a} + \dfrac{{s_r}^2}{n_r}}  } = \dfrac{ \bar{x}_a - \bar{x}_r}{ \sqrt{\dfrac{{s_a}^2}{n_a} + \dfrac{{s_r}^2}{n_r}}  }\]</span></p>
<p>Recall the summary statistics we computed during our exploratory data analysis in Section <a href="10-hypothesis-testing.html#imdb-data">10.5.1</a>.</p>
<pre class="sourceCode r"><code class="sourceCode r">movies_sample <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(genre) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">n =</span> <span class="kw">n</span>(), <span class="dt">mean_rating =</span> <span class="kw">mean</span>(rating), <span class="dt">std_dev =</span> <span class="kw">sd</span>(rating))</code></pre>
<pre><code># A tibble: 2 x 4
  genre       n mean_rating std_dev
  &lt;chr&gt;   &lt;int&gt;       &lt;dbl&gt;   &lt;dbl&gt;
1 Action     32     5.275   1.36121
2 Romance    36     6.32222 1.60963</code></pre>
<p>Using these values, we can show that the observed two-sample <span class="math inline">\(t\)</span>-test statistic is -2.906. Great! How can we compute the p-value using this theory-based test statistic? We need to compare it to a null distribution, which we construct next.</p>
</div>
<div id="null-distribution" class="section level4 unnumbered">
<h4>Null distribution</h4>
<p>Let’s revisit the null distribution for the test statistic <span class="math inline">\(\bar{x}_a - \bar{x}_r\)</span> we constructed in Section <a href="10-hypothesis-testing.html#ht-case-study">10.5</a>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Construct null distribution of xbar_a - xbar_m:</span>
null_distribution_movies &lt;-<span class="st"> </span>movies_sample <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">specify</span>(<span class="dt">formula =</span> rating <span class="op">~</span><span class="st"> </span>genre) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">hypothesize</span>(<span class="dt">null =</span> <span class="st">&quot;independence&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">generate</span>(<span class="dt">reps =</span> <span class="dv">1000</span>, <span class="dt">type =</span> <span class="st">&quot;permute&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">calculate</span>(<span class="dt">stat =</span> <span class="st">&quot;diff in means&quot;</span>, <span class="dt">order =</span> <span class="kw">c</span>(<span class="st">&quot;Action&quot;</span>, <span class="st">&quot;Romance&quot;</span>))</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Visualize:</span>
<span class="kw">visualize</span>(null_distribution_movies, <span class="dt">bins =</span> <span class="dv">10</span>)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:t-stat-1"></span>
<img src="moderndive_files/figure-html/t-stat-1-1.png" alt="Null distribution using difference in means." width="100%" />
<p class="caption">
FIGURE 10.21: Null distribution using difference in means.
</p>
</div>
<p>The <code>infer</code> package also includes some built-in theory-based test statistics as well. So instead of calculating the test statistic of interest as the <code>&quot;diff in means&quot;</code> <span class="math inline">\(\bar{x}_a - \bar{x}_r\)</span>, we can calculate the above defined <span class="math inline">\(t\)</span>-statistic by setting <code>stat = &quot;t&quot;</code>:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Construct null distribution of t:</span>
null_distribution_movies_t &lt;-<span class="st"> </span>movies_sample <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">specify</span>(<span class="dt">formula =</span> rating <span class="op">~</span><span class="st"> </span>genre) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">hypothesize</span>(<span class="dt">null =</span> <span class="st">&quot;independence&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">generate</span>(<span class="dt">reps =</span> <span class="dv">1000</span>, <span class="dt">type =</span> <span class="st">&quot;permute&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="co"># Notice we switched stat from &quot;diff in means&quot; to &quot;t&quot;</span>
<span class="st">  </span><span class="kw">calculate</span>(<span class="dt">stat =</span> <span class="st">&quot;t&quot;</span>, <span class="dt">order =</span> <span class="kw">c</span>(<span class="st">&quot;Action&quot;</span>, <span class="st">&quot;Romance&quot;</span>))</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Visualize:</span>
<span class="kw">visualize</span>(null_distribution_movies_t, <span class="dt">bins =</span> <span class="dv">10</span>)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:t-stat-2"></span>
<img src="moderndive_files/figure-html/t-stat-2-1.png" alt="Null distribution using t-statistic." width="100%" />
<p class="caption">
FIGURE 10.22: Null distribution using t-statistic.
</p>
</div>
<p>Observe that while the shape of the <code>stat = &quot;diff in means&quot;</code> null distribution is the similar to <code>stat = &quot;t&quot;</code> null distribution, the scale on the x-axis has changed with the <span class="math inline">\(t\)</span> values having less spread than the difference in means.
However, a traditional theory-based <span class="math inline">\(t\)</span>-test doesn’t look at the simulated histogram in <code>null_distribution_movies_t</code>, but instead it looks at the <span class="math inline">\(t\)</span>-distribution curve with degrees of freedom equal to roughly 65.85. This calculation is based on the complicated formula referenced above which we approximated with <span class="math inline">\(df = n_a + n_r - 2\)</span> = 32 + 36 - 2 = 66. We overlay this <span class="math inline">\(t\)</span>-distribution curve over the top of our simulated <span class="math inline">\(t\)</span>-statistics using the <code>method = &quot;both&quot;</code> argument in <code>visualize()</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">visualize</span>(null_distribution_movies_t, <span class="dt">bins =</span> <span class="dv">10</span>, <span class="dt">method =</span> <span class="st">&quot;both&quot;</span>)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:t-stat-3"></span>
<img src="moderndive_files/figure-html/t-stat-3-1.png" alt="Null distribution using t-statistic and t-distribution." width="100%" />
<p class="caption">
FIGURE 10.23: Null distribution using t-statistic and t-distribution.
</p>
</div>
<p>Observe that the curve does a good job of approximating the histogram here. To calculate the <span class="math inline">\(p\)</span>-value in this case, we need to figure out how much of the total area under the <span class="math inline">\(t\)</span>-distribution curve is at our observed <span class="math inline">\(t\)</span>-statistic or is “more extreme.” Since our alternative hypothesis <span class="math inline">\(H_A: \mu_a - \mu_r \neq 0\)</span> is a two-sided alternative, we need add up the areas at both tails.</p>
<p>We first compute the observed two-sample <span class="math inline">\(t\)</span>-statistic using <code>infer</code> verbs:</p>
<pre class="sourceCode r"><code class="sourceCode r">obs_two_sample_t &lt;-<span class="st"> </span>movies_sample <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">specify</span>(<span class="dt">formula =</span> rating <span class="op">~</span><span class="st"> </span>genre) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">calculate</span>(<span class="dt">stat =</span> <span class="st">&quot;t&quot;</span>, <span class="dt">order =</span> <span class="kw">c</span>(<span class="st">&quot;Action&quot;</span>, <span class="st">&quot;Romance&quot;</span>))
obs_two_sample_t</code></pre>
<pre><code># A tibble: 1 x 1
      stat
     &lt;dbl&gt;
1 -2.90589</code></pre>
<p>So we are interested in finding the percentage of values that are at or above <code>obs_two_sample_t</code> = -2.906 or at or below <code>-obs_two_sample_t</code> = 2.906. We do this using the <code>shade_p_value()</code> function with the <code>direction</code> argument set to <code>&quot;both&quot;</code>:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">visualize</span>(null_distribution_movies_t, <span class="dt">method =</span> <span class="st">&quot;both&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">shade_p_value</span>(<span class="dt">obs_stat =</span> obs_two_sample_t, <span class="dt">direction =</span> <span class="st">&quot;both&quot;</span>)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:t-stat-4"></span>
<img src="moderndive_files/figure-html/t-stat-4-1.png" alt="Null distribution using t-statistic and t-distribution with p-value shaded." width="100%" />
<p class="caption">
FIGURE 10.24: Null distribution using t-statistic and t-distribution with p-value shaded.
</p>
</div>
<p>What is the p-value? We apply <code>get_p_value()</code> to our null distribution saved in <code>null_distribution_movies_t</code>:</p>
<pre class="sourceCode r"><code class="sourceCode r">null_distribution_movies_t <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">get_p_value</span>(<span class="dt">obs_stat =</span> obs_two_sample_t, <span class="dt">direction =</span> <span class="st">&quot;both&quot;</span>)</code></pre>
<pre><code># A tibble: 1 x 1
  p_value
    &lt;dbl&gt;
1   0.004</code></pre>
<p>However, to be able to use the t-test and other such theoretical methods, there are always a few conditions to check. The <code>infer</code> package does not automatically check these conditions, hence the warning message we received above. These conditions are necessary so that the underlying mathematical theory holds. In order for the results of our two-sample <span class="math inline">\(t\)</span>-test to be valid, three conditions must be met:</p>
<ol style="list-style-type: decimal">
<li>Nearly normal populations or large sample sizes. A general rule of thumb that works in many (but not all) situations is that <span class="math inline">\(n\)</span> should be greater than 30.</li>
<li>Both samples are selected independently of each other.</li>
<li>All observations are independent from each other.</li>
</ol>
<p>Let’s see if these conditions hold for our <code>movies_sample</code> data:</p>
<ol style="list-style-type: decimal">
<li>This is met since <span class="math inline">\(n_a\)</span> = 32 and <span class="math inline">\(n_r\)</span> = 36 are both larger than 30, satisfying our rule of thumb.</li>
<li>This is met since we sampled the action and romance movies at random and in an unbiased fashion from the database of all IMDb movies.</li>
<li>Unfortunately, we don’t know how IMDb computes the ratings. For example, if the same person rated multiple movies, then those observations would be related and hence not independent.</li>
</ol>
<p>Assuming all three conditions are met, we can be reasonably certain that the theory-based <span class="math inline">\(t\)</span>-test results are valid. If any of the conditions were not met, we couldn’t put as much faith into any conclusions.</p>
<!--
On the other hand, the only simulation-based assumption that needs to be met in the simulation based method are that the sample is selected at random.  

They are our preferred method as they have fewer assumptions, are conceptually easier to understand, and since computing power has recently become easily accessible, they can be run quickly. That being said since much of the world's research still relies on traditional theory-based methods and thus it is important to understand them. 
-->
</div>
</div>
<div id="when-inference-is-not-needed" class="section level3">
<h3><span class="header-section-number">10.6.2</span> When inference is not needed</h3>
<p>We’ve now walked through a several different examples of how to use the <code>infer</code> package to perform statistical inference: construct confidence intervals and conduct hypothesis tests. For each of these examples, we made it a point to always perform an exploratory data analysis (EDA) first, specifically using data visualization via <code>ggplot2</code> and data wrangling via <code>dplyr</code> beforehand. We <em>highly</em> encourage you to always do the same. As a beginner to statistics, EDA helps you develop intuition as to what statistical methods like confidence intervals and hypothesis tests can tell us. Even as a seasoned practitioner of statistics, EDA helps guide your statistical investigations. In particular, is statistical inference even needed?</p>
<p>Let’s consider an example. Say we’re interested in the following question: Of flights leaving a New York City airport, are Hawaiian Airlines flights in the air for longer than Alaska Airlines flights? Furthermore, let’s assume that 2013 flights are a representative sample of all such flights and thus we can use the data in the <code>flights</code> data frame in the <code>nycflights13</code>  package we introduced in Section <a href="2-getting-started.html#nycflights13">2.4</a>. Let’s filter this data frame to only consider Hawaiian <code>HA</code> and Alaska <code>AS</code> using their <code>carrier</code> codes as listed in the <code>airlines</code> data frame.</p>
<pre class="sourceCode r"><code class="sourceCode r">flights_sample &lt;-<span class="st"> </span>flights <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(carrier <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;HA&quot;</span>, <span class="st">&quot;AS&quot;</span>))</code></pre>
<p>There are two possible statistical inference methods we could use to answer such questions. First, we could construct a 95% confidence interval for the difference in population means <span class="math inline">\(\mu_{HA} - \mu_{AS}\)</span>, where <span class="math inline">\(\mu_{HA}\)</span> is the mean air time of all Hawaiian Airlines flights and <span class="math inline">\(\mu_{AS}\)</span> is the mean air time of all Alaska Airlines flights. We could then check if the entirety of the interval is greater than 0, suggesting <span class="math inline">\(\mu_{HA} - \mu_{AS} &gt; 0\)</span> i.e. <span class="math inline">\(\mu_{HA} &gt; \mu_{AS}\)</span>. Second, we could perform a hypothesis test of the null hypothesis <span class="math inline">\(H_0: \mu_{HA} - \mu_{AS} = 0\)</span> versus the alternative hypothesis <span class="math inline">\(H_A: \mu_{HA} - \mu_{AS} &gt; 0\)</span>.</p>
<p>However, let’s first construct an exploratory visualization as we suggest. Since <code>air_time</code> is numerical and <code>carrier</code> is categorical, a boxplot can display the relationship between these two variables, which we display in Figure <a href="10-hypothesis-testing.html#fig:ha-as-flights-boxplot">10.25</a></p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(<span class="dt">data =</span> flights_sample, <span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">x =</span> carrier, <span class="dt">y =</span> air_time)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_boxplot</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Carrier&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Air Time&quot;</span>)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:ha-as-flights-boxplot"></span>
<img src="moderndive_files/figure-html/ha-as-flights-boxplot-1.png" alt="Air time for Hawaiian and Alaska Airlines flights departing NYC in 2013." width="\textwidth" />
<p class="caption">
FIGURE 10.25: Air time for Hawaiian and Alaska Airlines flights departing NYC in 2013.
</p>
</div>
<p>This is what we like to call “you don’t need no PhD in statistics” moments. You don’t need to be an expert in statistics to know that Alaska Airlines and Hawaiian Airlines have significantly different air times. The two boxes don’t even overlap! Constructing a confidence interval or conducting a hypothesis test would frankly not provide much more information.</p>
<p>In our example, why do we observe such a clear cut difference between these two airlines? Let’s delve a little deeper using data wrangling. Let’s first group by the rows of <code>flights_sample</code> by not only <code>carrier</code> but also destination <code>dest</code>. Subsequently we’ll compute two summary statistics: the number of observations using <code>n()</code> and the mean airtime:</p>
<pre class="sourceCode r"><code class="sourceCode r">flights_sample <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(carrier, dest) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">n =</span> <span class="kw">n</span>(), <span class="dt">mean_time =</span> <span class="kw">mean</span>(air_time, <span class="dt">na.rm =</span><span class="ot">TRUE</span>))</code></pre>
<pre><code># A tibble: 2 x 4
# Groups:   carrier [2]
  carrier dest      n mean_time
  &lt;chr&gt;   &lt;chr&gt; &lt;int&gt;     &lt;dbl&gt;
1 AS      SEA     714   325.618
2 HA      HNL     342   623.088</code></pre>
<p>It turns out that Alaska only flies to <code>SEA</code> (Seattle) from New York City (NYC) while Hawaiian only flies to <code>HNL</code> (Honolulu) from NYC. Given the clear difference in distance from New York City to Seattle versus New York City to Honolulu, it is not surprising that we observe such different air times in flights.</p>
<p>This is a clear example of not needing to do anything more than some simple exploratory data analysis with data visualization and descriptive statistics to get an appropriate inferential conclusion. This is why we highly recommend you perform an EDA of any sample data first before going to the trouble of running statistical methods like confidence intervals and hypothesis testing.</p>
<div class="learncheck">
<p>
<strong><em>Learning check</em></strong>
</p>
</div>
<p><strong>(LC10.16)</strong> Could we make the same type of immediate conclusion that SFO had a statistically greater <code>air_time</code> if, say, its corresponding standard deviation was 200 minutes? What about 100 minutes? Explain.</p>
<div class="learncheck">

</div>
</div>
<div id="problems-with-p-values" class="section level3">
<h3><span class="header-section-number">10.6.3</span> Problems with p-values</h3>
<p>On top of the many common misunderstandings about hypothesis testing and p-values we listed in Section <a href="10-hypothesis-testing.html#ht-interpretation">10.4</a>, another unfortunate consequence of the expanded use of p-values and hypothesis testing is a phenomenon known as “p-hacking.”  p-hacking is act of “cherry-picking” only results that are “statistically significant” while dismissing those that aren’t, even if at the expense of the scientific ideas. There are lots of articles and much has been written recently about misunderstandings and the problems with p-values that we encourage readers to check out and to ponder on. Here are just a few:</p>
<ol style="list-style-type: decimal">
<li><a href="https://en.wikipedia.org/wiki/Misunderstandings_of_p-values">Misunderstandings of <span class="math inline">\(p\)</span>-values</a></li>
<li><a href="https://www.vox.com/science-and-health/2017/7/31/16021654/p-values-statistical-significance-redefine-0005">What a nerdy debate about p-values shows about science - and how to fix it</a></li>
<li><a href="https://www.nature.com/news/statisticians-issue-warning-over-misuse-of-p-values-1.19503">Statisticians issue warning over misuse of <span class="math inline">\(P\)</span> values</a></li>
<li><a href="https://fivethirtyeight.com/features/you-cant-trust-what-you-read-about-nutrition/">You Can’t Trust What You Read About Nutrition</a></li>
<li><a href="http://www.fharrell.com/post/pval-litany/">A Litany of Problems with p-values</a></li>
</ol>
<p>In fact, the American Statistical Association put out a statement in 2016 titled <a href="https://www.amstat.org/asa/files/pdfs/P-ValueStatement.pdf">“The ASA Statement on p-Values: Context, Process, and Purpose”</a> with six principles underlying the proper use and interpretation of the p-value. The ASA released this guidance on p-values to improve the conduct and interpretation of quantitative science and inform the growing emphasis on reproducibility of science research.</p>
<p>We as authors much prefer the use of confidence intervals for statistical inference, as they are in our opinions much less prone to misinterpretations. However, many fields still use <span class="math inline">\(p\)</span>-values exclusively for statistical inference and thus we still included them in our text. We also encourage to learn more about “p-hacking” and its implication for science.</p>
</div>
<div id="additional-resources-7" class="section level3">
<h3><span class="header-section-number">10.6.4</span> Additional resources</h3>
<p>An R script file of all R code used in this chapter is available <a href="scripts/10-hypothesis-testing.R">here</a>.</p>
<p>If you want to more examples of the <code>infer</code> workflow to construct confidence intervals, we suggest you check out the <code>infer</code> package homepage, in particular, a series of example analyses available at <a href="https://infer.netlify.com/articles/" class="uri">https://infer.netlify.com/articles/</a>.</p>
</div>
<div id="whats-to-come-8" class="section level3">
<h3><span class="header-section-number">10.6.5</span> What’s to come</h3>
<p>We conclude by showing the <code>infer</code> pipeline diagram for hypothesis testing.</p>
<div class="figure" style="text-align: center"><span id="fig:infer-workflow-ht"></span>
<img src="images/flowcharts/infer/ht_diagram.png" alt="infer package workflow for hypothesis testing." width="100%" />
<p class="caption">
FIGURE 10.26: infer package workflow for hypothesis testing.
</p>
</div>
<p>In Chapter <a href="11-inference-for-regression.html#inference-for-regression">11</a>, we’ll revisit the regression models we studied in Chapters <a href="6-regression.html#regression">6</a> on basic regression and <a href="7-multiple-regression.html#multiple-regression">7</a>. Armed with our understanding of confidence intervals from Chapter <a href="9-confidence-intervals.html#confidence-intervals">9</a> and hypothesis tests from this chapter, we’ll study inference for regression. For example, recall Table <a href="6-regression.html#tab:regtable">6.2</a>, where we displayed the regression table corresponding to our regression model for teaching score as a function of beauty score.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Fit regression model:</span>
score_model &lt;-<span class="st"> </span><span class="kw">lm</span>(score <span class="op">~</span><span class="st"> </span>bty_avg, <span class="dt">data =</span> evals)
<span class="co"># Get regression table:</span>
<span class="kw">get_regression_table</span>(score_model)</code></pre>
<table class="table" style="font-size: 16px; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:regression-table-inference">TABLE 10.3: </span>Linear regression table
</caption>
<thead>
<tr>
<th style="text-align:left;">
term
</th>
<th style="text-align:right;">
estimate
</th>
<th style="text-align:right;">
std_error
</th>
<th style="text-align:right;">
statistic
</th>
<th style="text-align:right;">
p_value
</th>
<th style="text-align:right;">
lower_ci
</th>
<th style="text-align:right;">
upper_ci
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
intercept
</td>
<td style="text-align:right;">
3.880
</td>
<td style="text-align:right;">
0.076
</td>
<td style="text-align:right;">
50.96
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
3.731
</td>
<td style="text-align:right;">
4.030
</td>
</tr>
<tr>
<td style="text-align:left;">
bty_avg
</td>
<td style="text-align:right;">
0.067
</td>
<td style="text-align:right;">
0.016
</td>
<td style="text-align:right;">
4.09
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.035
</td>
<td style="text-align:right;">
0.099
</td>
</tr>
</tbody>
</table>
<p>We previously saw in Section <a href="6-regression.html#model1table">6.1.2</a> that the values in the <code>estimate</code> column are the fitted intercept <span class="math inline">\(b_0\)</span> and fitted slope for beauty score <span class="math inline">\(b_1\)</span>. In Chapter <a href="11-inference-for-regression.html#inference-for-regression">11</a>, we’ll unpack the remaining columns: <code>std_error</code> which is the standard error, <code>statistic</code> which is the observed <strong>standardized</strong> test statistic to compute the <code>p_value</code>, and the 95% confidence intervals as given by <code>lower_ci</code> and <code>upper_ci</code>.</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="9-confidence-intervals.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="11-inference-for-regression.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/moderndive/moderndive_book/edit/master/10-hypothesis-testing.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
